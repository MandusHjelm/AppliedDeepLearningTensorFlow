{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandus Hjelm:  Project Generative Adversarial Network, GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating network model using gpu 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utils import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input, Conv2DTranspose, ConvLSTM2D, TimeDistributed\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.layers import Input, merge, GaussianNoise\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, LeakyReLU, AveragePooling2D\n",
    "import keras.backend as kb\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModel():\n",
    "    def __init__(self, batch_size=32, inputShape=(128, 128, 3), dropout_prob=0.25): \n",
    "        self.batch_size = batch_size\n",
    "        self.inputShape = inputShape\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Calculate the shape of patches\n",
    "        patch = int(self.inputShape[0] / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "  \n",
    "        # Build and compile the discriminator\n",
    "        #optDisc = Adam(0.001, 0.5)\n",
    "        optGEN = Adam(0.001, 0.5)\n",
    "        optDisc = SGD(0.01)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optDisc,metrics=['accuracy'])\n",
    " \n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        first_frame = Input(shape=self.inputShape)\n",
    "        last_frame = Input(shape=self.inputShape)\n",
    "\n",
    "        # By conditioning on the first frame generate a fake version of the last frame\n",
    "        fake_last_frame = self.generator(first_frame)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # Discriminators determines validity of fake and condition first image pairs\n",
    "        valid = self.discriminator([fake_last_frame, first_frame])\n",
    "\n",
    "        self.combined = Model(inputs=[last_frame, first_frame], outputs=[valid, fake_last_frame])\n",
    "        self.combined.compile(loss=['mse', 'mae'], # mean squared and mean absolute errors\n",
    "                              loss_weights=[1, 30],\n",
    "                              optimizer=optGEN)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \n",
    "        inputs = Input(shape=self.inputShape)\n",
    "        momentumVar = 0.8\n",
    "        GenActivation ='sigmoid'\n",
    "        dropoutVar = 0.20 \n",
    "        # Number of filters in the first layer of Generator and Discriminator\n",
    "        filtersize = 64\n",
    "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "        \n",
    "        def down_sample(layer_input, filters, k_size=4, bn=True,dropoutBoool=False,\n",
    "                        kernel_initializer='he_normal',strides=2 ):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            convLayer = Conv2D(filters, kernel_size=k_size, strides=strides, padding='same', \n",
    "                               kernel_initializer=kernel_initializer)(layer_input)\n",
    "            if bn:\n",
    "                convLayer = BatchNormalization(momentum=momentumVar)(convLayer)\n",
    "            if dropoutBoool:\n",
    "                convLayer = Dropout(dropoutVar)(convLayer)\n",
    "            #convLayer = LeakyReLU(alpha=0.2)(convLayer)\n",
    "            convLayer = Activation('relu')(convLayer)\n",
    "            return convLayer\n",
    "        \n",
    "        def up_sample(layer_input, skip_input, filters, k_size=(5,5), dropoutBoool=False, bn=True):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            #uplayer = UpSampling2D(size=2)(layer_input)\n",
    "            #uplayer = Conv2D(filters, kernel_size=k_size, strides=1, padding='same', activation='relu')(uplayer)\n",
    "            uplayer= Conv2DTranspose(filters, kernel_size=k_size, strides=(2,2),activation=\"relu\", padding='same',\n",
    "                                     kernel_initializer='he_normal')(layer_input)\n",
    "            if bn:\n",
    "                uplayer = BatchNormalization(momentum=momentumVar)(uplayer)\n",
    "            if dropoutBoool:\n",
    "                upLayer = Dropout(dropoutVar)(uplayer)\n",
    "            uplayer = Concatenate()([uplayer, skip_input])\n",
    "            return uplayer\n",
    "\n",
    "                # Downsampling\n",
    "        start = Conv2D( filters =filtersize , kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                       kernel_initializer = init)(inputs)\n",
    "        d1 = down_sample(start, filtersize, bn=False, dropoutBoool=False)\n",
    "        d2 = down_sample(d1, filtersize*2,dropoutBoool=False)\n",
    "        #d21 = down_sample(d2, filtersize*2,strides=1)\n",
    "        d3 = down_sample(d2, filtersize*4,dropoutBoool=False)\n",
    "        #d4 = down_sample(d3, filtersize*8,dropoutBoool=False)\n",
    "        #d41= down_sample(d4, filtersize*2,strides=1)\n",
    "        #d5 = down_sample(d4, filtersize*8)\n",
    "        #d6 = down_sample(d5, filtersize*8,bn=True)\n",
    "        #d7 = down_sample(d6, filtersize*8)\n",
    "\n",
    "        # Upsampling\n",
    "        #u1 = up_sample(d7, d6, filtersize*8)\n",
    "        #u1= Dense(8,activation=\"relu\",input_dim=filtersize*8)(u1)\n",
    "        #u2 = up_sample(d6, d5, filtersize*8)\n",
    "        #u2= Dense(8,activation=\"relu\",input_dim=filtersize*8)(d5)\n",
    "        #u3 = up_sample(d5, d4, filtersize*8)\n",
    "        #u4 = up_sample(d4, d3, filtersize*4,dropoutBoool=True)\n",
    "        u5 = up_sample(d3, d2, filtersize*2,dropoutBoool=True)\n",
    "        u6 = up_sample(u5, d1, filtersize,dropoutBoool=True)\n",
    "        u7 = up_sample(u6,start,filtersize, dropoutBoool=False,bn=False)\n",
    "        \n",
    "        nbr_img_channels = self.inputShape[2]\n",
    "        print(nbr_img_channels)\n",
    "        outputs = Conv2D(nbr_img_channels, (1, 1), activation=GenActivation)(u7)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
    "        model.summary() \n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "  \n",
    "        last_img = Input(shape=self.inputShape)\n",
    "        first_img = Input(shape=self.inputShape)\n",
    "        \n",
    "        DiscAct =  'softmax'\n",
    "        momentumVariable2 = 0.8\n",
    "        alpha = 0.2\n",
    "        \n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        # Using LeakyRelu because Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "        # Gives that as a tips with the alpha = 0.2\n",
    "        combined_imgs = Concatenate(axis=-1)([last_img, first_img])\n",
    "        #combined_imgs = BatchNormalization(momentum=momentumVariable2)(combined_imgs)\n",
    "        d1 = Conv2D(32, (3, 3), strides=2, padding='same')(combined_imgs) \n",
    "        #d1 = Activation(discActivation)(d1) \n",
    "        #d1 = BatchNormalization(momentum=momentumVariable2)(d1)\n",
    "        d1 = LeakyReLU(alpha=alpha)(d1)\n",
    "        #d1 = GaussianNoise(stddev=0.2)(d1)\n",
    "        d1 = Dropout(0.2)(d1)\n",
    "        \n",
    "        d2 = Conv2D(64, (3, 3), strides=2, padding='same')(d1)\n",
    "        d2 = BatchNormalization(momentum=momentumVariable2)(d2)\n",
    "        #d2 = Activation('relu')(d2) \n",
    "        d2 = LeakyReLU(alpha=alpha)(d2)\n",
    "        #d2 = GaussianNoise(stddev=0.2)(d2)\n",
    "        d2 = Dropout(0.2)(d2)\n",
    "        \n",
    "        d3 = Conv2D(128, (3, 3), strides=2, padding='same')(d2)\n",
    "        d3 = BatchNormalization(momentum=momentumVariable2)(d3)\n",
    "        d3 = LeakyReLU(alpha=alpha)(d3)\n",
    "        #d3 = Activation('relu')(d3) \n",
    "        d3 = Conv2D(256, (3, 3), strides=1, padding='same')(d3)\n",
    "\n",
    "         \n",
    "        validity = Conv2D(3, (3, 3), strides=2, padding='same', activation=DiscAct)(d3) #Check the filtersize \n",
    "        #validity = LeakyReLU(alpha=alpha)(validity)\n",
    "        #validity = Activation('relu')(validity) \n",
    "        \n",
    "        model = Model([last_img, first_img], validity,name='Discriminator')\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 6)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 32)   1760        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 64, 64, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 64, 32)   0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 256)  295168      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 3)      6915        conv2d_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 396,963\n",
      "Trainable params: 396,579\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "3\n",
      "Model: \"Generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   65600       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  131200      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 256)  524544      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 128)  819328      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   409664      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 64) 204864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 3)  387         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,159,683\n",
      "Trainable params: 2,158,531\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)\n",
    "modelObj = GANModel(batch_size=cfg.BATCH_SIZE, inputShape=image_shape,\n",
    "                                 dropout_prob=cfg.DROPOUT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logg files sorting and path. \n",
    "start_time = datetime.now()\n",
    "# Adversarial loss ground truths\n",
    "valid = np.ones((cfg.BATCH_SIZE,) + modelObj.disc_patch)\n",
    "fake = np.zeros((cfg.BATCH_SIZE,) + modelObj.disc_patch)\n",
    "# log file\n",
    "output_log_dir = \"./logs/{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "if not os.path.exists(output_log_dir):\n",
    "    os.makedirs(output_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47978437\n",
      "[Epoch 0/50] [Batch 0/300] [D loss: 0.866832] [G loss: 16.108828] time: 0:00:03.560833\n",
      "0.5177483\n",
      "[Epoch 0/50] [Batch 1/300] [D loss: 0.844763] [G loss: 13.861998] time: 0:00:03.853658\n",
      "0.5815659\n",
      "[Epoch 0/50] [Batch 2/300] [D loss: 0.841443] [G loss: 11.668509] time: 0:00:04.141633\n",
      "0.666764\n",
      "[Epoch 0/50] [Batch 3/300] [D loss: 0.840337] [G loss: 9.306491] time: 0:00:04.521968\n",
      "0.76860636\n",
      "[Epoch 0/50] [Batch 4/300] [D loss: 0.839600] [G loss: 7.111308] time: 0:00:04.813100\n",
      "0.864391\n",
      "[Epoch 0/50] [Batch 5/300] [D loss: 0.838897] [G loss: 5.131775] time: 0:00:05.103691\n",
      "0.9244302\n",
      "[Epoch 0/50] [Batch 6/300] [D loss: 0.838120] [G loss: 3.554386] time: 0:00:05.397382\n",
      "0.9594822\n",
      "[Epoch 0/50] [Batch 7/300] [D loss: 0.837534] [G loss: 2.742751] time: 0:00:05.692774\n",
      "0.90263814\n",
      "[Epoch 0/50] [Batch 8/300] [D loss: 0.833901] [G loss: 2.509740] time: 0:00:05.990472\n",
      "0.97626376\n",
      "[Epoch 0/50] [Batch 9/300] [D loss: 0.836404] [G loss: 2.211891] time: 0:00:06.287573\n",
      "0.9644208\n",
      "[Epoch 0/50] [Batch 10/300] [D loss: 0.832491] [G loss: 2.240022] time: 0:00:06.564686\n",
      "0.9506703\n",
      "[Epoch 0/50] [Batch 11/300] [D loss: 0.831191] [G loss: 2.058432] time: 0:00:06.859383\n",
      "0.94996053\n",
      "[Epoch 0/50] [Batch 12/300] [D loss: 0.830210] [G loss: 2.149677] time: 0:00:07.184955\n",
      "0.940372\n",
      "[Epoch 0/50] [Batch 13/300] [D loss: 0.830313] [G loss: 1.712209] time: 0:00:07.527819\n",
      "0.90842414\n",
      "[Epoch 0/50] [Batch 14/300] [D loss: 0.829974] [G loss: 1.671969] time: 0:00:07.830083\n",
      "0.944458\n",
      "[Epoch 0/50] [Batch 15/300] [D loss: 0.827607] [G loss: 1.461590] time: 0:00:08.134650\n",
      "0.9421794\n",
      "[Epoch 0/50] [Batch 16/300] [D loss: 0.826991] [G loss: 1.324878] time: 0:00:08.444957\n",
      "0.94943994\n",
      "[Epoch 0/50] [Batch 17/300] [D loss: 0.826363] [G loss: 1.359532] time: 0:00:08.728019\n",
      "0.9213202\n",
      "[Epoch 0/50] [Batch 18/300] [D loss: 0.824449] [G loss: 1.339701] time: 0:00:09.012287\n",
      "0.93865776\n",
      "[Epoch 0/50] [Batch 19/300] [D loss: 0.824192] [G loss: 1.099556] time: 0:00:09.313840\n",
      "0.93527365\n",
      "[Epoch 0/50] [Batch 20/300] [D loss: 0.827726] [G loss: 1.085954] time: 0:00:09.612172\n",
      "0.9188564\n",
      "[Epoch 0/50] [Batch 21/300] [D loss: 0.824150] [G loss: 1.252199] time: 0:00:09.919457\n",
      "0.94238514\n",
      "[Epoch 0/50] [Batch 22/300] [D loss: 0.824931] [G loss: 1.171257] time: 0:00:10.227787\n",
      "0.9253805\n",
      "[Epoch 0/50] [Batch 23/300] [D loss: 0.822917] [G loss: 1.088596] time: 0:00:10.515462\n",
      "0.92760754\n",
      "[Epoch 0/50] [Batch 24/300] [D loss: 0.822503] [G loss: 1.025391] time: 0:00:10.810580\n",
      "0.88343304\n",
      "[Epoch 0/50] [Batch 25/300] [D loss: 0.819838] [G loss: 1.079266] time: 0:00:11.112906\n",
      "0.91456944\n",
      "[Epoch 0/50] [Batch 26/300] [D loss: 0.822827] [G loss: 1.285991] time: 0:00:11.403524\n",
      "0.95400566\n",
      "[Epoch 0/50] [Batch 27/300] [D loss: 0.819833] [G loss: 1.321762] time: 0:00:11.724573\n",
      "0.9516697\n",
      "[Epoch 0/50] [Batch 28/300] [D loss: 0.822301] [G loss: 1.182403] time: 0:00:12.014086\n",
      "0.8963178\n",
      "[Epoch 0/50] [Batch 29/300] [D loss: 0.820318] [G loss: 1.198009] time: 0:00:12.319118\n",
      "0.91585445\n",
      "[Epoch 0/50] [Batch 30/300] [D loss: 0.817842] [G loss: 1.067775] time: 0:00:12.605560\n",
      "0.9431359\n",
      "[Epoch 0/50] [Batch 31/300] [D loss: 0.819047] [G loss: 1.010729] time: 0:00:12.879266\n",
      "0.87035435\n",
      "[Epoch 0/50] [Batch 32/300] [D loss: 0.817935] [G loss: 1.261572] time: 0:00:13.193218\n",
      "0.90719754\n",
      "[Epoch 0/50] [Batch 33/300] [D loss: 0.817180] [G loss: 1.220779] time: 0:00:13.494303\n",
      "0.93119454\n",
      "[Epoch 0/50] [Batch 34/300] [D loss: 0.816981] [G loss: 1.010205] time: 0:00:13.794426\n",
      "0.88908464\n",
      "[Epoch 0/50] [Batch 35/300] [D loss: 0.817104] [G loss: 1.261231] time: 0:00:14.107288\n",
      "0.9136925\n",
      "[Epoch 0/50] [Batch 36/300] [D loss: 0.817037] [G loss: 1.247162] time: 0:00:14.398600\n",
      "0.881373\n",
      "[Epoch 0/50] [Batch 37/300] [D loss: 0.815371] [G loss: 1.051489] time: 0:00:14.697701\n",
      "0.9203277\n",
      "[Epoch 0/50] [Batch 38/300] [D loss: 0.815517] [G loss: 0.914485] time: 0:00:14.998401\n",
      "0.950748\n",
      "[Epoch 0/50] [Batch 39/300] [D loss: 0.813647] [G loss: 0.910328] time: 0:00:15.324418\n",
      "0.93977624\n",
      "[Epoch 0/50] [Batch 40/300] [D loss: 0.813136] [G loss: 1.168762] time: 0:00:15.611072\n",
      "0.8760736\n",
      "[Epoch 0/50] [Batch 41/300] [D loss: 0.815280] [G loss: 1.064513] time: 0:00:15.905753\n",
      "0.9451878\n",
      "[Epoch 0/50] [Batch 42/300] [D loss: 0.812538] [G loss: 1.136199] time: 0:00:16.214848\n",
      "0.90221316\n",
      "[Epoch 0/50] [Batch 43/300] [D loss: 0.811679] [G loss: 0.893954] time: 0:00:16.515878\n",
      "0.9114322\n",
      "[Epoch 0/50] [Batch 44/300] [D loss: 0.812135] [G loss: 1.066948] time: 0:00:16.804183\n",
      "0.9291718\n",
      "[Epoch 0/50] [Batch 45/300] [D loss: 0.810655] [G loss: 1.088137] time: 0:00:17.106530\n",
      "0.90709895\n",
      "[Epoch 0/50] [Batch 46/300] [D loss: 0.810684] [G loss: 1.008959] time: 0:00:17.419255\n",
      "0.86325866\n",
      "[Epoch 0/50] [Batch 47/300] [D loss: 0.811339] [G loss: 1.008918] time: 0:00:17.727172\n",
      "0.9021418\n",
      "[Epoch 0/50] [Batch 48/300] [D loss: 0.811061] [G loss: 0.974206] time: 0:00:18.038191\n",
      "0.8945418\n",
      "[Epoch 0/50] [Batch 49/300] [D loss: 0.807909] [G loss: 1.202265] time: 0:00:18.343044\n",
      "0.90305066\n",
      "[Epoch 0/50] [Batch 50/300] [D loss: 0.808688] [G loss: 1.061376] time: 0:00:18.648781\n",
      "0.9572985\n",
      "[Epoch 0/50] [Batch 51/300] [D loss: 0.811342] [G loss: 1.075063] time: 0:00:18.930956\n",
      "0.922179\n",
      "[Epoch 0/50] [Batch 52/300] [D loss: 0.808513] [G loss: 1.266279] time: 0:00:19.234510\n",
      "0.9386093\n",
      "[Epoch 0/50] [Batch 53/300] [D loss: 0.808560] [G loss: 1.099636] time: 0:00:19.535266\n",
      "0.9338936\n",
      "[Epoch 0/50] [Batch 54/300] [D loss: 0.808262] [G loss: 1.151710] time: 0:00:19.837651\n",
      "0.8391228\n",
      "[Epoch 0/50] [Batch 55/300] [D loss: 0.808541] [G loss: 0.952278] time: 0:00:20.109395\n",
      "0.95106536\n",
      "[Epoch 0/50] [Batch 56/300] [D loss: 0.806498] [G loss: 1.111580] time: 0:00:20.408090\n",
      "0.91465145\n",
      "[Epoch 0/50] [Batch 57/300] [D loss: 0.807249] [G loss: 1.102894] time: 0:00:20.686709\n",
      "0.8952121\n",
      "[Epoch 0/50] [Batch 58/300] [D loss: 0.806134] [G loss: 0.988138] time: 0:00:20.969107\n",
      "0.9018627\n",
      "[Epoch 0/50] [Batch 59/300] [D loss: 0.804782] [G loss: 1.270913] time: 0:00:21.261838\n",
      "0.9137602\n",
      "[Epoch 0/50] [Batch 60/300] [D loss: 0.805007] [G loss: 0.958950] time: 0:00:21.546510\n",
      "0.9405658\n",
      "[Epoch 0/50] [Batch 61/300] [D loss: 0.804471] [G loss: 1.124243] time: 0:00:21.838220\n",
      "0.8823561\n",
      "[Epoch 0/50] [Batch 62/300] [D loss: 0.804532] [G loss: 1.036808] time: 0:00:22.130568\n",
      "0.93200654\n",
      "[Epoch 0/50] [Batch 63/300] [D loss: 0.803582] [G loss: 1.159925] time: 0:00:22.435087\n",
      "0.9616859\n",
      "[Epoch 0/50] [Batch 64/300] [D loss: 0.803220] [G loss: 1.286529] time: 0:00:22.736592\n",
      "0.8964475\n",
      "[Epoch 0/50] [Batch 65/300] [D loss: 0.804142] [G loss: 1.277235] time: 0:00:23.011600\n",
      "0.9429161\n",
      "[Epoch 0/50] [Batch 66/300] [D loss: 0.802299] [G loss: 1.028611] time: 0:00:23.308432\n",
      "0.8567352\n",
      "[Epoch 0/50] [Batch 67/300] [D loss: 0.803757] [G loss: 1.396601] time: 0:00:23.594893\n",
      "0.90967387\n",
      "[Epoch 0/50] [Batch 68/300] [D loss: 0.804043] [G loss: 1.071885] time: 0:00:23.882437\n",
      "0.87660545\n",
      "[Epoch 0/50] [Batch 69/300] [D loss: 0.803054] [G loss: 0.942820] time: 0:00:24.188877\n",
      "0.9593094\n",
      "[Epoch 0/50] [Batch 70/300] [D loss: 0.802734] [G loss: 1.005149] time: 0:00:24.514945\n",
      "0.87692815\n",
      "[Epoch 0/50] [Batch 71/300] [D loss: 0.799522] [G loss: 1.111968] time: 0:00:24.829162\n",
      "0.87919694\n",
      "[Epoch 0/50] [Batch 72/300] [D loss: 0.802351] [G loss: 0.997625] time: 0:00:25.137019\n",
      "0.95338583\n",
      "[Epoch 0/50] [Batch 73/300] [D loss: 0.799723] [G loss: 1.204674] time: 0:00:25.443166\n",
      "0.93424153\n",
      "[Epoch 0/50] [Batch 74/300] [D loss: 0.800453] [G loss: 1.193904] time: 0:00:25.760994\n",
      "0.86974174\n",
      "[Epoch 0/50] [Batch 75/300] [D loss: 0.802055] [G loss: 0.924461] time: 0:00:26.054721\n",
      "0.9417891\n",
      "[Epoch 0/50] [Batch 76/300] [D loss: 0.800414] [G loss: 1.019671] time: 0:00:26.366250\n",
      "0.9029549\n",
      "[Epoch 0/50] [Batch 77/300] [D loss: 0.799651] [G loss: 1.303553] time: 0:00:26.655310\n",
      "0.92756146\n",
      "[Epoch 0/50] [Batch 78/300] [D loss: 0.799596] [G loss: 0.919701] time: 0:00:26.955722\n",
      "0.9063677\n",
      "[Epoch 0/50] [Batch 79/300] [D loss: 0.799769] [G loss: 0.816050] time: 0:00:27.246505\n",
      "0.92710185\n",
      "[Epoch 0/50] [Batch 80/300] [D loss: 0.797535] [G loss: 1.117812] time: 0:00:27.549990\n",
      "0.9759598\n",
      "[Epoch 0/50] [Batch 81/300] [D loss: 0.799297] [G loss: 0.961168] time: 0:00:27.862279\n",
      "0.91670007\n",
      "[Epoch 0/50] [Batch 82/300] [D loss: 0.798911] [G loss: 1.267756] time: 0:00:28.167057\n",
      "0.9172363\n",
      "[Epoch 0/50] [Batch 83/300] [D loss: 0.797217] [G loss: 0.857063] time: 0:00:28.456887\n",
      "0.94792485\n",
      "[Epoch 0/50] [Batch 84/300] [D loss: 0.796382] [G loss: 1.182596] time: 0:00:28.756311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88407326\n",
      "[Epoch 0/50] [Batch 85/300] [D loss: 0.796014] [G loss: 1.057059] time: 0:00:29.052655\n",
      "0.93613887\n",
      "[Epoch 0/50] [Batch 86/300] [D loss: 0.796921] [G loss: 1.000349] time: 0:00:29.349039\n",
      "0.8929605\n",
      "[Epoch 0/50] [Batch 87/300] [D loss: 0.796639] [G loss: 1.017675] time: 0:00:29.629500\n",
      "0.90490896\n",
      "[Epoch 0/50] [Batch 88/300] [D loss: 0.796414] [G loss: 1.311961] time: 0:00:29.935941\n",
      "0.9677345\n",
      "[Epoch 0/50] [Batch 89/300] [D loss: 0.798164] [G loss: 0.857916] time: 0:00:30.227882\n",
      "0.9015772\n",
      "[Epoch 0/50] [Batch 90/300] [D loss: 0.796320] [G loss: 1.084090] time: 0:00:30.518757\n",
      "0.8664417\n",
      "[Epoch 0/50] [Batch 91/300] [D loss: 0.796500] [G loss: 1.100862] time: 0:00:30.828607\n",
      "0.9294825\n",
      "[Epoch 0/50] [Batch 92/300] [D loss: 0.796401] [G loss: 0.972993] time: 0:00:31.128821\n",
      "0.90838426\n",
      "[Epoch 0/50] [Batch 93/300] [D loss: 0.795544] [G loss: 1.012389] time: 0:00:31.432808\n",
      "0.902431\n",
      "[Epoch 0/50] [Batch 94/300] [D loss: 0.795462] [G loss: 1.222495] time: 0:00:31.737167\n",
      "0.85234004\n",
      "[Epoch 0/50] [Batch 95/300] [D loss: 0.794284] [G loss: 1.042435] time: 0:00:32.033473\n",
      "0.88994604\n",
      "[Epoch 0/50] [Batch 96/300] [D loss: 0.794130] [G loss: 1.077562] time: 0:00:32.330449\n",
      "0.9366072\n",
      "[Epoch 0/50] [Batch 97/300] [D loss: 0.794981] [G loss: 1.040125] time: 0:00:32.640939\n",
      "0.9028527\n",
      "[Epoch 0/50] [Batch 98/300] [D loss: 0.793399] [G loss: 0.950020] time: 0:00:32.944904\n",
      "0.9247448\n",
      "[Epoch 0/50] [Batch 99/300] [D loss: 0.794767] [G loss: 1.121246] time: 0:00:33.248491\n",
      "0.93376833\n",
      "[Epoch 0/50] [Batch 100/300] [D loss: 0.794243] [G loss: 1.079060] time: 0:00:33.532051\n",
      "0.9497058\n",
      "[Epoch 0/50] [Batch 101/300] [D loss: 0.795165] [G loss: 1.140687] time: 0:00:33.836532\n",
      "0.9007895\n",
      "[Epoch 0/50] [Batch 102/300] [D loss: 0.792224] [G loss: 0.949354] time: 0:00:34.115285\n",
      "0.91166633\n",
      "[Epoch 0/50] [Batch 103/300] [D loss: 0.791950] [G loss: 1.038442] time: 0:00:34.418223\n",
      "0.90214616\n",
      "[Epoch 0/50] [Batch 104/300] [D loss: 0.792738] [G loss: 1.259066] time: 0:00:34.706596\n",
      "0.9542199\n",
      "[Epoch 0/50] [Batch 105/300] [D loss: 0.793076] [G loss: 1.072456] time: 0:00:34.988226\n",
      "0.83197266\n",
      "[Epoch 0/50] [Batch 106/300] [D loss: 0.791902] [G loss: 1.095080] time: 0:00:35.285206\n",
      "0.88570124\n",
      "[Epoch 0/50] [Batch 107/300] [D loss: 0.792358] [G loss: 1.081820] time: 0:00:35.588786\n",
      "0.9349527\n",
      "[Epoch 0/50] [Batch 108/300] [D loss: 0.793396] [G loss: 0.965346] time: 0:00:35.907183\n",
      "0.90627575\n",
      "[Epoch 0/50] [Batch 109/300] [D loss: 0.792930] [G loss: 1.019727] time: 0:00:36.191225\n",
      "0.91325814\n",
      "[Epoch 0/50] [Batch 110/300] [D loss: 0.792551] [G loss: 1.022362] time: 0:00:36.474988\n",
      "0.94691545\n",
      "[Epoch 0/50] [Batch 111/300] [D loss: 0.790871] [G loss: 0.855380] time: 0:00:36.766606\n",
      "0.88933533\n",
      "[Epoch 0/50] [Batch 112/300] [D loss: 0.791473] [G loss: 0.944322] time: 0:00:37.045315\n",
      "0.9155474\n",
      "[Epoch 0/50] [Batch 113/300] [D loss: 0.791558] [G loss: 0.874366] time: 0:00:37.344702\n",
      "0.8917065\n",
      "[Epoch 0/50] [Batch 114/300] [D loss: 0.791116] [G loss: 1.054019] time: 0:00:37.635860\n",
      "0.90340924\n",
      "[Epoch 0/50] [Batch 115/300] [D loss: 0.790317] [G loss: 1.194234] time: 0:00:37.945633\n",
      "0.90340215\n",
      "[Epoch 0/50] [Batch 116/300] [D loss: 0.790247] [G loss: 1.047744] time: 0:00:38.246860\n",
      "0.96948504\n",
      "[Epoch 0/50] [Batch 117/300] [D loss: 0.790205] [G loss: 0.863015] time: 0:00:38.543387\n",
      "0.9341157\n",
      "[Epoch 0/50] [Batch 118/300] [D loss: 0.790965] [G loss: 1.034414] time: 0:00:38.832858\n",
      "0.9267628\n",
      "[Epoch 0/50] [Batch 119/300] [D loss: 0.789412] [G loss: 0.905056] time: 0:00:39.132056\n",
      "0.9687538\n",
      "[Epoch 0/50] [Batch 120/300] [D loss: 0.790106] [G loss: 1.080601] time: 0:00:39.425251\n",
      "0.9372093\n",
      "[Epoch 0/50] [Batch 121/300] [D loss: 0.788496] [G loss: 1.017422] time: 0:00:39.736896\n",
      "0.9217458\n",
      "[Epoch 0/50] [Batch 122/300] [D loss: 0.788583] [G loss: 0.959121] time: 0:00:40.040080\n",
      "0.8893614\n",
      "[Epoch 0/50] [Batch 123/300] [D loss: 0.789057] [G loss: 1.151379] time: 0:00:40.349856\n",
      "0.9108936\n",
      "[Epoch 0/50] [Batch 124/300] [D loss: 0.787839] [G loss: 1.186389] time: 0:00:40.652862\n",
      "0.91453886\n",
      "[Epoch 0/50] [Batch 125/300] [D loss: 0.788896] [G loss: 1.111433] time: 0:00:40.939763\n",
      "0.8885047\n",
      "[Epoch 0/50] [Batch 126/300] [D loss: 0.788324] [G loss: 1.189851] time: 0:00:41.250540\n",
      "0.9151079\n",
      "[Epoch 0/50] [Batch 127/300] [D loss: 0.787228] [G loss: 1.191976] time: 0:00:41.552644\n",
      "0.91471094\n",
      "[Epoch 0/50] [Batch 128/300] [D loss: 0.787094] [G loss: 0.893910] time: 0:00:41.851921\n",
      "0.92896515\n",
      "[Epoch 0/50] [Batch 129/300] [D loss: 0.788311] [G loss: 0.931729] time: 0:00:42.141807\n",
      "0.9709217\n",
      "[Epoch 0/50] [Batch 130/300] [D loss: 0.788054] [G loss: 0.925813] time: 0:00:42.437423\n",
      "0.87314576\n",
      "[Epoch 0/50] [Batch 131/300] [D loss: 0.787687] [G loss: 1.113261] time: 0:00:42.732656\n",
      "0.9182537\n",
      "[Epoch 0/50] [Batch 132/300] [D loss: 0.787937] [G loss: 1.152092] time: 0:00:43.039116\n",
      "0.8884936\n",
      "[Epoch 0/50] [Batch 133/300] [D loss: 0.787400] [G loss: 1.050599] time: 0:00:43.325797\n",
      "0.8921098\n",
      "[Epoch 0/50] [Batch 134/300] [D loss: 0.786989] [G loss: 0.810292] time: 0:00:43.627379\n",
      "0.9420225\n",
      "[Epoch 0/50] [Batch 135/300] [D loss: 0.787069] [G loss: 1.115613] time: 0:00:43.905883\n",
      "0.84957236\n",
      "[Epoch 0/50] [Batch 136/300] [D loss: 0.786037] [G loss: 1.044443] time: 0:00:44.206537\n",
      "0.9371362\n",
      "[Epoch 0/50] [Batch 137/300] [D loss: 0.786160] [G loss: 1.083338] time: 0:00:44.513070\n",
      "0.9130347\n",
      "[Epoch 0/50] [Batch 138/300] [D loss: 0.786334] [G loss: 1.048404] time: 0:00:44.817513\n",
      "0.9111285\n",
      "[Epoch 0/50] [Batch 139/300] [D loss: 0.785590] [G loss: 0.975700] time: 0:00:45.118117\n",
      "0.91880053\n",
      "[Epoch 0/50] [Batch 140/300] [D loss: 0.785379] [G loss: 0.989354] time: 0:00:45.426286\n",
      "0.9091229\n",
      "[Epoch 0/50] [Batch 141/300] [D loss: 0.785357] [G loss: 0.969061] time: 0:00:45.714627\n",
      "0.9529164\n",
      "[Epoch 0/50] [Batch 142/300] [D loss: 0.786673] [G loss: 1.042399] time: 0:00:46.025566\n",
      "0.9073348\n",
      "[Epoch 0/50] [Batch 143/300] [D loss: 0.785916] [G loss: 1.063611] time: 0:00:46.322880\n",
      "0.97284627\n",
      "[Epoch 0/50] [Batch 144/300] [D loss: 0.785795] [G loss: 0.824795] time: 0:00:46.622558\n",
      "0.9104002\n",
      "[Epoch 0/50] [Batch 145/300] [D loss: 0.785412] [G loss: 0.900953] time: 0:00:46.904657\n",
      "0.94016296\n",
      "[Epoch 0/50] [Batch 146/300] [D loss: 0.786085] [G loss: 0.942262] time: 0:00:47.186160\n",
      "0.87408024\n",
      "[Epoch 0/50] [Batch 147/300] [D loss: 0.785044] [G loss: 0.990033] time: 0:00:47.478580\n",
      "0.93613774\n",
      "[Epoch 0/50] [Batch 148/300] [D loss: 0.785986] [G loss: 0.948648] time: 0:00:47.780148\n",
      "0.9109874\n",
      "[Epoch 0/50] [Batch 149/300] [D loss: 0.783501] [G loss: 0.904316] time: 0:00:48.065532\n",
      "0.88791484\n",
      "[Epoch 0/50] [Batch 150/300] [D loss: 0.783651] [G loss: 1.012562] time: 0:00:48.352395\n",
      "0.9111007\n",
      "[Epoch 0/50] [Batch 151/300] [D loss: 0.783179] [G loss: 0.979891] time: 0:00:48.651848\n",
      "0.8690066\n",
      "[Epoch 0/50] [Batch 152/300] [D loss: 0.783810] [G loss: 1.025047] time: 0:00:48.957952\n",
      "0.9313653\n",
      "[Epoch 0/50] [Batch 153/300] [D loss: 0.783859] [G loss: 1.244987] time: 0:00:49.239714\n",
      "0.9220671\n",
      "[Epoch 0/50] [Batch 154/300] [D loss: 0.784848] [G loss: 1.027020] time: 0:00:49.513681\n",
      "0.93208617\n",
      "[Epoch 0/50] [Batch 155/300] [D loss: 0.783226] [G loss: 0.940169] time: 0:00:49.823979\n",
      "0.9125976\n",
      "[Epoch 0/50] [Batch 156/300] [D loss: 0.783979] [G loss: 1.097354] time: 0:00:50.119217\n",
      "0.91265804\n",
      "[Epoch 0/50] [Batch 157/300] [D loss: 0.783479] [G loss: 0.970053] time: 0:00:50.424111\n",
      "0.9006946\n",
      "[Epoch 0/50] [Batch 158/300] [D loss: 0.783618] [G loss: 0.947656] time: 0:00:50.733859\n",
      "0.92181045\n",
      "[Epoch 0/50] [Batch 159/300] [D loss: 0.782599] [G loss: 1.042794] time: 0:00:50.999084\n",
      "0.924211\n",
      "[Epoch 0/50] [Batch 160/300] [D loss: 0.782697] [G loss: 1.146479] time: 0:00:51.271783\n",
      "0.8795381\n",
      "[Epoch 0/50] [Batch 161/300] [D loss: 0.782405] [G loss: 1.124311] time: 0:00:51.566697\n",
      "0.93335253\n",
      "[Epoch 0/50] [Batch 162/300] [D loss: 0.781644] [G loss: 0.869627] time: 0:00:51.876998\n",
      "0.94167274\n",
      "[Epoch 0/50] [Batch 163/300] [D loss: 0.782677] [G loss: 1.336455] time: 0:00:52.192688\n",
      "0.89517707\n",
      "[Epoch 0/50] [Batch 164/300] [D loss: 0.781572] [G loss: 1.065897] time: 0:00:52.485740\n",
      "0.9283776\n",
      "[Epoch 0/50] [Batch 165/300] [D loss: 0.781296] [G loss: 0.985526] time: 0:00:52.780367\n",
      "0.8737828\n",
      "[Epoch 0/50] [Batch 166/300] [D loss: 0.781569] [G loss: 0.874274] time: 0:00:53.073862\n",
      "0.9524822\n",
      "[Epoch 0/50] [Batch 167/300] [D loss: 0.781850] [G loss: 1.246427] time: 0:00:53.360074\n",
      "0.9131601\n",
      "[Epoch 0/50] [Batch 168/300] [D loss: 0.782812] [G loss: 1.003042] time: 0:00:53.685221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95235807\n",
      "[Epoch 0/50] [Batch 169/300] [D loss: 0.781108] [G loss: 0.991289] time: 0:00:53.990512\n",
      "0.9738993\n",
      "[Epoch 0/50] [Batch 170/300] [D loss: 0.780963] [G loss: 0.905828] time: 0:00:54.293508\n",
      "0.94636106\n",
      "[Epoch 0/50] [Batch 171/300] [D loss: 0.781551] [G loss: 1.089163] time: 0:00:54.581328\n",
      "0.9468611\n",
      "[Epoch 0/50] [Batch 172/300] [D loss: 0.780661] [G loss: 1.063327] time: 0:00:54.882946\n",
      "0.9333441\n",
      "[Epoch 0/50] [Batch 173/300] [D loss: 0.781308] [G loss: 1.104012] time: 0:00:55.175668\n",
      "0.91971976\n",
      "[Epoch 0/50] [Batch 174/300] [D loss: 0.780674] [G loss: 0.992024] time: 0:00:55.469991\n",
      "0.8596897\n",
      "[Epoch 0/50] [Batch 175/300] [D loss: 0.781997] [G loss: 0.982430] time: 0:00:55.782162\n",
      "0.9054653\n",
      "[Epoch 0/50] [Batch 176/300] [D loss: 0.780518] [G loss: 0.922578] time: 0:00:56.089952\n",
      "0.9316163\n",
      "[Epoch 0/50] [Batch 177/300] [D loss: 0.780859] [G loss: 1.107644] time: 0:00:56.391856\n",
      "0.9167059\n",
      "[Epoch 0/50] [Batch 178/300] [D loss: 0.780630] [G loss: 0.919483] time: 0:00:56.702087\n",
      "0.9162192\n",
      "[Epoch 0/50] [Batch 179/300] [D loss: 0.781301] [G loss: 1.034135] time: 0:00:56.998944\n",
      "0.9120093\n",
      "[Epoch 0/50] [Batch 180/300] [D loss: 0.781157] [G loss: 0.910905] time: 0:00:57.309130\n",
      "0.9369707\n",
      "[Epoch 0/50] [Batch 181/300] [D loss: 0.780475] [G loss: 1.146886] time: 0:00:57.607042\n",
      "0.9236757\n",
      "[Epoch 0/50] [Batch 182/300] [D loss: 0.779903] [G loss: 0.978334] time: 0:00:57.913320\n",
      "0.90100545\n",
      "[Epoch 0/50] [Batch 183/300] [D loss: 0.780572] [G loss: 0.912479] time: 0:00:58.212277\n",
      "0.97228545\n",
      "[Epoch 0/50] [Batch 184/300] [D loss: 0.780388] [G loss: 1.014860] time: 0:00:58.511375\n",
      "0.8798167\n",
      "[Epoch 0/50] [Batch 185/300] [D loss: 0.779800] [G loss: 0.766311] time: 0:00:58.803686\n",
      "0.9344037\n",
      "[Epoch 0/50] [Batch 186/300] [D loss: 0.780606] [G loss: 1.023632] time: 0:00:59.102691\n",
      "0.8862982\n",
      "[Epoch 0/50] [Batch 187/300] [D loss: 0.780549] [G loss: 1.154395] time: 0:00:59.413617\n",
      "0.92031145\n",
      "[Epoch 0/50] [Batch 188/300] [D loss: 0.779067] [G loss: 1.094935] time: 0:00:59.716348\n",
      "0.90384126\n",
      "[Epoch 0/50] [Batch 189/300] [D loss: 0.780315] [G loss: 1.026049] time: 0:01:00.021349\n",
      "0.91975087\n",
      "[Epoch 0/50] [Batch 190/300] [D loss: 0.779793] [G loss: 1.038117] time: 0:01:00.328027\n",
      "0.88430375\n",
      "[Epoch 0/50] [Batch 191/300] [D loss: 0.779849] [G loss: 0.872605] time: 0:01:00.613018\n",
      "0.89530754\n",
      "[Epoch 0/50] [Batch 192/300] [D loss: 0.778555] [G loss: 0.932370] time: 0:01:00.913355\n",
      "0.9327779\n",
      "[Epoch 0/50] [Batch 193/300] [D loss: 0.778936] [G loss: 0.944132] time: 0:01:01.216520\n",
      "0.92141765\n",
      "[Epoch 0/50] [Batch 194/300] [D loss: 0.777528] [G loss: 0.952789] time: 0:01:01.521148\n",
      "0.85373193\n",
      "[Epoch 0/50] [Batch 195/300] [D loss: 0.779236] [G loss: 1.113933] time: 0:01:01.822388\n",
      "0.9177253\n",
      "[Epoch 0/50] [Batch 196/300] [D loss: 0.779365] [G loss: 1.030709] time: 0:01:02.149650\n",
      "0.9385805\n",
      "[Epoch 0/50] [Batch 197/300] [D loss: 0.778161] [G loss: 1.027798] time: 0:01:02.466521\n",
      "0.8937657\n",
      "[Epoch 0/50] [Batch 198/300] [D loss: 0.778021] [G loss: 1.259357] time: 0:01:02.783792\n",
      "0.9048458\n",
      "[Epoch 0/50] [Batch 199/300] [D loss: 0.778552] [G loss: 0.943299] time: 0:01:03.080966\n",
      "0.9301719\n",
      "[Epoch 0/50] [Batch 200/300] [D loss: 0.777691] [G loss: 1.000659] time: 0:01:03.383607\n",
      "0.9024119\n",
      "[Epoch 0/50] [Batch 201/300] [D loss: 0.778385] [G loss: 1.131071] time: 0:01:03.673438\n",
      "0.9536976\n",
      "[Epoch 0/50] [Batch 202/300] [D loss: 0.777383] [G loss: 0.929150] time: 0:01:03.999720\n",
      "0.8923719\n",
      "[Epoch 0/50] [Batch 203/300] [D loss: 0.777518] [G loss: 0.941726] time: 0:01:04.311430\n",
      "0.92311996\n",
      "[Epoch 0/50] [Batch 204/300] [D loss: 0.778096] [G loss: 1.049182] time: 0:01:04.616872\n",
      "0.94082135\n",
      "[Epoch 0/50] [Batch 205/300] [D loss: 0.777058] [G loss: 0.957182] time: 0:01:04.917826\n",
      "0.92204267\n",
      "[Epoch 0/50] [Batch 206/300] [D loss: 0.777675] [G loss: 1.002550] time: 0:01:05.227384\n",
      "0.9108727\n",
      "[Epoch 0/50] [Batch 207/300] [D loss: 0.776599] [G loss: 1.060072] time: 0:01:05.528676\n",
      "0.9460044\n",
      "[Epoch 0/50] [Batch 208/300] [D loss: 0.776865] [G loss: 0.901332] time: 0:01:05.845673\n",
      "0.9136459\n",
      "[Epoch 0/50] [Batch 209/300] [D loss: 0.775466] [G loss: 1.053613] time: 0:01:06.154013\n",
      "0.86615974\n",
      "[Epoch 0/50] [Batch 210/300] [D loss: 0.777503] [G loss: 0.862324] time: 0:01:06.456948\n",
      "0.9047008\n",
      "[Epoch 0/50] [Batch 211/300] [D loss: 0.777546] [G loss: 1.041831] time: 0:01:06.751587\n",
      "0.8704743\n",
      "[Epoch 0/50] [Batch 212/300] [D loss: 0.777353] [G loss: 0.983335] time: 0:01:07.051197\n",
      "0.89523387\n",
      "[Epoch 0/50] [Batch 213/300] [D loss: 0.777269] [G loss: 1.057862] time: 0:01:07.355787\n",
      "0.8837032\n",
      "[Epoch 0/50] [Batch 214/300] [D loss: 0.777267] [G loss: 0.804731] time: 0:01:07.651521\n",
      "0.9000856\n",
      "[Epoch 0/50] [Batch 215/300] [D loss: 0.776494] [G loss: 1.043381] time: 0:01:07.945935\n",
      "0.92055863\n",
      "[Epoch 0/50] [Batch 216/300] [D loss: 0.776004] [G loss: 0.916241] time: 0:01:08.256324\n",
      "0.94592077\n",
      "[Epoch 0/50] [Batch 217/300] [D loss: 0.777068] [G loss: 0.997075] time: 0:01:08.568209\n",
      "0.9419921\n",
      "[Epoch 0/50] [Batch 218/300] [D loss: 0.776822] [G loss: 1.057889] time: 0:01:08.862702\n",
      "0.91436046\n",
      "[Epoch 0/50] [Batch 219/300] [D loss: 0.776357] [G loss: 1.118773] time: 0:01:09.168558\n",
      "0.9121626\n",
      "[Epoch 0/50] [Batch 220/300] [D loss: 0.777594] [G loss: 0.880565] time: 0:01:09.469533\n",
      "0.8728872\n",
      "[Epoch 0/50] [Batch 221/300] [D loss: 0.775563] [G loss: 1.149355] time: 0:01:09.760212\n",
      "0.9364841\n",
      "[Epoch 0/50] [Batch 222/300] [D loss: 0.776595] [G loss: 0.954411] time: 0:01:10.060786\n",
      "0.91822743\n",
      "[Epoch 0/50] [Batch 223/300] [D loss: 0.776308] [G loss: 1.125980] time: 0:01:10.368735\n",
      "0.9748125\n",
      "[Epoch 0/50] [Batch 224/300] [D loss: 0.775692] [G loss: 1.074571] time: 0:01:10.692607\n",
      "0.8846236\n",
      "[Epoch 0/50] [Batch 225/300] [D loss: 0.775641] [G loss: 1.115923] time: 0:01:10.997381\n",
      "0.87819785\n",
      "[Epoch 0/50] [Batch 226/300] [D loss: 0.776211] [G loss: 0.861932] time: 0:01:11.285360\n",
      "0.9048414\n",
      "[Epoch 0/50] [Batch 227/300] [D loss: 0.776655] [G loss: 0.943610] time: 0:01:11.591560\n",
      "0.8919619\n",
      "[Epoch 0/50] [Batch 228/300] [D loss: 0.775435] [G loss: 0.995600] time: 0:01:11.894582\n",
      "0.92315626\n",
      "[Epoch 0/50] [Batch 229/300] [D loss: 0.775106] [G loss: 1.047827] time: 0:01:12.212415\n",
      "0.9071991\n",
      "[Epoch 0/50] [Batch 230/300] [D loss: 0.775493] [G loss: 1.016853] time: 0:01:12.519949\n",
      "0.9444728\n",
      "[Epoch 0/50] [Batch 231/300] [D loss: 0.775059] [G loss: 1.170789] time: 0:01:12.817999\n",
      "0.8868039\n",
      "[Epoch 0/50] [Batch 232/300] [D loss: 0.774817] [G loss: 0.932882] time: 0:01:13.120431\n",
      "0.9234705\n",
      "[Epoch 0/50] [Batch 233/300] [D loss: 0.775060] [G loss: 0.916348] time: 0:01:13.426313\n",
      "0.86019295\n",
      "[Epoch 0/50] [Batch 234/300] [D loss: 0.775783] [G loss: 0.992607] time: 0:01:13.701235\n",
      "0.92417955\n",
      "[Epoch 0/50] [Batch 235/300] [D loss: 0.774968] [G loss: 1.113281] time: 0:01:13.994048\n",
      "0.9040546\n",
      "[Epoch 0/50] [Batch 236/300] [D loss: 0.775076] [G loss: 0.909980] time: 0:01:14.274212\n",
      "0.9351031\n",
      "[Epoch 0/50] [Batch 237/300] [D loss: 0.774628] [G loss: 0.917345] time: 0:01:14.585796\n",
      "0.95351523\n",
      "[Epoch 0/50] [Batch 238/300] [D loss: 0.775283] [G loss: 0.932583] time: 0:01:14.891720\n",
      "0.89995813\n",
      "[Epoch 0/50] [Batch 239/300] [D loss: 0.774337] [G loss: 1.029748] time: 0:01:15.187360\n",
      "0.8453638\n",
      "[Epoch 0/50] [Batch 240/300] [D loss: 0.774257] [G loss: 0.910935] time: 0:01:15.482715\n",
      "0.9362371\n",
      "[Epoch 0/50] [Batch 241/300] [D loss: 0.773567] [G loss: 0.940429] time: 0:01:15.768436\n",
      "0.9381859\n",
      "[Epoch 0/50] [Batch 242/300] [D loss: 0.773974] [G loss: 0.972325] time: 0:01:16.075917\n",
      "0.9085546\n",
      "[Epoch 0/50] [Batch 243/300] [D loss: 0.774727] [G loss: 0.942772] time: 0:01:16.380268\n",
      "0.8923201\n",
      "[Epoch 0/50] [Batch 244/300] [D loss: 0.774126] [G loss: 0.980081] time: 0:01:16.706325\n",
      "0.920181\n",
      "[Epoch 0/50] [Batch 245/300] [D loss: 0.773992] [G loss: 0.993537] time: 0:01:17.017825\n",
      "0.9155829\n",
      "[Epoch 0/50] [Batch 246/300] [D loss: 0.774596] [G loss: 1.001665] time: 0:01:17.325196\n",
      "0.90756387\n",
      "[Epoch 0/50] [Batch 247/300] [D loss: 0.774702] [G loss: 1.228996] time: 0:01:17.630062\n",
      "0.8954957\n",
      "[Epoch 0/50] [Batch 248/300] [D loss: 0.773094] [G loss: 1.102716] time: 0:01:17.929254\n",
      "0.86944014\n",
      "[Epoch 0/50] [Batch 249/300] [D loss: 0.773935] [G loss: 1.197272] time: 0:01:18.242617\n",
      "0.91007894\n",
      "[Epoch 0/50] [Batch 250/300] [D loss: 0.773491] [G loss: 0.957610] time: 0:01:18.541940\n",
      "0.9274755\n",
      "[Epoch 0/50] [Batch 251/300] [D loss: 0.773917] [G loss: 1.104184] time: 0:01:18.859188\n",
      "0.89379865\n",
      "[Epoch 0/50] [Batch 252/300] [D loss: 0.773317] [G loss: 1.074931] time: 0:01:19.165518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91793066\n",
      "[Epoch 0/50] [Batch 253/300] [D loss: 0.773959] [G loss: 0.904831] time: 0:01:19.466883\n",
      "0.9400804\n",
      "[Epoch 0/50] [Batch 254/300] [D loss: 0.773638] [G loss: 0.940125] time: 0:01:19.769487\n",
      "0.9718287\n",
      "[Epoch 0/50] [Batch 255/300] [D loss: 0.773493] [G loss: 1.043488] time: 0:01:20.065339\n",
      "0.88242656\n",
      "[Epoch 0/50] [Batch 256/300] [D loss: 0.773693] [G loss: 0.978030] time: 0:01:20.357640\n",
      "0.9358561\n",
      "[Epoch 0/50] [Batch 257/300] [D loss: 0.773670] [G loss: 0.957147] time: 0:01:20.671467\n",
      "0.93167764\n",
      "[Epoch 0/50] [Batch 258/300] [D loss: 0.773760] [G loss: 1.018505] time: 0:01:20.978628\n",
      "0.89690906\n",
      "[Epoch 0/50] [Batch 259/300] [D loss: 0.773411] [G loss: 0.963404] time: 0:01:21.282642\n",
      "0.9106695\n",
      "[Epoch 0/50] [Batch 260/300] [D loss: 0.773105] [G loss: 0.841752] time: 0:01:21.568517\n",
      "0.9127938\n",
      "[Epoch 0/50] [Batch 261/300] [D loss: 0.773310] [G loss: 1.097353] time: 0:01:21.857156\n",
      "0.94658995\n",
      "[Epoch 0/50] [Batch 262/300] [D loss: 0.773114] [G loss: 0.963495] time: 0:01:22.156459\n",
      "0.8626848\n",
      "[Epoch 0/50] [Batch 263/300] [D loss: 0.773407] [G loss: 1.130444] time: 0:01:22.457211\n",
      "0.91442007\n",
      "[Epoch 0/50] [Batch 264/300] [D loss: 0.773208] [G loss: 1.093158] time: 0:01:22.770307\n",
      "0.9462817\n",
      "[Epoch 0/50] [Batch 265/300] [D loss: 0.772054] [G loss: 1.149295] time: 0:01:23.056233\n",
      "0.9438572\n",
      "[Epoch 0/50] [Batch 266/300] [D loss: 0.772027] [G loss: 1.074592] time: 0:01:23.348129\n",
      "0.968293\n",
      "[Epoch 0/50] [Batch 267/300] [D loss: 0.772205] [G loss: 1.171398] time: 0:01:23.648352\n",
      "0.9043431\n",
      "[Epoch 0/50] [Batch 268/300] [D loss: 0.772810] [G loss: 0.913954] time: 0:01:23.932024\n",
      "0.91238743\n",
      "[Epoch 0/50] [Batch 269/300] [D loss: 0.772474] [G loss: 0.957780] time: 0:01:24.241324\n",
      "0.92890143\n",
      "[Epoch 0/50] [Batch 270/300] [D loss: 0.772462] [G loss: 1.008169] time: 0:01:24.535366\n",
      "0.95146114\n",
      "[Epoch 0/50] [Batch 271/300] [D loss: 0.772382] [G loss: 1.033300] time: 0:01:24.833859\n",
      "0.90668505\n",
      "[Epoch 0/50] [Batch 272/300] [D loss: 0.772547] [G loss: 0.879421] time: 0:01:25.126173\n",
      "0.89016515\n",
      "[Epoch 0/50] [Batch 273/300] [D loss: 0.772376] [G loss: 1.221320] time: 0:01:25.417656\n",
      "0.9213753\n",
      "[Epoch 0/50] [Batch 274/300] [D loss: 0.772144] [G loss: 0.953431] time: 0:01:25.717829\n",
      "0.95327264\n",
      "[Epoch 0/50] [Batch 275/300] [D loss: 0.772179] [G loss: 0.862208] time: 0:01:26.025968\n",
      "0.9124364\n",
      "[Epoch 0/50] [Batch 276/300] [D loss: 0.772002] [G loss: 0.852739] time: 0:01:26.325833\n",
      "0.91697836\n",
      "[Epoch 0/50] [Batch 277/300] [D loss: 0.771923] [G loss: 0.846931] time: 0:01:26.630283\n",
      "0.9401886\n",
      "[Epoch 0/50] [Batch 278/300] [D loss: 0.772588] [G loss: 1.107468] time: 0:01:26.925748\n",
      "0.9444987\n",
      "[Epoch 0/50] [Batch 279/300] [D loss: 0.772317] [G loss: 0.977581] time: 0:01:27.203059\n",
      "0.9319032\n",
      "[Epoch 0/50] [Batch 280/300] [D loss: 0.771502] [G loss: 1.006278] time: 0:01:27.489286\n",
      "0.9463301\n",
      "[Epoch 0/50] [Batch 281/300] [D loss: 0.771338] [G loss: 1.101603] time: 0:01:27.790302\n",
      "0.9027874\n",
      "[Epoch 0/50] [Batch 282/300] [D loss: 0.771694] [G loss: 1.112853] time: 0:01:28.099450\n",
      "0.88748246\n",
      "[Epoch 0/50] [Batch 283/300] [D loss: 0.771970] [G loss: 1.200912] time: 0:01:28.421777\n",
      "0.90628844\n",
      "[Epoch 0/50] [Batch 284/300] [D loss: 0.771352] [G loss: 0.948412] time: 0:01:28.720697\n",
      "0.86348516\n",
      "[Epoch 0/50] [Batch 285/300] [D loss: 0.771806] [G loss: 0.926497] time: 0:01:29.026166\n",
      "0.88585156\n",
      "[Epoch 0/50] [Batch 286/300] [D loss: 0.771253] [G loss: 1.086785] time: 0:01:29.330035\n",
      "0.9197507\n",
      "[Epoch 0/50] [Batch 287/300] [D loss: 0.771619] [G loss: 0.947294] time: 0:01:29.627226\n",
      "0.8909977\n",
      "[Epoch 0/50] [Batch 288/300] [D loss: 0.771910] [G loss: 0.946732] time: 0:01:29.932357\n",
      "0.9266977\n",
      "[Epoch 0/50] [Batch 289/300] [D loss: 0.771435] [G loss: 0.959140] time: 0:01:30.223899\n",
      "0.9472556\n",
      "[Epoch 0/50] [Batch 290/300] [D loss: 0.771026] [G loss: 0.889258] time: 0:01:30.517739\n",
      "0.94052106\n",
      "[Epoch 0/50] [Batch 291/300] [D loss: 0.770968] [G loss: 0.857853] time: 0:01:30.819499\n",
      "0.90902966\n",
      "[Epoch 0/50] [Batch 292/300] [D loss: 0.771040] [G loss: 0.981532] time: 0:01:31.116157\n",
      "0.9129837\n",
      "[Epoch 0/50] [Batch 293/300] [D loss: 0.771149] [G loss: 0.902667] time: 0:01:31.436987\n",
      "0.93868494\n",
      "[Epoch 0/50] [Batch 294/300] [D loss: 0.770928] [G loss: 0.985163] time: 0:01:31.745739\n",
      "0.9396543\n",
      "[Epoch 0/50] [Batch 295/300] [D loss: 0.770817] [G loss: 0.852122] time: 0:01:32.045571\n",
      "0.84062886\n",
      "[Epoch 0/50] [Batch 296/300] [D loss: 0.770267] [G loss: 1.153094] time: 0:01:32.339231\n",
      "0.8981603\n",
      "[Epoch 0/50] [Batch 297/300] [D loss: 0.770821] [G loss: 0.927069] time: 0:01:32.639177\n",
      "0.95707965\n",
      "[Epoch 0/50] [Batch 298/300] [D loss: 0.771213] [G loss: 1.069801] time: 0:01:32.928477\n",
      "0.9078935\n",
      "[Epoch 0/50] [Batch 299/300] [D loss: 0.770703] [G loss: 1.086598] time: 0:01:33.244668\n",
      "0.9354069\n",
      "[Epoch 1/50] [Batch 1/300] [D loss: 0.770690] [G loss: 0.994266] time: 0:01:33.553574\n",
      "0.90474874\n",
      "[Epoch 1/50] [Batch 2/300] [D loss: 0.770862] [G loss: 1.018396] time: 0:01:33.866141\n",
      "0.85248023\n",
      "[Epoch 1/50] [Batch 3/300] [D loss: 0.771059] [G loss: 1.021695] time: 0:01:34.189629\n",
      "0.9206876\n",
      "[Epoch 1/50] [Batch 4/300] [D loss: 0.770594] [G loss: 0.976997] time: 0:01:34.506697\n",
      "0.8763171\n",
      "[Epoch 1/50] [Batch 5/300] [D loss: 0.770061] [G loss: 0.880118] time: 0:01:34.798617\n",
      "0.88931847\n",
      "[Epoch 1/50] [Batch 6/300] [D loss: 0.770950] [G loss: 0.926016] time: 0:01:35.096502\n",
      "0.9743729\n",
      "[Epoch 1/50] [Batch 7/300] [D loss: 0.770654] [G loss: 1.005683] time: 0:01:35.384323\n",
      "0.91925496\n",
      "[Epoch 1/50] [Batch 8/300] [D loss: 0.770158] [G loss: 0.991869] time: 0:01:35.678738\n",
      "0.90099317\n",
      "[Epoch 1/50] [Batch 9/300] [D loss: 0.770017] [G loss: 1.170323] time: 0:01:35.982998\n",
      "0.95226127\n",
      "[Epoch 1/50] [Batch 10/300] [D loss: 0.770517] [G loss: 1.090093] time: 0:01:36.288923\n",
      "0.8817399\n",
      "[Epoch 1/50] [Batch 11/300] [D loss: 0.770066] [G loss: 0.862374] time: 0:01:36.597534\n",
      "0.95632595\n",
      "[Epoch 1/50] [Batch 12/300] [D loss: 0.770205] [G loss: 1.040909] time: 0:01:36.919700\n",
      "0.9089888\n",
      "[Epoch 1/50] [Batch 13/300] [D loss: 0.769872] [G loss: 0.998800] time: 0:01:37.239788\n",
      "0.9115439\n",
      "[Epoch 1/50] [Batch 14/300] [D loss: 0.769709] [G loss: 1.061900] time: 0:01:37.528379\n",
      "0.9134259\n",
      "[Epoch 1/50] [Batch 15/300] [D loss: 0.770506] [G loss: 0.866702] time: 0:01:37.833975\n",
      "0.8716097\n",
      "[Epoch 1/50] [Batch 16/300] [D loss: 0.770501] [G loss: 1.045590] time: 0:01:38.130829\n",
      "0.94994146\n",
      "[Epoch 1/50] [Batch 17/300] [D loss: 0.769709] [G loss: 1.021862] time: 0:01:38.442585\n",
      "0.9191515\n",
      "[Epoch 1/50] [Batch 18/300] [D loss: 0.769775] [G loss: 0.932320] time: 0:01:38.748641\n",
      "0.9511273\n",
      "[Epoch 1/50] [Batch 19/300] [D loss: 0.769924] [G loss: 1.045496] time: 0:01:39.037205\n",
      "0.86259747\n",
      "[Epoch 1/50] [Batch 20/300] [D loss: 0.769322] [G loss: 0.892479] time: 0:01:39.339750\n",
      "0.89183456\n",
      "[Epoch 1/50] [Batch 21/300] [D loss: 0.769324] [G loss: 0.979206] time: 0:01:39.642789\n",
      "0.8927929\n",
      "[Epoch 1/50] [Batch 22/300] [D loss: 0.769225] [G loss: 0.838385] time: 0:01:39.929895\n",
      "0.9176976\n",
      "[Epoch 1/50] [Batch 23/300] [D loss: 0.769674] [G loss: 0.930017] time: 0:01:40.224204\n",
      "0.90920275\n",
      "[Epoch 1/50] [Batch 24/300] [D loss: 0.770158] [G loss: 0.910411] time: 0:01:40.524093\n",
      "0.90901524\n",
      "[Epoch 1/50] [Batch 25/300] [D loss: 0.770131] [G loss: 0.976442] time: 0:01:40.809982\n",
      "0.86556864\n",
      "[Epoch 1/50] [Batch 26/300] [D loss: 0.769541] [G loss: 0.944228] time: 0:01:41.114628\n",
      "0.91554886\n",
      "[Epoch 1/50] [Batch 27/300] [D loss: 0.768998] [G loss: 0.899749] time: 0:01:41.426562\n",
      "0.9214807\n",
      "[Epoch 1/50] [Batch 28/300] [D loss: 0.769570] [G loss: 0.974620] time: 0:01:41.728630\n",
      "0.9469401\n",
      "[Epoch 1/50] [Batch 29/300] [D loss: 0.769285] [G loss: 1.115639] time: 0:01:42.034244\n",
      "0.9331396\n",
      "[Epoch 1/50] [Batch 30/300] [D loss: 0.769022] [G loss: 1.015216] time: 0:01:42.343973\n",
      "0.8831525\n",
      "[Epoch 1/50] [Batch 31/300] [D loss: 0.769206] [G loss: 0.811607] time: 0:01:42.651499\n",
      "0.8786087\n",
      "[Epoch 1/50] [Batch 32/300] [D loss: 0.769313] [G loss: 0.899236] time: 0:01:42.949123\n",
      "0.9287767\n",
      "[Epoch 1/50] [Batch 33/300] [D loss: 0.768829] [G loss: 1.021516] time: 0:01:43.240118\n",
      "0.9095168\n",
      "[Epoch 1/50] [Batch 34/300] [D loss: 0.769339] [G loss: 0.932094] time: 0:01:43.535468\n",
      "0.8558503\n",
      "[Epoch 1/50] [Batch 35/300] [D loss: 0.768736] [G loss: 0.794749] time: 0:01:43.991105\n",
      "0.91249776\n",
      "[Epoch 1/50] [Batch 36/300] [D loss: 0.769056] [G loss: 1.010625] time: 0:01:44.294169\n",
      "0.93855095\n",
      "[Epoch 1/50] [Batch 37/300] [D loss: 0.769761] [G loss: 0.845133] time: 0:01:44.597214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94537634\n",
      "[Epoch 1/50] [Batch 38/300] [D loss: 0.768685] [G loss: 1.110883] time: 0:01:44.894919\n",
      "0.9417377\n",
      "[Epoch 1/50] [Batch 39/300] [D loss: 0.768699] [G loss: 0.889024] time: 0:01:45.202058\n",
      "0.92726344\n",
      "[Epoch 1/50] [Batch 40/300] [D loss: 0.768890] [G loss: 0.992675] time: 0:01:45.492614\n",
      "0.9068637\n",
      "[Epoch 1/50] [Batch 41/300] [D loss: 0.768100] [G loss: 0.941549] time: 0:01:45.798373\n",
      "0.86697274\n",
      "[Epoch 1/50] [Batch 42/300] [D loss: 0.768235] [G loss: 1.068254] time: 0:01:46.095087\n",
      "0.9009803\n",
      "[Epoch 1/50] [Batch 43/300] [D loss: 0.768447] [G loss: 0.979862] time: 0:01:46.383846\n",
      "0.91782045\n",
      "[Epoch 1/50] [Batch 44/300] [D loss: 0.768874] [G loss: 1.008081] time: 0:01:46.687774\n",
      "0.8928564\n",
      "[Epoch 1/50] [Batch 45/300] [D loss: 0.768221] [G loss: 0.876636] time: 0:01:46.965060\n",
      "0.92925143\n",
      "[Epoch 1/50] [Batch 46/300] [D loss: 0.768554] [G loss: 1.004256] time: 0:01:47.264708\n",
      "0.9511214\n",
      "[Epoch 1/50] [Batch 47/300] [D loss: 0.768550] [G loss: 1.046132] time: 0:01:47.577526\n",
      "0.9161419\n",
      "[Epoch 1/50] [Batch 48/300] [D loss: 0.768080] [G loss: 0.993232] time: 0:01:47.882671\n",
      "0.95059514\n",
      "[Epoch 1/50] [Batch 49/300] [D loss: 0.768324] [G loss: 1.026920] time: 0:01:48.185447\n",
      "0.9779153\n",
      "[Epoch 1/50] [Batch 50/300] [D loss: 0.768423] [G loss: 0.837836] time: 0:01:48.490895\n",
      "0.954879\n",
      "[Epoch 1/50] [Batch 51/300] [D loss: 0.768232] [G loss: 0.892357] time: 0:01:48.791283\n",
      "0.89172196\n",
      "[Epoch 1/50] [Batch 52/300] [D loss: 0.768449] [G loss: 0.936877] time: 0:01:49.085331\n",
      "0.96494913\n",
      "[Epoch 1/50] [Batch 53/300] [D loss: 0.768160] [G loss: 1.111907] time: 0:01:49.383848\n",
      "0.9182277\n",
      "[Epoch 1/50] [Batch 54/300] [D loss: 0.768346] [G loss: 0.867656] time: 0:01:49.673254\n",
      "0.94511884\n",
      "[Epoch 1/50] [Batch 55/300] [D loss: 0.768237] [G loss: 1.098326] time: 0:01:49.978890\n",
      "0.898962\n",
      "[Epoch 1/50] [Batch 56/300] [D loss: 0.767479] [G loss: 0.903864] time: 0:01:50.283120\n",
      "0.92753226\n",
      "[Epoch 1/50] [Batch 57/300] [D loss: 0.768325] [G loss: 0.950801] time: 0:01:50.563841\n",
      "0.9247797\n",
      "[Epoch 1/50] [Batch 58/300] [D loss: 0.768144] [G loss: 1.029482] time: 0:01:50.861845\n",
      "0.9070082\n",
      "[Epoch 1/50] [Batch 59/300] [D loss: 0.768026] [G loss: 1.132507] time: 0:01:51.158321\n",
      "0.9567313\n",
      "[Epoch 1/50] [Batch 60/300] [D loss: 0.768155] [G loss: 0.856658] time: 0:01:51.473018\n",
      "0.89812493\n",
      "[Epoch 1/50] [Batch 61/300] [D loss: 0.767516] [G loss: 1.062811] time: 0:01:51.763525\n",
      "0.89273125\n",
      "[Epoch 1/50] [Batch 62/300] [D loss: 0.767997] [G loss: 0.894840] time: 0:01:52.055413\n",
      "0.94219035\n",
      "[Epoch 1/50] [Batch 63/300] [D loss: 0.767895] [G loss: 0.852463] time: 0:01:52.340449\n",
      "0.91842014\n",
      "[Epoch 1/50] [Batch 64/300] [D loss: 0.766914] [G loss: 1.113829] time: 0:01:52.640767\n",
      "0.87055445\n",
      "[Epoch 1/50] [Batch 65/300] [D loss: 0.767313] [G loss: 1.171731] time: 0:01:52.920243\n",
      "0.9363866\n",
      "[Epoch 1/50] [Batch 66/300] [D loss: 0.768035] [G loss: 1.043549] time: 0:01:53.216444\n",
      "0.85941535\n",
      "[Epoch 1/50] [Batch 67/300] [D loss: 0.767633] [G loss: 0.998730] time: 0:01:53.510018\n",
      "0.9140329\n",
      "[Epoch 1/50] [Batch 68/300] [D loss: 0.767643] [G loss: 0.974986] time: 0:01:53.802399\n",
      "0.8899765\n",
      "[Epoch 1/50] [Batch 69/300] [D loss: 0.767612] [G loss: 0.987068] time: 0:01:54.091678\n",
      "0.90884894\n",
      "[Epoch 1/50] [Batch 70/300] [D loss: 0.767439] [G loss: 0.952805] time: 0:01:54.387546\n",
      "0.9202798\n",
      "[Epoch 1/50] [Batch 71/300] [D loss: 0.767382] [G loss: 0.870082] time: 0:01:54.677754\n",
      "0.92455524\n",
      "[Epoch 1/50] [Batch 72/300] [D loss: 0.767678] [G loss: 0.888251] time: 0:01:54.953460\n",
      "0.9037662\n",
      "[Epoch 1/50] [Batch 73/300] [D loss: 0.767490] [G loss: 1.001158] time: 0:01:55.221120\n",
      "0.88079673\n",
      "[Epoch 1/50] [Batch 74/300] [D loss: 0.767097] [G loss: 0.998522] time: 0:01:55.518390\n",
      "0.88598806\n",
      "[Epoch 1/50] [Batch 75/300] [D loss: 0.766915] [G loss: 1.052078] time: 0:01:55.809432\n",
      "0.8753374\n",
      "[Epoch 1/50] [Batch 76/300] [D loss: 0.767096] [G loss: 1.092387] time: 0:01:56.093475\n",
      "0.90215176\n",
      "[Epoch 1/50] [Batch 77/300] [D loss: 0.767524] [G loss: 0.905149] time: 0:01:56.375881\n",
      "0.9105081\n",
      "[Epoch 1/50] [Batch 78/300] [D loss: 0.766690] [G loss: 1.026500] time: 0:01:56.644434\n",
      "0.8517999\n",
      "[Epoch 1/50] [Batch 79/300] [D loss: 0.767327] [G loss: 1.045141] time: 0:01:56.930154\n",
      "0.9082253\n",
      "[Epoch 1/50] [Batch 80/300] [D loss: 0.767100] [G loss: 1.007438] time: 0:01:57.233527\n",
      "0.9791805\n",
      "[Epoch 1/50] [Batch 81/300] [D loss: 0.767404] [G loss: 0.950373] time: 0:01:57.533481\n",
      "0.9084573\n",
      "[Epoch 1/50] [Batch 82/300] [D loss: 0.767095] [G loss: 0.990854] time: 0:01:57.827718\n",
      "0.9173212\n",
      "[Epoch 1/50] [Batch 83/300] [D loss: 0.767365] [G loss: 0.820683] time: 0:01:58.117121\n",
      "0.8651228\n",
      "[Epoch 1/50] [Batch 84/300] [D loss: 0.767463] [G loss: 0.999297] time: 0:01:58.422917\n",
      "0.94514036\n",
      "[Epoch 1/50] [Batch 85/300] [D loss: 0.766519] [G loss: 1.155956] time: 0:01:58.711955\n",
      "0.9350362\n",
      "[Epoch 1/50] [Batch 86/300] [D loss: 0.766766] [G loss: 0.958112] time: 0:01:59.005723\n",
      "0.9102521\n",
      "[Epoch 1/50] [Batch 87/300] [D loss: 0.767087] [G loss: 0.868102] time: 0:01:59.303121\n",
      "0.9195902\n",
      "[Epoch 1/50] [Batch 88/300] [D loss: 0.767231] [G loss: 0.962196] time: 0:01:59.584467\n",
      "0.9347067\n",
      "[Epoch 1/50] [Batch 89/300] [D loss: 0.766681] [G loss: 1.067173] time: 0:01:59.886348\n",
      "0.9448297\n",
      "[Epoch 1/50] [Batch 90/300] [D loss: 0.767079] [G loss: 0.899962] time: 0:02:00.178645\n",
      "0.8767168\n",
      "[Epoch 1/50] [Batch 91/300] [D loss: 0.767004] [G loss: 0.776760] time: 0:02:00.459976\n",
      "0.8976383\n",
      "[Epoch 1/50] [Batch 92/300] [D loss: 0.766579] [G loss: 1.092242] time: 0:02:00.752644\n",
      "0.9132789\n",
      "[Epoch 1/50] [Batch 93/300] [D loss: 0.766813] [G loss: 0.849444] time: 0:02:01.048682\n",
      "0.97693056\n",
      "[Epoch 1/50] [Batch 94/300] [D loss: 0.767071] [G loss: 1.016033] time: 0:02:01.336362\n",
      "0.88131744\n",
      "[Epoch 1/50] [Batch 95/300] [D loss: 0.766816] [G loss: 0.914328] time: 0:02:01.622872\n",
      "0.9733843\n",
      "[Epoch 1/50] [Batch 96/300] [D loss: 0.766915] [G loss: 0.892039] time: 0:02:01.907179\n",
      "0.87675047\n",
      "[Epoch 1/50] [Batch 97/300] [D loss: 0.766522] [G loss: 0.895132] time: 0:02:02.190981\n",
      "0.89783937\n",
      "[Epoch 1/50] [Batch 98/300] [D loss: 0.766535] [G loss: 0.871241] time: 0:02:02.486014\n",
      "0.8833186\n",
      "[Epoch 1/50] [Batch 99/300] [D loss: 0.766537] [G loss: 0.891794] time: 0:02:02.795469\n",
      "0.90113264\n",
      "[Epoch 1/50] [Batch 100/300] [D loss: 0.766601] [G loss: 1.057556] time: 0:02:03.086356\n",
      "0.9309812\n",
      "[Epoch 1/50] [Batch 101/300] [D loss: 0.766552] [G loss: 0.815247] time: 0:02:03.386403\n",
      "0.9379354\n",
      "[Epoch 1/50] [Batch 102/300] [D loss: 0.766322] [G loss: 1.051330] time: 0:02:03.682695\n",
      "0.95308304\n",
      "[Epoch 1/50] [Batch 103/300] [D loss: 0.765746] [G loss: 1.069927] time: 0:02:03.973061\n",
      "0.95515996\n",
      "[Epoch 1/50] [Batch 104/300] [D loss: 0.765969] [G loss: 1.017985] time: 0:02:04.278958\n",
      "0.9323061\n",
      "[Epoch 1/50] [Batch 105/300] [D loss: 0.766608] [G loss: 0.904504] time: 0:02:04.564981\n",
      "0.9312691\n",
      "[Epoch 1/50] [Batch 106/300] [D loss: 0.766430] [G loss: 1.006217] time: 0:02:04.864921\n",
      "0.87927336\n",
      "[Epoch 1/50] [Batch 107/300] [D loss: 0.766795] [G loss: 0.906284] time: 0:02:05.166219\n",
      "0.913441\n",
      "[Epoch 1/50] [Batch 108/300] [D loss: 0.766124] [G loss: 0.928263] time: 0:02:05.454267\n",
      "0.9275971\n",
      "[Epoch 1/50] [Batch 109/300] [D loss: 0.765565] [G loss: 1.044204] time: 0:02:05.761988\n",
      "0.9338446\n",
      "[Epoch 1/50] [Batch 110/300] [D loss: 0.765979] [G loss: 0.874715] time: 0:02:06.054463\n",
      "0.8982398\n",
      "[Epoch 1/50] [Batch 111/300] [D loss: 0.766096] [G loss: 1.121921] time: 0:02:06.347278\n",
      "0.9359872\n",
      "[Epoch 1/50] [Batch 112/300] [D loss: 0.765744] [G loss: 0.870004] time: 0:02:06.652479\n",
      "0.9477978\n",
      "[Epoch 1/50] [Batch 113/300] [D loss: 0.765949] [G loss: 0.841091] time: 0:02:06.944306\n",
      "0.88164014\n",
      "[Epoch 1/50] [Batch 114/300] [D loss: 0.765631] [G loss: 0.987271] time: 0:02:07.234943\n",
      "0.830396\n",
      "[Epoch 1/50] [Batch 115/300] [D loss: 0.766088] [G loss: 1.297557] time: 0:02:07.533877\n",
      "0.91806215\n",
      "[Epoch 1/50] [Batch 116/300] [D loss: 0.766038] [G loss: 1.030988] time: 0:02:07.841573\n",
      "0.9356744\n",
      "[Epoch 1/50] [Batch 117/300] [D loss: 0.765883] [G loss: 0.896342] time: 0:02:08.138074\n",
      "0.880949\n",
      "[Epoch 1/50] [Batch 118/300] [D loss: 0.766067] [G loss: 0.996716] time: 0:02:08.434765\n",
      "0.94417953\n",
      "[Epoch 1/50] [Batch 119/300] [D loss: 0.765662] [G loss: 0.980228] time: 0:02:08.733876\n",
      "0.9679833\n",
      "[Epoch 1/50] [Batch 120/300] [D loss: 0.766084] [G loss: 0.956572] time: 0:02:09.031511\n",
      "0.9841645\n",
      "[Epoch 1/50] [Batch 121/300] [D loss: 0.765693] [G loss: 1.007830] time: 0:02:09.320118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90026146\n",
      "[Epoch 1/50] [Batch 122/300] [D loss: 0.765442] [G loss: 1.003390] time: 0:02:09.623246\n",
      "0.96435547\n",
      "[Epoch 1/50] [Batch 123/300] [D loss: 0.765794] [G loss: 1.016158] time: 0:02:09.932718\n",
      "0.9361498\n",
      "[Epoch 1/50] [Batch 124/300] [D loss: 0.765429] [G loss: 0.987779] time: 0:02:10.224842\n",
      "0.9119489\n",
      "[Epoch 1/50] [Batch 125/300] [D loss: 0.765917] [G loss: 1.007369] time: 0:02:10.522010\n",
      "0.94154006\n",
      "[Epoch 1/50] [Batch 126/300] [D loss: 0.765405] [G loss: 1.048853] time: 0:02:10.811490\n",
      "0.9197336\n",
      "[Epoch 1/50] [Batch 127/300] [D loss: 0.765371] [G loss: 0.995123] time: 0:02:11.097108\n",
      "0.9385008\n",
      "[Epoch 1/50] [Batch 128/300] [D loss: 0.765378] [G loss: 0.698619] time: 0:02:11.395490\n",
      "0.8799844\n",
      "[Epoch 1/50] [Batch 129/300] [D loss: 0.765032] [G loss: 0.773544] time: 0:02:11.692481\n",
      "0.92116565\n",
      "[Epoch 1/50] [Batch 130/300] [D loss: 0.765599] [G loss: 0.857763] time: 0:02:11.991108\n",
      "0.9240277\n",
      "[Epoch 1/50] [Batch 131/300] [D loss: 0.765488] [G loss: 0.851436] time: 0:02:12.292763\n",
      "0.90277386\n",
      "[Epoch 1/50] [Batch 132/300] [D loss: 0.765276] [G loss: 0.892667] time: 0:02:12.587341\n",
      "0.9090839\n",
      "[Epoch 1/50] [Batch 133/300] [D loss: 0.765136] [G loss: 0.849144] time: 0:02:12.889586\n",
      "0.92946845\n",
      "[Epoch 1/50] [Batch 134/300] [D loss: 0.765382] [G loss: 0.944039] time: 0:02:13.199181\n",
      "0.8935407\n",
      "[Epoch 1/50] [Batch 135/300] [D loss: 0.765260] [G loss: 0.900093] time: 0:02:13.487615\n",
      "0.9427438\n",
      "[Epoch 1/50] [Batch 136/300] [D loss: 0.765525] [G loss: 0.905642] time: 0:02:13.777886\n",
      "0.9267768\n",
      "[Epoch 1/50] [Batch 137/300] [D loss: 0.764989] [G loss: 0.922780] time: 0:02:14.082986\n",
      "0.93976307\n",
      "[Epoch 1/50] [Batch 138/300] [D loss: 0.764856] [G loss: 0.822316] time: 0:02:14.384452\n",
      "0.9071021\n",
      "[Epoch 1/50] [Batch 139/300] [D loss: 0.765154] [G loss: 0.894322] time: 0:02:14.701346\n",
      "0.89491224\n",
      "[Epoch 1/50] [Batch 140/300] [D loss: 0.765242] [G loss: 0.838957] time: 0:02:15.011618\n",
      "0.8964414\n",
      "[Epoch 1/50] [Batch 141/300] [D loss: 0.765247] [G loss: 0.954808] time: 0:02:15.308069\n",
      "0.92186123\n",
      "[Epoch 1/50] [Batch 142/300] [D loss: 0.764752] [G loss: 0.915723] time: 0:02:15.623841\n",
      "0.87969345\n",
      "[Epoch 1/50] [Batch 143/300] [D loss: 0.765079] [G loss: 1.068203] time: 0:02:15.927554\n",
      "0.9073873\n",
      "[Epoch 1/50] [Batch 144/300] [D loss: 0.764913] [G loss: 1.024521] time: 0:02:16.234212\n",
      "0.9095013\n",
      "[Epoch 1/50] [Batch 145/300] [D loss: 0.765006] [G loss: 1.018678] time: 0:02:16.541266\n",
      "0.9447157\n",
      "[Epoch 1/50] [Batch 146/300] [D loss: 0.764809] [G loss: 0.956497] time: 0:02:16.831288\n",
      "0.8985074\n",
      "[Epoch 1/50] [Batch 147/300] [D loss: 0.764769] [G loss: 0.903490] time: 0:02:17.130613\n",
      "0.92465353\n",
      "[Epoch 1/50] [Batch 148/300] [D loss: 0.764853] [G loss: 0.932418] time: 0:02:17.437235\n",
      "0.9249582\n",
      "[Epoch 1/50] [Batch 149/300] [D loss: 0.764964] [G loss: 0.997758] time: 0:02:17.746945\n",
      "0.93233633\n",
      "[Epoch 1/50] [Batch 150/300] [D loss: 0.764588] [G loss: 0.905148] time: 0:02:18.063859\n",
      "0.91710997\n",
      "[Epoch 1/50] [Batch 151/300] [D loss: 0.765151] [G loss: 1.024589] time: 0:02:18.370983\n",
      "0.8649176\n",
      "[Epoch 1/50] [Batch 152/300] [D loss: 0.764894] [G loss: 0.924431] time: 0:02:18.691929\n",
      "0.9142745\n",
      "[Epoch 1/50] [Batch 153/300] [D loss: 0.764802] [G loss: 1.015166] time: 0:02:19.003719\n",
      "0.90445226\n",
      "[Epoch 1/50] [Batch 154/300] [D loss: 0.764929] [G loss: 0.880120] time: 0:02:19.314458\n",
      "0.9163994\n",
      "[Epoch 1/50] [Batch 155/300] [D loss: 0.764083] [G loss: 0.959861] time: 0:02:19.621019\n",
      "0.869967\n",
      "[Epoch 1/50] [Batch 156/300] [D loss: 0.764688] [G loss: 1.066430] time: 0:02:19.923762\n",
      "0.92924976\n",
      "[Epoch 1/50] [Batch 157/300] [D loss: 0.764411] [G loss: 1.118978] time: 0:02:20.212106\n",
      "0.9391563\n",
      "[Epoch 1/50] [Batch 158/300] [D loss: 0.765197] [G loss: 0.976298] time: 0:02:20.508480\n",
      "0.9319845\n",
      "[Epoch 1/50] [Batch 159/300] [D loss: 0.764616] [G loss: 1.042415] time: 0:02:20.818772\n",
      "0.928757\n",
      "[Epoch 1/50] [Batch 160/300] [D loss: 0.765091] [G loss: 0.941204] time: 0:02:21.109207\n",
      "0.90182203\n",
      "[Epoch 1/50] [Batch 161/300] [D loss: 0.764590] [G loss: 0.901095] time: 0:02:21.424346\n",
      "0.87502337\n",
      "[Epoch 1/50] [Batch 162/300] [D loss: 0.764189] [G loss: 0.931686] time: 0:02:21.723348\n",
      "0.9439855\n",
      "[Epoch 1/50] [Batch 163/300] [D loss: 0.764480] [G loss: 0.987745] time: 0:02:22.024367\n",
      "0.90182835\n",
      "[Epoch 1/50] [Batch 164/300] [D loss: 0.764518] [G loss: 0.962690] time: 0:02:22.303031\n",
      "0.9066672\n",
      "[Epoch 1/50] [Batch 165/300] [D loss: 0.764055] [G loss: 0.932870] time: 0:02:22.596064\n",
      "0.92270595\n",
      "[Epoch 1/50] [Batch 166/300] [D loss: 0.764391] [G loss: 0.806486] time: 0:02:22.886199\n",
      "0.9283373\n",
      "[Epoch 1/50] [Batch 167/300] [D loss: 0.764339] [G loss: 0.943290] time: 0:02:23.197877\n",
      "0.91303366\n",
      "[Epoch 1/50] [Batch 168/300] [D loss: 0.764377] [G loss: 1.007668] time: 0:02:23.492330\n",
      "0.9239094\n",
      "[Epoch 1/50] [Batch 169/300] [D loss: 0.764626] [G loss: 0.911320] time: 0:02:23.799150\n",
      "0.9176609\n",
      "[Epoch 1/50] [Batch 170/300] [D loss: 0.764255] [G loss: 0.957790] time: 0:02:24.096856\n",
      "0.87029094\n",
      "[Epoch 1/50] [Batch 171/300] [D loss: 0.764553] [G loss: 0.958558] time: 0:02:24.396801\n",
      "0.94671774\n",
      "[Epoch 1/50] [Batch 172/300] [D loss: 0.764837] [G loss: 0.875869] time: 0:02:24.700677\n",
      "0.9084484\n",
      "[Epoch 1/50] [Batch 173/300] [D loss: 0.764279] [G loss: 0.989277] time: 0:02:24.984945\n",
      "0.9277659\n",
      "[Epoch 1/50] [Batch 174/300] [D loss: 0.764247] [G loss: 0.890847] time: 0:02:25.267756\n",
      "0.94365424\n",
      "[Epoch 1/50] [Batch 175/300] [D loss: 0.764266] [G loss: 0.924344] time: 0:02:25.565905\n",
      "0.94246846\n",
      "[Epoch 1/50] [Batch 176/300] [D loss: 0.764307] [G loss: 0.804022] time: 0:02:25.866924\n",
      "0.908747\n",
      "[Epoch 1/50] [Batch 177/300] [D loss: 0.764132] [G loss: 0.980433] time: 0:02:26.148470\n",
      "0.919272\n",
      "[Epoch 1/50] [Batch 178/300] [D loss: 0.764298] [G loss: 0.894363] time: 0:02:26.424557\n",
      "0.945944\n",
      "[Epoch 1/50] [Batch 179/300] [D loss: 0.764344] [G loss: 0.946324] time: 0:02:26.733623\n",
      "0.9280588\n",
      "[Epoch 1/50] [Batch 180/300] [D loss: 0.763765] [G loss: 0.952651] time: 0:02:27.047502\n",
      "0.93990374\n",
      "[Epoch 1/50] [Batch 181/300] [D loss: 0.763863] [G loss: 0.982297] time: 0:02:27.360426\n",
      "0.8603044\n",
      "[Epoch 1/50] [Batch 182/300] [D loss: 0.763938] [G loss: 1.326467] time: 0:02:27.661665\n",
      "0.90868455\n",
      "[Epoch 1/50] [Batch 183/300] [D loss: 0.763733] [G loss: 0.966265] time: 0:02:27.979931\n",
      "0.93855673\n",
      "[Epoch 1/50] [Batch 184/300] [D loss: 0.763678] [G loss: 0.965774] time: 0:02:28.275367\n",
      "0.92536134\n",
      "[Epoch 1/50] [Batch 185/300] [D loss: 0.764125] [G loss: 0.873123] time: 0:02:28.570725\n",
      "0.91009265\n",
      "[Epoch 1/50] [Batch 186/300] [D loss: 0.764011] [G loss: 0.992524] time: 0:02:28.878717\n",
      "0.94675785\n",
      "[Epoch 1/50] [Batch 187/300] [D loss: 0.764165] [G loss: 0.825071] time: 0:02:29.188315\n",
      "0.94354033\n",
      "[Epoch 1/50] [Batch 188/300] [D loss: 0.763648] [G loss: 1.037499] time: 0:02:29.476681\n",
      "0.94035465\n",
      "[Epoch 1/50] [Batch 189/300] [D loss: 0.763819] [G loss: 0.987854] time: 0:02:29.782481\n",
      "0.9163458\n",
      "[Epoch 1/50] [Batch 190/300] [D loss: 0.764007] [G loss: 1.017275] time: 0:02:30.071849\n",
      "0.860471\n",
      "[Epoch 1/50] [Batch 191/300] [D loss: 0.764108] [G loss: 0.948983] time: 0:02:30.375907\n",
      "0.91150016\n",
      "[Epoch 1/50] [Batch 192/300] [D loss: 0.763583] [G loss: 1.030108] time: 0:02:30.646022\n",
      "0.94006675\n",
      "[Epoch 1/50] [Batch 193/300] [D loss: 0.763307] [G loss: 1.038273] time: 0:02:30.939465\n",
      "0.82519394\n",
      "[Epoch 1/50] [Batch 194/300] [D loss: 0.763733] [G loss: 1.016896] time: 0:02:31.226944\n",
      "0.87081265\n",
      "[Epoch 1/50] [Batch 195/300] [D loss: 0.763760] [G loss: 0.926388] time: 0:02:31.524345\n",
      "0.9506847\n",
      "[Epoch 1/50] [Batch 196/300] [D loss: 0.764091] [G loss: 1.045903] time: 0:02:31.829605\n",
      "0.938463\n",
      "[Epoch 1/50] [Batch 197/300] [D loss: 0.763779] [G loss: 0.966046] time: 0:02:32.136791\n",
      "0.8747783\n",
      "[Epoch 1/50] [Batch 198/300] [D loss: 0.763373] [G loss: 1.166014] time: 0:02:32.442624\n",
      "0.91152143\n",
      "[Epoch 1/50] [Batch 199/300] [D loss: 0.763673] [G loss: 0.785623] time: 0:02:32.734140\n",
      "0.92171675\n",
      "[Epoch 1/50] [Batch 200/300] [D loss: 0.763586] [G loss: 1.005639] time: 0:02:33.028975\n",
      "0.927604\n",
      "[Epoch 1/50] [Batch 201/300] [D loss: 0.763547] [G loss: 0.808949] time: 0:02:33.325120\n",
      "0.8525526\n",
      "[Epoch 1/50] [Batch 202/300] [D loss: 0.763502] [G loss: 0.909760] time: 0:02:33.626575\n",
      "0.89426833\n",
      "[Epoch 1/50] [Batch 203/300] [D loss: 0.763781] [G loss: 1.080117] time: 0:02:33.932775\n",
      "0.9109778\n",
      "[Epoch 1/50] [Batch 204/300] [D loss: 0.763335] [G loss: 0.862331] time: 0:02:34.250172\n",
      "0.9056177\n",
      "[Epoch 1/50] [Batch 205/300] [D loss: 0.763331] [G loss: 0.950447] time: 0:02:34.556293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90639085\n",
      "[Epoch 1/50] [Batch 206/300] [D loss: 0.763384] [G loss: 0.870782] time: 0:02:34.868957\n",
      "0.93485445\n",
      "[Epoch 1/50] [Batch 207/300] [D loss: 0.763574] [G loss: 0.831425] time: 0:02:35.165476\n",
      "0.8603272\n",
      "[Epoch 1/50] [Batch 208/300] [D loss: 0.763354] [G loss: 0.912011] time: 0:02:35.461293\n",
      "0.8675685\n",
      "[Epoch 1/50] [Batch 209/300] [D loss: 0.763540] [G loss: 1.064806] time: 0:02:35.764148\n",
      "0.92762333\n",
      "[Epoch 1/50] [Batch 210/300] [D loss: 0.763381] [G loss: 0.889894] time: 0:02:36.061447\n",
      "0.91491294\n",
      "[Epoch 1/50] [Batch 211/300] [D loss: 0.763510] [G loss: 0.769231] time: 0:02:36.364427\n",
      "0.89431334\n",
      "[Epoch 1/50] [Batch 212/300] [D loss: 0.763675] [G loss: 0.947311] time: 0:02:36.665393\n",
      "0.96797466\n",
      "[Epoch 1/50] [Batch 213/300] [D loss: 0.763359] [G loss: 0.981243] time: 0:02:36.959456\n",
      "0.9421194\n",
      "[Epoch 1/50] [Batch 214/300] [D loss: 0.763128] [G loss: 0.928804] time: 0:02:37.265947\n",
      "0.939085\n",
      "[Epoch 1/50] [Batch 215/300] [D loss: 0.763197] [G loss: 0.949511] time: 0:02:37.574888\n",
      "0.8538828\n",
      "[Epoch 1/50] [Batch 216/300] [D loss: 0.763211] [G loss: 1.042973] time: 0:02:37.878397\n",
      "0.8885371\n",
      "[Epoch 1/50] [Batch 217/300] [D loss: 0.763484] [G loss: 0.850020] time: 0:02:38.197542\n",
      "0.9636614\n",
      "[Epoch 1/50] [Batch 218/300] [D loss: 0.763294] [G loss: 0.963760] time: 0:02:38.504129\n",
      "0.84952205\n",
      "[Epoch 1/50] [Batch 219/300] [D loss: 0.763377] [G loss: 0.912161] time: 0:02:38.791976\n",
      "0.93298\n",
      "[Epoch 1/50] [Batch 220/300] [D loss: 0.762943] [G loss: 0.926947] time: 0:02:39.113027\n",
      "0.9154044\n",
      "[Epoch 1/50] [Batch 221/300] [D loss: 0.763453] [G loss: 0.947749] time: 0:02:39.415360\n",
      "0.90394765\n",
      "[Epoch 1/50] [Batch 222/300] [D loss: 0.763123] [G loss: 1.145725] time: 0:02:39.705820\n",
      "0.9299156\n",
      "[Epoch 1/50] [Batch 223/300] [D loss: 0.763080] [G loss: 0.900847] time: 0:02:40.017312\n",
      "0.9376653\n",
      "[Epoch 1/50] [Batch 224/300] [D loss: 0.763256] [G loss: 0.959417] time: 0:02:40.327111\n",
      "0.9247461\n",
      "[Epoch 1/50] [Batch 225/300] [D loss: 0.762901] [G loss: 1.110601] time: 0:02:40.637534\n",
      "0.9079933\n",
      "[Epoch 1/50] [Batch 226/300] [D loss: 0.762889] [G loss: 0.951749] time: 0:02:40.915471\n",
      "0.9291086\n",
      "[Epoch 1/50] [Batch 227/300] [D loss: 0.762973] [G loss: 0.944724] time: 0:02:41.193789\n",
      "0.97827643\n",
      "[Epoch 1/50] [Batch 228/300] [D loss: 0.762946] [G loss: 1.045874] time: 0:02:41.504268\n",
      "0.909266\n",
      "[Epoch 1/50] [Batch 229/300] [D loss: 0.762989] [G loss: 1.045149] time: 0:02:41.798589\n",
      "0.89323354\n",
      "[Epoch 1/50] [Batch 230/300] [D loss: 0.762795] [G loss: 0.953065] time: 0:02:42.103684\n",
      "0.9344774\n",
      "[Epoch 1/50] [Batch 231/300] [D loss: 0.762822] [G loss: 0.963953] time: 0:02:42.402255\n",
      "0.9111896\n",
      "[Epoch 1/50] [Batch 232/300] [D loss: 0.762806] [G loss: 1.072212] time: 0:02:42.695531\n",
      "0.8954192\n",
      "[Epoch 1/50] [Batch 233/300] [D loss: 0.762813] [G loss: 0.972322] time: 0:02:42.992785\n",
      "0.9310382\n",
      "[Epoch 1/50] [Batch 234/300] [D loss: 0.762996] [G loss: 1.116244] time: 0:02:43.293929\n",
      "0.9314914\n",
      "[Epoch 1/50] [Batch 235/300] [D loss: 0.762581] [G loss: 0.932198] time: 0:02:43.590514\n",
      "0.84002644\n",
      "[Epoch 1/50] [Batch 236/300] [D loss: 0.762736] [G loss: 1.141831] time: 0:02:43.863731\n",
      "0.934675\n",
      "[Epoch 1/50] [Batch 237/300] [D loss: 0.762746] [G loss: 0.891456] time: 0:02:44.151473\n",
      "0.89207095\n",
      "[Epoch 1/50] [Batch 238/300] [D loss: 0.762701] [G loss: 1.022814] time: 0:02:44.446137\n",
      "0.8839633\n",
      "[Epoch 1/50] [Batch 239/300] [D loss: 0.762837] [G loss: 1.035271] time: 0:02:44.757292\n",
      "0.9445243\n",
      "[Epoch 1/50] [Batch 240/300] [D loss: 0.763116] [G loss: 0.786461] time: 0:02:45.052630\n",
      "0.9042025\n",
      "[Epoch 1/50] [Batch 241/300] [D loss: 0.762676] [G loss: 1.009811] time: 0:02:45.358683\n",
      "0.89912313\n",
      "[Epoch 1/50] [Batch 242/300] [D loss: 0.763208] [G loss: 0.916906] time: 0:02:45.656900\n",
      "0.88685673\n",
      "[Epoch 1/50] [Batch 243/300] [D loss: 0.762358] [G loss: 1.067536] time: 0:02:45.958442\n",
      "0.88292426\n",
      "[Epoch 1/50] [Batch 244/300] [D loss: 0.762296] [G loss: 0.960587] time: 0:02:46.274096\n",
      "0.93097895\n",
      "[Epoch 1/50] [Batch 245/300] [D loss: 0.762480] [G loss: 0.815737] time: 0:02:46.588674\n",
      "0.8650152\n",
      "[Epoch 1/50] [Batch 246/300] [D loss: 0.762409] [G loss: 1.034475] time: 0:02:46.896582\n",
      "0.9437432\n",
      "[Epoch 1/50] [Batch 247/300] [D loss: 0.762526] [G loss: 0.781542] time: 0:02:47.188995\n",
      "0.8955002\n",
      "[Epoch 1/50] [Batch 248/300] [D loss: 0.762573] [G loss: 0.867415] time: 0:02:47.474690\n",
      "0.9270217\n",
      "[Epoch 1/50] [Batch 249/300] [D loss: 0.762397] [G loss: 0.915068] time: 0:02:47.767108\n",
      "0.91961354\n",
      "[Epoch 1/50] [Batch 250/300] [D loss: 0.762433] [G loss: 1.116231] time: 0:02:48.086470\n",
      "0.92866904\n",
      "[Epoch 1/50] [Batch 251/300] [D loss: 0.762282] [G loss: 1.004606] time: 0:02:48.393702\n",
      "0.94393665\n",
      "[Epoch 1/50] [Batch 252/300] [D loss: 0.762466] [G loss: 0.852817] time: 0:02:48.691370\n",
      "0.9409383\n",
      "[Epoch 1/50] [Batch 253/300] [D loss: 0.762474] [G loss: 0.979774] time: 0:02:48.978993\n",
      "0.8913703\n",
      "[Epoch 1/50] [Batch 254/300] [D loss: 0.761965] [G loss: 1.174784] time: 0:02:49.275224\n",
      "0.9007869\n",
      "[Epoch 1/50] [Batch 255/300] [D loss: 0.762459] [G loss: 0.806127] time: 0:02:49.582727\n",
      "0.9397938\n",
      "[Epoch 1/50] [Batch 256/300] [D loss: 0.762410] [G loss: 0.928847] time: 0:02:49.882510\n",
      "0.8755681\n",
      "[Epoch 1/50] [Batch 257/300] [D loss: 0.762583] [G loss: 1.009931] time: 0:02:50.176584\n",
      "0.86667186\n",
      "[Epoch 1/50] [Batch 258/300] [D loss: 0.762326] [G loss: 1.009681] time: 0:02:50.469364\n",
      "0.937835\n",
      "[Epoch 1/50] [Batch 259/300] [D loss: 0.762535] [G loss: 0.952411] time: 0:02:50.783483\n",
      "0.919859\n",
      "[Epoch 1/50] [Batch 260/300] [D loss: 0.762204] [G loss: 0.939534] time: 0:02:51.089574\n",
      "0.9567885\n",
      "[Epoch 1/50] [Batch 261/300] [D loss: 0.762821] [G loss: 0.805908] time: 0:02:51.395149\n",
      "0.893331\n",
      "[Epoch 1/50] [Batch 262/300] [D loss: 0.762050] [G loss: 0.771173] time: 0:02:51.696799\n",
      "0.9156494\n",
      "[Epoch 1/50] [Batch 263/300] [D loss: 0.762415] [G loss: 0.832595] time: 0:02:51.996029\n",
      "0.9280937\n",
      "[Epoch 1/50] [Batch 264/300] [D loss: 0.762565] [G loss: 0.864032] time: 0:02:52.305847\n",
      "0.951183\n",
      "[Epoch 1/50] [Batch 265/300] [D loss: 0.762294] [G loss: 0.798654] time: 0:02:52.618054\n",
      "0.85697865\n",
      "[Epoch 1/50] [Batch 266/300] [D loss: 0.761982] [G loss: 0.967796] time: 0:02:52.893114\n",
      "0.923615\n",
      "[Epoch 1/50] [Batch 267/300] [D loss: 0.762219] [G loss: 0.999669] time: 0:02:53.189692\n",
      "0.9379411\n",
      "[Epoch 1/50] [Batch 268/300] [D loss: 0.762589] [G loss: 0.846650] time: 0:02:53.496478\n",
      "0.91395\n",
      "[Epoch 1/50] [Batch 269/300] [D loss: 0.762461] [G loss: 1.004331] time: 0:02:53.803196\n",
      "0.91157484\n",
      "[Epoch 1/50] [Batch 270/300] [D loss: 0.762099] [G loss: 0.909588] time: 0:02:54.102131\n",
      "0.9335168\n",
      "[Epoch 1/50] [Batch 271/300] [D loss: 0.761964] [G loss: 1.134916] time: 0:02:54.397162\n",
      "0.90341216\n",
      "[Epoch 1/50] [Batch 272/300] [D loss: 0.762184] [G loss: 0.825637] time: 0:02:54.712590\n",
      "0.9222639\n",
      "[Epoch 1/50] [Batch 273/300] [D loss: 0.762053] [G loss: 0.770398] time: 0:02:55.021419\n",
      "0.90289396\n",
      "[Epoch 1/50] [Batch 274/300] [D loss: 0.761778] [G loss: 0.958377] time: 0:02:55.335449\n",
      "0.9044719\n",
      "[Epoch 1/50] [Batch 275/300] [D loss: 0.761824] [G loss: 0.811900] time: 0:02:55.656187\n",
      "0.87874883\n",
      "[Epoch 1/50] [Batch 276/300] [D loss: 0.761493] [G loss: 0.864700] time: 0:02:55.964094\n",
      "0.9091006\n",
      "[Epoch 1/50] [Batch 277/300] [D loss: 0.762216] [G loss: 0.944237] time: 0:02:56.267875\n",
      "0.89021605\n",
      "[Epoch 1/50] [Batch 278/300] [D loss: 0.762052] [G loss: 0.897294] time: 0:02:56.569186\n",
      "0.95568913\n",
      "[Epoch 1/50] [Batch 279/300] [D loss: 0.761796] [G loss: 0.883104] time: 0:02:56.883075\n",
      "0.92776036\n",
      "[Epoch 1/50] [Batch 280/300] [D loss: 0.762171] [G loss: 0.902597] time: 0:02:57.199594\n",
      "0.947993\n",
      "[Epoch 1/50] [Batch 281/300] [D loss: 0.761855] [G loss: 0.872471] time: 0:02:57.507155\n",
      "0.89187163\n",
      "[Epoch 1/50] [Batch 282/300] [D loss: 0.762053] [G loss: 0.881793] time: 0:02:57.801378\n",
      "0.8798439\n",
      "[Epoch 1/50] [Batch 283/300] [D loss: 0.761972] [G loss: 0.851857] time: 0:02:58.099996\n",
      "0.89071673\n",
      "[Epoch 1/50] [Batch 284/300] [D loss: 0.762068] [G loss: 1.140200] time: 0:02:58.407120\n",
      "0.8845809\n",
      "[Epoch 1/50] [Batch 285/300] [D loss: 0.761849] [G loss: 0.933267] time: 0:02:58.729930\n",
      "0.93915385\n",
      "[Epoch 1/50] [Batch 286/300] [D loss: 0.761470] [G loss: 0.903998] time: 0:02:59.007801\n",
      "0.9256173\n",
      "[Epoch 1/50] [Batch 287/300] [D loss: 0.761639] [G loss: 1.010176] time: 0:02:59.305805\n",
      "0.8345167\n",
      "[Epoch 1/50] [Batch 288/300] [D loss: 0.761660] [G loss: 0.894426] time: 0:02:59.602891\n",
      "0.90515786\n",
      "[Epoch 1/50] [Batch 289/300] [D loss: 0.761976] [G loss: 0.988932] time: 0:02:59.918839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89891845\n",
      "[Epoch 1/50] [Batch 290/300] [D loss: 0.761924] [G loss: 1.071285] time: 0:03:00.210750\n",
      "0.8996441\n",
      "[Epoch 1/50] [Batch 291/300] [D loss: 0.762050] [G loss: 0.982803] time: 0:03:00.516992\n",
      "0.9266054\n",
      "[Epoch 1/50] [Batch 292/300] [D loss: 0.761670] [G loss: 0.868994] time: 0:03:00.833407\n",
      "0.9434829\n",
      "[Epoch 1/50] [Batch 293/300] [D loss: 0.761614] [G loss: 0.983793] time: 0:03:01.143929\n",
      "0.88888735\n",
      "[Epoch 1/50] [Batch 294/300] [D loss: 0.761778] [G loss: 0.859171] time: 0:03:01.449725\n",
      "0.90829283\n",
      "[Epoch 1/50] [Batch 295/300] [D loss: 0.761812] [G loss: 0.755264] time: 0:03:01.773057\n",
      "0.9387269\n",
      "[Epoch 1/50] [Batch 296/300] [D loss: 0.761380] [G loss: 1.052052] time: 0:03:02.081185\n",
      "0.8670358\n",
      "[Epoch 1/50] [Batch 297/300] [D loss: 0.761873] [G loss: 0.991285] time: 0:03:02.366426\n",
      "0.93729013\n",
      "[Epoch 1/50] [Batch 298/300] [D loss: 0.761712] [G loss: 0.969613] time: 0:03:02.662307\n",
      "0.9379931\n",
      "[Epoch 1/50] [Batch 299/300] [D loss: 0.761544] [G loss: 0.796369] time: 0:03:02.967489\n",
      "0.9570406\n",
      "[Epoch 2/50] [Batch 0/300] [D loss: 0.761716] [G loss: 0.980702] time: 0:03:03.270799\n",
      "0.9096031\n",
      "[Epoch 2/50] [Batch 2/300] [D loss: 0.761444] [G loss: 0.877717] time: 0:03:03.576453\n",
      "0.9357626\n",
      "[Epoch 2/50] [Batch 3/300] [D loss: 0.761585] [G loss: 0.956730] time: 0:03:03.877048\n",
      "0.9448677\n",
      "[Epoch 2/50] [Batch 4/300] [D loss: 0.762090] [G loss: 1.007519] time: 0:03:04.175975\n",
      "0.9382138\n",
      "[Epoch 2/50] [Batch 5/300] [D loss: 0.761471] [G loss: 1.109839] time: 0:03:04.490371\n",
      "0.93696284\n",
      "[Epoch 2/50] [Batch 6/300] [D loss: 0.761394] [G loss: 0.851975] time: 0:03:04.792729\n",
      "0.92014533\n",
      "[Epoch 2/50] [Batch 7/300] [D loss: 0.761517] [G loss: 0.897454] time: 0:03:05.105926\n",
      "0.9619519\n",
      "[Epoch 2/50] [Batch 8/300] [D loss: 0.761288] [G loss: 0.937309] time: 0:03:05.413678\n",
      "0.9018767\n",
      "[Epoch 2/50] [Batch 9/300] [D loss: 0.761247] [G loss: 1.069389] time: 0:03:05.706803\n",
      "0.9152028\n",
      "[Epoch 2/50] [Batch 10/300] [D loss: 0.761534] [G loss: 0.923502] time: 0:03:06.010389\n",
      "0.91107893\n",
      "[Epoch 2/50] [Batch 11/300] [D loss: 0.761393] [G loss: 0.994754] time: 0:03:06.326717\n",
      "0.90207106\n",
      "[Epoch 2/50] [Batch 12/300] [D loss: 0.761420] [G loss: 0.818784] time: 0:03:06.626074\n",
      "0.9009879\n",
      "[Epoch 2/50] [Batch 13/300] [D loss: 0.761763] [G loss: 0.817031] time: 0:03:06.912067\n",
      "0.94836545\n",
      "[Epoch 2/50] [Batch 14/300] [D loss: 0.761547] [G loss: 1.140197] time: 0:03:07.214571\n",
      "0.8645778\n",
      "[Epoch 2/50] [Batch 15/300] [D loss: 0.761496] [G loss: 0.998861] time: 0:03:07.526093\n",
      "0.94215804\n",
      "[Epoch 2/50] [Batch 16/300] [D loss: 0.761277] [G loss: 0.963879] time: 0:03:07.838429\n",
      "0.90715337\n",
      "[Epoch 2/50] [Batch 17/300] [D loss: 0.761496] [G loss: 0.891535] time: 0:03:08.142205\n",
      "0.9468324\n",
      "[Epoch 2/50] [Batch 18/300] [D loss: 0.761909] [G loss: 0.833033] time: 0:03:08.446499\n",
      "0.8996088\n",
      "[Epoch 2/50] [Batch 19/300] [D loss: 0.761029] [G loss: 1.024804] time: 0:03:08.745934\n",
      "0.9475756\n",
      "[Epoch 2/50] [Batch 20/300] [D loss: 0.761175] [G loss: 0.950055] time: 0:03:09.046913\n",
      "0.91430044\n",
      "[Epoch 2/50] [Batch 21/300] [D loss: 0.761231] [G loss: 0.919169] time: 0:03:09.354888\n",
      "0.9204836\n",
      "[Epoch 2/50] [Batch 22/300] [D loss: 0.760831] [G loss: 1.081726] time: 0:03:09.659500\n",
      "0.84468174\n",
      "[Epoch 2/50] [Batch 23/300] [D loss: 0.761243] [G loss: 0.948670] time: 0:03:09.965824\n",
      "0.8780877\n",
      "[Epoch 2/50] [Batch 24/300] [D loss: 0.760945] [G loss: 1.042401] time: 0:03:10.271918\n",
      "0.9130648\n",
      "[Epoch 2/50] [Batch 25/300] [D loss: 0.761517] [G loss: 0.758733] time: 0:03:10.565390\n",
      "0.9268052\n",
      "[Epoch 2/50] [Batch 26/300] [D loss: 0.761134] [G loss: 0.882344] time: 0:03:10.854625\n",
      "0.93000054\n",
      "[Epoch 2/50] [Batch 27/300] [D loss: 0.761044] [G loss: 1.029613] time: 0:03:11.160938\n",
      "0.91857624\n",
      "[Epoch 2/50] [Batch 28/300] [D loss: 0.761332] [G loss: 1.025826] time: 0:03:11.461182\n",
      "0.9380391\n",
      "[Epoch 2/50] [Batch 29/300] [D loss: 0.760980] [G loss: 0.821709] time: 0:03:11.774300\n",
      "0.94241315\n",
      "[Epoch 2/50] [Batch 30/300] [D loss: 0.761157] [G loss: 0.966136] time: 0:03:12.088422\n",
      "0.8966386\n",
      "[Epoch 2/50] [Batch 31/300] [D loss: 0.761290] [G loss: 1.015184] time: 0:03:12.391074\n",
      "0.9209351\n",
      "[Epoch 2/50] [Batch 32/300] [D loss: 0.761120] [G loss: 0.885741] time: 0:03:12.685148\n",
      "0.90679055\n",
      "[Epoch 2/50] [Batch 33/300] [D loss: 0.761297] [G loss: 0.875104] time: 0:03:12.976736\n",
      "0.96537894\n",
      "[Epoch 2/50] [Batch 34/300] [D loss: 0.761348] [G loss: 0.906702] time: 0:03:13.289350\n",
      "0.9120838\n",
      "[Epoch 2/50] [Batch 35/300] [D loss: 0.761013] [G loss: 0.905844] time: 0:03:13.590622\n",
      "0.895649\n",
      "[Epoch 2/50] [Batch 36/300] [D loss: 0.761116] [G loss: 1.043565] time: 0:03:13.896092\n",
      "0.91456777\n",
      "[Epoch 2/50] [Batch 37/300] [D loss: 0.761497] [G loss: 0.983607] time: 0:03:14.202149\n",
      "0.8870533\n",
      "[Epoch 2/50] [Batch 38/300] [D loss: 0.761051] [G loss: 0.991351] time: 0:03:14.494479\n",
      "0.9014923\n",
      "[Epoch 2/50] [Batch 39/300] [D loss: 0.760887] [G loss: 1.016297] time: 0:03:14.788848\n",
      "0.91625935\n",
      "[Epoch 2/50] [Batch 40/300] [D loss: 0.760653] [G loss: 0.895652] time: 0:03:15.095443\n",
      "0.8984933\n",
      "[Epoch 2/50] [Batch 41/300] [D loss: 0.760887] [G loss: 0.870451] time: 0:03:15.404762\n",
      "0.89691895\n",
      "[Epoch 2/50] [Batch 42/300] [D loss: 0.761044] [G loss: 1.053535] time: 0:03:15.721820\n",
      "0.9131277\n",
      "[Epoch 2/50] [Batch 43/300] [D loss: 0.761089] [G loss: 0.886414] time: 0:03:16.030562\n",
      "0.9026592\n",
      "[Epoch 2/50] [Batch 44/300] [D loss: 0.760997] [G loss: 0.965679] time: 0:03:16.324031\n",
      "0.8714347\n",
      "[Epoch 2/50] [Batch 45/300] [D loss: 0.760803] [G loss: 0.943445] time: 0:03:16.633841\n",
      "0.9500888\n",
      "[Epoch 2/50] [Batch 46/300] [D loss: 0.761185] [G loss: 0.908358] time: 0:03:16.937924\n",
      "0.91029793\n",
      "[Epoch 2/50] [Batch 47/300] [D loss: 0.760988] [G loss: 1.094372] time: 0:03:17.242393\n",
      "0.93231374\n",
      "[Epoch 2/50] [Batch 48/300] [D loss: 0.760959] [G loss: 0.929014] time: 0:03:17.545438\n",
      "0.9019368\n",
      "[Epoch 2/50] [Batch 49/300] [D loss: 0.760662] [G loss: 0.889753] time: 0:03:17.840424\n",
      "0.9300177\n",
      "[Epoch 2/50] [Batch 50/300] [D loss: 0.760560] [G loss: 0.915170] time: 0:03:18.142952\n",
      "0.8928246\n",
      "[Epoch 2/50] [Batch 51/300] [D loss: 0.761058] [G loss: 0.878382] time: 0:03:18.424689\n",
      "0.9088762\n",
      "[Epoch 2/50] [Batch 52/300] [D loss: 0.760783] [G loss: 0.863809] time: 0:03:18.739763\n",
      "0.91939324\n",
      "[Epoch 2/50] [Batch 53/300] [D loss: 0.761211] [G loss: 0.781750] time: 0:03:19.036233\n",
      "0.86789364\n",
      "[Epoch 2/50] [Batch 54/300] [D loss: 0.761016] [G loss: 0.889520] time: 0:03:19.346765\n",
      "0.9059755\n",
      "[Epoch 2/50] [Batch 55/300] [D loss: 0.760922] [G loss: 1.086624] time: 0:03:19.640668\n",
      "0.92164534\n",
      "[Epoch 2/50] [Batch 56/300] [D loss: 0.760701] [G loss: 0.966575] time: 0:03:19.917885\n",
      "0.92687815\n",
      "[Epoch 2/50] [Batch 57/300] [D loss: 0.760902] [G loss: 0.796274] time: 0:03:20.199985\n",
      "0.94687456\n",
      "[Epoch 2/50] [Batch 58/300] [D loss: 0.760326] [G loss: 1.044905] time: 0:03:20.504965\n",
      "0.89631814\n",
      "[Epoch 2/50] [Batch 59/300] [D loss: 0.760681] [G loss: 0.901001] time: 0:03:20.810459\n",
      "0.9517355\n",
      "[Epoch 2/50] [Batch 60/300] [D loss: 0.760725] [G loss: 0.936981] time: 0:03:21.107277\n",
      "0.87557745\n",
      "[Epoch 2/50] [Batch 61/300] [D loss: 0.760750] [G loss: 0.924042] time: 0:03:21.416795\n",
      "0.935761\n",
      "[Epoch 2/50] [Batch 62/300] [D loss: 0.760857] [G loss: 0.859326] time: 0:03:21.715353\n",
      "0.9117057\n",
      "[Epoch 2/50] [Batch 63/300] [D loss: 0.760773] [G loss: 1.013252] time: 0:03:22.018974\n",
      "0.8891528\n",
      "[Epoch 2/50] [Batch 64/300] [D loss: 0.761137] [G loss: 0.829419] time: 0:03:22.316077\n",
      "0.9183946\n",
      "[Epoch 2/50] [Batch 65/300] [D loss: 0.760758] [G loss: 0.917377] time: 0:03:22.623775\n",
      "0.8824165\n",
      "[Epoch 2/50] [Batch 66/300] [D loss: 0.760604] [G loss: 0.832528] time: 0:03:22.925562\n",
      "0.9506065\n",
      "[Epoch 2/50] [Batch 67/300] [D loss: 0.760540] [G loss: 0.889526] time: 0:03:23.231720\n",
      "0.87535113\n",
      "[Epoch 2/50] [Batch 68/300] [D loss: 0.760245] [G loss: 0.974425] time: 0:03:23.525929\n",
      "0.92039514\n",
      "[Epoch 2/50] [Batch 69/300] [D loss: 0.760718] [G loss: 1.019060] time: 0:03:23.831405\n",
      "0.9073046\n",
      "[Epoch 2/50] [Batch 70/300] [D loss: 0.760689] [G loss: 0.883124] time: 0:03:24.157992\n",
      "0.8782153\n",
      "[Epoch 2/50] [Batch 71/300] [D loss: 0.760854] [G loss: 0.887337] time: 0:03:24.460553\n",
      "0.90845436\n",
      "[Epoch 2/50] [Batch 72/300] [D loss: 0.760678] [G loss: 0.951052] time: 0:03:24.767212\n",
      "0.9350222\n",
      "[Epoch 2/50] [Batch 73/300] [D loss: 0.760241] [G loss: 0.850555] time: 0:03:25.053062\n",
      "0.87127066\n",
      "[Epoch 2/50] [Batch 74/300] [D loss: 0.760326] [G loss: 0.858134] time: 0:03:25.356146\n",
      "0.88547295\n",
      "[Epoch 2/50] [Batch 75/300] [D loss: 0.760579] [G loss: 0.816674] time: 0:03:25.673911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91652054\n",
      "[Epoch 2/50] [Batch 76/300] [D loss: 0.760502] [G loss: 0.844941] time: 0:03:25.958874\n",
      "0.8792078\n",
      "[Epoch 2/50] [Batch 77/300] [D loss: 0.760425] [G loss: 0.875385] time: 0:03:26.274096\n",
      "0.90589666\n",
      "[Epoch 2/50] [Batch 78/300] [D loss: 0.760369] [G loss: 0.881676] time: 0:03:26.563025\n",
      "0.97564965\n",
      "[Epoch 2/50] [Batch 79/300] [D loss: 0.760235] [G loss: 0.849731] time: 0:03:26.861913\n",
      "0.9208068\n",
      "[Epoch 2/50] [Batch 80/300] [D loss: 0.760413] [G loss: 0.996732] time: 0:03:27.133758\n",
      "0.9156473\n",
      "[Epoch 2/50] [Batch 81/300] [D loss: 0.760493] [G loss: 0.938031] time: 0:03:27.560510\n",
      "0.91842765\n",
      "[Epoch 2/50] [Batch 82/300] [D loss: 0.760351] [G loss: 0.863552] time: 0:03:27.851166\n",
      "0.9403358\n",
      "[Epoch 2/50] [Batch 83/300] [D loss: 0.760855] [G loss: 0.808989] time: 0:03:28.140997\n",
      "0.8895979\n",
      "[Epoch 2/50] [Batch 84/300] [D loss: 0.760522] [G loss: 0.945101] time: 0:03:28.456816\n",
      "0.9061179\n",
      "[Epoch 2/50] [Batch 85/300] [D loss: 0.760563] [G loss: 1.109865] time: 0:03:28.765129\n",
      "0.861311\n",
      "[Epoch 2/50] [Batch 86/300] [D loss: 0.760234] [G loss: 1.034806] time: 0:03:29.085803\n",
      "0.9138468\n",
      "[Epoch 2/50] [Batch 87/300] [D loss: 0.760497] [G loss: 0.877042] time: 0:03:29.385433\n",
      "0.89150864\n",
      "[Epoch 2/50] [Batch 88/300] [D loss: 0.760091] [G loss: 0.833927] time: 0:03:29.686144\n",
      "0.9329602\n",
      "[Epoch 2/50] [Batch 89/300] [D loss: 0.760317] [G loss: 1.071271] time: 0:03:29.990593\n",
      "0.8971992\n",
      "[Epoch 2/50] [Batch 90/300] [D loss: 0.760378] [G loss: 0.990020] time: 0:03:30.276499\n",
      "0.9044173\n",
      "[Epoch 2/50] [Batch 91/300] [D loss: 0.760289] [G loss: 0.913774] time: 0:03:30.570512\n",
      "0.9135933\n",
      "[Epoch 2/50] [Batch 92/300] [D loss: 0.760288] [G loss: 0.875878] time: 0:03:30.833940\n",
      "0.8709633\n",
      "[Epoch 2/50] [Batch 93/300] [D loss: 0.760395] [G loss: 0.848501] time: 0:03:31.129007\n",
      "0.9378827\n",
      "[Epoch 2/50] [Batch 94/300] [D loss: 0.760370] [G loss: 1.017294] time: 0:03:31.430523\n",
      "0.884774\n",
      "[Epoch 2/50] [Batch 95/300] [D loss: 0.760081] [G loss: 0.838557] time: 0:03:31.753052\n",
      "0.9516575\n",
      "[Epoch 2/50] [Batch 96/300] [D loss: 0.760273] [G loss: 0.948791] time: 0:03:32.047528\n",
      "0.9288989\n",
      "[Epoch 2/50] [Batch 97/300] [D loss: 0.760234] [G loss: 1.059832] time: 0:03:32.334260\n",
      "0.9847844\n",
      "[Epoch 2/50] [Batch 98/300] [D loss: 0.760084] [G loss: 0.820050] time: 0:03:32.616556\n",
      "0.89538056\n",
      "[Epoch 2/50] [Batch 99/300] [D loss: 0.760234] [G loss: 0.736367] time: 0:03:32.898660\n",
      "0.8978121\n",
      "[Epoch 2/50] [Batch 100/300] [D loss: 0.760064] [G loss: 0.995861] time: 0:03:33.202341\n",
      "0.8912949\n",
      "[Epoch 2/50] [Batch 101/300] [D loss: 0.760157] [G loss: 0.815513] time: 0:03:33.497682\n",
      "0.90335625\n",
      "[Epoch 2/50] [Batch 102/300] [D loss: 0.760274] [G loss: 0.785655] time: 0:03:33.782743\n",
      "0.9058201\n",
      "[Epoch 2/50] [Batch 103/300] [D loss: 0.760300] [G loss: 0.884788] time: 0:03:34.081184\n",
      "0.8877732\n",
      "[Epoch 2/50] [Batch 104/300] [D loss: 0.760172] [G loss: 0.961151] time: 0:03:34.378610\n",
      "0.95984596\n",
      "[Epoch 2/50] [Batch 105/300] [D loss: 0.759963] [G loss: 0.869776] time: 0:03:34.676108\n",
      "0.88251805\n",
      "[Epoch 2/50] [Batch 106/300] [D loss: 0.760108] [G loss: 1.066989] time: 0:03:34.976924\n",
      "0.92229253\n",
      "[Epoch 2/50] [Batch 107/300] [D loss: 0.760158] [G loss: 0.902614] time: 0:03:35.282917\n",
      "0.91147596\n",
      "[Epoch 2/50] [Batch 108/300] [D loss: 0.760180] [G loss: 0.817872] time: 0:03:35.570942\n",
      "0.9451299\n",
      "[Epoch 2/50] [Batch 109/300] [D loss: 0.760136] [G loss: 0.951676] time: 0:03:35.853061\n",
      "0.9297786\n",
      "[Epoch 2/50] [Batch 110/300] [D loss: 0.760386] [G loss: 0.869791] time: 0:03:36.142188\n",
      "0.9309985\n",
      "[Epoch 2/50] [Batch 111/300] [D loss: 0.759887] [G loss: 0.866962] time: 0:03:36.421863\n",
      "0.94015723\n",
      "[Epoch 2/50] [Batch 112/300] [D loss: 0.759972] [G loss: 0.985170] time: 0:03:36.718663\n",
      "0.92489666\n",
      "[Epoch 2/50] [Batch 113/300] [D loss: 0.760098] [G loss: 0.910198] time: 0:03:37.016836\n",
      "0.9149793\n",
      "[Epoch 2/50] [Batch 114/300] [D loss: 0.760068] [G loss: 0.914577] time: 0:03:37.313981\n",
      "0.9180561\n",
      "[Epoch 2/50] [Batch 115/300] [D loss: 0.759999] [G loss: 0.840217] time: 0:03:37.597390\n",
      "0.98306394\n",
      "[Epoch 2/50] [Batch 116/300] [D loss: 0.760011] [G loss: 0.908359] time: 0:03:37.895033\n",
      "0.92706364\n",
      "[Epoch 2/50] [Batch 117/300] [D loss: 0.760216] [G loss: 0.934906] time: 0:03:38.186610\n",
      "0.8865776\n",
      "[Epoch 2/50] [Batch 118/300] [D loss: 0.760057] [G loss: 0.889959] time: 0:03:38.484813\n",
      "0.90744185\n",
      "[Epoch 2/50] [Batch 119/300] [D loss: 0.759838] [G loss: 0.997453] time: 0:03:38.784321\n",
      "0.91405183\n",
      "[Epoch 2/50] [Batch 120/300] [D loss: 0.759838] [G loss: 0.879147] time: 0:03:39.085176\n",
      "0.9389594\n",
      "[Epoch 2/50] [Batch 121/300] [D loss: 0.760009] [G loss: 0.880130] time: 0:03:39.361532\n",
      "0.94041544\n",
      "[Epoch 2/50] [Batch 122/300] [D loss: 0.759888] [G loss: 0.976702] time: 0:03:39.646613\n",
      "0.8991963\n",
      "[Epoch 2/50] [Batch 123/300] [D loss: 0.759949] [G loss: 0.845980] time: 0:03:39.946831\n",
      "0.9531944\n",
      "[Epoch 2/50] [Batch 124/300] [D loss: 0.759981] [G loss: 0.859430] time: 0:03:40.223592\n",
      "0.9237768\n",
      "[Epoch 2/50] [Batch 125/300] [D loss: 0.759819] [G loss: 1.018911] time: 0:03:40.509727\n",
      "0.9540933\n",
      "[Epoch 2/50] [Batch 126/300] [D loss: 0.759982] [G loss: 0.986524] time: 0:03:40.808917\n",
      "0.9197523\n",
      "[Epoch 2/50] [Batch 127/300] [D loss: 0.760244] [G loss: 0.859690] time: 0:03:41.110811\n",
      "0.88864225\n",
      "[Epoch 2/50] [Batch 128/300] [D loss: 0.760044] [G loss: 0.977771] time: 0:03:41.408548\n",
      "0.89516956\n",
      "[Epoch 2/50] [Batch 129/300] [D loss: 0.760043] [G loss: 1.018692] time: 0:03:41.703011\n",
      "0.9486454\n",
      "[Epoch 2/50] [Batch 130/300] [D loss: 0.759750] [G loss: 0.808851] time: 0:03:42.009741\n",
      "0.8766687\n",
      "[Epoch 2/50] [Batch 131/300] [D loss: 0.760011] [G loss: 0.962012] time: 0:03:42.314125\n",
      "0.9313628\n",
      "[Epoch 2/50] [Batch 132/300] [D loss: 0.759687] [G loss: 0.665011] time: 0:03:42.609563\n",
      "0.9463105\n",
      "[Epoch 2/50] [Batch 133/300] [D loss: 0.759667] [G loss: 0.915268] time: 0:03:42.908567\n",
      "0.9457459\n",
      "[Epoch 2/50] [Batch 134/300] [D loss: 0.759820] [G loss: 0.997852] time: 0:03:43.204277\n",
      "0.883419\n",
      "[Epoch 2/50] [Batch 135/300] [D loss: 0.759693] [G loss: 0.967010] time: 0:03:43.500556\n",
      "0.93162084\n",
      "[Epoch 2/50] [Batch 136/300] [D loss: 0.759810] [G loss: 0.937221] time: 0:03:43.798620\n",
      "0.9237692\n",
      "[Epoch 2/50] [Batch 137/300] [D loss: 0.759687] [G loss: 0.990473] time: 0:03:44.102051\n",
      "0.9172506\n",
      "[Epoch 2/50] [Batch 138/300] [D loss: 0.759807] [G loss: 0.879977] time: 0:03:44.397888\n",
      "0.88491154\n",
      "[Epoch 2/50] [Batch 139/300] [D loss: 0.759273] [G loss: 1.001751] time: 0:03:44.687569\n",
      "0.9043908\n",
      "[Epoch 2/50] [Batch 140/300] [D loss: 0.759829] [G loss: 0.914856] time: 0:03:44.993513\n",
      "0.8879826\n",
      "[Epoch 2/50] [Batch 141/300] [D loss: 0.759786] [G loss: 0.920206] time: 0:03:45.301006\n",
      "0.8370795\n",
      "[Epoch 2/50] [Batch 142/300] [D loss: 0.759846] [G loss: 1.015194] time: 0:03:45.601872\n",
      "0.90627176\n",
      "[Epoch 2/50] [Batch 143/300] [D loss: 0.759250] [G loss: 0.926950] time: 0:03:45.885773\n",
      "0.9177642\n",
      "[Epoch 2/50] [Batch 144/300] [D loss: 0.759677] [G loss: 0.948777] time: 0:03:46.188702\n",
      "0.9158392\n",
      "[Epoch 2/50] [Batch 145/300] [D loss: 0.759686] [G loss: 0.970785] time: 0:03:46.484923\n",
      "0.92297333\n",
      "[Epoch 2/50] [Batch 146/300] [D loss: 0.759722] [G loss: 0.920311] time: 0:03:46.787939\n",
      "0.9088232\n",
      "[Epoch 2/50] [Batch 147/300] [D loss: 0.759535] [G loss: 0.788367] time: 0:03:47.061747\n",
      "0.90779155\n",
      "[Epoch 2/50] [Batch 148/300] [D loss: 0.759660] [G loss: 0.992891] time: 0:03:47.362106\n",
      "0.9051675\n",
      "[Epoch 2/50] [Batch 149/300] [D loss: 0.759792] [G loss: 0.967918] time: 0:03:47.654434\n",
      "0.934997\n",
      "[Epoch 2/50] [Batch 150/300] [D loss: 0.759896] [G loss: 0.920758] time: 0:03:47.933428\n",
      "0.8829529\n",
      "[Epoch 2/50] [Batch 151/300] [D loss: 0.759478] [G loss: 0.836279] time: 0:03:48.227716\n",
      "0.9420939\n",
      "[Epoch 2/50] [Batch 152/300] [D loss: 0.759728] [G loss: 1.045430] time: 0:03:48.520585\n",
      "0.94795233\n",
      "[Epoch 2/50] [Batch 153/300] [D loss: 0.759669] [G loss: 0.960061] time: 0:03:48.822444\n",
      "0.9177657\n",
      "[Epoch 2/50] [Batch 154/300] [D loss: 0.759607] [G loss: 0.877941] time: 0:03:49.116153\n",
      "0.9074977\n",
      "[Epoch 2/50] [Batch 155/300] [D loss: 0.759562] [G loss: 1.132225] time: 0:03:49.426859\n",
      "0.91835135\n",
      "[Epoch 2/50] [Batch 156/300] [D loss: 0.759454] [G loss: 0.895777] time: 0:03:49.732984\n",
      "0.91980296\n",
      "[Epoch 2/50] [Batch 157/300] [D loss: 0.759236] [G loss: 1.020912] time: 0:03:50.041277\n",
      "0.93453044\n",
      "[Epoch 2/50] [Batch 158/300] [D loss: 0.759578] [G loss: 0.844738] time: 0:03:50.341853\n",
      "0.9452335\n",
      "[Epoch 2/50] [Batch 159/300] [D loss: 0.759423] [G loss: 1.016867] time: 0:03:50.630456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8842017\n",
      "[Epoch 2/50] [Batch 160/300] [D loss: 0.759673] [G loss: 1.031561] time: 0:03:50.913801\n",
      "0.9387699\n",
      "[Epoch 2/50] [Batch 161/300] [D loss: 0.759508] [G loss: 0.752669] time: 0:03:51.215249\n",
      "0.8981137\n",
      "[Epoch 2/50] [Batch 162/300] [D loss: 0.759441] [G loss: 1.004155] time: 0:03:51.497943\n",
      "0.8936947\n",
      "[Epoch 2/50] [Batch 163/300] [D loss: 0.759445] [G loss: 1.010778] time: 0:03:51.805544\n",
      "0.8553801\n",
      "[Epoch 2/50] [Batch 164/300] [D loss: 0.759403] [G loss: 1.087131] time: 0:03:52.090536\n",
      "0.930614\n",
      "[Epoch 2/50] [Batch 165/300] [D loss: 0.759373] [G loss: 1.000955] time: 0:03:52.398100\n",
      "0.8542512\n",
      "[Epoch 2/50] [Batch 166/300] [D loss: 0.759727] [G loss: 0.934770] time: 0:03:52.696783\n",
      "0.8999939\n",
      "[Epoch 2/50] [Batch 167/300] [D loss: 0.759283] [G loss: 0.816139] time: 0:03:53.000395\n",
      "0.92466086\n",
      "[Epoch 2/50] [Batch 168/300] [D loss: 0.759534] [G loss: 1.023584] time: 0:03:53.300276\n",
      "0.86507624\n",
      "[Epoch 2/50] [Batch 169/300] [D loss: 0.759355] [G loss: 0.970780] time: 0:03:53.595878\n",
      "0.92632216\n",
      "[Epoch 2/50] [Batch 170/300] [D loss: 0.759431] [G loss: 0.913141] time: 0:03:53.905723\n",
      "0.93823385\n",
      "[Epoch 2/50] [Batch 171/300] [D loss: 0.759597] [G loss: 1.003272] time: 0:03:54.197144\n",
      "0.9301937\n",
      "[Epoch 2/50] [Batch 172/300] [D loss: 0.759652] [G loss: 0.841769] time: 0:03:54.494290\n",
      "0.8466132\n",
      "[Epoch 2/50] [Batch 173/300] [D loss: 0.759455] [G loss: 1.030095] time: 0:03:54.796509\n",
      "0.9342682\n",
      "[Epoch 2/50] [Batch 174/300] [D loss: 0.759301] [G loss: 0.878976] time: 0:03:55.103551\n",
      "0.8793326\n",
      "[Epoch 2/50] [Batch 175/300] [D loss: 0.759504] [G loss: 0.811382] time: 0:03:55.378856\n",
      "0.9361816\n",
      "[Epoch 2/50] [Batch 176/300] [D loss: 0.759501] [G loss: 0.910360] time: 0:03:55.682781\n",
      "0.89766616\n",
      "[Epoch 2/50] [Batch 177/300] [D loss: 0.759434] [G loss: 0.993676] time: 0:03:55.984345\n",
      "0.94285107\n",
      "[Epoch 2/50] [Batch 178/300] [D loss: 0.759252] [G loss: 0.858248] time: 0:03:56.279801\n",
      "0.90326065\n",
      "[Epoch 2/50] [Batch 179/300] [D loss: 0.759434] [G loss: 0.892081] time: 0:03:56.571405\n",
      "0.9200253\n",
      "[Epoch 2/50] [Batch 180/300] [D loss: 0.759400] [G loss: 0.867393] time: 0:03:56.886602\n",
      "0.9307439\n",
      "[Epoch 2/50] [Batch 181/300] [D loss: 0.759526] [G loss: 0.905726] time: 0:03:57.160333\n",
      "0.89999133\n",
      "[Epoch 2/50] [Batch 182/300] [D loss: 0.759194] [G loss: 0.994974] time: 0:03:57.452458\n",
      "0.91523284\n",
      "[Epoch 2/50] [Batch 183/300] [D loss: 0.759088] [G loss: 0.937706] time: 0:03:57.765440\n",
      "0.9691209\n",
      "[Epoch 2/50] [Batch 184/300] [D loss: 0.758906] [G loss: 0.973397] time: 0:03:58.053748\n",
      "0.9149785\n",
      "[Epoch 2/50] [Batch 185/300] [D loss: 0.759214] [G loss: 0.976673] time: 0:03:58.362830\n",
      "0.9075281\n",
      "[Epoch 2/50] [Batch 186/300] [D loss: 0.759100] [G loss: 0.717488] time: 0:03:58.645256\n",
      "0.88147926\n",
      "[Epoch 2/50] [Batch 187/300] [D loss: 0.759296] [G loss: 0.888429] time: 0:03:58.926369\n",
      "0.8847447\n",
      "[Epoch 2/50] [Batch 188/300] [D loss: 0.758989] [G loss: 0.914790] time: 0:03:59.214736\n",
      "0.8792965\n",
      "[Epoch 2/50] [Batch 189/300] [D loss: 0.759080] [G loss: 1.009273] time: 0:03:59.509560\n",
      "0.90606195\n",
      "[Epoch 2/50] [Batch 190/300] [D loss: 0.759186] [G loss: 0.981941] time: 0:03:59.821714\n",
      "0.92297214\n",
      "[Epoch 2/50] [Batch 191/300] [D loss: 0.759158] [G loss: 0.982549] time: 0:04:00.129796\n",
      "0.8730507\n",
      "[Epoch 2/50] [Batch 192/300] [D loss: 0.759491] [G loss: 0.896043] time: 0:04:00.423925\n",
      "0.9265797\n",
      "[Epoch 2/50] [Batch 193/300] [D loss: 0.759208] [G loss: 0.958864] time: 0:04:00.721466\n",
      "0.9556799\n",
      "[Epoch 2/50] [Batch 194/300] [D loss: 0.759081] [G loss: 0.918696] time: 0:04:01.009045\n",
      "0.8758134\n",
      "[Epoch 2/50] [Batch 195/300] [D loss: 0.758989] [G loss: 0.952224] time: 0:04:01.305977\n",
      "0.9165742\n",
      "[Epoch 2/50] [Batch 196/300] [D loss: 0.759111] [G loss: 0.974841] time: 0:04:01.609359\n",
      "0.9683805\n",
      "[Epoch 2/50] [Batch 197/300] [D loss: 0.759106] [G loss: 0.856545] time: 0:04:01.912634\n",
      "0.8962245\n",
      "[Epoch 2/50] [Batch 198/300] [D loss: 0.759095] [G loss: 1.123848] time: 0:04:02.202824\n",
      "0.9165826\n",
      "[Epoch 2/50] [Batch 199/300] [D loss: 0.758903] [G loss: 1.038714] time: 0:04:02.490662\n",
      "0.86472434\n",
      "[Epoch 2/50] [Batch 200/300] [D loss: 0.759078] [G loss: 0.947893] time: 0:04:02.792265\n",
      "0.9071994\n",
      "[Epoch 2/50] [Batch 201/300] [D loss: 0.759364] [G loss: 0.827522] time: 0:04:03.102568\n",
      "0.94201154\n",
      "[Epoch 2/50] [Batch 202/300] [D loss: 0.759057] [G loss: 0.845247] time: 0:04:03.411029\n",
      "0.906765\n",
      "[Epoch 2/50] [Batch 203/300] [D loss: 0.759076] [G loss: 1.005648] time: 0:04:03.720129\n",
      "0.91052157\n",
      "[Epoch 2/50] [Batch 204/300] [D loss: 0.759187] [G loss: 0.900513] time: 0:04:04.027874\n",
      "0.91295844\n",
      "[Epoch 2/50] [Batch 205/300] [D loss: 0.758948] [G loss: 0.990490] time: 0:04:04.328322\n",
      "0.8981662\n",
      "[Epoch 2/50] [Batch 206/300] [D loss: 0.758871] [G loss: 0.996723] time: 0:04:04.620781\n",
      "0.9252755\n",
      "[Epoch 2/50] [Batch 207/300] [D loss: 0.759215] [G loss: 0.847048] time: 0:04:04.923380\n",
      "0.91984695\n",
      "[Epoch 2/50] [Batch 208/300] [D loss: 0.759116] [G loss: 0.797887] time: 0:04:05.219303\n",
      "0.8953647\n",
      "[Epoch 2/50] [Batch 209/300] [D loss: 0.759076] [G loss: 0.883239] time: 0:04:05.524175\n",
      "0.9184688\n",
      "[Epoch 2/50] [Batch 210/300] [D loss: 0.759011] [G loss: 1.130745] time: 0:04:05.802040\n",
      "0.96072584\n",
      "[Epoch 2/50] [Batch 211/300] [D loss: 0.759057] [G loss: 0.967977] time: 0:04:06.081060\n",
      "0.9015332\n",
      "[Epoch 2/50] [Batch 212/300] [D loss: 0.758897] [G loss: 0.786776] time: 0:04:06.378846\n",
      "0.88310844\n",
      "[Epoch 2/50] [Batch 213/300] [D loss: 0.759062] [G loss: 1.011408] time: 0:04:06.677451\n",
      "0.9184601\n",
      "[Epoch 2/50] [Batch 214/300] [D loss: 0.758937] [G loss: 0.843094] time: 0:04:06.968861\n",
      "0.85394627\n",
      "[Epoch 2/50] [Batch 215/300] [D loss: 0.759079] [G loss: 0.791907] time: 0:04:07.262940\n",
      "0.9242387\n",
      "[Epoch 2/50] [Batch 216/300] [D loss: 0.758986] [G loss: 0.806301] time: 0:04:07.555854\n",
      "0.88218635\n",
      "[Epoch 2/50] [Batch 217/300] [D loss: 0.758925] [G loss: 0.925037] time: 0:04:07.865331\n",
      "0.8804261\n",
      "[Epoch 2/50] [Batch 218/300] [D loss: 0.759217] [G loss: 0.884065] time: 0:04:08.160122\n",
      "0.8675618\n",
      "[Epoch 2/50] [Batch 219/300] [D loss: 0.758976] [G loss: 1.044597] time: 0:04:08.446618\n",
      "0.9335995\n",
      "[Epoch 2/50] [Batch 220/300] [D loss: 0.758898] [G loss: 0.960352] time: 0:04:08.758717\n",
      "0.880661\n",
      "[Epoch 2/50] [Batch 221/300] [D loss: 0.758827] [G loss: 0.889061] time: 0:04:09.027798\n",
      "0.9038289\n",
      "[Epoch 2/50] [Batch 222/300] [D loss: 0.758878] [G loss: 0.942369] time: 0:04:09.312236\n",
      "0.8633809\n",
      "[Epoch 2/50] [Batch 223/300] [D loss: 0.758869] [G loss: 0.831825] time: 0:04:09.600344\n",
      "0.90653896\n",
      "[Epoch 2/50] [Batch 224/300] [D loss: 0.758691] [G loss: 0.893683] time: 0:04:09.912061\n",
      "0.9348952\n",
      "[Epoch 2/50] [Batch 225/300] [D loss: 0.758900] [G loss: 1.023740] time: 0:04:10.210357\n",
      "0.9442335\n",
      "[Epoch 2/50] [Batch 226/300] [D loss: 0.759024] [G loss: 0.797009] time: 0:04:10.524494\n",
      "0.9437828\n",
      "[Epoch 2/50] [Batch 227/300] [D loss: 0.758903] [G loss: 0.829019] time: 0:04:10.820677\n",
      "0.93041784\n",
      "[Epoch 2/50] [Batch 228/300] [D loss: 0.758875] [G loss: 0.852477] time: 0:04:11.093579\n",
      "0.9162519\n",
      "[Epoch 2/50] [Batch 229/300] [D loss: 0.759035] [G loss: 0.884184] time: 0:04:11.380131\n",
      "0.8766079\n",
      "[Epoch 2/50] [Batch 230/300] [D loss: 0.758951] [G loss: 0.895951] time: 0:04:11.685520\n",
      "0.907262\n",
      "[Epoch 2/50] [Batch 231/300] [D loss: 0.758775] [G loss: 1.024108] time: 0:04:11.963679\n",
      "0.94189334\n",
      "[Epoch 2/50] [Batch 232/300] [D loss: 0.758836] [G loss: 0.865284] time: 0:04:12.256084\n",
      "0.85088605\n",
      "[Epoch 2/50] [Batch 233/300] [D loss: 0.758792] [G loss: 1.008121] time: 0:04:12.540682\n",
      "0.9146604\n",
      "[Epoch 2/50] [Batch 234/300] [D loss: 0.758745] [G loss: 0.992717] time: 0:04:12.827250\n",
      "0.91258603\n",
      "[Epoch 2/50] [Batch 235/300] [D loss: 0.758818] [G loss: 0.826058] time: 0:04:13.125519\n",
      "0.8976539\n",
      "[Epoch 2/50] [Batch 236/300] [D loss: 0.758786] [G loss: 1.087580] time: 0:04:13.425335\n",
      "0.8972308\n",
      "[Epoch 2/50] [Batch 237/300] [D loss: 0.758601] [G loss: 0.797035] time: 0:04:13.722474\n",
      "0.87655354\n",
      "[Epoch 2/50] [Batch 238/300] [D loss: 0.758767] [G loss: 0.931673] time: 0:04:14.026232\n",
      "0.8759423\n",
      "[Epoch 2/50] [Batch 239/300] [D loss: 0.758748] [G loss: 0.933185] time: 0:04:14.330713\n",
      "0.9007166\n",
      "[Epoch 2/50] [Batch 240/300] [D loss: 0.758663] [G loss: 1.071545] time: 0:04:14.638430\n",
      "0.9296405\n",
      "[Epoch 2/50] [Batch 241/300] [D loss: 0.758782] [G loss: 0.898908] time: 0:04:14.935598\n",
      "0.904509\n",
      "[Epoch 2/50] [Batch 242/300] [D loss: 0.758731] [G loss: 1.103652] time: 0:04:15.228972\n",
      "0.91483265\n",
      "[Epoch 2/50] [Batch 243/300] [D loss: 0.758753] [G loss: 1.001746] time: 0:04:15.533905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8961697\n",
      "[Epoch 2/50] [Batch 244/300] [D loss: 0.758632] [G loss: 0.883550] time: 0:04:15.831487\n",
      "0.92239934\n",
      "[Epoch 2/50] [Batch 245/300] [D loss: 0.758832] [G loss: 0.991215] time: 0:04:16.100711\n",
      "0.89857125\n",
      "[Epoch 2/50] [Batch 246/300] [D loss: 0.758787] [G loss: 0.933344] time: 0:04:16.408133\n",
      "0.9247353\n",
      "[Epoch 2/50] [Batch 247/300] [D loss: 0.758574] [G loss: 0.956372] time: 0:04:16.700019\n",
      "0.9030466\n",
      "[Epoch 2/50] [Batch 248/300] [D loss: 0.758763] [G loss: 0.910964] time: 0:04:16.992502\n",
      "0.90476316\n",
      "[Epoch 2/50] [Batch 249/300] [D loss: 0.758740] [G loss: 0.774379] time: 0:04:17.277940\n",
      "0.912134\n",
      "[Epoch 2/50] [Batch 250/300] [D loss: 0.758742] [G loss: 0.966978] time: 0:04:17.593005\n",
      "0.9126975\n",
      "[Epoch 2/50] [Batch 251/300] [D loss: 0.758689] [G loss: 0.872230] time: 0:04:17.865139\n",
      "0.9332891\n",
      "[Epoch 2/50] [Batch 252/300] [D loss: 0.758714] [G loss: 0.857045] time: 0:04:18.157922\n",
      "0.91436625\n",
      "[Epoch 2/50] [Batch 253/300] [D loss: 0.758709] [G loss: 0.841110] time: 0:04:18.459383\n",
      "0.9452887\n",
      "[Epoch 2/50] [Batch 254/300] [D loss: 0.758850] [G loss: 0.939291] time: 0:04:18.767493\n",
      "0.95180297\n",
      "[Epoch 2/50] [Batch 255/300] [D loss: 0.758662] [G loss: 0.883081] time: 0:04:19.041282\n",
      "0.923652\n",
      "[Epoch 2/50] [Batch 256/300] [D loss: 0.758745] [G loss: 0.897855] time: 0:04:19.318335\n",
      "0.890172\n",
      "[Epoch 2/50] [Batch 257/300] [D loss: 0.758467] [G loss: 1.011734] time: 0:04:19.603831\n",
      "0.88612986\n",
      "[Epoch 2/50] [Batch 258/300] [D loss: 0.758628] [G loss: 0.991881] time: 0:04:19.890510\n",
      "0.88597465\n",
      "[Epoch 2/50] [Batch 259/300] [D loss: 0.758755] [G loss: 0.840154] time: 0:04:20.179133\n",
      "0.9206683\n",
      "[Epoch 2/50] [Batch 260/300] [D loss: 0.758677] [G loss: 0.964762] time: 0:04:20.475902\n",
      "0.90930563\n",
      "[Epoch 2/50] [Batch 261/300] [D loss: 0.758501] [G loss: 0.786296] time: 0:04:20.778638\n",
      "0.90139407\n",
      "[Epoch 2/50] [Batch 262/300] [D loss: 0.758527] [G loss: 0.921834] time: 0:04:21.069557\n",
      "0.938286\n",
      "[Epoch 2/50] [Batch 263/300] [D loss: 0.758259] [G loss: 0.964143] time: 0:04:21.366155\n",
      "0.90491074\n",
      "[Epoch 2/50] [Batch 264/300] [D loss: 0.758505] [G loss: 0.886789] time: 0:04:21.666324\n",
      "0.88003665\n",
      "[Epoch 2/50] [Batch 265/300] [D loss: 0.758547] [G loss: 0.959024] time: 0:04:21.977564\n",
      "0.8652227\n",
      "[Epoch 2/50] [Batch 266/300] [D loss: 0.758540] [G loss: 0.995642] time: 0:04:22.274404\n",
      "0.9488125\n",
      "[Epoch 2/50] [Batch 267/300] [D loss: 0.758716] [G loss: 0.911159] time: 0:04:22.577316\n",
      "0.9107875\n",
      "[Epoch 2/50] [Batch 268/300] [D loss: 0.758379] [G loss: 0.883758] time: 0:04:22.871665\n",
      "0.8364069\n",
      "[Epoch 2/50] [Batch 269/300] [D loss: 0.758597] [G loss: 1.077625] time: 0:04:23.164246\n",
      "0.8674893\n",
      "[Epoch 2/50] [Batch 270/300] [D loss: 0.758227] [G loss: 0.787491] time: 0:04:23.464347\n",
      "0.92559665\n",
      "[Epoch 2/50] [Batch 271/300] [D loss: 0.758478] [G loss: 0.856528] time: 0:04:23.769741\n",
      "0.93140763\n",
      "[Epoch 2/50] [Batch 272/300] [D loss: 0.758406] [G loss: 0.936461] time: 0:04:24.061399\n",
      "0.9136097\n",
      "[Epoch 2/50] [Batch 273/300] [D loss: 0.758281] [G loss: 0.891883] time: 0:04:24.353330\n",
      "0.9386495\n",
      "[Epoch 2/50] [Batch 274/300] [D loss: 0.758606] [G loss: 0.938473] time: 0:04:24.660761\n",
      "0.9176577\n",
      "[Epoch 2/50] [Batch 275/300] [D loss: 0.758588] [G loss: 0.876531] time: 0:04:24.960493\n",
      "0.94050837\n",
      "[Epoch 2/50] [Batch 276/300] [D loss: 0.758537] [G loss: 0.762796] time: 0:04:25.271701\n",
      "0.9263628\n",
      "[Epoch 2/50] [Batch 277/300] [D loss: 0.758436] [G loss: 0.919852] time: 0:04:25.573442\n",
      "0.86919075\n",
      "[Epoch 2/50] [Batch 278/300] [D loss: 0.758344] [G loss: 0.930542] time: 0:04:25.886504\n",
      "0.930839\n",
      "[Epoch 2/50] [Batch 279/300] [D loss: 0.758582] [G loss: 0.923105] time: 0:04:26.189120\n",
      "0.8991217\n",
      "[Epoch 2/50] [Batch 280/300] [D loss: 0.758432] [G loss: 0.816183] time: 0:04:26.491481\n",
      "0.9465287\n",
      "[Epoch 2/50] [Batch 281/300] [D loss: 0.758232] [G loss: 0.963550] time: 0:04:26.796542\n",
      "0.93059903\n",
      "[Epoch 2/50] [Batch 282/300] [D loss: 0.758485] [G loss: 1.081984] time: 0:04:27.082625\n",
      "0.9501634\n",
      "[Epoch 2/50] [Batch 283/300] [D loss: 0.758358] [G loss: 0.875445] time: 0:04:27.388015\n",
      "0.9296654\n",
      "[Epoch 2/50] [Batch 284/300] [D loss: 0.758580] [G loss: 0.951931] time: 0:04:27.679953\n",
      "0.83656424\n",
      "[Epoch 2/50] [Batch 285/300] [D loss: 0.758261] [G loss: 0.884296] time: 0:04:27.969123\n",
      "0.97268134\n",
      "[Epoch 2/50] [Batch 286/300] [D loss: 0.758618] [G loss: 0.815846] time: 0:04:28.277263\n",
      "0.8785475\n",
      "[Epoch 2/50] [Batch 287/300] [D loss: 0.758332] [G loss: 1.155388] time: 0:04:28.579876\n",
      "0.9400653\n",
      "[Epoch 2/50] [Batch 288/300] [D loss: 0.758331] [G loss: 0.972644] time: 0:04:28.880333\n",
      "0.9371051\n",
      "[Epoch 2/50] [Batch 289/300] [D loss: 0.758144] [G loss: 0.919587] time: 0:04:29.181681\n",
      "0.91859657\n",
      "[Epoch 2/50] [Batch 290/300] [D loss: 0.758338] [G loss: 0.896969] time: 0:04:29.492573\n",
      "0.96215695\n",
      "[Epoch 2/50] [Batch 291/300] [D loss: 0.758363] [G loss: 0.888826] time: 0:04:29.788663\n",
      "0.9295514\n",
      "[Epoch 2/50] [Batch 292/300] [D loss: 0.758346] [G loss: 0.954326] time: 0:04:30.088986\n",
      "0.91587067\n",
      "[Epoch 2/50] [Batch 293/300] [D loss: 0.758321] [G loss: 0.871246] time: 0:04:30.385800\n",
      "0.86615115\n",
      "[Epoch 2/50] [Batch 294/300] [D loss: 0.758157] [G loss: 0.916927] time: 0:04:30.680099\n",
      "0.8701577\n",
      "[Epoch 2/50] [Batch 295/300] [D loss: 0.758442] [G loss: 0.874110] time: 0:04:30.977143\n",
      "0.9382208\n",
      "[Epoch 2/50] [Batch 296/300] [D loss: 0.758066] [G loss: 0.848583] time: 0:04:31.270664\n",
      "0.885506\n",
      "[Epoch 2/50] [Batch 297/300] [D loss: 0.758349] [G loss: 1.004051] time: 0:04:31.562129\n",
      "0.91045046\n",
      "[Epoch 2/50] [Batch 298/300] [D loss: 0.758173] [G loss: 0.962268] time: 0:04:31.870436\n",
      "0.94690824\n",
      "[Epoch 2/50] [Batch 299/300] [D loss: 0.758274] [G loss: 0.947132] time: 0:04:32.171470\n",
      "0.8873735\n",
      "[Epoch 3/50] [Batch 0/300] [D loss: 0.758166] [G loss: 0.894693] time: 0:04:32.474886\n",
      "0.92027444\n",
      "[Epoch 3/50] [Batch 1/300] [D loss: 0.758214] [G loss: 0.885814] time: 0:04:32.773066\n",
      "0.951183\n",
      "[Epoch 3/50] [Batch 3/300] [D loss: 0.758240] [G loss: 0.943905] time: 0:04:33.061136\n",
      "0.8995314\n",
      "[Epoch 3/50] [Batch 4/300] [D loss: 0.758260] [G loss: 0.772839] time: 0:04:33.356680\n",
      "0.90806055\n",
      "[Epoch 3/50] [Batch 5/300] [D loss: 0.758104] [G loss: 0.937741] time: 0:04:33.656750\n",
      "0.89132756\n",
      "[Epoch 3/50] [Batch 6/300] [D loss: 0.758167] [G loss: 0.935228] time: 0:04:33.971441\n",
      "0.93903166\n",
      "[Epoch 3/50] [Batch 7/300] [D loss: 0.758270] [G loss: 1.138342] time: 0:04:34.271952\n",
      "0.93551224\n",
      "[Epoch 3/50] [Batch 8/300] [D loss: 0.758094] [G loss: 0.867500] time: 0:04:34.577735\n",
      "0.9293186\n",
      "[Epoch 3/50] [Batch 9/300] [D loss: 0.758354] [G loss: 1.021439] time: 0:04:34.871368\n",
      "0.91035\n",
      "[Epoch 3/50] [Batch 10/300] [D loss: 0.758210] [G loss: 0.995241] time: 0:04:35.155539\n",
      "0.96066046\n",
      "[Epoch 3/50] [Batch 11/300] [D loss: 0.758121] [G loss: 1.014103] time: 0:04:35.448322\n",
      "0.9349491\n",
      "[Epoch 3/50] [Batch 12/300] [D loss: 0.758322] [G loss: 0.951408] time: 0:04:35.735414\n",
      "0.90156\n",
      "[Epoch 3/50] [Batch 13/300] [D loss: 0.758036] [G loss: 0.923096] time: 0:04:36.024249\n",
      "0.8775011\n",
      "[Epoch 3/50] [Batch 14/300] [D loss: 0.758172] [G loss: 0.911933] time: 0:04:36.315448\n",
      "0.93528897\n",
      "[Epoch 3/50] [Batch 15/300] [D loss: 0.758234] [G loss: 0.873630] time: 0:04:36.611611\n",
      "0.9077057\n",
      "[Epoch 3/50] [Batch 16/300] [D loss: 0.757942] [G loss: 0.963732] time: 0:04:36.905585\n",
      "0.95039386\n",
      "[Epoch 3/50] [Batch 17/300] [D loss: 0.758276] [G loss: 0.806850] time: 0:04:37.192629\n",
      "0.8923013\n",
      "[Epoch 3/50] [Batch 18/300] [D loss: 0.757950] [G loss: 0.848578] time: 0:04:37.485654\n",
      "0.90826625\n",
      "[Epoch 3/50] [Batch 19/300] [D loss: 0.758344] [G loss: 0.781209] time: 0:04:37.781449\n",
      "0.9173153\n",
      "[Epoch 3/50] [Batch 20/300] [D loss: 0.757931] [G loss: 0.829622] time: 0:04:38.069747\n",
      "0.89836544\n",
      "[Epoch 3/50] [Batch 21/300] [D loss: 0.758089] [G loss: 1.011740] time: 0:04:38.368212\n",
      "0.92604965\n",
      "[Epoch 3/50] [Batch 22/300] [D loss: 0.757875] [G loss: 0.941698] time: 0:04:38.662543\n",
      "0.9287922\n",
      "[Epoch 3/50] [Batch 23/300] [D loss: 0.758087] [G loss: 0.954053] time: 0:04:38.949469\n",
      "0.95886374\n",
      "[Epoch 3/50] [Batch 24/300] [D loss: 0.758046] [G loss: 0.898441] time: 0:04:39.226425\n",
      "0.94317275\n",
      "[Epoch 3/50] [Batch 25/300] [D loss: 0.758099] [G loss: 1.119698] time: 0:04:39.494601\n",
      "0.8985462\n",
      "[Epoch 3/50] [Batch 26/300] [D loss: 0.758260] [G loss: 0.905822] time: 0:04:39.789944\n",
      "0.9708336\n",
      "[Epoch 3/50] [Batch 27/300] [D loss: 0.758187] [G loss: 0.932085] time: 0:04:40.081553\n",
      "0.91372055\n",
      "[Epoch 3/50] [Batch 28/300] [D loss: 0.758064] [G loss: 0.948833] time: 0:04:40.374026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205518\n",
      "[Epoch 3/50] [Batch 29/300] [D loss: 0.758050] [G loss: 0.735278] time: 0:04:40.672445\n",
      "0.8975353\n",
      "[Epoch 3/50] [Batch 30/300] [D loss: 0.758212] [G loss: 1.009261] time: 0:04:40.968939\n",
      "0.8703967\n",
      "[Epoch 3/50] [Batch 31/300] [D loss: 0.758025] [G loss: 0.833649] time: 0:04:41.268107\n",
      "0.9447332\n",
      "[Epoch 3/50] [Batch 32/300] [D loss: 0.758122] [G loss: 0.881201] time: 0:04:41.560274\n",
      "0.9151227\n",
      "[Epoch 3/50] [Batch 33/300] [D loss: 0.757952] [G loss: 0.939871] time: 0:04:41.854892\n",
      "0.90573245\n",
      "[Epoch 3/50] [Batch 34/300] [D loss: 0.758129] [G loss: 0.905997] time: 0:04:42.148442\n",
      "0.89480615\n",
      "[Epoch 3/50] [Batch 35/300] [D loss: 0.758015] [G loss: 0.896217] time: 0:04:42.453577\n",
      "0.86738557\n",
      "[Epoch 3/50] [Batch 36/300] [D loss: 0.757995] [G loss: 0.973931] time: 0:04:42.763437\n",
      "0.93376845\n",
      "[Epoch 3/50] [Batch 37/300] [D loss: 0.758043] [G loss: 0.884761] time: 0:04:43.058796\n",
      "0.9768886\n",
      "[Epoch 3/50] [Batch 38/300] [D loss: 0.757948] [G loss: 0.802965] time: 0:04:43.342804\n",
      "0.9218152\n",
      "[Epoch 3/50] [Batch 39/300] [D loss: 0.758056] [G loss: 0.763943] time: 0:04:43.642171\n",
      "0.9049743\n",
      "[Epoch 3/50] [Batch 40/300] [D loss: 0.757991] [G loss: 0.783350] time: 0:04:43.923947\n",
      "0.9114713\n",
      "[Epoch 3/50] [Batch 41/300] [D loss: 0.757984] [G loss: 0.862933] time: 0:04:44.226964\n",
      "0.86475784\n",
      "[Epoch 3/50] [Batch 42/300] [D loss: 0.758091] [G loss: 1.004425] time: 0:04:44.523096\n",
      "0.87277347\n",
      "[Epoch 3/50] [Batch 43/300] [D loss: 0.758049] [G loss: 0.933687] time: 0:04:44.816955\n",
      "0.9276683\n",
      "[Epoch 3/50] [Batch 44/300] [D loss: 0.757953] [G loss: 0.798020] time: 0:04:45.124432\n",
      "0.96747464\n",
      "[Epoch 3/50] [Batch 45/300] [D loss: 0.757936] [G loss: 0.821421] time: 0:04:45.408265\n",
      "0.86733454\n",
      "[Epoch 3/50] [Batch 46/300] [D loss: 0.758032] [G loss: 0.906283] time: 0:04:45.706067\n",
      "0.9214838\n",
      "[Epoch 3/50] [Batch 47/300] [D loss: 0.757859] [G loss: 0.901009] time: 0:04:46.021518\n",
      "0.9216425\n",
      "[Epoch 3/50] [Batch 48/300] [D loss: 0.758051] [G loss: 0.918317] time: 0:04:46.322430\n",
      "0.9216637\n",
      "[Epoch 3/50] [Batch 49/300] [D loss: 0.758003] [G loss: 1.066811] time: 0:04:46.621728\n",
      "0.9205963\n",
      "[Epoch 3/50] [Batch 50/300] [D loss: 0.757683] [G loss: 0.957465] time: 0:04:46.903769\n",
      "0.9288225\n",
      "[Epoch 3/50] [Batch 51/300] [D loss: 0.757803] [G loss: 0.956943] time: 0:04:47.213673\n",
      "0.85475963\n",
      "[Epoch 3/50] [Batch 52/300] [D loss: 0.757794] [G loss: 0.832558] time: 0:04:47.510949\n",
      "0.95287186\n",
      "[Epoch 3/50] [Batch 53/300] [D loss: 0.757986] [G loss: 0.860828] time: 0:04:47.829147\n",
      "0.9045916\n",
      "[Epoch 3/50] [Batch 54/300] [D loss: 0.758041] [G loss: 0.812608] time: 0:04:48.136147\n",
      "0.9067126\n",
      "[Epoch 3/50] [Batch 55/300] [D loss: 0.758067] [G loss: 0.800629] time: 0:04:48.427910\n",
      "0.91704535\n",
      "[Epoch 3/50] [Batch 56/300] [D loss: 0.757693] [G loss: 0.951933] time: 0:04:48.734766\n",
      "0.92912173\n",
      "[Epoch 3/50] [Batch 57/300] [D loss: 0.757877] [G loss: 1.072463] time: 0:04:49.032990\n",
      "0.88392085\n",
      "[Epoch 3/50] [Batch 58/300] [D loss: 0.758036] [G loss: 0.964971] time: 0:04:49.332476\n",
      "0.93178874\n",
      "[Epoch 3/50] [Batch 59/300] [D loss: 0.757715] [G loss: 0.849905] time: 0:04:49.638409\n",
      "0.90974015\n",
      "[Epoch 3/50] [Batch 60/300] [D loss: 0.757849] [G loss: 0.923664] time: 0:04:49.916308\n",
      "0.90357566\n",
      "[Epoch 3/50] [Batch 61/300] [D loss: 0.757759] [G loss: 0.880348] time: 0:04:50.209262\n",
      "0.87183833\n",
      "[Epoch 3/50] [Batch 62/300] [D loss: 0.757697] [G loss: 0.864246] time: 0:04:50.507233\n",
      "0.9332146\n",
      "[Epoch 3/50] [Batch 63/300] [D loss: 0.757801] [G loss: 1.036086] time: 0:04:50.803907\n",
      "0.9099205\n",
      "[Epoch 3/50] [Batch 64/300] [D loss: 0.757791] [G loss: 0.844417] time: 0:04:51.089564\n",
      "0.91245383\n",
      "[Epoch 3/50] [Batch 65/300] [D loss: 0.757773] [G loss: 0.897752] time: 0:04:51.384717\n",
      "0.91853046\n",
      "[Epoch 3/50] [Batch 66/300] [D loss: 0.757732] [G loss: 1.003506] time: 0:04:51.693427\n",
      "0.9301955\n",
      "[Epoch 3/50] [Batch 67/300] [D loss: 0.757638] [G loss: 1.067978] time: 0:04:51.990117\n",
      "0.8223409\n",
      "[Epoch 3/50] [Batch 68/300] [D loss: 0.757753] [G loss: 0.922592] time: 0:04:52.302345\n",
      "0.9250881\n",
      "[Epoch 3/50] [Batch 69/300] [D loss: 0.757959] [G loss: 0.888527] time: 0:04:52.595476\n",
      "0.8793071\n",
      "[Epoch 3/50] [Batch 70/300] [D loss: 0.757776] [G loss: 0.899399] time: 0:04:52.902381\n",
      "0.97074294\n",
      "[Epoch 3/50] [Batch 71/300] [D loss: 0.757676] [G loss: 0.876766] time: 0:04:53.198979\n",
      "0.91136926\n",
      "[Epoch 3/50] [Batch 72/300] [D loss: 0.758078] [G loss: 1.026094] time: 0:04:53.486511\n",
      "0.8915043\n",
      "[Epoch 3/50] [Batch 73/300] [D loss: 0.757741] [G loss: 0.791450] time: 0:04:53.787143\n",
      "0.9526313\n",
      "[Epoch 3/50] [Batch 74/300] [D loss: 0.757606] [G loss: 0.995830] time: 0:04:54.083639\n",
      "0.920502\n",
      "[Epoch 3/50] [Batch 75/300] [D loss: 0.757866] [G loss: 0.829328] time: 0:04:54.367584\n",
      "0.8870352\n",
      "[Epoch 3/50] [Batch 76/300] [D loss: 0.757845] [G loss: 0.836020] time: 0:04:54.660558\n",
      "0.9285919\n",
      "[Epoch 3/50] [Batch 77/300] [D loss: 0.757512] [G loss: 1.147344] time: 0:04:54.943275\n",
      "0.91485864\n",
      "[Epoch 3/50] [Batch 78/300] [D loss: 0.757611] [G loss: 1.031986] time: 0:04:55.246936\n",
      "0.89229417\n",
      "[Epoch 3/50] [Batch 79/300] [D loss: 0.757602] [G loss: 0.946373] time: 0:04:55.547048\n",
      "0.91504484\n",
      "[Epoch 3/50] [Batch 80/300] [D loss: 0.757864] [G loss: 0.809340] time: 0:04:55.840257\n",
      "0.8901513\n",
      "[Epoch 3/50] [Batch 81/300] [D loss: 0.757425] [G loss: 1.113103] time: 0:04:56.122396\n",
      "0.8776071\n",
      "[Epoch 3/50] [Batch 82/300] [D loss: 0.757582] [G loss: 0.868373] time: 0:04:56.424207\n",
      "0.90032786\n",
      "[Epoch 3/50] [Batch 83/300] [D loss: 0.757755] [G loss: 0.891471] time: 0:04:56.713047\n",
      "0.92643166\n",
      "[Epoch 3/50] [Batch 84/300] [D loss: 0.757673] [G loss: 0.922744] time: 0:04:57.008164\n",
      "0.8712213\n",
      "[Epoch 3/50] [Batch 85/300] [D loss: 0.757718] [G loss: 0.857938] time: 0:04:57.293939\n",
      "0.86188936\n",
      "[Epoch 3/50] [Batch 86/300] [D loss: 0.757645] [G loss: 0.889406] time: 0:04:57.597404\n",
      "0.8825653\n",
      "[Epoch 3/50] [Batch 87/300] [D loss: 0.757563] [G loss: 0.954036] time: 0:04:57.901226\n",
      "0.9824796\n",
      "[Epoch 3/50] [Batch 88/300] [D loss: 0.757752] [G loss: 0.794296] time: 0:04:58.201356\n",
      "0.9474382\n",
      "[Epoch 3/50] [Batch 89/300] [D loss: 0.757639] [G loss: 0.990863] time: 0:04:58.490845\n",
      "0.8887484\n",
      "[Epoch 3/50] [Batch 90/300] [D loss: 0.757854] [G loss: 0.820688] time: 0:04:58.778099\n",
      "0.8535085\n",
      "[Epoch 3/50] [Batch 91/300] [D loss: 0.757479] [G loss: 1.071798] time: 0:04:59.070008\n",
      "0.8950486\n",
      "[Epoch 3/50] [Batch 92/300] [D loss: 0.757276] [G loss: 0.897526] time: 0:04:59.374537\n",
      "0.9251835\n",
      "[Epoch 3/50] [Batch 93/300] [D loss: 0.757816] [G loss: 0.778287] time: 0:04:59.665728\n",
      "0.8851816\n",
      "[Epoch 3/50] [Batch 94/300] [D loss: 0.757611] [G loss: 0.895869] time: 0:04:59.964788\n",
      "0.8669767\n",
      "[Epoch 3/50] [Batch 95/300] [D loss: 0.757546] [G loss: 0.972845] time: 0:05:00.252806\n",
      "0.9320213\n",
      "[Epoch 3/50] [Batch 96/300] [D loss: 0.757538] [G loss: 1.108448] time: 0:05:00.538219\n",
      "0.9011221\n",
      "[Epoch 3/50] [Batch 97/300] [D loss: 0.757584] [G loss: 0.978986] time: 0:05:00.810508\n",
      "0.89082843\n",
      "[Epoch 3/50] [Batch 98/300] [D loss: 0.757683] [G loss: 0.795288] time: 0:05:01.116748\n",
      "0.8765495\n",
      "[Epoch 3/50] [Batch 99/300] [D loss: 0.757375] [G loss: 0.816573] time: 0:05:01.400964\n",
      "0.9149235\n",
      "[Epoch 3/50] [Batch 100/300] [D loss: 0.757630] [G loss: 0.797622] time: 0:05:01.701926\n",
      "0.8778781\n",
      "[Epoch 3/50] [Batch 101/300] [D loss: 0.757619] [G loss: 0.932832] time: 0:05:01.998022\n",
      "0.89746934\n",
      "[Epoch 3/50] [Batch 102/300] [D loss: 0.757682] [G loss: 0.977812] time: 0:05:02.300067\n",
      "0.94343525\n",
      "[Epoch 3/50] [Batch 103/300] [D loss: 0.757786] [G loss: 0.855285] time: 0:05:02.577367\n",
      "0.9183815\n",
      "[Epoch 3/50] [Batch 104/300] [D loss: 0.757363] [G loss: 1.100903] time: 0:05:02.867531\n",
      "0.8678741\n",
      "[Epoch 3/50] [Batch 105/300] [D loss: 0.757292] [G loss: 0.869358] time: 0:05:03.156782\n",
      "0.9331064\n",
      "[Epoch 3/50] [Batch 106/300] [D loss: 0.757444] [G loss: 0.915067] time: 0:05:03.447678\n",
      "0.9335916\n",
      "[Epoch 3/50] [Batch 107/300] [D loss: 0.757681] [G loss: 0.941243] time: 0:05:03.756211\n",
      "0.9082764\n",
      "[Epoch 3/50] [Batch 108/300] [D loss: 0.757625] [G loss: 0.787090] time: 0:05:04.066516\n",
      "0.8660385\n",
      "[Epoch 3/50] [Batch 109/300] [D loss: 0.757582] [G loss: 1.060611] time: 0:05:04.348098\n",
      "0.89392966\n",
      "[Epoch 3/50] [Batch 110/300] [D loss: 0.757583] [G loss: 0.923641] time: 0:05:04.635598\n",
      "0.91089135\n",
      "[Epoch 3/50] [Batch 111/300] [D loss: 0.757472] [G loss: 0.923020] time: 0:05:04.910312\n",
      "0.90373534\n",
      "[Epoch 3/50] [Batch 112/300] [D loss: 0.757548] [G loss: 0.858310] time: 0:05:05.206032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92452544\n",
      "[Epoch 3/50] [Batch 113/300] [D loss: 0.757620] [G loss: 0.791448] time: 0:05:05.512554\n",
      "0.9360542\n",
      "[Epoch 3/50] [Batch 114/300] [D loss: 0.757530] [G loss: 0.805491] time: 0:05:05.802799\n",
      "0.974531\n",
      "[Epoch 3/50] [Batch 115/300] [D loss: 0.757502] [G loss: 0.872777] time: 0:05:06.100482\n",
      "0.9256823\n",
      "[Epoch 3/50] [Batch 116/300] [D loss: 0.757430] [G loss: 0.732770] time: 0:05:06.407535\n",
      "0.88519996\n",
      "[Epoch 3/50] [Batch 117/300] [D loss: 0.757429] [G loss: 0.861258] time: 0:05:06.702632\n",
      "0.9763945\n",
      "[Epoch 3/50] [Batch 118/300] [D loss: 0.757453] [G loss: 0.994105] time: 0:05:06.987719\n",
      "0.88951087\n",
      "[Epoch 3/50] [Batch 119/300] [D loss: 0.757500] [G loss: 0.936960] time: 0:05:07.283945\n",
      "0.9064979\n",
      "[Epoch 3/50] [Batch 120/300] [D loss: 0.757533] [G loss: 0.755737] time: 0:05:07.572842\n",
      "0.942272\n",
      "[Epoch 3/50] [Batch 121/300] [D loss: 0.757495] [G loss: 0.870967] time: 0:05:07.870162\n",
      "0.8688993\n",
      "[Epoch 3/50] [Batch 122/300] [D loss: 0.757596] [G loss: 0.961516] time: 0:05:08.148769\n",
      "0.8955698\n",
      "[Epoch 3/50] [Batch 123/300] [D loss: 0.757476] [G loss: 0.888693] time: 0:05:08.458776\n",
      "0.90637803\n",
      "[Epoch 3/50] [Batch 124/300] [D loss: 0.757448] [G loss: 0.937666] time: 0:05:08.749604\n",
      "0.96075374\n",
      "[Epoch 3/50] [Batch 125/300] [D loss: 0.757234] [G loss: 0.940542] time: 0:05:09.049057\n",
      "0.9073346\n",
      "[Epoch 3/50] [Batch 126/300] [D loss: 0.757358] [G loss: 0.935679] time: 0:05:09.358851\n",
      "0.8820965\n",
      "[Epoch 3/50] [Batch 127/300] [D loss: 0.757203] [G loss: 0.897083] time: 0:05:09.649271\n",
      "0.900606\n",
      "[Epoch 3/50] [Batch 128/300] [D loss: 0.757389] [G loss: 0.904894] time: 0:05:09.950413\n",
      "0.9012074\n",
      "[Epoch 3/50] [Batch 129/300] [D loss: 0.757509] [G loss: 1.014025] time: 0:05:10.237953\n",
      "0.84815794\n",
      "[Epoch 3/50] [Batch 130/300] [D loss: 0.757522] [G loss: 0.866230] time: 0:05:10.543128\n",
      "0.9232512\n",
      "[Epoch 3/50] [Batch 131/300] [D loss: 0.757423] [G loss: 0.825591] time: 0:05:10.850222\n",
      "0.95846623\n",
      "[Epoch 3/50] [Batch 132/300] [D loss: 0.757633] [G loss: 0.895160] time: 0:05:11.149872\n",
      "0.90234345\n",
      "[Epoch 3/50] [Batch 133/300] [D loss: 0.757446] [G loss: 1.025403] time: 0:05:11.452444\n",
      "0.8752187\n",
      "[Epoch 3/50] [Batch 134/300] [D loss: 0.757307] [G loss: 0.918225] time: 0:05:11.748641\n",
      "0.93047315\n",
      "[Epoch 3/50] [Batch 135/300] [D loss: 0.757578] [G loss: 0.825967] time: 0:05:12.038515\n",
      "0.903076\n",
      "[Epoch 3/50] [Batch 136/300] [D loss: 0.757301] [G loss: 0.872331] time: 0:05:12.341961\n",
      "0.9400199\n",
      "[Epoch 3/50] [Batch 137/300] [D loss: 0.757391] [G loss: 0.918555] time: 0:05:12.631953\n",
      "0.8878079\n",
      "[Epoch 3/50] [Batch 138/300] [D loss: 0.757343] [G loss: 0.767391] time: 0:05:12.908916\n",
      "0.94571924\n",
      "[Epoch 3/50] [Batch 139/300] [D loss: 0.757554] [G loss: 0.815475] time: 0:05:13.204865\n",
      "0.89916897\n",
      "[Epoch 3/50] [Batch 140/300] [D loss: 0.757433] [G loss: 0.830779] time: 0:05:13.506933\n",
      "0.94910544\n",
      "[Epoch 3/50] [Batch 141/300] [D loss: 0.757383] [G loss: 0.950749] time: 0:05:13.807724\n",
      "0.8771637\n",
      "[Epoch 3/50] [Batch 142/300] [D loss: 0.757298] [G loss: 0.921040] time: 0:05:14.107728\n",
      "0.9763336\n",
      "[Epoch 3/50] [Batch 143/300] [D loss: 0.757322] [G loss: 0.895488] time: 0:05:14.405791\n",
      "0.89517957\n",
      "[Epoch 3/50] [Batch 144/300] [D loss: 0.757208] [G loss: 0.859197] time: 0:05:14.694241\n",
      "0.9504544\n",
      "[Epoch 3/50] [Batch 145/300] [D loss: 0.757537] [G loss: 0.752529] time: 0:05:14.993042\n",
      "0.9081285\n",
      "[Epoch 3/50] [Batch 146/300] [D loss: 0.757384] [G loss: 0.878712] time: 0:05:15.298790\n",
      "0.8629295\n",
      "[Epoch 3/50] [Batch 147/300] [D loss: 0.757273] [G loss: 0.807493] time: 0:05:15.589240\n",
      "0.93157816\n",
      "[Epoch 3/50] [Batch 148/300] [D loss: 0.757246] [G loss: 0.998810] time: 0:05:15.895884\n",
      "0.91563934\n",
      "[Epoch 3/50] [Batch 149/300] [D loss: 0.757396] [G loss: 0.890387] time: 0:05:16.203531\n",
      "0.94244295\n",
      "[Epoch 3/50] [Batch 150/300] [D loss: 0.757176] [G loss: 0.838582] time: 0:05:16.511484\n",
      "0.9083095\n",
      "[Epoch 3/50] [Batch 151/300] [D loss: 0.757292] [G loss: 0.813818] time: 0:05:16.809392\n",
      "0.9179401\n",
      "[Epoch 3/50] [Batch 152/300] [D loss: 0.757139] [G loss: 0.966592] time: 0:05:17.113747\n",
      "0.91082996\n",
      "[Epoch 3/50] [Batch 153/300] [D loss: 0.757267] [G loss: 0.853210] time: 0:05:17.426555\n",
      "0.9036811\n",
      "[Epoch 3/50] [Batch 154/300] [D loss: 0.757421] [G loss: 0.816065] time: 0:05:17.726356\n",
      "0.9256127\n",
      "[Epoch 3/50] [Batch 155/300] [D loss: 0.757076] [G loss: 0.873627] time: 0:05:18.026917\n",
      "0.9278975\n",
      "[Epoch 3/50] [Batch 156/300] [D loss: 0.757334] [G loss: 0.883741] time: 0:05:18.295131\n",
      "0.94984317\n",
      "[Epoch 3/50] [Batch 157/300] [D loss: 0.757375] [G loss: 0.745204] time: 0:05:18.593393\n",
      "0.9518923\n",
      "[Epoch 3/50] [Batch 158/300] [D loss: 0.757357] [G loss: 0.806368] time: 0:05:18.907591\n",
      "0.9611466\n",
      "[Epoch 3/50] [Batch 159/300] [D loss: 0.757220] [G loss: 0.790360] time: 0:05:19.189458\n",
      "0.8759403\n",
      "[Epoch 3/50] [Batch 160/300] [D loss: 0.757324] [G loss: 0.871353] time: 0:05:19.480949\n",
      "0.8952689\n",
      "[Epoch 3/50] [Batch 161/300] [D loss: 0.757357] [G loss: 0.944093] time: 0:05:19.782359\n",
      "0.9182138\n",
      "[Epoch 3/50] [Batch 162/300] [D loss: 0.757236] [G loss: 0.926933] time: 0:05:20.085098\n",
      "0.9382803\n",
      "[Epoch 3/50] [Batch 163/300] [D loss: 0.757199] [G loss: 0.893717] time: 0:05:20.387149\n",
      "0.94548327\n",
      "[Epoch 3/50] [Batch 164/300] [D loss: 0.757058] [G loss: 0.832668] time: 0:05:20.681115\n",
      "0.9629423\n",
      "[Epoch 3/50] [Batch 165/300] [D loss: 0.756980] [G loss: 0.860186] time: 0:05:20.973168\n",
      "0.92228156\n",
      "[Epoch 3/50] [Batch 166/300] [D loss: 0.757282] [G loss: 1.035433] time: 0:05:21.274712\n",
      "0.891229\n",
      "[Epoch 3/50] [Batch 167/300] [D loss: 0.757295] [G loss: 0.909104] time: 0:05:21.577327\n",
      "0.8535671\n",
      "[Epoch 3/50] [Batch 168/300] [D loss: 0.757183] [G loss: 0.898723] time: 0:05:21.869328\n",
      "0.8694017\n",
      "[Epoch 3/50] [Batch 169/300] [D loss: 0.757105] [G loss: 0.904919] time: 0:05:22.158020\n",
      "0.92889214\n",
      "[Epoch 3/50] [Batch 170/300] [D loss: 0.757169] [G loss: 1.070629] time: 0:05:22.459126\n",
      "0.93855673\n",
      "[Epoch 3/50] [Batch 171/300] [D loss: 0.757155] [G loss: 1.003351] time: 0:05:22.747238\n",
      "0.90234375\n",
      "[Epoch 3/50] [Batch 172/300] [D loss: 0.757103] [G loss: 0.849486] time: 0:05:23.046368\n",
      "0.9138966\n",
      "[Epoch 3/50] [Batch 173/300] [D loss: 0.757113] [G loss: 0.851641] time: 0:05:23.353596\n",
      "0.9001785\n",
      "[Epoch 3/50] [Batch 174/300] [D loss: 0.757047] [G loss: 0.989206] time: 0:05:23.644416\n",
      "0.9321249\n",
      "[Epoch 3/50] [Batch 175/300] [D loss: 0.757100] [G loss: 1.046800] time: 0:05:23.949585\n",
      "0.9209326\n",
      "[Epoch 3/50] [Batch 176/300] [D loss: 0.757138] [G loss: 0.866479] time: 0:05:24.233724\n",
      "0.9467414\n",
      "[Epoch 3/50] [Batch 177/300] [D loss: 0.757321] [G loss: 0.737494] time: 0:05:24.531515\n",
      "0.95485574\n",
      "[Epoch 3/50] [Batch 178/300] [D loss: 0.757224] [G loss: 1.014446] time: 0:05:24.827842\n",
      "0.9272173\n",
      "[Epoch 3/50] [Batch 179/300] [D loss: 0.757073] [G loss: 0.886588] time: 0:05:25.125683\n",
      "0.9420237\n",
      "[Epoch 3/50] [Batch 180/300] [D loss: 0.757218] [G loss: 1.113320] time: 0:05:25.418910\n",
      "0.9330816\n",
      "[Epoch 3/50] [Batch 181/300] [D loss: 0.757123] [G loss: 0.793521] time: 0:05:25.709171\n",
      "0.92281896\n",
      "[Epoch 3/50] [Batch 182/300] [D loss: 0.757043] [G loss: 1.056072] time: 0:05:25.994466\n",
      "0.9420235\n",
      "[Epoch 3/50] [Batch 183/300] [D loss: 0.756934] [G loss: 0.902158] time: 0:05:26.289351\n",
      "0.8801208\n",
      "[Epoch 3/50] [Batch 184/300] [D loss: 0.757042] [G loss: 0.806604] time: 0:05:26.594450\n",
      "0.94129103\n",
      "[Epoch 3/50] [Batch 185/300] [D loss: 0.757137] [G loss: 0.970667] time: 0:05:26.892190\n",
      "0.9799156\n",
      "[Epoch 3/50] [Batch 186/300] [D loss: 0.757143] [G loss: 0.838280] time: 0:05:27.170512\n",
      "0.92618316\n",
      "[Epoch 3/50] [Batch 187/300] [D loss: 0.757103] [G loss: 0.824387] time: 0:05:27.465747\n",
      "0.8883386\n",
      "[Epoch 3/50] [Batch 188/300] [D loss: 0.757144] [G loss: 0.994844] time: 0:05:27.772457\n",
      "0.85521954\n",
      "[Epoch 3/50] [Batch 189/300] [D loss: 0.757077] [G loss: 0.966586] time: 0:05:28.066496\n",
      "0.89405507\n",
      "[Epoch 3/50] [Batch 190/300] [D loss: 0.756965] [G loss: 1.026206] time: 0:05:28.373095\n",
      "0.92842835\n",
      "[Epoch 3/50] [Batch 191/300] [D loss: 0.756989] [G loss: 1.036279] time: 0:05:28.668617\n",
      "0.8781176\n",
      "[Epoch 3/50] [Batch 192/300] [D loss: 0.757022] [G loss: 0.865658] time: 0:05:28.957229\n",
      "0.906316\n",
      "[Epoch 3/50] [Batch 193/300] [D loss: 0.756954] [G loss: 0.838252] time: 0:05:29.256980\n",
      "0.89504045\n",
      "[Epoch 3/50] [Batch 194/300] [D loss: 0.757016] [G loss: 0.774127] time: 0:05:29.558888\n",
      "0.90100425\n",
      "[Epoch 3/50] [Batch 195/300] [D loss: 0.756909] [G loss: 0.829638] time: 0:05:29.856908\n",
      "0.9160449\n",
      "[Epoch 3/50] [Batch 196/300] [D loss: 0.756951] [G loss: 0.952673] time: 0:05:30.158045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89515847\n",
      "[Epoch 3/50] [Batch 197/300] [D loss: 0.756997] [G loss: 0.908038] time: 0:05:30.453609\n",
      "0.9034367\n",
      "[Epoch 3/50] [Batch 198/300] [D loss: 0.757004] [G loss: 0.722048] time: 0:05:30.746463\n",
      "0.9364384\n",
      "[Epoch 3/50] [Batch 199/300] [D loss: 0.757011] [G loss: 0.814525] time: 0:05:31.049903\n",
      "0.9297072\n",
      "[Epoch 3/50] [Batch 200/300] [D loss: 0.756989] [G loss: 0.889986] time: 0:05:31.346372\n",
      "0.9687868\n",
      "[Epoch 3/50] [Batch 201/300] [D loss: 0.756915] [G loss: 0.836809] time: 0:05:31.646897\n",
      "0.9368766\n",
      "[Epoch 3/50] [Batch 202/300] [D loss: 0.756924] [G loss: 0.806071] time: 0:05:31.918399\n",
      "0.942797\n",
      "[Epoch 3/50] [Batch 203/300] [D loss: 0.756979] [G loss: 0.895224] time: 0:05:32.214387\n",
      "0.9272518\n",
      "[Epoch 3/50] [Batch 204/300] [D loss: 0.756914] [G loss: 1.018907] time: 0:05:32.507719\n",
      "0.8758363\n",
      "[Epoch 3/50] [Batch 205/300] [D loss: 0.756968] [G loss: 0.871282] time: 0:05:32.808421\n",
      "0.91020465\n",
      "[Epoch 3/50] [Batch 206/300] [D loss: 0.756993] [G loss: 1.013795] time: 0:05:33.097621\n",
      "0.94539195\n",
      "[Epoch 3/50] [Batch 207/300] [D loss: 0.756885] [G loss: 0.920076] time: 0:05:33.391021\n",
      "0.9614462\n",
      "[Epoch 3/50] [Batch 208/300] [D loss: 0.756897] [G loss: 0.831616] time: 0:05:33.685583\n",
      "0.89855504\n",
      "[Epoch 3/50] [Batch 209/300] [D loss: 0.756841] [G loss: 0.958006] time: 0:05:33.986746\n",
      "0.9246058\n",
      "[Epoch 3/50] [Batch 210/300] [D loss: 0.756977] [G loss: 1.010804] time: 0:05:34.297442\n",
      "0.9194457\n",
      "[Epoch 3/50] [Batch 211/300] [D loss: 0.756939] [G loss: 0.837608] time: 0:05:34.602749\n",
      "0.8597171\n",
      "[Epoch 3/50] [Batch 212/300] [D loss: 0.756944] [G loss: 0.825527] time: 0:05:34.915863\n",
      "0.9276018\n",
      "[Epoch 3/50] [Batch 213/300] [D loss: 0.756858] [G loss: 0.882148] time: 0:05:35.224247\n",
      "0.9243865\n",
      "[Epoch 3/50] [Batch 214/300] [D loss: 0.756758] [G loss: 0.893259] time: 0:05:35.540544\n",
      "0.9150165\n",
      "[Epoch 3/50] [Batch 215/300] [D loss: 0.756906] [G loss: 0.910766] time: 0:05:35.852053\n",
      "0.90269107\n",
      "[Epoch 3/50] [Batch 216/300] [D loss: 0.756967] [G loss: 1.032127] time: 0:05:36.153527\n",
      "0.9021495\n",
      "[Epoch 3/50] [Batch 217/300] [D loss: 0.757050] [G loss: 0.862750] time: 0:05:36.460461\n",
      "0.89999676\n",
      "[Epoch 3/50] [Batch 218/300] [D loss: 0.757095] [G loss: 1.007438] time: 0:05:36.765062\n",
      "0.91611856\n",
      "[Epoch 3/50] [Batch 219/300] [D loss: 0.757074] [G loss: 0.908979] time: 0:05:37.061902\n",
      "0.91465706\n",
      "[Epoch 3/50] [Batch 220/300] [D loss: 0.756685] [G loss: 0.924702] time: 0:05:37.371208\n",
      "0.96949345\n",
      "[Epoch 3/50] [Batch 221/300] [D loss: 0.757030] [G loss: 0.831311] time: 0:05:37.671949\n",
      "0.9117927\n",
      "[Epoch 3/50] [Batch 222/300] [D loss: 0.756900] [G loss: 0.863086] time: 0:05:37.967142\n",
      "0.9212651\n",
      "[Epoch 3/50] [Batch 223/300] [D loss: 0.756928] [G loss: 0.973183] time: 0:05:38.273985\n",
      "0.9261391\n",
      "[Epoch 3/50] [Batch 224/300] [D loss: 0.757124] [G loss: 0.830950] time: 0:05:38.556400\n",
      "0.8935507\n",
      "[Epoch 3/50] [Batch 225/300] [D loss: 0.756996] [G loss: 0.819402] time: 0:05:38.840304\n",
      "0.9370721\n",
      "[Epoch 3/50] [Batch 226/300] [D loss: 0.756926] [G loss: 0.812810] time: 0:05:39.136919\n",
      "0.9214168\n",
      "[Epoch 3/50] [Batch 227/300] [D loss: 0.756817] [G loss: 0.964769] time: 0:05:39.440919\n",
      "0.9290676\n",
      "[Epoch 3/50] [Batch 228/300] [D loss: 0.756937] [G loss: 0.841973] time: 0:05:39.738051\n",
      "0.91568947\n",
      "[Epoch 3/50] [Batch 229/300] [D loss: 0.756863] [G loss: 0.865147] time: 0:05:40.034507\n",
      "0.9040995\n",
      "[Epoch 3/50] [Batch 230/300] [D loss: 0.756744] [G loss: 0.881691] time: 0:05:40.317747\n",
      "0.9057245\n",
      "[Epoch 3/50] [Batch 231/300] [D loss: 0.756895] [G loss: 0.921911] time: 0:05:40.615706\n",
      "0.9573036\n",
      "[Epoch 3/50] [Batch 232/300] [D loss: 0.756677] [G loss: 0.902829] time: 0:05:40.906862\n",
      "0.9414973\n",
      "[Epoch 3/50] [Batch 233/300] [D loss: 0.756858] [G loss: 0.866787] time: 0:05:41.195558\n",
      "0.888208\n",
      "[Epoch 3/50] [Batch 234/300] [D loss: 0.756861] [G loss: 0.967434] time: 0:05:41.495131\n",
      "0.9359848\n",
      "[Epoch 3/50] [Batch 235/300] [D loss: 0.756828] [G loss: 0.985521] time: 0:05:41.787052\n",
      "0.8953719\n",
      "[Epoch 3/50] [Batch 236/300] [D loss: 0.756751] [G loss: 1.013016] time: 0:05:42.072662\n",
      "0.95977926\n",
      "[Epoch 3/50] [Batch 237/300] [D loss: 0.756850] [G loss: 0.780514] time: 0:05:42.370635\n",
      "0.937799\n",
      "[Epoch 3/50] [Batch 238/300] [D loss: 0.757028] [G loss: 0.757643] time: 0:05:42.659627\n",
      "0.9204169\n",
      "[Epoch 3/50] [Batch 239/300] [D loss: 0.756767] [G loss: 0.919602] time: 0:05:42.958319\n",
      "0.9053769\n",
      "[Epoch 3/50] [Batch 240/300] [D loss: 0.756678] [G loss: 0.966236] time: 0:05:43.248872\n",
      "0.9367387\n",
      "[Epoch 3/50] [Batch 241/300] [D loss: 0.756963] [G loss: 0.807447] time: 0:05:43.536291\n",
      "0.87614363\n",
      "[Epoch 3/50] [Batch 242/300] [D loss: 0.756865] [G loss: 0.810949] time: 0:05:43.824558\n",
      "0.9342436\n",
      "[Epoch 3/50] [Batch 243/300] [D loss: 0.757141] [G loss: 0.837030] time: 0:05:44.117796\n",
      "0.9656849\n",
      "[Epoch 3/50] [Batch 244/300] [D loss: 0.756886] [G loss: 0.939090] time: 0:05:44.414209\n",
      "0.92471176\n",
      "[Epoch 3/50] [Batch 245/300] [D loss: 0.756677] [G loss: 0.949558] time: 0:05:44.718225\n",
      "0.87074834\n",
      "[Epoch 3/50] [Batch 246/300] [D loss: 0.756805] [G loss: 1.022671] time: 0:05:45.013028\n",
      "0.8870581\n",
      "[Epoch 3/50] [Batch 247/300] [D loss: 0.756892] [G loss: 0.749774] time: 0:05:45.313108\n",
      "0.9156874\n",
      "[Epoch 3/50] [Batch 248/300] [D loss: 0.756776] [G loss: 0.845317] time: 0:05:45.610257\n",
      "0.84858274\n",
      "[Epoch 3/50] [Batch 249/300] [D loss: 0.756878] [G loss: 0.942189] time: 0:05:45.913334\n",
      "0.91594154\n",
      "[Epoch 3/50] [Batch 250/300] [D loss: 0.756640] [G loss: 0.894487] time: 0:05:46.218152\n",
      "0.9155531\n",
      "[Epoch 3/50] [Batch 251/300] [D loss: 0.756662] [G loss: 0.833549] time: 0:05:46.524946\n",
      "0.91464156\n",
      "[Epoch 3/50] [Batch 252/300] [D loss: 0.756982] [G loss: 0.897014] time: 0:05:46.823689\n",
      "0.8879128\n",
      "[Epoch 3/50] [Batch 253/300] [D loss: 0.756646] [G loss: 0.951630] time: 0:05:47.114619\n",
      "0.9305954\n",
      "[Epoch 3/50] [Batch 254/300] [D loss: 0.756689] [G loss: 0.883926] time: 0:05:47.415051\n",
      "0.91139656\n",
      "[Epoch 3/50] [Batch 255/300] [D loss: 0.756829] [G loss: 0.855863] time: 0:05:47.709258\n",
      "0.9661436\n",
      "[Epoch 3/50] [Batch 256/300] [D loss: 0.756750] [G loss: 0.990899] time: 0:05:48.004332\n",
      "0.97990036\n",
      "[Epoch 3/50] [Batch 257/300] [D loss: 0.756837] [G loss: 1.056969] time: 0:05:48.300583\n",
      "0.88029736\n",
      "[Epoch 3/50] [Batch 258/300] [D loss: 0.756736] [G loss: 0.824254] time: 0:05:48.600486\n",
      "0.9353866\n",
      "[Epoch 3/50] [Batch 259/300] [D loss: 0.756789] [G loss: 0.849312] time: 0:05:48.901333\n",
      "0.86902666\n",
      "[Epoch 3/50] [Batch 260/300] [D loss: 0.756755] [G loss: 0.905954] time: 0:05:49.195282\n",
      "0.9268861\n",
      "[Epoch 3/50] [Batch 261/300] [D loss: 0.756795] [G loss: 0.739993] time: 0:05:49.503943\n",
      "0.95100754\n",
      "[Epoch 3/50] [Batch 262/300] [D loss: 0.756796] [G loss: 0.931672] time: 0:05:49.777600\n",
      "0.88539666\n",
      "[Epoch 3/50] [Batch 263/300] [D loss: 0.756793] [G loss: 0.862755] time: 0:05:50.074060\n",
      "0.9679189\n",
      "[Epoch 3/50] [Batch 264/300] [D loss: 0.756745] [G loss: 0.840060] time: 0:05:50.357422\n",
      "0.93819195\n",
      "[Epoch 3/50] [Batch 265/300] [D loss: 0.756542] [G loss: 0.800796] time: 0:05:50.652563\n",
      "0.93510574\n",
      "[Epoch 3/50] [Batch 266/300] [D loss: 0.756636] [G loss: 0.983325] time: 0:05:50.961186\n",
      "0.8921625\n",
      "[Epoch 3/50] [Batch 267/300] [D loss: 0.756678] [G loss: 0.797407] time: 0:05:51.255494\n",
      "0.8819225\n",
      "[Epoch 3/50] [Batch 268/300] [D loss: 0.756695] [G loss: 0.821848] time: 0:05:51.555458\n",
      "0.92122793\n",
      "[Epoch 3/50] [Batch 269/300] [D loss: 0.756575] [G loss: 0.984667] time: 0:05:51.875486\n",
      "0.902278\n",
      "[Epoch 3/50] [Batch 270/300] [D loss: 0.756632] [G loss: 0.791193] time: 0:05:52.189192\n",
      "0.8534527\n",
      "[Epoch 3/50] [Batch 271/300] [D loss: 0.756723] [G loss: 0.900565] time: 0:05:52.469672\n",
      "0.8734425\n",
      "[Epoch 3/50] [Batch 272/300] [D loss: 0.756926] [G loss: 0.929890] time: 0:05:52.772022\n",
      "0.8972025\n",
      "[Epoch 3/50] [Batch 273/300] [D loss: 0.756576] [G loss: 0.933978] time: 0:05:53.059839\n",
      "0.9291391\n",
      "[Epoch 3/50] [Batch 274/300] [D loss: 0.756694] [G loss: 0.769912] time: 0:05:53.360128\n",
      "0.94289297\n",
      "[Epoch 3/50] [Batch 275/300] [D loss: 0.756517] [G loss: 0.920410] time: 0:05:53.631013\n",
      "0.9130046\n",
      "[Epoch 3/50] [Batch 276/300] [D loss: 0.756677] [G loss: 0.812474] time: 0:05:53.936814\n",
      "0.9117064\n",
      "[Epoch 3/50] [Batch 277/300] [D loss: 0.756647] [G loss: 0.843297] time: 0:05:54.224204\n",
      "0.91708523\n",
      "[Epoch 3/50] [Batch 278/300] [D loss: 0.756745] [G loss: 0.799463] time: 0:05:54.504351\n",
      "0.94818187\n",
      "[Epoch 3/50] [Batch 279/300] [D loss: 0.756726] [G loss: 0.866928] time: 0:05:54.808288\n",
      "0.9191508\n",
      "[Epoch 3/50] [Batch 280/300] [D loss: 0.756573] [G loss: 0.910893] time: 0:05:55.115317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92176867\n",
      "[Epoch 3/50] [Batch 281/300] [D loss: 0.756596] [G loss: 0.863989] time: 0:05:55.406815\n",
      "0.93440413\n",
      "[Epoch 3/50] [Batch 282/300] [D loss: 0.756747] [G loss: 0.744509] time: 0:05:55.708867\n",
      "0.9743896\n",
      "[Epoch 3/50] [Batch 283/300] [D loss: 0.756661] [G loss: 0.861865] time: 0:05:56.012607\n",
      "0.9526053\n",
      "[Epoch 3/50] [Batch 284/300] [D loss: 0.756798] [G loss: 0.783928] time: 0:05:56.309681\n",
      "0.96675926\n",
      "[Epoch 3/50] [Batch 285/300] [D loss: 0.756714] [G loss: 1.089091] time: 0:05:56.594996\n",
      "0.8853431\n",
      "[Epoch 3/50] [Batch 286/300] [D loss: 0.756699] [G loss: 0.814340] time: 0:05:56.905305\n",
      "0.87990874\n",
      "[Epoch 3/50] [Batch 287/300] [D loss: 0.756548] [G loss: 1.052955] time: 0:05:57.203836\n",
      "0.92796946\n",
      "[Epoch 3/50] [Batch 288/300] [D loss: 0.756614] [G loss: 1.058103] time: 0:05:57.506445\n",
      "0.9096305\n",
      "[Epoch 3/50] [Batch 289/300] [D loss: 0.756590] [G loss: 0.805973] time: 0:05:57.806262\n",
      "0.92378885\n",
      "[Epoch 3/50] [Batch 290/300] [D loss: 0.756731] [G loss: 1.059549] time: 0:05:58.102788\n",
      "0.91936177\n",
      "[Epoch 3/50] [Batch 291/300] [D loss: 0.756516] [G loss: 0.907009] time: 0:05:58.403753\n",
      "0.8785377\n",
      "[Epoch 3/50] [Batch 292/300] [D loss: 0.756623] [G loss: 0.859109] time: 0:05:58.689662\n",
      "0.9260636\n",
      "[Epoch 3/50] [Batch 293/300] [D loss: 0.756562] [G loss: 0.768523] time: 0:05:58.995907\n",
      "0.9263169\n",
      "[Epoch 3/50] [Batch 294/300] [D loss: 0.756654] [G loss: 0.784876] time: 0:05:59.293125\n",
      "0.9117858\n",
      "[Epoch 3/50] [Batch 295/300] [D loss: 0.756402] [G loss: 0.889315] time: 0:05:59.578546\n",
      "0.9217147\n",
      "[Epoch 3/50] [Batch 296/300] [D loss: 0.756552] [G loss: 0.812312] time: 0:05:59.879733\n",
      "0.9451938\n",
      "[Epoch 3/50] [Batch 297/300] [D loss: 0.756666] [G loss: 0.763391] time: 0:06:00.175424\n",
      "0.88762265\n",
      "[Epoch 3/50] [Batch 298/300] [D loss: 0.756632] [G loss: 0.922446] time: 0:06:00.464315\n",
      "0.93087274\n",
      "[Epoch 3/50] [Batch 299/300] [D loss: 0.756653] [G loss: 0.822759] time: 0:06:00.743488\n",
      "0.93624663\n",
      "[Epoch 4/50] [Batch 0/300] [D loss: 0.756582] [G loss: 0.897784] time: 0:06:01.019665\n",
      "0.8929641\n",
      "[Epoch 4/50] [Batch 1/300] [D loss: 0.756517] [G loss: 0.941373] time: 0:06:01.303345\n",
      "0.91020226\n",
      "[Epoch 4/50] [Batch 2/300] [D loss: 0.756521] [G loss: 0.861415] time: 0:06:01.605464\n",
      "0.93703765\n",
      "[Epoch 4/50] [Batch 4/300] [D loss: 0.756613] [G loss: 0.884447] time: 0:06:01.933722\n",
      "0.9065414\n",
      "[Epoch 4/50] [Batch 5/300] [D loss: 0.756436] [G loss: 0.747095] time: 0:06:02.204224\n",
      "0.93576986\n",
      "[Epoch 4/50] [Batch 6/300] [D loss: 0.756508] [G loss: 0.810740] time: 0:06:02.493404\n",
      "0.90099007\n",
      "[Epoch 4/50] [Batch 7/300] [D loss: 0.756587] [G loss: 0.900576] time: 0:06:02.800032\n",
      "0.9181168\n",
      "[Epoch 4/50] [Batch 8/300] [D loss: 0.756408] [G loss: 0.940095] time: 0:06:03.094795\n",
      "0.916864\n",
      "[Epoch 4/50] [Batch 9/300] [D loss: 0.756599] [G loss: 0.895926] time: 0:06:03.395641\n",
      "0.94350696\n",
      "[Epoch 4/50] [Batch 10/300] [D loss: 0.756693] [G loss: 0.842248] time: 0:06:03.710810\n",
      "0.9168504\n",
      "[Epoch 4/50] [Batch 11/300] [D loss: 0.756388] [G loss: 0.820753] time: 0:06:04.000650\n",
      "0.91483146\n",
      "[Epoch 4/50] [Batch 12/300] [D loss: 0.756557] [G loss: 0.791828] time: 0:06:04.306269\n",
      "0.9010264\n",
      "[Epoch 4/50] [Batch 13/300] [D loss: 0.756402] [G loss: 0.774497] time: 0:06:04.607714\n",
      "0.93133\n",
      "[Epoch 4/50] [Batch 14/300] [D loss: 0.756424] [G loss: 0.944529] time: 0:06:04.904194\n",
      "0.9112709\n",
      "[Epoch 4/50] [Batch 15/300] [D loss: 0.756536] [G loss: 0.930664] time: 0:06:05.199823\n",
      "0.9079356\n",
      "[Epoch 4/50] [Batch 16/300] [D loss: 0.756781] [G loss: 0.819766] time: 0:06:05.480816\n",
      "0.8739951\n",
      "[Epoch 4/50] [Batch 17/300] [D loss: 0.756635] [G loss: 0.945028] time: 0:06:05.788334\n",
      "0.9365802\n",
      "[Epoch 4/50] [Batch 18/300] [D loss: 0.756561] [G loss: 0.942345] time: 0:06:06.094428\n",
      "0.9805827\n",
      "[Epoch 4/50] [Batch 19/300] [D loss: 0.756448] [G loss: 0.912786] time: 0:06:06.383907\n",
      "0.8802295\n",
      "[Epoch 4/50] [Batch 20/300] [D loss: 0.756437] [G loss: 0.835659] time: 0:06:06.686210\n",
      "0.8895864\n",
      "[Epoch 4/50] [Batch 21/300] [D loss: 0.756406] [G loss: 0.962912] time: 0:06:06.986122\n",
      "0.83792114\n",
      "[Epoch 4/50] [Batch 22/300] [D loss: 0.756400] [G loss: 0.880907] time: 0:06:07.299588\n",
      "0.89806205\n",
      "[Epoch 4/50] [Batch 23/300] [D loss: 0.756491] [G loss: 0.876006] time: 0:06:07.606296\n",
      "0.9263696\n",
      "[Epoch 4/50] [Batch 24/300] [D loss: 0.756534] [G loss: 1.029813] time: 0:06:07.888978\n",
      "0.92211455\n",
      "[Epoch 4/50] [Batch 25/300] [D loss: 0.756406] [G loss: 0.838857] time: 0:06:08.195217\n",
      "0.97998595\n",
      "[Epoch 4/50] [Batch 26/300] [D loss: 0.756521] [G loss: 0.880887] time: 0:06:08.489422\n",
      "0.93144506\n",
      "[Epoch 4/50] [Batch 27/300] [D loss: 0.756312] [G loss: 0.959055] time: 0:06:08.785020\n",
      "0.9557347\n",
      "[Epoch 4/50] [Batch 28/300] [D loss: 0.756433] [G loss: 0.994773] time: 0:06:09.104679\n",
      "0.9378526\n",
      "[Epoch 4/50] [Batch 29/300] [D loss: 0.756386] [G loss: 0.866758] time: 0:06:09.400874\n",
      "0.9481643\n",
      "[Epoch 4/50] [Batch 30/300] [D loss: 0.756458] [G loss: 0.894244] time: 0:06:09.702103\n",
      "0.9205418\n",
      "[Epoch 4/50] [Batch 31/300] [D loss: 0.756577] [G loss: 0.858765] time: 0:06:10.006423\n",
      "0.9059929\n",
      "[Epoch 4/50] [Batch 32/300] [D loss: 0.756412] [G loss: 0.764122] time: 0:06:10.285697\n",
      "0.9186168\n",
      "[Epoch 4/50] [Batch 33/300] [D loss: 0.756380] [G loss: 0.987089] time: 0:06:10.583972\n",
      "0.93961746\n",
      "[Epoch 4/50] [Batch 34/300] [D loss: 0.756324] [G loss: 0.812271] time: 0:06:10.894590\n",
      "0.9338458\n",
      "[Epoch 4/50] [Batch 35/300] [D loss: 0.756296] [G loss: 0.698830] time: 0:06:11.193017\n",
      "0.9385542\n",
      "[Epoch 4/50] [Batch 36/300] [D loss: 0.756395] [G loss: 0.918425] time: 0:06:11.487610\n",
      "0.8444007\n",
      "[Epoch 4/50] [Batch 37/300] [D loss: 0.756299] [G loss: 0.919538] time: 0:06:11.789755\n",
      "0.9474109\n",
      "[Epoch 4/50] [Batch 38/300] [D loss: 0.756384] [G loss: 0.950598] time: 0:06:12.094833\n",
      "0.9246127\n",
      "[Epoch 4/50] [Batch 39/300] [D loss: 0.756443] [G loss: 0.798555] time: 0:06:12.399306\n",
      "0.93571687\n",
      "[Epoch 4/50] [Batch 40/300] [D loss: 0.756463] [G loss: 0.865937] time: 0:06:12.705263\n",
      "0.94706464\n",
      "[Epoch 4/50] [Batch 41/300] [D loss: 0.756461] [G loss: 0.737436] time: 0:06:13.010134\n",
      "0.89407986\n",
      "[Epoch 4/50] [Batch 42/300] [D loss: 0.756355] [G loss: 0.741567] time: 0:06:13.309986\n",
      "0.88777953\n",
      "[Epoch 4/50] [Batch 43/300] [D loss: 0.756307] [G loss: 0.909721] time: 0:06:13.585510\n",
      "0.8887894\n",
      "[Epoch 4/50] [Batch 44/300] [D loss: 0.756326] [G loss: 0.841445] time: 0:06:13.896577\n",
      "0.86946017\n",
      "[Epoch 4/50] [Batch 45/300] [D loss: 0.756274] [G loss: 0.853538] time: 0:06:14.194165\n",
      "0.9202215\n",
      "[Epoch 4/50] [Batch 46/300] [D loss: 0.756312] [G loss: 0.967233] time: 0:06:14.482568\n",
      "0.9286733\n",
      "[Epoch 4/50] [Batch 47/300] [D loss: 0.756568] [G loss: 0.795368] time: 0:06:14.786675\n",
      "0.8899943\n",
      "[Epoch 4/50] [Batch 48/300] [D loss: 0.756269] [G loss: 0.920013] time: 0:06:15.076054\n",
      "0.9567862\n",
      "[Epoch 4/50] [Batch 49/300] [D loss: 0.756437] [G loss: 0.825275] time: 0:06:15.375932\n",
      "0.96876794\n",
      "[Epoch 4/50] [Batch 50/300] [D loss: 0.756256] [G loss: 0.943210] time: 0:06:15.649782\n",
      "0.90908027\n",
      "[Epoch 4/50] [Batch 51/300] [D loss: 0.756289] [G loss: 0.946484] time: 0:06:15.954730\n",
      "0.9434206\n",
      "[Epoch 4/50] [Batch 52/300] [D loss: 0.756331] [G loss: 0.917023] time: 0:06:16.259081\n",
      "0.8994878\n",
      "[Epoch 4/50] [Batch 53/300] [D loss: 0.756311] [G loss: 0.937500] time: 0:06:16.560328\n",
      "0.86446935\n",
      "[Epoch 4/50] [Batch 54/300] [D loss: 0.756390] [G loss: 0.766978] time: 0:06:16.855576\n",
      "0.9353097\n",
      "[Epoch 4/50] [Batch 55/300] [D loss: 0.756345] [G loss: 0.947916] time: 0:06:17.150981\n",
      "0.9153815\n",
      "[Epoch 4/50] [Batch 56/300] [D loss: 0.756359] [G loss: 0.814500] time: 0:06:17.440938\n",
      "0.9023493\n",
      "[Epoch 4/50] [Batch 57/300] [D loss: 0.756284] [G loss: 0.836621] time: 0:06:17.720833\n",
      "0.89428234\n",
      "[Epoch 4/50] [Batch 58/300] [D loss: 0.756304] [G loss: 0.925088] time: 0:06:18.027520\n",
      "0.8972096\n",
      "[Epoch 4/50] [Batch 59/300] [D loss: 0.756351] [G loss: 0.811795] time: 0:06:18.338638\n",
      "0.8834885\n",
      "[Epoch 4/50] [Batch 60/300] [D loss: 0.756257] [G loss: 0.940068] time: 0:06:18.637313\n",
      "0.9003183\n",
      "[Epoch 4/50] [Batch 61/300] [D loss: 0.756064] [G loss: 0.859073] time: 0:06:18.949618\n",
      "0.93696374\n",
      "[Epoch 4/50] [Batch 62/300] [D loss: 0.756339] [G loss: 0.975221] time: 0:06:19.246274\n",
      "0.88057846\n",
      "[Epoch 4/50] [Batch 63/300] [D loss: 0.756341] [G loss: 0.949987] time: 0:06:19.557184\n",
      "0.908626\n",
      "[Epoch 4/50] [Batch 64/300] [D loss: 0.756051] [G loss: 0.889660] time: 0:06:19.847965\n",
      "0.8849761\n",
      "[Epoch 4/50] [Batch 65/300] [D loss: 0.756140] [G loss: 0.679302] time: 0:06:20.146209\n",
      "0.9677847\n",
      "[Epoch 4/50] [Batch 66/300] [D loss: 0.756473] [G loss: 0.824241] time: 0:06:20.437597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95375586\n",
      "[Epoch 4/50] [Batch 67/300] [D loss: 0.756441] [G loss: 0.869188] time: 0:06:20.733014\n",
      "0.9657006\n",
      "[Epoch 4/50] [Batch 68/300] [D loss: 0.756190] [G loss: 0.902429] time: 0:06:21.022096\n",
      "0.91142464\n",
      "[Epoch 4/50] [Batch 69/300] [D loss: 0.756250] [G loss: 0.848125] time: 0:06:21.315878\n",
      "0.9140585\n",
      "[Epoch 4/50] [Batch 70/300] [D loss: 0.756218] [G loss: 0.935595] time: 0:06:21.617961\n",
      "0.97328\n",
      "[Epoch 4/50] [Batch 71/300] [D loss: 0.756288] [G loss: 0.790968] time: 0:06:21.888541\n",
      "0.9087508\n",
      "[Epoch 4/50] [Batch 72/300] [D loss: 0.756353] [G loss: 0.881786] time: 0:06:22.185148\n",
      "0.8637194\n",
      "[Epoch 4/50] [Batch 73/300] [D loss: 0.756199] [G loss: 0.931358] time: 0:06:22.488611\n",
      "0.9005205\n",
      "[Epoch 4/50] [Batch 74/300] [D loss: 0.756160] [G loss: 0.805328] time: 0:06:22.785135\n",
      "0.87247086\n",
      "[Epoch 4/50] [Batch 75/300] [D loss: 0.756200] [G loss: 0.911864] time: 0:06:23.096815\n",
      "0.95546454\n",
      "[Epoch 4/50] [Batch 76/300] [D loss: 0.756356] [G loss: 0.766111] time: 0:06:23.382740\n",
      "0.91876215\n",
      "[Epoch 4/50] [Batch 77/300] [D loss: 0.756217] [G loss: 0.899996] time: 0:06:23.704087\n",
      "0.8908062\n",
      "[Epoch 4/50] [Batch 78/300] [D loss: 0.756318] [G loss: 0.922633] time: 0:06:23.985227\n",
      "0.92940646\n",
      "[Epoch 4/50] [Batch 79/300] [D loss: 0.756067] [G loss: 1.031407] time: 0:06:24.277259\n",
      "0.93517613\n",
      "[Epoch 4/50] [Batch 80/300] [D loss: 0.756159] [G loss: 0.875383] time: 0:06:24.574241\n",
      "0.9095278\n",
      "[Epoch 4/50] [Batch 81/300] [D loss: 0.756344] [G loss: 0.892585] time: 0:06:24.875086\n",
      "0.8763086\n",
      "[Epoch 4/50] [Batch 82/300] [D loss: 0.756166] [G loss: 0.871273] time: 0:06:25.173060\n",
      "0.9328802\n",
      "[Epoch 4/50] [Batch 83/300] [D loss: 0.756238] [G loss: 0.869295] time: 0:06:25.459482\n",
      "0.8859027\n",
      "[Epoch 4/50] [Batch 84/300] [D loss: 0.756096] [G loss: 1.060189] time: 0:06:25.763723\n",
      "0.90787315\n",
      "[Epoch 4/50] [Batch 85/300] [D loss: 0.756231] [G loss: 0.851420] time: 0:06:26.059947\n",
      "0.8857892\n",
      "[Epoch 4/50] [Batch 86/300] [D loss: 0.756218] [G loss: 0.753122] time: 0:06:26.361848\n",
      "0.9319274\n",
      "[Epoch 4/50] [Batch 87/300] [D loss: 0.756131] [G loss: 0.935293] time: 0:06:26.659099\n",
      "0.9174948\n",
      "[Epoch 4/50] [Batch 88/300] [D loss: 0.756115] [G loss: 0.902718] time: 0:06:26.956391\n",
      "0.9132991\n",
      "[Epoch 4/50] [Batch 89/300] [D loss: 0.756258] [G loss: 0.853046] time: 0:06:27.255084\n",
      "0.9208918\n",
      "[Epoch 4/50] [Batch 90/300] [D loss: 0.756054] [G loss: 0.867435] time: 0:06:27.551224\n",
      "0.9406386\n",
      "[Epoch 4/50] [Batch 91/300] [D loss: 0.756199] [G loss: 0.837165] time: 0:06:27.851154\n",
      "0.88597876\n",
      "[Epoch 4/50] [Batch 92/300] [D loss: 0.756164] [G loss: 0.877767] time: 0:06:28.142168\n",
      "0.89611936\n",
      "[Epoch 4/50] [Batch 93/300] [D loss: 0.756294] [G loss: 0.817793] time: 0:06:28.441423\n",
      "0.9295826\n",
      "[Epoch 4/50] [Batch 94/300] [D loss: 0.756195] [G loss: 0.888615] time: 0:06:28.718427\n",
      "0.896338\n",
      "[Epoch 4/50] [Batch 95/300] [D loss: 0.756097] [G loss: 0.907742] time: 0:06:29.020889\n",
      "0.8795729\n",
      "[Epoch 4/50] [Batch 96/300] [D loss: 0.756135] [G loss: 0.829117] time: 0:06:29.297825\n",
      "0.94575816\n",
      "[Epoch 4/50] [Batch 97/300] [D loss: 0.756088] [G loss: 0.854569] time: 0:06:29.596390\n",
      "0.910301\n",
      "[Epoch 4/50] [Batch 98/300] [D loss: 0.756336] [G loss: 0.851802] time: 0:06:29.890658\n",
      "0.94580317\n",
      "[Epoch 4/50] [Batch 99/300] [D loss: 0.756231] [G loss: 0.796745] time: 0:06:30.184355\n",
      "0.9847462\n",
      "[Epoch 4/50] [Batch 100/300] [D loss: 0.756154] [G loss: 0.920406] time: 0:06:30.484992\n",
      "0.91310495\n",
      "[Epoch 4/50] [Batch 101/300] [D loss: 0.756129] [G loss: 0.835222] time: 0:06:30.787494\n",
      "0.9225137\n",
      "[Epoch 4/50] [Batch 102/300] [D loss: 0.756030] [G loss: 1.094356] time: 0:06:31.087124\n",
      "0.93350667\n",
      "[Epoch 4/50] [Batch 103/300] [D loss: 0.756140] [G loss: 0.853230] time: 0:06:31.385436\n",
      "0.90131444\n",
      "[Epoch 4/50] [Batch 104/300] [D loss: 0.756201] [G loss: 0.917914] time: 0:06:31.687606\n",
      "0.91695327\n",
      "[Epoch 4/50] [Batch 105/300] [D loss: 0.756178] [G loss: 0.803569] time: 0:06:31.996925\n",
      "0.9379906\n",
      "[Epoch 4/50] [Batch 106/300] [D loss: 0.756065] [G loss: 0.892542] time: 0:06:32.299003\n",
      "0.9364612\n",
      "[Epoch 4/50] [Batch 107/300] [D loss: 0.756075] [G loss: 0.763122] time: 0:06:32.612501\n",
      "0.90710545\n",
      "[Epoch 4/50] [Batch 108/300] [D loss: 0.756207] [G loss: 0.795760] time: 0:06:32.909797\n",
      "0.9004137\n",
      "[Epoch 4/50] [Batch 109/300] [D loss: 0.756056] [G loss: 0.959123] time: 0:06:33.187385\n",
      "0.94471437\n",
      "[Epoch 4/50] [Batch 110/300] [D loss: 0.756138] [G loss: 0.920422] time: 0:06:33.486748\n",
      "0.9139313\n",
      "[Epoch 4/50] [Batch 111/300] [D loss: 0.756103] [G loss: 0.864580] time: 0:06:33.786580\n",
      "0.939017\n",
      "[Epoch 4/50] [Batch 112/300] [D loss: 0.756074] [G loss: 0.790399] time: 0:06:34.074405\n",
      "0.9362958\n",
      "[Epoch 4/50] [Batch 113/300] [D loss: 0.756051] [G loss: 0.802956] time: 0:06:34.368556\n",
      "0.93429226\n",
      "[Epoch 4/50] [Batch 114/300] [D loss: 0.756002] [G loss: 0.888669] time: 0:06:34.663387\n",
      "0.896101\n",
      "[Epoch 4/50] [Batch 115/300] [D loss: 0.756191] [G loss: 0.898373] time: 0:06:34.941032\n",
      "0.9322734\n",
      "[Epoch 4/50] [Batch 116/300] [D loss: 0.756100] [G loss: 0.819385] time: 0:06:35.257090\n",
      "0.87746793\n",
      "[Epoch 4/50] [Batch 117/300] [D loss: 0.756031] [G loss: 0.809636] time: 0:06:35.545506\n",
      "0.9366401\n",
      "[Epoch 4/50] [Batch 118/300] [D loss: 0.756220] [G loss: 0.948539] time: 0:06:35.849328\n",
      "0.92124647\n",
      "[Epoch 4/50] [Batch 119/300] [D loss: 0.755988] [G loss: 0.888434] time: 0:06:36.150005\n",
      "0.9679709\n",
      "[Epoch 4/50] [Batch 120/300] [D loss: 0.756002] [G loss: 0.916173] time: 0:06:36.452904\n",
      "0.8614842\n",
      "[Epoch 4/50] [Batch 121/300] [D loss: 0.755941] [G loss: 0.844412] time: 0:06:36.769442\n",
      "0.9367085\n",
      "[Epoch 4/50] [Batch 122/300] [D loss: 0.756367] [G loss: 0.830613] time: 0:06:37.062818\n",
      "0.9387977\n",
      "[Epoch 4/50] [Batch 123/300] [D loss: 0.756033] [G loss: 0.909980] time: 0:06:37.365213\n",
      "0.93626666\n",
      "[Epoch 4/50] [Batch 124/300] [D loss: 0.755989] [G loss: 0.781741] time: 0:06:37.649872\n",
      "0.9023673\n",
      "[Epoch 4/50] [Batch 125/300] [D loss: 0.755968] [G loss: 0.990789] time: 0:06:37.936527\n",
      "0.9256809\n",
      "[Epoch 4/50] [Batch 126/300] [D loss: 0.756091] [G loss: 0.817423] time: 0:06:38.249230\n",
      "0.921449\n",
      "[Epoch 4/50] [Batch 127/300] [D loss: 0.756138] [G loss: 0.771136] time: 0:06:38.558386\n",
      "0.9320834\n",
      "[Epoch 4/50] [Batch 128/300] [D loss: 0.755935] [G loss: 0.892765] time: 0:06:38.851084\n",
      "0.91588646\n",
      "[Epoch 4/50] [Batch 129/300] [D loss: 0.756076] [G loss: 0.774776] time: 0:06:39.142176\n",
      "0.93428856\n",
      "[Epoch 4/50] [Batch 130/300] [D loss: 0.756084] [G loss: 0.785570] time: 0:06:39.425538\n",
      "0.9095781\n",
      "[Epoch 4/50] [Batch 131/300] [D loss: 0.755775] [G loss: 0.952726] time: 0:06:39.724053\n",
      "0.897206\n",
      "[Epoch 4/50] [Batch 132/300] [D loss: 0.756086] [G loss: 0.842494] time: 0:06:40.025080\n",
      "0.9245851\n",
      "[Epoch 4/50] [Batch 133/300] [D loss: 0.756033] [G loss: 0.907662] time: 0:06:40.325818\n",
      "0.9035489\n",
      "[Epoch 4/50] [Batch 134/300] [D loss: 0.756055] [G loss: 0.934067] time: 0:06:40.619896\n",
      "0.910278\n",
      "[Epoch 4/50] [Batch 135/300] [D loss: 0.756057] [G loss: 0.946161] time: 0:06:40.916912\n",
      "0.87310404\n",
      "[Epoch 4/50] [Batch 136/300] [D loss: 0.755992] [G loss: 1.067843] time: 0:06:41.221620\n",
      "0.9042364\n",
      "[Epoch 4/50] [Batch 137/300] [D loss: 0.755868] [G loss: 0.711721] time: 0:06:41.510720\n",
      "0.9188814\n",
      "[Epoch 4/50] [Batch 138/300] [D loss: 0.756067] [G loss: 0.806917] time: 0:06:41.794605\n",
      "0.9062138\n",
      "[Epoch 4/50] [Batch 139/300] [D loss: 0.755971] [G loss: 0.837259] time: 0:06:42.078629\n",
      "0.9278822\n",
      "[Epoch 4/50] [Batch 140/300] [D loss: 0.755837] [G loss: 0.994810] time: 0:06:42.374320\n",
      "0.9256615\n",
      "[Epoch 4/50] [Batch 141/300] [D loss: 0.756097] [G loss: 0.746741] time: 0:06:42.666342\n",
      "0.90359694\n",
      "[Epoch 4/50] [Batch 142/300] [D loss: 0.756054] [G loss: 0.875458] time: 0:06:42.961265\n",
      "0.87311953\n",
      "[Epoch 4/50] [Batch 143/300] [D loss: 0.756030] [G loss: 0.803392] time: 0:06:43.260912\n",
      "0.89196205\n",
      "[Epoch 4/50] [Batch 144/300] [D loss: 0.756037] [G loss: 0.848604] time: 0:06:43.576724\n",
      "0.898669\n",
      "[Epoch 4/50] [Batch 145/300] [D loss: 0.755977] [G loss: 0.822927] time: 0:06:43.896686\n",
      "0.8967723\n",
      "[Epoch 4/50] [Batch 146/300] [D loss: 0.756022] [G loss: 0.810190] time: 0:06:44.187094\n",
      "0.9373536\n",
      "[Epoch 4/50] [Batch 147/300] [D loss: 0.756063] [G loss: 0.801994] time: 0:06:44.497817\n",
      "0.9087837\n",
      "[Epoch 4/50] [Batch 148/300] [D loss: 0.755906] [G loss: 0.818877] time: 0:06:44.779367\n",
      "0.8711881\n",
      "[Epoch 4/50] [Batch 149/300] [D loss: 0.755885] [G loss: 0.909615] time: 0:06:45.057106\n",
      "0.8719879\n",
      "[Epoch 4/50] [Batch 150/300] [D loss: 0.755828] [G loss: 0.989841] time: 0:06:45.373813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97431976\n",
      "[Epoch 4/50] [Batch 151/300] [D loss: 0.755945] [G loss: 0.797124] time: 0:06:45.672652\n",
      "0.9218238\n",
      "[Epoch 4/50] [Batch 152/300] [D loss: 0.756063] [G loss: 0.845606] time: 0:06:45.963123\n",
      "0.9048724\n",
      "[Epoch 4/50] [Batch 153/300] [D loss: 0.755983] [G loss: 0.916960] time: 0:06:46.258573\n",
      "0.90564686\n",
      "[Epoch 4/50] [Batch 154/300] [D loss: 0.756026] [G loss: 0.901633] time: 0:06:46.558573\n",
      "0.8708822\n",
      "[Epoch 4/50] [Batch 155/300] [D loss: 0.756096] [G loss: 0.860519] time: 0:06:46.847135\n",
      "0.8981362\n",
      "[Epoch 4/50] [Batch 156/300] [D loss: 0.755809] [G loss: 1.039611] time: 0:06:47.135273\n",
      "0.9108312\n",
      "[Epoch 4/50] [Batch 157/300] [D loss: 0.755878] [G loss: 1.001184] time: 0:06:47.417451\n",
      "0.951895\n",
      "[Epoch 4/50] [Batch 158/300] [D loss: 0.755886] [G loss: 0.949332] time: 0:06:47.712738\n",
      "0.9701617\n",
      "[Epoch 4/50] [Batch 159/300] [D loss: 0.755960] [G loss: 0.796683] time: 0:06:48.032878\n",
      "0.876157\n",
      "[Epoch 4/50] [Batch 160/300] [D loss: 0.755966] [G loss: 0.758400] time: 0:06:48.331719\n",
      "0.9051903\n",
      "[Epoch 4/50] [Batch 161/300] [D loss: 0.755820] [G loss: 0.947498] time: 0:06:48.634496\n",
      "0.92851216\n",
      "[Epoch 4/50] [Batch 162/300] [D loss: 0.755945] [G loss: 0.814284] time: 0:06:48.940137\n",
      "0.93591815\n",
      "[Epoch 4/50] [Batch 163/300] [D loss: 0.755831] [G loss: 0.893182] time: 0:06:49.221989\n",
      "0.93041104\n",
      "[Epoch 4/50] [Batch 164/300] [D loss: 0.755974] [G loss: 0.833355] time: 0:06:49.491820\n",
      "0.84850645\n",
      "[Epoch 4/50] [Batch 165/300] [D loss: 0.755919] [G loss: 0.964106] time: 0:06:49.787000\n",
      "0.88731766\n",
      "[Epoch 4/50] [Batch 166/300] [D loss: 0.755955] [G loss: 0.878874] time: 0:06:50.079337\n",
      "0.9240351\n",
      "[Epoch 4/50] [Batch 167/300] [D loss: 0.755866] [G loss: 0.918219] time: 0:06:50.402546\n",
      "0.8926615\n",
      "[Epoch 4/50] [Batch 168/300] [D loss: 0.755730] [G loss: 1.005506] time: 0:06:50.699059\n",
      "0.91810435\n",
      "[Epoch 4/50] [Batch 169/300] [D loss: 0.755878] [G loss: 0.730091] time: 0:06:50.992804\n",
      "0.8836942\n",
      "[Epoch 4/50] [Batch 170/300] [D loss: 0.755872] [G loss: 0.845532] time: 0:06:51.284492\n",
      "0.9211576\n",
      "[Epoch 4/50] [Batch 171/300] [D loss: 0.755758] [G loss: 0.864652] time: 0:06:51.591927\n",
      "0.91087127\n",
      "[Epoch 4/50] [Batch 172/300] [D loss: 0.755970] [G loss: 0.823639] time: 0:06:51.867395\n",
      "0.9208699\n",
      "[Epoch 4/50] [Batch 173/300] [D loss: 0.755816] [G loss: 0.844953] time: 0:06:52.157088\n",
      "0.89737964\n",
      "[Epoch 4/50] [Batch 174/300] [D loss: 0.755845] [G loss: 0.861848] time: 0:06:52.431425\n",
      "0.9034662\n",
      "[Epoch 4/50] [Batch 175/300] [D loss: 0.755970] [G loss: 0.859562] time: 0:06:52.732163\n",
      "0.9102011\n",
      "[Epoch 4/50] [Batch 176/300] [D loss: 0.755950] [G loss: 0.722443] time: 0:06:53.033997\n",
      "0.89333755\n",
      "[Epoch 4/50] [Batch 177/300] [D loss: 0.755804] [G loss: 0.923838] time: 0:06:53.344198\n",
      "0.91007423\n",
      "[Epoch 4/50] [Batch 178/300] [D loss: 0.755779] [G loss: 0.852983] time: 0:06:53.643464\n",
      "0.87057686\n",
      "[Epoch 4/50] [Batch 179/300] [D loss: 0.755932] [G loss: 0.956138] time: 0:06:53.948243\n",
      "0.8739608\n",
      "[Epoch 4/50] [Batch 180/300] [D loss: 0.755859] [G loss: 0.799735] time: 0:06:54.253818\n",
      "0.85699654\n",
      "[Epoch 4/50] [Batch 181/300] [D loss: 0.755838] [G loss: 0.856497] time: 0:06:54.562095\n",
      "0.89506835\n",
      "[Epoch 4/50] [Batch 182/300] [D loss: 0.755717] [G loss: 0.920014] time: 0:06:54.845493\n",
      "0.8683911\n",
      "[Epoch 4/50] [Batch 183/300] [D loss: 0.755888] [G loss: 0.938914] time: 0:06:55.146363\n",
      "0.89754623\n",
      "[Epoch 4/50] [Batch 184/300] [D loss: 0.755901] [G loss: 0.870783] time: 0:06:55.440635\n",
      "0.9679956\n",
      "[Epoch 4/50] [Batch 185/300] [D loss: 0.755884] [G loss: 0.966959] time: 0:06:55.747842\n",
      "0.9275561\n",
      "[Epoch 4/50] [Batch 186/300] [D loss: 0.756034] [G loss: 0.880478] time: 0:06:56.039941\n",
      "0.87905556\n",
      "[Epoch 4/50] [Batch 187/300] [D loss: 0.755828] [G loss: 0.949458] time: 0:06:56.341043\n",
      "0.903593\n",
      "[Epoch 4/50] [Batch 188/300] [D loss: 0.755828] [G loss: 0.913890] time: 0:06:56.647380\n",
      "0.8914117\n",
      "[Epoch 4/50] [Batch 189/300] [D loss: 0.755891] [G loss: 0.763203] time: 0:06:56.957877\n",
      "0.8910265\n",
      "[Epoch 4/50] [Batch 190/300] [D loss: 0.755879] [G loss: 0.903641] time: 0:06:57.272492\n",
      "0.9121886\n",
      "[Epoch 4/50] [Batch 191/300] [D loss: 0.755906] [G loss: 0.777099] time: 0:06:57.568573\n",
      "0.93458337\n",
      "[Epoch 4/50] [Batch 192/300] [D loss: 0.755859] [G loss: 0.865306] time: 0:06:57.872740\n",
      "0.93203706\n",
      "[Epoch 4/50] [Batch 193/300] [D loss: 0.755687] [G loss: 0.819398] time: 0:06:58.175353\n",
      "0.90715736\n",
      "[Epoch 4/50] [Batch 194/300] [D loss: 0.755765] [G loss: 0.937635] time: 0:06:58.482062\n",
      "0.88682723\n",
      "[Epoch 4/50] [Batch 195/300] [D loss: 0.755784] [G loss: 0.956255] time: 0:06:58.762281\n",
      "0.8872586\n",
      "[Epoch 4/50] [Batch 196/300] [D loss: 0.755859] [G loss: 0.792911] time: 0:06:59.055525\n",
      "0.93428373\n",
      "[Epoch 4/50] [Batch 197/300] [D loss: 0.755917] [G loss: 0.853924] time: 0:06:59.335268\n",
      "0.8872673\n",
      "[Epoch 4/50] [Batch 198/300] [D loss: 0.755776] [G loss: 0.834415] time: 0:06:59.611577\n",
      "0.88257927\n",
      "[Epoch 4/50] [Batch 199/300] [D loss: 0.755888] [G loss: 0.939351] time: 0:06:59.900942\n",
      "0.938401\n",
      "[Epoch 4/50] [Batch 200/300] [D loss: 0.755773] [G loss: 0.744608] time: 0:07:00.193311\n",
      "0.91706437\n",
      "[Epoch 4/50] [Batch 201/300] [D loss: 0.755812] [G loss: 0.890076] time: 0:07:00.509936\n",
      "0.8938432\n",
      "[Epoch 4/50] [Batch 202/300] [D loss: 0.755829] [G loss: 0.853906] time: 0:07:00.811036\n",
      "0.90986866\n",
      "[Epoch 4/50] [Batch 203/300] [D loss: 0.755696] [G loss: 1.051488] time: 0:07:01.116934\n",
      "0.9005931\n",
      "[Epoch 4/50] [Batch 204/300] [D loss: 0.755847] [G loss: 0.960779] time: 0:07:01.419593\n",
      "0.9174607\n",
      "[Epoch 4/50] [Batch 205/300] [D loss: 0.755718] [G loss: 0.805401] time: 0:07:01.719154\n",
      "0.9003954\n",
      "[Epoch 4/50] [Batch 206/300] [D loss: 0.755815] [G loss: 0.859459] time: 0:07:02.020514\n",
      "0.9234569\n",
      "[Epoch 4/50] [Batch 207/300] [D loss: 0.755769] [G loss: 0.961073] time: 0:07:02.331214\n",
      "0.92903805\n",
      "[Epoch 4/50] [Batch 208/300] [D loss: 0.755867] [G loss: 0.800163] time: 0:07:02.639492\n",
      "0.9200523\n",
      "[Epoch 4/50] [Batch 209/300] [D loss: 0.755801] [G loss: 0.929904] time: 0:07:02.939962\n",
      "0.91838557\n",
      "[Epoch 4/50] [Batch 210/300] [D loss: 0.755869] [G loss: 0.713837] time: 0:07:03.230859\n",
      "0.883882\n",
      "[Epoch 4/50] [Batch 211/300] [D loss: 0.755792] [G loss: 0.811468] time: 0:07:03.528693\n",
      "0.8946645\n",
      "[Epoch 4/50] [Batch 212/300] [D loss: 0.755733] [G loss: 0.877957] time: 0:07:03.821941\n",
      "0.90603536\n",
      "[Epoch 4/50] [Batch 213/300] [D loss: 0.755803] [G loss: 0.772586] time: 0:07:04.111504\n",
      "0.89021224\n",
      "[Epoch 4/50] [Batch 214/300] [D loss: 0.755830] [G loss: 0.755350] time: 0:07:04.413332\n",
      "0.8988411\n",
      "[Epoch 4/50] [Batch 215/300] [D loss: 0.755796] [G loss: 0.656404] time: 0:07:04.706384\n",
      "0.940619\n",
      "[Epoch 4/50] [Batch 216/300] [D loss: 0.755826] [G loss: 0.834686] time: 0:07:04.998928\n",
      "0.9603076\n",
      "[Epoch 4/50] [Batch 217/300] [D loss: 0.755749] [G loss: 0.804301] time: 0:07:05.311265\n",
      "0.951967\n",
      "[Epoch 4/50] [Batch 218/300] [D loss: 0.755758] [G loss: 0.815458] time: 0:07:05.614855\n",
      "0.8747614\n",
      "[Epoch 4/50] [Batch 219/300] [D loss: 0.755643] [G loss: 0.913208] time: 0:07:05.904561\n",
      "0.84254247\n",
      "[Epoch 4/50] [Batch 220/300] [D loss: 0.755768] [G loss: 0.741460] time: 0:07:06.197486\n",
      "0.93682146\n",
      "[Epoch 4/50] [Batch 221/300] [D loss: 0.755711] [G loss: 0.710091] time: 0:07:06.497792\n",
      "0.9441127\n",
      "[Epoch 4/50] [Batch 222/300] [D loss: 0.755691] [G loss: 0.882892] time: 0:07:06.810089\n",
      "0.8590502\n",
      "[Epoch 4/50] [Batch 223/300] [D loss: 0.755665] [G loss: 0.914146] time: 0:07:07.096905\n",
      "0.96244746\n",
      "[Epoch 4/50] [Batch 224/300] [D loss: 0.755769] [G loss: 0.804796] time: 0:07:07.394893\n",
      "0.88988835\n",
      "[Epoch 4/50] [Batch 225/300] [D loss: 0.755677] [G loss: 0.848115] time: 0:07:07.697665\n",
      "0.93732905\n",
      "[Epoch 4/50] [Batch 226/300] [D loss: 0.755834] [G loss: 0.802173] time: 0:07:08.017560\n",
      "0.93173474\n",
      "[Epoch 4/50] [Batch 227/300] [D loss: 0.755634] [G loss: 0.935986] time: 0:07:08.325985\n",
      "0.8926094\n",
      "[Epoch 4/50] [Batch 228/300] [D loss: 0.755732] [G loss: 0.853053] time: 0:07:08.630801\n",
      "0.8982038\n",
      "[Epoch 4/50] [Batch 229/300] [D loss: 0.755599] [G loss: 1.071516] time: 0:07:08.918330\n",
      "0.9094854\n",
      "[Epoch 4/50] [Batch 230/300] [D loss: 0.755725] [G loss: 0.823385] time: 0:07:09.203812\n",
      "0.8973296\n",
      "[Epoch 4/50] [Batch 231/300] [D loss: 0.755854] [G loss: 0.812500] time: 0:07:09.519796\n",
      "0.90320486\n",
      "[Epoch 4/50] [Batch 232/300] [D loss: 0.755784] [G loss: 0.806479] time: 0:07:09.819218\n",
      "0.94644266\n",
      "[Epoch 4/50] [Batch 233/300] [D loss: 0.755636] [G loss: 0.887704] time: 0:07:10.108117\n",
      "0.95187396\n",
      "[Epoch 4/50] [Batch 234/300] [D loss: 0.755687] [G loss: 0.807147] time: 0:07:10.404816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8453331\n",
      "[Epoch 4/50] [Batch 235/300] [D loss: 0.755573] [G loss: 0.872184] time: 0:07:10.706454\n",
      "0.92348886\n",
      "[Epoch 4/50] [Batch 236/300] [D loss: 0.755784] [G loss: 0.835623] time: 0:07:11.001470\n",
      "0.8914757\n",
      "[Epoch 4/50] [Batch 237/300] [D loss: 0.755661] [G loss: 0.920982] time: 0:07:11.306905\n",
      "0.87126404\n",
      "[Epoch 4/50] [Batch 238/300] [D loss: 0.755810] [G loss: 0.923488] time: 0:07:11.609414\n",
      "0.862799\n",
      "[Epoch 4/50] [Batch 239/300] [D loss: 0.755595] [G loss: 0.894907] time: 0:07:11.903691\n",
      "0.95944685\n",
      "[Epoch 4/50] [Batch 240/300] [D loss: 0.755605] [G loss: 0.900172] time: 0:07:12.178324\n",
      "0.8806552\n",
      "[Epoch 4/50] [Batch 241/300] [D loss: 0.755638] [G loss: 0.863364] time: 0:07:12.483538\n",
      "0.9235778\n",
      "[Epoch 4/50] [Batch 242/300] [D loss: 0.755761] [G loss: 0.754102] time: 0:07:12.771003\n",
      "0.89850163\n",
      "[Epoch 4/50] [Batch 243/300] [D loss: 0.755688] [G loss: 0.692583] time: 0:07:13.055263\n",
      "0.84741896\n",
      "[Epoch 4/50] [Batch 244/300] [D loss: 0.755589] [G loss: 0.971480] time: 0:07:13.355947\n",
      "0.89893335\n",
      "[Epoch 4/50] [Batch 245/300] [D loss: 0.755786] [G loss: 0.779104] time: 0:07:13.643340\n",
      "0.9447815\n",
      "[Epoch 4/50] [Batch 246/300] [D loss: 0.755732] [G loss: 0.896590] time: 0:07:13.942645\n",
      "0.9042041\n",
      "[Epoch 4/50] [Batch 247/300] [D loss: 0.755568] [G loss: 0.947522] time: 0:07:14.240040\n",
      "0.93388337\n",
      "[Epoch 4/50] [Batch 248/300] [D loss: 0.755582] [G loss: 0.875065] time: 0:07:14.534564\n",
      "0.93312716\n",
      "[Epoch 4/50] [Batch 249/300] [D loss: 0.755809] [G loss: 0.748659] time: 0:07:14.833235\n",
      "0.9437844\n",
      "[Epoch 4/50] [Batch 250/300] [D loss: 0.755736] [G loss: 0.970106] time: 0:07:15.099957\n",
      "0.9699213\n",
      "[Epoch 4/50] [Batch 251/300] [D loss: 0.755573] [G loss: 0.716428] time: 0:07:15.383876\n",
      "0.9195358\n",
      "[Epoch 4/50] [Batch 252/300] [D loss: 0.755760] [G loss: 0.979632] time: 0:07:15.655761\n",
      "0.8520624\n",
      "[Epoch 4/50] [Batch 253/300] [D loss: 0.755548] [G loss: 0.902880] time: 0:07:15.952115\n",
      "0.94814044\n",
      "[Epoch 4/50] [Batch 254/300] [D loss: 0.755733] [G loss: 0.985901] time: 0:07:16.250481\n",
      "0.9556565\n",
      "[Epoch 4/50] [Batch 255/300] [D loss: 0.755778] [G loss: 0.904246] time: 0:07:16.541540\n",
      "0.9178267\n",
      "[Epoch 4/50] [Batch 256/300] [D loss: 0.755572] [G loss: 0.806229] time: 0:07:16.829564\n",
      "0.88466835\n",
      "[Epoch 4/50] [Batch 257/300] [D loss: 0.755552] [G loss: 0.798242] time: 0:07:17.133997\n",
      "0.94056225\n",
      "[Epoch 4/50] [Batch 258/300] [D loss: 0.755772] [G loss: 0.841787] time: 0:07:17.402399\n",
      "0.91896206\n",
      "[Epoch 4/50] [Batch 259/300] [D loss: 0.755629] [G loss: 0.874085] time: 0:07:17.702992\n",
      "0.9323182\n",
      "[Epoch 4/50] [Batch 260/300] [D loss: 0.755618] [G loss: 0.709470] time: 0:07:18.001287\n",
      "0.8798923\n",
      "[Epoch 4/50] [Batch 261/300] [D loss: 0.755565] [G loss: 0.867431] time: 0:07:18.302910\n",
      "0.917038\n",
      "[Epoch 4/50] [Batch 262/300] [D loss: 0.755617] [G loss: 0.791597] time: 0:07:18.592493\n",
      "0.9226479\n",
      "[Epoch 4/50] [Batch 263/300] [D loss: 0.755555] [G loss: 0.968427] time: 0:07:18.893500\n",
      "0.93579984\n",
      "[Epoch 4/50] [Batch 264/300] [D loss: 0.755455] [G loss: 0.941110] time: 0:07:19.207016\n",
      "0.9390616\n",
      "[Epoch 4/50] [Batch 265/300] [D loss: 0.755550] [G loss: 0.951132] time: 0:07:19.503749\n",
      "0.8567197\n",
      "[Epoch 4/50] [Batch 266/300] [D loss: 0.755715] [G loss: 0.744764] time: 0:07:19.796832\n",
      "0.89919806\n",
      "[Epoch 4/50] [Batch 267/300] [D loss: 0.755576] [G loss: 0.840118] time: 0:07:20.113650\n",
      "0.8784763\n",
      "[Epoch 4/50] [Batch 268/300] [D loss: 0.755651] [G loss: 0.895242] time: 0:07:20.408080\n",
      "0.8762422\n",
      "[Epoch 4/50] [Batch 269/300] [D loss: 0.755639] [G loss: 0.961870] time: 0:07:20.706643\n",
      "0.897307\n",
      "[Epoch 4/50] [Batch 270/300] [D loss: 0.755737] [G loss: 0.827300] time: 0:07:21.009560\n",
      "0.92760414\n",
      "[Epoch 4/50] [Batch 271/300] [D loss: 0.755658] [G loss: 0.911655] time: 0:07:21.294920\n",
      "0.9382496\n",
      "[Epoch 4/50] [Batch 272/300] [D loss: 0.755640] [G loss: 0.870275] time: 0:07:21.584630\n",
      "0.8699351\n",
      "[Epoch 4/50] [Batch 273/300] [D loss: 0.755562] [G loss: 0.878241] time: 0:07:21.892771\n",
      "0.917239\n",
      "[Epoch 4/50] [Batch 274/300] [D loss: 0.755531] [G loss: 0.814728] time: 0:07:22.197474\n",
      "0.91919273\n",
      "[Epoch 4/50] [Batch 275/300] [D loss: 0.755528] [G loss: 0.850469] time: 0:07:22.485240\n",
      "0.9051177\n",
      "[Epoch 4/50] [Batch 276/300] [D loss: 0.755622] [G loss: 0.889663] time: 0:07:22.788654\n",
      "0.8812027\n",
      "[Epoch 4/50] [Batch 277/300] [D loss: 0.755670] [G loss: 0.870711] time: 0:07:23.088403\n",
      "0.9344668\n",
      "[Epoch 4/50] [Batch 278/300] [D loss: 0.755503] [G loss: 0.796603] time: 0:07:23.382251\n",
      "0.8639026\n",
      "[Epoch 4/50] [Batch 279/300] [D loss: 0.755534] [G loss: 0.833025] time: 0:07:23.677218\n",
      "0.953839\n",
      "[Epoch 4/50] [Batch 280/300] [D loss: 0.755750] [G loss: 0.828367] time: 0:07:23.976353\n",
      "0.89089173\n",
      "[Epoch 4/50] [Batch 281/300] [D loss: 0.755576] [G loss: 0.763373] time: 0:07:24.265881\n",
      "0.8969037\n",
      "[Epoch 4/50] [Batch 282/300] [D loss: 0.755507] [G loss: 0.838636] time: 0:07:24.577520\n",
      "0.9343567\n",
      "[Epoch 4/50] [Batch 283/300] [D loss: 0.755419] [G loss: 0.762397] time: 0:07:24.863701\n",
      "0.8946734\n",
      "[Epoch 4/50] [Batch 284/300] [D loss: 0.755613] [G loss: 0.856354] time: 0:07:25.139879\n",
      "0.9288514\n",
      "[Epoch 4/50] [Batch 285/300] [D loss: 0.755522] [G loss: 0.872351] time: 0:07:25.435536\n",
      "0.9747669\n",
      "[Epoch 4/50] [Batch 286/300] [D loss: 0.755553] [G loss: 0.788453] time: 0:07:25.723893\n",
      "0.8793846\n",
      "[Epoch 4/50] [Batch 287/300] [D loss: 0.755531] [G loss: 0.892453] time: 0:07:26.011414\n",
      "0.9170046\n",
      "[Epoch 4/50] [Batch 288/300] [D loss: 0.755463] [G loss: 0.691994] time: 0:07:26.309248\n",
      "0.93267417\n",
      "[Epoch 4/50] [Batch 289/300] [D loss: 0.755511] [G loss: 0.850921] time: 0:07:26.605317\n",
      "0.9375655\n",
      "[Epoch 4/50] [Batch 290/300] [D loss: 0.755507] [G loss: 0.901157] time: 0:07:26.913073\n",
      "0.94519925\n",
      "[Epoch 4/50] [Batch 291/300] [D loss: 0.755511] [G loss: 0.734933] time: 0:07:27.208752\n",
      "0.9126835\n",
      "[Epoch 4/50] [Batch 292/300] [D loss: 0.755507] [G loss: 0.895036] time: 0:07:27.510581\n",
      "0.88976794\n",
      "[Epoch 4/50] [Batch 293/300] [D loss: 0.755430] [G loss: 0.898046] time: 0:07:27.807950\n",
      "0.8561563\n",
      "[Epoch 4/50] [Batch 294/300] [D loss: 0.755578] [G loss: 0.953729] time: 0:07:28.098862\n",
      "0.9054529\n",
      "[Epoch 4/50] [Batch 295/300] [D loss: 0.755592] [G loss: 0.805241] time: 0:07:28.382522\n",
      "0.8907985\n",
      "[Epoch 4/50] [Batch 296/300] [D loss: 0.755520] [G loss: 0.785073] time: 0:07:28.684076\n",
      "0.870467\n",
      "[Epoch 4/50] [Batch 297/300] [D loss: 0.755521] [G loss: 0.915758] time: 0:07:28.994865\n",
      "0.9227808\n",
      "[Epoch 4/50] [Batch 298/300] [D loss: 0.755571] [G loss: 0.828388] time: 0:07:29.300235\n",
      "0.933038\n",
      "[Epoch 4/50] [Batch 299/300] [D loss: 0.755433] [G loss: 0.749148] time: 0:07:29.602149\n",
      "0.9430142\n",
      "[Epoch 5/50] [Batch 0/300] [D loss: 0.755496] [G loss: 0.935857] time: 0:07:29.895791\n",
      "0.9071999\n",
      "[Epoch 5/50] [Batch 1/300] [D loss: 0.755427] [G loss: 0.903047] time: 0:07:30.209912\n",
      "0.8895989\n",
      "[Epoch 5/50] [Batch 2/300] [D loss: 0.755401] [G loss: 1.096341] time: 0:07:30.516967\n",
      "0.84677386\n",
      "[Epoch 5/50] [Batch 3/300] [D loss: 0.755455] [G loss: 0.823291] time: 0:07:30.815880\n",
      "0.84694105\n",
      "[Epoch 5/50] [Batch 5/300] [D loss: 0.755431] [G loss: 0.859285] time: 0:07:31.125821\n",
      "0.88335973\n",
      "[Epoch 5/50] [Batch 6/300] [D loss: 0.755586] [G loss: 0.758462] time: 0:07:31.427969\n",
      "0.9444406\n",
      "[Epoch 5/50] [Batch 7/300] [D loss: 0.755435] [G loss: 0.853540] time: 0:07:31.730598\n",
      "0.90116686\n",
      "[Epoch 5/50] [Batch 8/300] [D loss: 0.755552] [G loss: 0.818337] time: 0:07:32.023830\n",
      "0.91176766\n",
      "[Epoch 5/50] [Batch 9/300] [D loss: 0.755546] [G loss: 0.842807] time: 0:07:32.334221\n",
      "0.91751194\n",
      "[Epoch 5/50] [Batch 10/300] [D loss: 0.755511] [G loss: 0.899115] time: 0:07:32.632934\n",
      "0.9593201\n",
      "[Epoch 5/50] [Batch 11/300] [D loss: 0.755556] [G loss: 0.791453] time: 0:07:32.928701\n",
      "0.9539167\n",
      "[Epoch 5/50] [Batch 12/300] [D loss: 0.755541] [G loss: 0.770168] time: 0:07:33.233847\n",
      "0.9115729\n",
      "[Epoch 5/50] [Batch 13/300] [D loss: 0.755429] [G loss: 0.765776] time: 0:07:33.533127\n",
      "0.9158657\n",
      "[Epoch 5/50] [Batch 14/300] [D loss: 0.755498] [G loss: 0.852891] time: 0:07:33.833886\n",
      "0.9066532\n",
      "[Epoch 5/50] [Batch 15/300] [D loss: 0.755481] [G loss: 0.926164] time: 0:07:34.130542\n",
      "0.93269634\n",
      "[Epoch 5/50] [Batch 16/300] [D loss: 0.755504] [G loss: 0.719550] time: 0:07:34.424084\n",
      "0.937633\n",
      "[Epoch 5/50] [Batch 17/300] [D loss: 0.755562] [G loss: 0.798492] time: 0:07:34.718592\n",
      "0.8771935\n",
      "[Epoch 5/50] [Batch 18/300] [D loss: 0.755447] [G loss: 0.821121] time: 0:07:35.010028\n",
      "0.88449806\n",
      "[Epoch 5/50] [Batch 19/300] [D loss: 0.755501] [G loss: 0.850593] time: 0:07:35.301002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9325905\n",
      "[Epoch 5/50] [Batch 20/300] [D loss: 0.755581] [G loss: 0.721933] time: 0:07:35.612099\n",
      "0.86596775\n",
      "[Epoch 5/50] [Batch 21/300] [D loss: 0.755386] [G loss: 0.798358] time: 0:07:35.897129\n",
      "0.92019516\n",
      "[Epoch 5/50] [Batch 22/300] [D loss: 0.755542] [G loss: 0.785777] time: 0:07:36.213323\n",
      "0.9121833\n",
      "[Epoch 5/50] [Batch 23/300] [D loss: 0.755343] [G loss: 0.841122] time: 0:07:36.512506\n",
      "0.9068549\n",
      "[Epoch 5/50] [Batch 24/300] [D loss: 0.755468] [G loss: 0.892693] time: 0:07:36.797720\n",
      "0.8937893\n",
      "[Epoch 5/50] [Batch 25/300] [D loss: 0.755501] [G loss: 0.883109] time: 0:07:37.097062\n",
      "0.9292788\n",
      "[Epoch 5/50] [Batch 26/300] [D loss: 0.755489] [G loss: 0.896861] time: 0:07:37.397659\n",
      "0.87275714\n",
      "[Epoch 5/50] [Batch 27/300] [D loss: 0.755500] [G loss: 0.980405] time: 0:07:37.687066\n",
      "0.8891115\n",
      "[Epoch 5/50] [Batch 28/300] [D loss: 0.755483] [G loss: 0.887299] time: 0:07:37.992260\n",
      "0.9151605\n",
      "[Epoch 5/50] [Batch 29/300] [D loss: 0.755382] [G loss: 0.818356] time: 0:07:38.309605\n",
      "0.8958896\n",
      "[Epoch 5/50] [Batch 30/300] [D loss: 0.755519] [G loss: 0.814815] time: 0:07:38.592101\n",
      "0.9319772\n",
      "[Epoch 5/50] [Batch 31/300] [D loss: 0.755344] [G loss: 0.970665] time: 0:07:38.903481\n",
      "0.90752107\n",
      "[Epoch 5/50] [Batch 32/300] [D loss: 0.755359] [G loss: 0.994160] time: 0:07:39.189408\n",
      "0.861412\n",
      "[Epoch 5/50] [Batch 33/300] [D loss: 0.755434] [G loss: 0.830556] time: 0:07:39.490824\n",
      "0.8477575\n",
      "[Epoch 5/50] [Batch 34/300] [D loss: 0.755350] [G loss: 0.752127] time: 0:07:39.787058\n",
      "0.93194145\n",
      "[Epoch 5/50] [Batch 35/300] [D loss: 0.755445] [G loss: 0.890644] time: 0:07:40.081093\n",
      "0.8848104\n",
      "[Epoch 5/50] [Batch 36/300] [D loss: 0.755283] [G loss: 0.997957] time: 0:07:40.393294\n",
      "0.8875365\n",
      "[Epoch 5/50] [Batch 37/300] [D loss: 0.755366] [G loss: 0.968317] time: 0:07:40.706252\n",
      "0.9456615\n",
      "[Epoch 5/50] [Batch 38/300] [D loss: 0.755462] [G loss: 0.780353] time: 0:07:41.011881\n",
      "0.90168595\n",
      "[Epoch 5/50] [Batch 39/300] [D loss: 0.755417] [G loss: 1.028660] time: 0:07:41.316737\n",
      "0.950133\n",
      "[Epoch 5/50] [Batch 40/300] [D loss: 0.755480] [G loss: 0.785636] time: 0:07:41.604622\n",
      "0.8832329\n",
      "[Epoch 5/50] [Batch 41/300] [D loss: 0.755433] [G loss: 0.887038] time: 0:07:41.887998\n",
      "0.90915424\n",
      "[Epoch 5/50] [Batch 42/300] [D loss: 0.755292] [G loss: 0.775723] time: 0:07:42.190391\n",
      "0.9167247\n",
      "[Epoch 5/50] [Batch 43/300] [D loss: 0.755268] [G loss: 0.803596] time: 0:07:42.485217\n",
      "0.85816425\n",
      "[Epoch 5/50] [Batch 44/300] [D loss: 0.755385] [G loss: 0.822054] time: 0:07:42.780667\n",
      "0.8824776\n",
      "[Epoch 5/50] [Batch 45/300] [D loss: 0.755356] [G loss: 0.956316] time: 0:07:43.085139\n",
      "0.935821\n",
      "[Epoch 5/50] [Batch 46/300] [D loss: 0.755415] [G loss: 0.710519] time: 0:07:43.385577\n",
      "0.9311623\n",
      "[Epoch 5/50] [Batch 47/300] [D loss: 0.755333] [G loss: 0.816605] time: 0:07:43.658976\n",
      "0.93508273\n",
      "[Epoch 5/50] [Batch 48/300] [D loss: 0.755377] [G loss: 0.778283] time: 0:07:43.935992\n",
      "0.9417079\n",
      "[Epoch 5/50] [Batch 49/300] [D loss: 0.755458] [G loss: 0.940947] time: 0:07:44.231717\n",
      "0.9142638\n",
      "[Epoch 5/50] [Batch 50/300] [D loss: 0.755400] [G loss: 0.862415] time: 0:07:44.523553\n",
      "0.9124947\n",
      "[Epoch 5/50] [Batch 51/300] [D loss: 0.755410] [G loss: 0.725970] time: 0:07:44.805816\n",
      "0.8736474\n",
      "[Epoch 5/50] [Batch 52/300] [D loss: 0.755412] [G loss: 0.916229] time: 0:07:45.101879\n",
      "0.91912913\n",
      "[Epoch 5/50] [Batch 53/300] [D loss: 0.755489] [G loss: 0.824024] time: 0:07:45.411465\n",
      "0.92007273\n",
      "[Epoch 5/50] [Batch 54/300] [D loss: 0.755379] [G loss: 0.962857] time: 0:07:45.805122\n",
      "0.9198558\n",
      "[Epoch 5/50] [Batch 55/300] [D loss: 0.755415] [G loss: 0.741518] time: 0:07:46.098418\n",
      "0.91666585\n",
      "[Epoch 5/50] [Batch 56/300] [D loss: 0.755364] [G loss: 0.774494] time: 0:07:46.402178\n",
      "0.9187765\n",
      "[Epoch 5/50] [Batch 57/300] [D loss: 0.755339] [G loss: 0.843143] time: 0:07:46.690861\n",
      "0.88264185\n",
      "[Epoch 5/50] [Batch 58/300] [D loss: 0.755264] [G loss: 0.857018] time: 0:07:46.989986\n",
      "0.898853\n",
      "[Epoch 5/50] [Batch 59/300] [D loss: 0.755402] [G loss: 0.688140] time: 0:07:47.284899\n",
      "0.8945845\n",
      "[Epoch 5/50] [Batch 60/300] [D loss: 0.755320] [G loss: 0.835662] time: 0:07:47.586816\n",
      "0.96259075\n",
      "[Epoch 5/50] [Batch 61/300] [D loss: 0.755282] [G loss: 0.787433] time: 0:07:47.881573\n",
      "0.90591913\n",
      "[Epoch 5/50] [Batch 62/300] [D loss: 0.755320] [G loss: 1.000493] time: 0:07:48.186786\n",
      "0.9460292\n",
      "[Epoch 5/50] [Batch 63/300] [D loss: 0.755450] [G loss: 0.903338] time: 0:07:48.475509\n",
      "0.9264441\n",
      "[Epoch 5/50] [Batch 64/300] [D loss: 0.755303] [G loss: 0.662526] time: 0:07:48.769042\n",
      "0.9089593\n",
      "[Epoch 5/50] [Batch 65/300] [D loss: 0.755365] [G loss: 0.792044] time: 0:07:49.067744\n",
      "0.94116503\n",
      "[Epoch 5/50] [Batch 66/300] [D loss: 0.755349] [G loss: 0.679615] time: 0:07:49.357627\n",
      "0.89024395\n",
      "[Epoch 5/50] [Batch 67/300] [D loss: 0.755349] [G loss: 0.875566] time: 0:07:49.659507\n",
      "0.948271\n",
      "[Epoch 5/50] [Batch 68/300] [D loss: 0.755417] [G loss: 0.828421] time: 0:07:49.949042\n",
      "0.90378076\n",
      "[Epoch 5/50] [Batch 69/300] [D loss: 0.755202] [G loss: 0.854237] time: 0:07:50.253915\n",
      "0.90658563\n",
      "[Epoch 5/50] [Batch 70/300] [D loss: 0.755352] [G loss: 0.781109] time: 0:07:50.565217\n",
      "0.8755696\n",
      "[Epoch 5/50] [Batch 71/300] [D loss: 0.755339] [G loss: 0.828339] time: 0:07:50.855848\n",
      "0.89383394\n",
      "[Epoch 5/50] [Batch 72/300] [D loss: 0.755365] [G loss: 0.787533] time: 0:07:51.150987\n",
      "0.8957831\n",
      "[Epoch 5/50] [Batch 73/300] [D loss: 0.755268] [G loss: 0.857593] time: 0:07:51.424318\n",
      "0.9217122\n",
      "[Epoch 5/50] [Batch 74/300] [D loss: 0.755324] [G loss: 0.805025] time: 0:07:51.711318\n",
      "0.95402527\n",
      "[Epoch 5/50] [Batch 75/300] [D loss: 0.755242] [G loss: 0.940418] time: 0:07:52.008110\n",
      "0.91249585\n",
      "[Epoch 5/50] [Batch 76/300] [D loss: 0.755200] [G loss: 0.896609] time: 0:07:52.313181\n",
      "0.9238837\n",
      "[Epoch 5/50] [Batch 77/300] [D loss: 0.755260] [G loss: 0.840674] time: 0:07:52.610705\n",
      "0.912328\n",
      "[Epoch 5/50] [Batch 78/300] [D loss: 0.755272] [G loss: 0.831690] time: 0:07:52.913448\n",
      "0.9097786\n",
      "[Epoch 5/50] [Batch 79/300] [D loss: 0.755425] [G loss: 0.789577] time: 0:07:53.220021\n",
      "0.9162791\n",
      "[Epoch 5/50] [Batch 80/300] [D loss: 0.755229] [G loss: 0.818147] time: 0:07:53.520185\n",
      "0.9578047\n",
      "[Epoch 5/50] [Batch 81/300] [D loss: 0.755352] [G loss: 0.830058] time: 0:07:53.796539\n",
      "0.8755121\n",
      "[Epoch 5/50] [Batch 82/300] [D loss: 0.755318] [G loss: 0.861258] time: 0:07:54.107239\n",
      "0.9289808\n",
      "[Epoch 5/50] [Batch 83/300] [D loss: 0.755297] [G loss: 0.900460] time: 0:07:54.398383\n",
      "0.90278417\n",
      "[Epoch 5/50] [Batch 84/300] [D loss: 0.755240] [G loss: 0.749505] time: 0:07:54.696306\n",
      "0.955461\n",
      "[Epoch 5/50] [Batch 85/300] [D loss: 0.755525] [G loss: 0.871767] time: 0:07:54.996881\n",
      "0.891942\n",
      "[Epoch 5/50] [Batch 86/300] [D loss: 0.755206] [G loss: 0.804716] time: 0:07:55.303579\n",
      "0.9315338\n",
      "[Epoch 5/50] [Batch 87/300] [D loss: 0.755341] [G loss: 0.787100] time: 0:07:55.595915\n",
      "0.9159414\n",
      "[Epoch 5/50] [Batch 88/300] [D loss: 0.755352] [G loss: 0.740672] time: 0:07:55.879917\n",
      "0.8800638\n",
      "[Epoch 5/50] [Batch 89/300] [D loss: 0.755247] [G loss: 0.978612] time: 0:07:56.195823\n",
      "0.8803563\n",
      "[Epoch 5/50] [Batch 90/300] [D loss: 0.755213] [G loss: 0.849012] time: 0:07:56.492133\n",
      "0.920935\n",
      "[Epoch 5/50] [Batch 91/300] [D loss: 0.755311] [G loss: 0.813129] time: 0:07:56.780159\n",
      "0.9263002\n",
      "[Epoch 5/50] [Batch 92/300] [D loss: 0.755275] [G loss: 0.876626] time: 0:07:57.081370\n",
      "0.87025476\n",
      "[Epoch 5/50] [Batch 93/300] [D loss: 0.755246] [G loss: 0.980268] time: 0:07:57.374482\n",
      "0.937119\n",
      "[Epoch 5/50] [Batch 94/300] [D loss: 0.755422] [G loss: 0.746498] time: 0:07:57.676654\n",
      "0.86171764\n",
      "[Epoch 5/50] [Batch 95/300] [D loss: 0.755172] [G loss: 0.946358] time: 0:07:57.975667\n",
      "0.9258345\n",
      "[Epoch 5/50] [Batch 96/300] [D loss: 0.755371] [G loss: 0.779681] time: 0:07:58.288025\n",
      "0.8827903\n",
      "[Epoch 5/50] [Batch 97/300] [D loss: 0.755358] [G loss: 0.822762] time: 0:07:58.591501\n",
      "0.88988525\n",
      "[Epoch 5/50] [Batch 98/300] [D loss: 0.755386] [G loss: 0.653936] time: 0:07:58.891866\n",
      "0.9444116\n",
      "[Epoch 5/50] [Batch 99/300] [D loss: 0.755336] [G loss: 0.905827] time: 0:07:59.189504\n",
      "0.8914369\n",
      "[Epoch 5/50] [Batch 100/300] [D loss: 0.755253] [G loss: 0.913434] time: 0:07:59.493536\n",
      "0.9066593\n",
      "[Epoch 5/50] [Batch 101/300] [D loss: 0.755206] [G loss: 0.830971] time: 0:07:59.795518\n",
      "0.87599736\n",
      "[Epoch 5/50] [Batch 102/300] [D loss: 0.755164] [G loss: 0.848431] time: 0:08:00.095470\n",
      "0.94030446\n",
      "[Epoch 5/50] [Batch 103/300] [D loss: 0.755290] [G loss: 0.925141] time: 0:08:00.404149\n",
      "0.93229914\n",
      "[Epoch 5/50] [Batch 104/300] [D loss: 0.755293] [G loss: 0.814542] time: 0:08:00.689527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93942624\n",
      "[Epoch 5/50] [Batch 105/300] [D loss: 0.755158] [G loss: 0.771731] time: 0:08:00.979113\n",
      "0.96832675\n",
      "[Epoch 5/50] [Batch 106/300] [D loss: 0.755327] [G loss: 0.881260] time: 0:08:01.253097\n",
      "0.8772888\n",
      "[Epoch 5/50] [Batch 107/300] [D loss: 0.755207] [G loss: 0.907558] time: 0:08:01.536282\n",
      "0.87882143\n",
      "[Epoch 5/50] [Batch 108/300] [D loss: 0.755178] [G loss: 0.888662] time: 0:08:01.849599\n",
      "0.94699717\n",
      "[Epoch 5/50] [Batch 109/300] [D loss: 0.755251] [G loss: 0.827721] time: 0:08:02.160271\n",
      "0.88491386\n",
      "[Epoch 5/50] [Batch 110/300] [D loss: 0.755324] [G loss: 0.874716] time: 0:08:02.459730\n",
      "0.89273447\n",
      "[Epoch 5/50] [Batch 111/300] [D loss: 0.755277] [G loss: 0.781253] time: 0:08:02.742625\n",
      "0.924428\n",
      "[Epoch 5/50] [Batch 112/300] [D loss: 0.755183] [G loss: 0.868274] time: 0:08:03.041462\n",
      "0.9000888\n",
      "[Epoch 5/50] [Batch 113/300] [D loss: 0.755184] [G loss: 0.883327] time: 0:08:03.338579\n",
      "0.90168184\n",
      "[Epoch 5/50] [Batch 114/300] [D loss: 0.755103] [G loss: 0.865890] time: 0:08:03.646641\n",
      "0.8895801\n",
      "[Epoch 5/50] [Batch 115/300] [D loss: 0.755114] [G loss: 0.844955] time: 0:08:03.943668\n",
      "0.9357204\n",
      "[Epoch 5/50] [Batch 116/300] [D loss: 0.755276] [G loss: 0.817125] time: 0:08:04.242926\n",
      "0.93598557\n",
      "[Epoch 5/50] [Batch 117/300] [D loss: 0.755136] [G loss: 0.855191] time: 0:08:04.533884\n",
      "0.9531514\n",
      "[Epoch 5/50] [Batch 118/300] [D loss: 0.755075] [G loss: 1.016795] time: 0:08:04.837058\n",
      "0.9014592\n",
      "[Epoch 5/50] [Batch 119/300] [D loss: 0.755095] [G loss: 0.800686] time: 0:08:05.127284\n",
      "0.9092185\n",
      "[Epoch 5/50] [Batch 120/300] [D loss: 0.755210] [G loss: 0.851446] time: 0:08:05.423238\n",
      "0.9367053\n",
      "[Epoch 5/50] [Batch 121/300] [D loss: 0.755111] [G loss: 0.799415] time: 0:08:05.724727\n",
      "0.8826875\n",
      "[Epoch 5/50] [Batch 122/300] [D loss: 0.755140] [G loss: 0.777994] time: 0:08:06.028727\n",
      "0.97175026\n",
      "[Epoch 5/50] [Batch 123/300] [D loss: 0.755161] [G loss: 0.769052] time: 0:08:06.332774\n",
      "0.88383484\n",
      "[Epoch 5/50] [Batch 124/300] [D loss: 0.755136] [G loss: 0.991212] time: 0:08:06.618968\n",
      "0.9113722\n",
      "[Epoch 5/50] [Batch 125/300] [D loss: 0.755244] [G loss: 0.798463] time: 0:08:06.915639\n",
      "0.8877241\n",
      "[Epoch 5/50] [Batch 126/300] [D loss: 0.755139] [G loss: 0.708760] time: 0:08:07.219097\n",
      "0.9399387\n",
      "[Epoch 5/50] [Batch 127/300] [D loss: 0.755155] [G loss: 0.886674] time: 0:08:07.529202\n",
      "0.90993446\n",
      "[Epoch 5/50] [Batch 128/300] [D loss: 0.755241] [G loss: 0.884442] time: 0:08:07.831989\n",
      "0.90213233\n",
      "[Epoch 5/50] [Batch 129/300] [D loss: 0.755149] [G loss: 0.740586] time: 0:08:08.150074\n",
      "0.8983651\n",
      "[Epoch 5/50] [Batch 130/300] [D loss: 0.755232] [G loss: 0.976426] time: 0:08:08.448766\n",
      "0.9188618\n",
      "[Epoch 5/50] [Batch 131/300] [D loss: 0.755075] [G loss: 0.799522] time: 0:08:08.742868\n",
      "0.8981754\n",
      "[Epoch 5/50] [Batch 132/300] [D loss: 0.755251] [G loss: 0.792116] time: 0:08:09.048719\n",
      "0.8958084\n",
      "[Epoch 5/50] [Batch 133/300] [D loss: 0.755171] [G loss: 0.905374] time: 0:08:09.359852\n",
      "0.9111631\n",
      "[Epoch 5/50] [Batch 134/300] [D loss: 0.755146] [G loss: 0.851087] time: 0:08:09.666144\n",
      "0.8881476\n",
      "[Epoch 5/50] [Batch 135/300] [D loss: 0.755095] [G loss: 0.819836] time: 0:08:09.970900\n",
      "0.93048596\n",
      "[Epoch 5/50] [Batch 136/300] [D loss: 0.755240] [G loss: 0.774749] time: 0:08:10.274979\n",
      "0.9372792\n",
      "[Epoch 5/50] [Batch 137/300] [D loss: 0.755203] [G loss: 0.952430] time: 0:08:10.579708\n",
      "0.89803106\n",
      "[Epoch 5/50] [Batch 138/300] [D loss: 0.755264] [G loss: 0.808139] time: 0:08:10.887127\n",
      "0.9048551\n",
      "[Epoch 5/50] [Batch 139/300] [D loss: 0.755184] [G loss: 0.884537] time: 0:08:11.189024\n",
      "0.8904748\n",
      "[Epoch 5/50] [Batch 140/300] [D loss: 0.755132] [G loss: 0.848756] time: 0:08:11.491312\n",
      "0.90063405\n",
      "[Epoch 5/50] [Batch 141/300] [D loss: 0.755140] [G loss: 0.892071] time: 0:08:11.798607\n",
      "0.89408827\n",
      "[Epoch 5/50] [Batch 142/300] [D loss: 0.755264] [G loss: 0.718938] time: 0:08:12.107463\n",
      "0.9048359\n",
      "[Epoch 5/50] [Batch 143/300] [D loss: 0.755209] [G loss: 0.862429] time: 0:08:12.403490\n",
      "0.89227295\n",
      "[Epoch 5/50] [Batch 144/300] [D loss: 0.755210] [G loss: 0.859072] time: 0:08:12.714182\n",
      "0.9059519\n",
      "[Epoch 5/50] [Batch 145/300] [D loss: 0.755077] [G loss: 0.830575] time: 0:08:13.017874\n",
      "0.91353136\n",
      "[Epoch 5/50] [Batch 146/300] [D loss: 0.755213] [G loss: 0.890557] time: 0:08:13.305455\n",
      "0.9226429\n",
      "[Epoch 5/50] [Batch 147/300] [D loss: 0.755146] [G loss: 0.802042] time: 0:08:13.605206\n",
      "0.89806455\n",
      "[Epoch 5/50] [Batch 148/300] [D loss: 0.755069] [G loss: 0.877819] time: 0:08:13.900017\n",
      "0.9017773\n",
      "[Epoch 5/50] [Batch 149/300] [D loss: 0.755230] [G loss: 0.939697] time: 0:08:14.201145\n",
      "0.9172349\n",
      "[Epoch 5/50] [Batch 150/300] [D loss: 0.755107] [G loss: 0.784130] time: 0:08:14.497926\n",
      "0.917284\n",
      "[Epoch 5/50] [Batch 151/300] [D loss: 0.755172] [G loss: 0.801148] time: 0:08:14.790307\n",
      "0.93281937\n",
      "[Epoch 5/50] [Batch 152/300] [D loss: 0.755221] [G loss: 0.794239] time: 0:08:15.083685\n",
      "0.9101672\n",
      "[Epoch 5/50] [Batch 153/300] [D loss: 0.755066] [G loss: 0.992832] time: 0:08:15.391733\n",
      "0.9290652\n",
      "[Epoch 5/50] [Batch 154/300] [D loss: 0.755146] [G loss: 0.768418] time: 0:08:15.671979\n",
      "0.917414\n",
      "[Epoch 5/50] [Batch 155/300] [D loss: 0.755172] [G loss: 0.798156] time: 0:08:15.964522\n",
      "0.90386456\n",
      "[Epoch 5/50] [Batch 156/300] [D loss: 0.755158] [G loss: 0.738546] time: 0:08:16.273276\n",
      "0.8800973\n",
      "[Epoch 5/50] [Batch 157/300] [D loss: 0.755195] [G loss: 0.818952] time: 0:08:16.569868\n",
      "0.91743064\n",
      "[Epoch 5/50] [Batch 158/300] [D loss: 0.755133] [G loss: 0.861491] time: 0:08:16.885331\n",
      "0.912872\n",
      "[Epoch 5/50] [Batch 159/300] [D loss: 0.755150] [G loss: 0.826776] time: 0:08:17.184645\n",
      "0.89849406\n",
      "[Epoch 5/50] [Batch 160/300] [D loss: 0.755192] [G loss: 0.855180] time: 0:08:17.482066\n",
      "0.8675713\n",
      "[Epoch 5/50] [Batch 161/300] [D loss: 0.755083] [G loss: 1.030230] time: 0:08:17.790383\n",
      "0.9590897\n",
      "[Epoch 5/50] [Batch 162/300] [D loss: 0.755222] [G loss: 0.866814] time: 0:08:18.080445\n",
      "0.8814083\n",
      "[Epoch 5/50] [Batch 163/300] [D loss: 0.755003] [G loss: 0.895756] time: 0:08:18.370814\n",
      "0.9414881\n",
      "[Epoch 5/50] [Batch 164/300] [D loss: 0.755053] [G loss: 0.756487] time: 0:08:18.671444\n",
      "0.91466093\n",
      "[Epoch 5/50] [Batch 165/300] [D loss: 0.755183] [G loss: 0.840131] time: 0:08:18.965111\n",
      "0.8760085\n",
      "[Epoch 5/50] [Batch 166/300] [D loss: 0.755208] [G loss: 0.899897] time: 0:08:19.255160\n",
      "0.9311015\n",
      "[Epoch 5/50] [Batch 167/300] [D loss: 0.755202] [G loss: 0.811006] time: 0:08:19.562996\n",
      "0.9819391\n",
      "[Epoch 5/50] [Batch 168/300] [D loss: 0.755088] [G loss: 0.761823] time: 0:08:19.853141\n",
      "0.9030066\n",
      "[Epoch 5/50] [Batch 169/300] [D loss: 0.755147] [G loss: 0.958138] time: 0:08:20.160592\n",
      "0.94605565\n",
      "[Epoch 5/50] [Batch 170/300] [D loss: 0.755084] [G loss: 0.974347] time: 0:08:20.461049\n",
      "0.8715635\n",
      "[Epoch 5/50] [Batch 171/300] [D loss: 0.755051] [G loss: 0.843235] time: 0:08:20.755841\n",
      "0.9047773\n",
      "[Epoch 5/50] [Batch 172/300] [D loss: 0.755034] [G loss: 0.864726] time: 0:08:21.046606\n",
      "0.94227105\n",
      "[Epoch 5/50] [Batch 173/300] [D loss: 0.755084] [G loss: 0.867883] time: 0:08:21.347829\n",
      "0.91957134\n",
      "[Epoch 5/50] [Batch 174/300] [D loss: 0.755158] [G loss: 0.766030] time: 0:08:21.649475\n",
      "0.9182523\n",
      "[Epoch 5/50] [Batch 175/300] [D loss: 0.755081] [G loss: 0.800906] time: 0:08:21.961648\n",
      "0.87505263\n",
      "[Epoch 5/50] [Batch 176/300] [D loss: 0.755055] [G loss: 0.732735] time: 0:08:22.266576\n",
      "0.9550063\n",
      "[Epoch 5/50] [Batch 177/300] [D loss: 0.755160] [G loss: 0.724745] time: 0:08:22.556585\n",
      "0.8778799\n",
      "[Epoch 5/50] [Batch 178/300] [D loss: 0.755243] [G loss: 0.835967] time: 0:08:22.863603\n",
      "0.8564666\n",
      "[Epoch 5/50] [Batch 179/300] [D loss: 0.755046] [G loss: 0.766025] time: 0:08:23.155442\n",
      "0.877481\n",
      "[Epoch 5/50] [Batch 180/300] [D loss: 0.755109] [G loss: 0.840035] time: 0:08:23.428088\n",
      "0.92236775\n",
      "[Epoch 5/50] [Batch 181/300] [D loss: 0.754986] [G loss: 0.852457] time: 0:08:23.736662\n",
      "0.92861205\n",
      "[Epoch 5/50] [Batch 182/300] [D loss: 0.755117] [G loss: 0.826202] time: 0:08:24.038975\n",
      "0.9352007\n",
      "[Epoch 5/50] [Batch 183/300] [D loss: 0.755078] [G loss: 0.845018] time: 0:08:24.331993\n",
      "0.9255236\n",
      "[Epoch 5/50] [Batch 184/300] [D loss: 0.755095] [G loss: 0.934918] time: 0:08:24.616937\n",
      "0.8854409\n",
      "[Epoch 5/50] [Batch 185/300] [D loss: 0.755139] [G loss: 0.784420] time: 0:08:24.913118\n",
      "0.91829664\n",
      "[Epoch 5/50] [Batch 186/300] [D loss: 0.755075] [G loss: 0.764811] time: 0:08:25.212065\n",
      "0.8891534\n",
      "[Epoch 5/50] [Batch 187/300] [D loss: 0.755124] [G loss: 0.824433] time: 0:08:25.521667\n",
      "0.9488384\n",
      "[Epoch 5/50] [Batch 188/300] [D loss: 0.755160] [G loss: 0.790588] time: 0:08:25.833510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8994439\n",
      "[Epoch 5/50] [Batch 189/300] [D loss: 0.755245] [G loss: 0.846430] time: 0:08:26.146003\n",
      "0.8927329\n",
      "[Epoch 5/50] [Batch 190/300] [D loss: 0.755026] [G loss: 0.767633] time: 0:08:26.442765\n",
      "0.9551187\n",
      "[Epoch 5/50] [Batch 191/300] [D loss: 0.755025] [G loss: 0.866787] time: 0:08:26.742415\n",
      "0.9355803\n",
      "[Epoch 5/50] [Batch 192/300] [D loss: 0.755045] [G loss: 0.744773] time: 0:08:27.023507\n",
      "0.88976574\n",
      "[Epoch 5/50] [Batch 193/300] [D loss: 0.754964] [G loss: 0.754859] time: 0:08:27.315460\n",
      "0.94076276\n",
      "[Epoch 5/50] [Batch 194/300] [D loss: 0.754979] [G loss: 0.726626] time: 0:08:27.624920\n",
      "0.9164608\n",
      "[Epoch 5/50] [Batch 195/300] [D loss: 0.755110] [G loss: 0.770031] time: 0:08:27.911946\n",
      "0.90613395\n",
      "[Epoch 5/50] [Batch 196/300] [D loss: 0.755074] [G loss: 0.856899] time: 0:08:28.214520\n",
      "0.92719984\n",
      "[Epoch 5/50] [Batch 197/300] [D loss: 0.755025] [G loss: 0.738926] time: 0:08:28.505926\n",
      "0.90385455\n",
      "[Epoch 5/50] [Batch 198/300] [D loss: 0.754962] [G loss: 0.826310] time: 0:08:28.788071\n",
      "0.93448836\n",
      "[Epoch 5/50] [Batch 199/300] [D loss: 0.755081] [G loss: 0.805847] time: 0:08:29.075890\n",
      "0.94052154\n",
      "[Epoch 5/50] [Batch 200/300] [D loss: 0.754974] [G loss: 0.880567] time: 0:08:29.374653\n",
      "0.9050531\n",
      "[Epoch 5/50] [Batch 201/300] [D loss: 0.755063] [G loss: 0.757407] time: 0:08:29.675706\n",
      "0.9348143\n",
      "[Epoch 5/50] [Batch 202/300] [D loss: 0.755177] [G loss: 0.758953] time: 0:08:29.971435\n",
      "0.8911944\n",
      "[Epoch 5/50] [Batch 203/300] [D loss: 0.755017] [G loss: 0.784752] time: 0:08:30.264887\n",
      "0.955936\n",
      "[Epoch 5/50] [Batch 204/300] [D loss: 0.755020] [G loss: 0.825660] time: 0:08:30.576703\n",
      "0.9115565\n",
      "[Epoch 5/50] [Batch 205/300] [D loss: 0.755007] [G loss: 0.859903] time: 0:08:30.872348\n",
      "0.88768035\n",
      "[Epoch 5/50] [Batch 206/300] [D loss: 0.755089] [G loss: 0.738802] time: 0:08:31.175613\n",
      "0.89743185\n",
      "[Epoch 5/50] [Batch 207/300] [D loss: 0.755051] [G loss: 0.801447] time: 0:08:31.471840\n",
      "0.9130371\n",
      "[Epoch 5/50] [Batch 208/300] [D loss: 0.755027] [G loss: 0.814938] time: 0:08:31.773244\n",
      "0.9059689\n",
      "[Epoch 5/50] [Batch 209/300] [D loss: 0.754981] [G loss: 0.748467] time: 0:08:32.083206\n",
      "0.90257597\n",
      "[Epoch 5/50] [Batch 210/300] [D loss: 0.754998] [G loss: 0.809164] time: 0:08:32.376129\n",
      "0.8921416\n",
      "[Epoch 5/50] [Batch 211/300] [D loss: 0.755125] [G loss: 0.989294] time: 0:08:32.700532\n",
      "0.96977997\n",
      "[Epoch 5/50] [Batch 212/300] [D loss: 0.754989] [G loss: 0.824412] time: 0:08:32.996786\n",
      "0.8985503\n",
      "[Epoch 5/50] [Batch 213/300] [D loss: 0.755008] [G loss: 0.828298] time: 0:08:33.291843\n",
      "0.95425826\n",
      "[Epoch 5/50] [Batch 214/300] [D loss: 0.755086] [G loss: 0.740281] time: 0:08:33.577524\n",
      "0.9238998\n",
      "[Epoch 5/50] [Batch 215/300] [D loss: 0.755056] [G loss: 0.810781] time: 0:08:33.854330\n",
      "0.9252598\n",
      "[Epoch 5/50] [Batch 216/300] [D loss: 0.755026] [G loss: 0.809602] time: 0:08:34.155287\n",
      "0.9417179\n",
      "[Epoch 5/50] [Batch 217/300] [D loss: 0.754924] [G loss: 0.890899] time: 0:08:34.452519\n",
      "0.8857203\n",
      "[Epoch 5/50] [Batch 218/300] [D loss: 0.755028] [G loss: 0.829709] time: 0:08:34.754835\n",
      "0.9417243\n",
      "[Epoch 5/50] [Batch 219/300] [D loss: 0.754933] [G loss: 0.919126] time: 0:08:35.058047\n",
      "0.9074486\n",
      "[Epoch 5/50] [Batch 220/300] [D loss: 0.755013] [G loss: 0.864464] time: 0:08:35.352154\n",
      "0.9309292\n",
      "[Epoch 5/50] [Batch 221/300] [D loss: 0.754899] [G loss: 0.824941] time: 0:08:35.645040\n",
      "0.93019885\n",
      "[Epoch 5/50] [Batch 222/300] [D loss: 0.755010] [G loss: 0.847523] time: 0:08:35.937167\n",
      "0.91058236\n",
      "[Epoch 5/50] [Batch 223/300] [D loss: 0.754991] [G loss: 0.892833] time: 0:08:36.247311\n",
      "0.88803864\n",
      "[Epoch 5/50] [Batch 224/300] [D loss: 0.754991] [G loss: 0.811944] time: 0:08:36.545502\n",
      "0.93395805\n",
      "[Epoch 5/50] [Batch 225/300] [D loss: 0.755117] [G loss: 0.780175] time: 0:08:36.832703\n",
      "0.89359576\n",
      "[Epoch 5/50] [Batch 226/300] [D loss: 0.755060] [G loss: 0.790985] time: 0:08:37.137787\n",
      "0.93536997\n",
      "[Epoch 5/50] [Batch 227/300] [D loss: 0.754947] [G loss: 0.778420] time: 0:08:37.471465\n",
      "0.91699696\n",
      "[Epoch 5/50] [Batch 228/300] [D loss: 0.754943] [G loss: 0.739150] time: 0:08:37.760007\n",
      "0.9210666\n",
      "[Epoch 5/50] [Batch 229/300] [D loss: 0.755105] [G loss: 0.847134] time: 0:08:38.073707\n",
      "0.90340304\n",
      "[Epoch 5/50] [Batch 230/300] [D loss: 0.755000] [G loss: 0.823310] time: 0:08:38.365063\n",
      "0.926639\n",
      "[Epoch 5/50] [Batch 231/300] [D loss: 0.755017] [G loss: 0.737141] time: 0:08:38.676349\n",
      "0.90571254\n",
      "[Epoch 5/50] [Batch 232/300] [D loss: 0.755108] [G loss: 0.807601] time: 0:08:38.981674\n",
      "0.90894556\n",
      "[Epoch 5/50] [Batch 233/300] [D loss: 0.754992] [G loss: 0.729570] time: 0:08:39.273849\n",
      "0.8978996\n",
      "[Epoch 5/50] [Batch 234/300] [D loss: 0.755010] [G loss: 0.737810] time: 0:08:39.587393\n",
      "0.90236545\n",
      "[Epoch 5/50] [Batch 235/300] [D loss: 0.754888] [G loss: 0.840409] time: 0:08:39.887702\n",
      "0.91043574\n",
      "[Epoch 5/50] [Batch 236/300] [D loss: 0.754969] [G loss: 0.943788] time: 0:08:40.193200\n",
      "0.9218729\n",
      "[Epoch 5/50] [Batch 237/300] [D loss: 0.754940] [G loss: 0.785943] time: 0:08:40.489448\n",
      "0.8875734\n",
      "[Epoch 5/50] [Batch 238/300] [D loss: 0.754982] [G loss: 0.738471] time: 0:08:40.777951\n",
      "0.9158535\n",
      "[Epoch 5/50] [Batch 239/300] [D loss: 0.754950] [G loss: 0.899162] time: 0:08:41.068515\n",
      "0.9188294\n",
      "[Epoch 5/50] [Batch 240/300] [D loss: 0.754909] [G loss: 0.831316] time: 0:08:41.374556\n",
      "0.9065911\n",
      "[Epoch 5/50] [Batch 241/300] [D loss: 0.754990] [G loss: 0.759321] time: 0:08:41.683953\n",
      "0.9352614\n",
      "[Epoch 5/50] [Batch 242/300] [D loss: 0.755031] [G loss: 0.771667] time: 0:08:41.962938\n",
      "0.93068093\n",
      "[Epoch 5/50] [Batch 243/300] [D loss: 0.754928] [G loss: 0.881555] time: 0:08:42.272103\n",
      "0.95599174\n",
      "[Epoch 5/50] [Batch 244/300] [D loss: 0.754921] [G loss: 0.758316] time: 0:08:42.583987\n",
      "0.9073348\n",
      "[Epoch 5/50] [Batch 245/300] [D loss: 0.754893] [G loss: 0.776851] time: 0:08:42.884303\n",
      "0.90082926\n",
      "[Epoch 5/50] [Batch 246/300] [D loss: 0.755003] [G loss: 0.894148] time: 0:08:43.187606\n",
      "0.8825121\n",
      "[Epoch 5/50] [Batch 247/300] [D loss: 0.754990] [G loss: 0.835349] time: 0:08:43.482466\n",
      "0.90206593\n",
      "[Epoch 5/50] [Batch 248/300] [D loss: 0.755050] [G loss: 0.839273] time: 0:08:43.792150\n",
      "0.93677264\n",
      "[Epoch 5/50] [Batch 249/300] [D loss: 0.754886] [G loss: 0.859198] time: 0:08:44.073260\n",
      "0.88988215\n",
      "[Epoch 5/50] [Batch 250/300] [D loss: 0.754820] [G loss: 0.903627] time: 0:08:44.358972\n",
      "0.9355116\n",
      "[Epoch 5/50] [Batch 251/300] [D loss: 0.754945] [G loss: 0.691956] time: 0:08:44.653803\n",
      "0.87285894\n",
      "[Epoch 5/50] [Batch 252/300] [D loss: 0.755011] [G loss: 0.716343] time: 0:08:44.947809\n",
      "0.9288288\n",
      "[Epoch 5/50] [Batch 253/300] [D loss: 0.754887] [G loss: 0.823851] time: 0:08:45.242444\n",
      "0.8922499\n",
      "[Epoch 5/50] [Batch 254/300] [D loss: 0.754820] [G loss: 0.887460] time: 0:08:45.541663\n",
      "0.9149873\n",
      "[Epoch 5/50] [Batch 255/300] [D loss: 0.754879] [G loss: 0.781415] time: 0:08:45.843834\n",
      "0.92439437\n",
      "[Epoch 5/50] [Batch 256/300] [D loss: 0.754875] [G loss: 0.922478] time: 0:08:46.144435\n",
      "0.8596056\n",
      "[Epoch 5/50] [Batch 257/300] [D loss: 0.754890] [G loss: 0.923996] time: 0:08:46.440859\n",
      "0.91595095\n",
      "[Epoch 5/50] [Batch 258/300] [D loss: 0.754821] [G loss: 0.930306] time: 0:08:46.723720\n",
      "0.9201258\n",
      "[Epoch 5/50] [Batch 259/300] [D loss: 0.754882] [G loss: 0.760232] time: 0:08:47.032376\n",
      "0.9392948\n",
      "[Epoch 5/50] [Batch 260/300] [D loss: 0.754854] [G loss: 0.869040] time: 0:08:47.332363\n",
      "0.88399094\n",
      "[Epoch 5/50] [Batch 261/300] [D loss: 0.754853] [G loss: 0.960375] time: 0:08:47.635816\n",
      "0.9256187\n",
      "[Epoch 5/50] [Batch 262/300] [D loss: 0.754951] [G loss: 0.788662] time: 0:08:47.936527\n",
      "0.89991546\n",
      "[Epoch 5/50] [Batch 263/300] [D loss: 0.754845] [G loss: 0.812374] time: 0:08:48.234979\n",
      "0.9439621\n",
      "[Epoch 5/50] [Batch 264/300] [D loss: 0.754988] [G loss: 0.888704] time: 0:08:48.541838\n",
      "0.9137787\n",
      "[Epoch 5/50] [Batch 265/300] [D loss: 0.754902] [G loss: 0.857282] time: 0:08:48.837127\n",
      "0.88196975\n",
      "[Epoch 5/50] [Batch 266/300] [D loss: 0.754828] [G loss: 0.883073] time: 0:08:49.114001\n",
      "0.9306588\n",
      "[Epoch 5/50] [Batch 267/300] [D loss: 0.754972] [G loss: 0.808754] time: 0:08:49.402657\n",
      "0.88654965\n",
      "[Epoch 5/50] [Batch 268/300] [D loss: 0.754890] [G loss: 1.164833] time: 0:08:49.696154\n",
      "0.92778826\n",
      "[Epoch 5/50] [Batch 269/300] [D loss: 0.754961] [G loss: 0.799383] time: 0:08:49.994468\n",
      "0.9137686\n",
      "[Epoch 5/50] [Batch 270/300] [D loss: 0.754861] [G loss: 0.929122] time: 0:08:50.277699\n",
      "0.9090919\n",
      "[Epoch 5/50] [Batch 271/300] [D loss: 0.755002] [G loss: 0.842965] time: 0:08:50.565969\n",
      "0.9353018\n",
      "[Epoch 5/50] [Batch 272/300] [D loss: 0.754904] [G loss: 0.770017] time: 0:08:50.874804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93795735\n",
      "[Epoch 5/50] [Batch 273/300] [D loss: 0.754949] [G loss: 0.815003] time: 0:08:51.177595\n",
      "0.90381676\n",
      "[Epoch 5/50] [Batch 274/300] [D loss: 0.754864] [G loss: 0.744886] time: 0:08:51.466780\n",
      "0.95587134\n",
      "[Epoch 5/50] [Batch 275/300] [D loss: 0.754992] [G loss: 0.832105] time: 0:08:51.768206\n",
      "0.9471827\n",
      "[Epoch 5/50] [Batch 276/300] [D loss: 0.754934] [G loss: 0.728120] time: 0:08:52.055181\n",
      "0.91100425\n",
      "[Epoch 5/50] [Batch 277/300] [D loss: 0.755004] [G loss: 0.759087] time: 0:08:52.360583\n",
      "0.9355595\n",
      "[Epoch 5/50] [Batch 278/300] [D loss: 0.754960] [G loss: 0.707589] time: 0:08:52.649910\n",
      "0.93246317\n",
      "[Epoch 5/50] [Batch 279/300] [D loss: 0.754814] [G loss: 0.823716] time: 0:08:52.960780\n",
      "0.9317835\n",
      "[Epoch 5/50] [Batch 280/300] [D loss: 0.754904] [G loss: 0.877003] time: 0:08:53.255276\n",
      "0.89061946\n",
      "[Epoch 5/50] [Batch 281/300] [D loss: 0.754820] [G loss: 0.859455] time: 0:08:53.560165\n",
      "0.91821885\n",
      "[Epoch 5/50] [Batch 282/300] [D loss: 0.754829] [G loss: 0.786770] time: 0:08:53.863820\n",
      "0.9390502\n",
      "[Epoch 5/50] [Batch 283/300] [D loss: 0.754770] [G loss: 0.765666] time: 0:08:54.147424\n",
      "0.8989119\n",
      "[Epoch 5/50] [Batch 284/300] [D loss: 0.754900] [G loss: 0.844034] time: 0:08:54.433393\n",
      "0.94397086\n",
      "[Epoch 5/50] [Batch 285/300] [D loss: 0.754941] [G loss: 0.810660] time: 0:08:54.729840\n",
      "0.9477818\n",
      "[Epoch 5/50] [Batch 286/300] [D loss: 0.754852] [G loss: 0.864669] time: 0:08:55.043067\n",
      "0.925585\n",
      "[Epoch 5/50] [Batch 287/300] [D loss: 0.754874] [G loss: 0.863665] time: 0:08:55.345075\n",
      "0.8993973\n",
      "[Epoch 5/50] [Batch 288/300] [D loss: 0.754787] [G loss: 0.891543] time: 0:08:55.634830\n",
      "0.94100046\n",
      "[Epoch 5/50] [Batch 289/300] [D loss: 0.754957] [G loss: 0.861248] time: 0:08:55.935242\n",
      "0.9138637\n",
      "[Epoch 5/50] [Batch 290/300] [D loss: 0.754796] [G loss: 0.819731] time: 0:08:56.225555\n",
      "0.9534858\n",
      "[Epoch 5/50] [Batch 291/300] [D loss: 0.754969] [G loss: 0.883895] time: 0:08:56.514739\n",
      "0.9272785\n",
      "[Epoch 5/50] [Batch 292/300] [D loss: 0.754936] [G loss: 0.857536] time: 0:08:56.811540\n",
      "0.8818507\n",
      "[Epoch 5/50] [Batch 293/300] [D loss: 0.754827] [G loss: 0.798091] time: 0:08:57.108491\n",
      "0.92378217\n",
      "[Epoch 5/50] [Batch 294/300] [D loss: 0.754902] [G loss: 0.876941] time: 0:08:57.420387\n",
      "0.91761214\n",
      "[Epoch 5/50] [Batch 295/300] [D loss: 0.754843] [G loss: 0.833492] time: 0:08:57.714043\n",
      "0.92857856\n",
      "[Epoch 5/50] [Batch 296/300] [D loss: 0.754864] [G loss: 0.811862] time: 0:08:58.015760\n",
      "0.93437463\n",
      "[Epoch 5/50] [Batch 297/300] [D loss: 0.754820] [G loss: 0.821709] time: 0:08:58.311795\n",
      "0.9183139\n",
      "[Epoch 5/50] [Batch 298/300] [D loss: 0.754800] [G loss: 0.811240] time: 0:08:58.607329\n",
      "0.9407403\n",
      "[Epoch 5/50] [Batch 299/300] [D loss: 0.754876] [G loss: 0.836236] time: 0:08:58.893638\n",
      "0.9332235\n",
      "[Epoch 6/50] [Batch 0/300] [D loss: 0.754965] [G loss: 0.819457] time: 0:08:59.210274\n",
      "0.9276337\n",
      "[Epoch 6/50] [Batch 1/300] [D loss: 0.754744] [G loss: 0.862337] time: 0:08:59.507920\n",
      "0.92726296\n",
      "[Epoch 6/50] [Batch 2/300] [D loss: 0.754729] [G loss: 0.829148] time: 0:08:59.807598\n",
      "0.9023871\n",
      "[Epoch 6/50] [Batch 3/300] [D loss: 0.755001] [G loss: 0.746407] time: 0:09:00.106317\n",
      "0.9124275\n",
      "[Epoch 6/50] [Batch 4/300] [D loss: 0.754899] [G loss: 0.833397] time: 0:09:00.409209\n",
      "0.8767349\n",
      "[Epoch 6/50] [Batch 6/300] [D loss: 0.754996] [G loss: 0.748386] time: 0:09:00.711957\n",
      "0.8538148\n",
      "[Epoch 6/50] [Batch 7/300] [D loss: 0.754761] [G loss: 0.886719] time: 0:09:01.003980\n",
      "0.93340015\n",
      "[Epoch 6/50] [Batch 8/300] [D loss: 0.754820] [G loss: 0.703448] time: 0:09:01.307281\n",
      "0.94929844\n",
      "[Epoch 6/50] [Batch 9/300] [D loss: 0.754821] [G loss: 0.787687] time: 0:09:01.594496\n",
      "0.95268035\n",
      "[Epoch 6/50] [Batch 10/300] [D loss: 0.754775] [G loss: 0.777435] time: 0:09:01.889078\n",
      "0.85531086\n",
      "[Epoch 6/50] [Batch 11/300] [D loss: 0.754780] [G loss: 0.764487] time: 0:09:02.182443\n",
      "0.9307499\n",
      "[Epoch 6/50] [Batch 12/300] [D loss: 0.754840] [G loss: 0.824374] time: 0:09:02.480844\n",
      "0.9169739\n",
      "[Epoch 6/50] [Batch 13/300] [D loss: 0.754815] [G loss: 0.901619] time: 0:09:02.779543\n",
      "0.9546704\n",
      "[Epoch 6/50] [Batch 14/300] [D loss: 0.754831] [G loss: 0.893109] time: 0:09:03.062936\n",
      "0.94671327\n",
      "[Epoch 6/50] [Batch 15/300] [D loss: 0.754938] [G loss: 0.890423] time: 0:09:03.378776\n",
      "0.88709635\n",
      "[Epoch 6/50] [Batch 16/300] [D loss: 0.754899] [G loss: 0.718755] time: 0:09:03.670900\n",
      "0.87763923\n",
      "[Epoch 6/50] [Batch 17/300] [D loss: 0.754852] [G loss: 0.767964] time: 0:09:03.965195\n",
      "0.92787933\n",
      "[Epoch 6/50] [Batch 18/300] [D loss: 0.754810] [G loss: 0.762315] time: 0:09:04.267193\n",
      "0.8756426\n",
      "[Epoch 6/50] [Batch 19/300] [D loss: 0.754734] [G loss: 0.876499] time: 0:09:04.546644\n",
      "0.9172694\n",
      "[Epoch 6/50] [Batch 20/300] [D loss: 0.754911] [G loss: 0.843251] time: 0:09:04.853510\n",
      "0.8788058\n",
      "[Epoch 6/50] [Batch 21/300] [D loss: 0.754855] [G loss: 0.787610] time: 0:09:05.153150\n",
      "0.9338787\n",
      "[Epoch 6/50] [Batch 22/300] [D loss: 0.754807] [G loss: 0.785702] time: 0:09:05.471968\n",
      "0.9224829\n",
      "[Epoch 6/50] [Batch 23/300] [D loss: 0.754752] [G loss: 0.910690] time: 0:09:05.762914\n",
      "0.8608897\n",
      "[Epoch 6/50] [Batch 24/300] [D loss: 0.754661] [G loss: 0.828083] time: 0:09:06.066708\n",
      "0.9176381\n",
      "[Epoch 6/50] [Batch 25/300] [D loss: 0.754796] [G loss: 0.799806] time: 0:09:06.354048\n",
      "0.9158237\n",
      "[Epoch 6/50] [Batch 26/300] [D loss: 0.754729] [G loss: 0.808077] time: 0:09:06.652344\n",
      "0.91528034\n",
      "[Epoch 6/50] [Batch 27/300] [D loss: 0.754796] [G loss: 0.805660] time: 0:09:06.944038\n",
      "0.88361233\n",
      "[Epoch 6/50] [Batch 28/300] [D loss: 0.754729] [G loss: 0.720591] time: 0:09:07.249460\n",
      "0.91426307\n",
      "[Epoch 6/50] [Batch 29/300] [D loss: 0.754767] [G loss: 0.943557] time: 0:09:07.547866\n",
      "0.9529546\n",
      "[Epoch 6/50] [Batch 30/300] [D loss: 0.754821] [G loss: 0.800644] time: 0:09:07.859091\n",
      "0.9230971\n",
      "[Epoch 6/50] [Batch 31/300] [D loss: 0.754843] [G loss: 0.802436] time: 0:09:08.137015\n",
      "0.93064857\n",
      "[Epoch 6/50] [Batch 32/300] [D loss: 0.754819] [G loss: 0.847113] time: 0:09:08.430342\n",
      "0.95053726\n",
      "[Epoch 6/50] [Batch 33/300] [D loss: 0.754792] [G loss: 0.999535] time: 0:09:08.733009\n",
      "0.9386051\n",
      "[Epoch 6/50] [Batch 34/300] [D loss: 0.754886] [G loss: 0.866467] time: 0:09:09.007255\n",
      "0.908103\n",
      "[Epoch 6/50] [Batch 35/300] [D loss: 0.754737] [G loss: 0.834113] time: 0:09:09.303205\n",
      "0.9093361\n",
      "[Epoch 6/50] [Batch 36/300] [D loss: 0.754737] [G loss: 0.753084] time: 0:09:09.601764\n",
      "0.9617447\n",
      "[Epoch 6/50] [Batch 37/300] [D loss: 0.754663] [G loss: 0.833250] time: 0:09:09.885921\n",
      "0.9086606\n",
      "[Epoch 6/50] [Batch 38/300] [D loss: 0.754850] [G loss: 0.733294] time: 0:09:10.186713\n",
      "0.92576075\n",
      "[Epoch 6/50] [Batch 39/300] [D loss: 0.754772] [G loss: 0.824013] time: 0:09:10.492990\n",
      "0.9453934\n",
      "[Epoch 6/50] [Batch 40/300] [D loss: 0.754704] [G loss: 0.858280] time: 0:09:10.795277\n",
      "0.90933466\n",
      "[Epoch 6/50] [Batch 41/300] [D loss: 0.754723] [G loss: 0.696754] time: 0:09:11.075201\n",
      "0.90985745\n",
      "[Epoch 6/50] [Batch 42/300] [D loss: 0.754749] [G loss: 0.821384] time: 0:09:11.386412\n",
      "0.92685795\n",
      "[Epoch 6/50] [Batch 43/300] [D loss: 0.754766] [G loss: 0.743586] time: 0:09:11.674813\n",
      "0.84085894\n",
      "[Epoch 6/50] [Batch 44/300] [D loss: 0.754748] [G loss: 0.830594] time: 0:09:11.963139\n",
      "0.90854424\n",
      "[Epoch 6/50] [Batch 45/300] [D loss: 0.754774] [G loss: 0.622124] time: 0:09:12.260256\n",
      "0.8804235\n",
      "[Epoch 6/50] [Batch 46/300] [D loss: 0.754645] [G loss: 0.756071] time: 0:09:12.554773\n",
      "0.8912785\n",
      "[Epoch 6/50] [Batch 47/300] [D loss: 0.754773] [G loss: 0.920053] time: 0:09:12.845882\n",
      "0.9344798\n",
      "[Epoch 6/50] [Batch 48/300] [D loss: 0.754799] [G loss: 0.874416] time: 0:09:13.146625\n",
      "0.9189876\n",
      "[Epoch 6/50] [Batch 49/300] [D loss: 0.754708] [G loss: 0.813340] time: 0:09:13.453783\n",
      "0.9189563\n",
      "[Epoch 6/50] [Batch 50/300] [D loss: 0.754752] [G loss: 0.817816] time: 0:09:13.750686\n",
      "0.87819415\n",
      "[Epoch 6/50] [Batch 51/300] [D loss: 0.754728] [G loss: 0.774494] time: 0:09:14.041676\n",
      "0.9624474\n",
      "[Epoch 6/50] [Batch 52/300] [D loss: 0.754716] [G loss: 0.715655] time: 0:09:14.342866\n",
      "0.9097471\n",
      "[Epoch 6/50] [Batch 53/300] [D loss: 0.754887] [G loss: 0.753042] time: 0:09:14.644857\n",
      "0.89113456\n",
      "[Epoch 6/50] [Batch 54/300] [D loss: 0.754728] [G loss: 0.779283] time: 0:09:14.929882\n",
      "0.92430276\n",
      "[Epoch 6/50] [Batch 55/300] [D loss: 0.754801] [G loss: 0.812054] time: 0:09:15.220781\n",
      "0.87500596\n",
      "[Epoch 6/50] [Batch 56/300] [D loss: 0.754650] [G loss: 0.885381] time: 0:09:15.511022\n",
      "0.8732864\n",
      "[Epoch 6/50] [Batch 57/300] [D loss: 0.754708] [G loss: 0.865207] time: 0:09:15.807848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92393845\n",
      "[Epoch 6/50] [Batch 58/300] [D loss: 0.754735] [G loss: 0.881212] time: 0:09:16.104384\n",
      "0.9182615\n",
      "[Epoch 6/50] [Batch 59/300] [D loss: 0.754886] [G loss: 0.748004] time: 0:09:16.403756\n",
      "0.90067273\n",
      "[Epoch 6/50] [Batch 60/300] [D loss: 0.754732] [G loss: 0.752266] time: 0:09:16.698296\n",
      "0.9663649\n",
      "[Epoch 6/50] [Batch 61/300] [D loss: 0.754740] [G loss: 0.872141] time: 0:09:16.987457\n",
      "0.9384765\n",
      "[Epoch 6/50] [Batch 62/300] [D loss: 0.754740] [G loss: 0.717802] time: 0:09:17.285728\n",
      "0.93822473\n",
      "[Epoch 6/50] [Batch 63/300] [D loss: 0.754679] [G loss: 0.758659] time: 0:09:17.576016\n",
      "0.91805077\n",
      "[Epoch 6/50] [Batch 64/300] [D loss: 0.754805] [G loss: 0.725416] time: 0:09:17.873225\n",
      "0.87973875\n",
      "[Epoch 6/50] [Batch 65/300] [D loss: 0.754691] [G loss: 0.735510] time: 0:09:18.176003\n",
      "0.90311503\n",
      "[Epoch 6/50] [Batch 66/300] [D loss: 0.754659] [G loss: 0.796381] time: 0:09:18.467570\n",
      "0.908405\n",
      "[Epoch 6/50] [Batch 67/300] [D loss: 0.754720] [G loss: 0.670305] time: 0:09:18.767498\n",
      "0.8831102\n",
      "[Epoch 6/50] [Batch 68/300] [D loss: 0.754658] [G loss: 0.797223] time: 0:09:19.068635\n",
      "0.9209964\n",
      "[Epoch 6/50] [Batch 69/300] [D loss: 0.754659] [G loss: 0.814667] time: 0:09:19.364449\n",
      "0.910667\n",
      "[Epoch 6/50] [Batch 70/300] [D loss: 0.754716] [G loss: 0.865064] time: 0:09:19.667517\n",
      "0.9243855\n",
      "[Epoch 6/50] [Batch 71/300] [D loss: 0.754701] [G loss: 0.827893] time: 0:09:19.968389\n",
      "0.8759098\n",
      "[Epoch 6/50] [Batch 72/300] [D loss: 0.754730] [G loss: 0.793244] time: 0:09:20.260795\n",
      "0.8630486\n",
      "[Epoch 6/50] [Batch 73/300] [D loss: 0.754712] [G loss: 0.912315] time: 0:09:20.552164\n",
      "0.88029623\n",
      "[Epoch 6/50] [Batch 74/300] [D loss: 0.754674] [G loss: 0.745843] time: 0:09:20.857610\n",
      "0.94618064\n",
      "[Epoch 6/50] [Batch 75/300] [D loss: 0.754776] [G loss: 0.748170] time: 0:09:21.143475\n",
      "0.97328734\n",
      "[Epoch 6/50] [Batch 76/300] [D loss: 0.754730] [G loss: 0.907634] time: 0:09:21.444542\n",
      "0.8567621\n",
      "[Epoch 6/50] [Batch 77/300] [D loss: 0.754696] [G loss: 0.980796] time: 0:09:21.752059\n",
      "0.9052865\n",
      "[Epoch 6/50] [Batch 78/300] [D loss: 0.754724] [G loss: 0.693092] time: 0:09:22.036087\n",
      "0.9540902\n",
      "[Epoch 6/50] [Batch 79/300] [D loss: 0.754729] [G loss: 0.692286] time: 0:09:22.338975\n",
      "0.9237597\n",
      "[Epoch 6/50] [Batch 80/300] [D loss: 0.754579] [G loss: 0.871362] time: 0:09:22.645790\n",
      "0.9072616\n",
      "[Epoch 6/50] [Batch 81/300] [D loss: 0.754803] [G loss: 0.768937] time: 0:09:22.942040\n",
      "0.91674805\n",
      "[Epoch 6/50] [Batch 82/300] [D loss: 0.754735] [G loss: 0.706530] time: 0:09:23.242261\n",
      "0.8937653\n",
      "[Epoch 6/50] [Batch 83/300] [D loss: 0.754676] [G loss: 0.899270] time: 0:09:23.523564\n",
      "0.93902856\n",
      "[Epoch 6/50] [Batch 84/300] [D loss: 0.754706] [G loss: 0.951865] time: 0:09:23.812333\n",
      "0.8683793\n",
      "[Epoch 6/50] [Batch 85/300] [D loss: 0.754704] [G loss: 0.809784] time: 0:09:24.116205\n",
      "0.91278076\n",
      "[Epoch 6/50] [Batch 86/300] [D loss: 0.754681] [G loss: 0.842227] time: 0:09:24.415231\n",
      "0.91147894\n",
      "[Epoch 6/50] [Batch 87/300] [D loss: 0.754632] [G loss: 0.868695] time: 0:09:24.713683\n",
      "0.8727544\n",
      "[Epoch 6/50] [Batch 88/300] [D loss: 0.754729] [G loss: 0.729656] time: 0:09:25.008227\n",
      "0.8305771\n",
      "[Epoch 6/50] [Batch 89/300] [D loss: 0.754761] [G loss: 0.834620] time: 0:09:25.306735\n",
      "0.96106654\n",
      "[Epoch 6/50] [Batch 90/300] [D loss: 0.754684] [G loss: 0.783388] time: 0:09:25.608977\n",
      "0.8909929\n",
      "[Epoch 6/50] [Batch 91/300] [D loss: 0.754588] [G loss: 0.825039] time: 0:09:25.929883\n",
      "0.9432791\n",
      "[Epoch 6/50] [Batch 92/300] [D loss: 0.754734] [G loss: 0.834898] time: 0:09:26.211855\n",
      "0.90737003\n",
      "[Epoch 6/50] [Batch 93/300] [D loss: 0.754714] [G loss: 0.822410] time: 0:09:26.508827\n",
      "0.9266846\n",
      "[Epoch 6/50] [Batch 94/300] [D loss: 0.754632] [G loss: 0.800377] time: 0:09:26.794580\n",
      "0.90834683\n",
      "[Epoch 6/50] [Batch 95/300] [D loss: 0.754682] [G loss: 0.888935] time: 0:09:27.101027\n",
      "0.8993669\n",
      "[Epoch 6/50] [Batch 96/300] [D loss: 0.754784] [G loss: 0.745220] time: 0:09:27.393933\n",
      "0.8869779\n",
      "[Epoch 6/50] [Batch 97/300] [D loss: 0.754581] [G loss: 0.930848] time: 0:09:27.697452\n",
      "0.922712\n",
      "[Epoch 6/50] [Batch 98/300] [D loss: 0.754648] [G loss: 0.715371] time: 0:09:27.978593\n",
      "0.92524815\n",
      "[Epoch 6/50] [Batch 99/300] [D loss: 0.754686] [G loss: 0.839478] time: 0:09:28.286989\n",
      "0.9156089\n",
      "[Epoch 6/50] [Batch 100/300] [D loss: 0.754655] [G loss: 0.919045] time: 0:09:28.592547\n",
      "0.9334609\n",
      "[Epoch 6/50] [Batch 101/300] [D loss: 0.754688] [G loss: 0.784389] time: 0:09:28.896427\n",
      "0.9116499\n",
      "[Epoch 6/50] [Batch 102/300] [D loss: 0.754751] [G loss: 0.717889] time: 0:09:29.209374\n",
      "0.9601794\n",
      "[Epoch 6/50] [Batch 103/300] [D loss: 0.754838] [G loss: 0.781351] time: 0:09:29.509059\n",
      "0.9192583\n",
      "[Epoch 6/50] [Batch 104/300] [D loss: 0.754696] [G loss: 0.816757] time: 0:09:29.824204\n",
      "0.8620303\n",
      "[Epoch 6/50] [Batch 105/300] [D loss: 0.754577] [G loss: 0.815307] time: 0:09:30.249238\n",
      "0.90470624\n",
      "[Epoch 6/50] [Batch 106/300] [D loss: 0.754709] [G loss: 0.820062] time: 0:09:30.549216\n",
      "0.89917296\n",
      "[Epoch 6/50] [Batch 107/300] [D loss: 0.754596] [G loss: 0.872534] time: 0:09:30.849500\n",
      "0.93185216\n",
      "[Epoch 6/50] [Batch 108/300] [D loss: 0.754681] [G loss: 0.886745] time: 0:09:31.167941\n",
      "0.87885875\n",
      "[Epoch 6/50] [Batch 109/300] [D loss: 0.754629] [G loss: 0.783521] time: 0:09:31.462681\n",
      "0.9130373\n",
      "[Epoch 6/50] [Batch 110/300] [D loss: 0.754696] [G loss: 0.811148] time: 0:09:31.764430\n",
      "0.87612534\n",
      "[Epoch 6/50] [Batch 111/300] [D loss: 0.754561] [G loss: 0.862834] time: 0:09:32.049570\n",
      "0.8552606\n",
      "[Epoch 6/50] [Batch 112/300] [D loss: 0.754631] [G loss: 0.834663] time: 0:09:32.335499\n",
      "0.91279787\n",
      "[Epoch 6/50] [Batch 113/300] [D loss: 0.754631] [G loss: 0.706497] time: 0:09:32.635152\n",
      "0.91808444\n",
      "[Epoch 6/50] [Batch 114/300] [D loss: 0.754563] [G loss: 0.745933] time: 0:09:32.924820\n",
      "0.91263866\n",
      "[Epoch 6/50] [Batch 115/300] [D loss: 0.754554] [G loss: 0.889564] time: 0:09:33.235795\n",
      "0.90733194\n",
      "[Epoch 6/50] [Batch 116/300] [D loss: 0.754575] [G loss: 0.818897] time: 0:09:33.526185\n",
      "0.8634499\n",
      "[Epoch 6/50] [Batch 117/300] [D loss: 0.754545] [G loss: 0.802546] time: 0:09:33.821469\n",
      "0.9243869\n",
      "[Epoch 6/50] [Batch 118/300] [D loss: 0.754595] [G loss: 0.826994] time: 0:09:34.116685\n",
      "0.91387534\n",
      "[Epoch 6/50] [Batch 119/300] [D loss: 0.754630] [G loss: 0.753138] time: 0:09:34.402566\n",
      "0.91539675\n",
      "[Epoch 6/50] [Batch 120/300] [D loss: 0.754591] [G loss: 0.665592] time: 0:09:34.694679\n",
      "0.95908767\n",
      "[Epoch 6/50] [Batch 121/300] [D loss: 0.754599] [G loss: 0.776180] time: 0:09:34.994973\n",
      "0.9196252\n",
      "[Epoch 6/50] [Batch 122/300] [D loss: 0.754610] [G loss: 0.798598] time: 0:09:35.303520\n",
      "0.8476801\n",
      "[Epoch 6/50] [Batch 123/300] [D loss: 0.754663] [G loss: 0.772883] time: 0:09:35.606676\n",
      "0.8808411\n",
      "[Epoch 6/50] [Batch 124/300] [D loss: 0.754661] [G loss: 0.912558] time: 0:09:35.909265\n",
      "0.9038587\n",
      "[Epoch 6/50] [Batch 125/300] [D loss: 0.754557] [G loss: 0.853973] time: 0:09:36.187796\n",
      "0.9319747\n",
      "[Epoch 6/50] [Batch 126/300] [D loss: 0.754583] [G loss: 0.742955] time: 0:09:36.490102\n",
      "0.8647708\n",
      "[Epoch 6/50] [Batch 127/300] [D loss: 0.754572] [G loss: 0.835236] time: 0:09:36.792333\n",
      "0.91327924\n",
      "[Epoch 6/50] [Batch 128/300] [D loss: 0.754554] [G loss: 0.675974] time: 0:09:37.102160\n",
      "0.9286654\n",
      "[Epoch 6/50] [Batch 129/300] [D loss: 0.754542] [G loss: 0.873774] time: 0:09:37.392778\n",
      "0.9385667\n",
      "[Epoch 6/50] [Batch 130/300] [D loss: 0.754569] [G loss: 0.808914] time: 0:09:37.683637\n",
      "0.91654253\n",
      "[Epoch 6/50] [Batch 131/300] [D loss: 0.754478] [G loss: 0.877001] time: 0:09:37.987012\n",
      "0.8760855\n",
      "[Epoch 6/50] [Batch 132/300] [D loss: 0.754674] [G loss: 0.925623] time: 0:09:38.284602\n",
      "0.9181604\n",
      "[Epoch 6/50] [Batch 133/300] [D loss: 0.754464] [G loss: 0.889869] time: 0:09:38.562320\n",
      "0.9163657\n",
      "[Epoch 6/50] [Batch 134/300] [D loss: 0.754629] [G loss: 0.921057] time: 0:09:38.853904\n",
      "0.9348058\n",
      "[Epoch 6/50] [Batch 135/300] [D loss: 0.754650] [G loss: 0.732565] time: 0:09:39.157286\n",
      "0.93747735\n",
      "[Epoch 6/50] [Batch 136/300] [D loss: 0.754508] [G loss: 0.891042] time: 0:09:39.454038\n",
      "0.94183666\n",
      "[Epoch 6/50] [Batch 137/300] [D loss: 0.754618] [G loss: 0.780049] time: 0:09:39.739683\n",
      "0.94257015\n",
      "[Epoch 6/50] [Batch 138/300] [D loss: 0.754567] [G loss: 0.748794] time: 0:09:40.042553\n",
      "0.8869392\n",
      "[Epoch 6/50] [Batch 139/300] [D loss: 0.754659] [G loss: 0.744266] time: 0:09:40.328148\n",
      "0.91782236\n",
      "[Epoch 6/50] [Batch 140/300] [D loss: 0.754602] [G loss: 0.799310] time: 0:09:40.632839\n",
      "0.94207025\n",
      "[Epoch 6/50] [Batch 141/300] [D loss: 0.754583] [G loss: 0.846817] time: 0:09:40.931365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349254\n",
      "[Epoch 6/50] [Batch 142/300] [D loss: 0.754606] [G loss: 0.764281] time: 0:09:41.233645\n",
      "0.87481505\n",
      "[Epoch 6/50] [Batch 143/300] [D loss: 0.754584] [G loss: 0.780067] time: 0:09:41.536520\n",
      "0.9108157\n",
      "[Epoch 6/50] [Batch 144/300] [D loss: 0.754503] [G loss: 0.754992] time: 0:09:41.852675\n",
      "0.915921\n",
      "[Epoch 6/50] [Batch 145/300] [D loss: 0.754513] [G loss: 0.834991] time: 0:09:42.154747\n",
      "0.8985993\n",
      "[Epoch 6/50] [Batch 146/300] [D loss: 0.754571] [G loss: 0.745660] time: 0:09:42.458007\n",
      "0.9287837\n",
      "[Epoch 6/50] [Batch 147/300] [D loss: 0.754572] [G loss: 0.734459] time: 0:09:42.762876\n",
      "0.9412036\n",
      "[Epoch 6/50] [Batch 148/300] [D loss: 0.754550] [G loss: 0.696972] time: 0:09:43.068296\n",
      "0.8734179\n",
      "[Epoch 6/50] [Batch 149/300] [D loss: 0.754645] [G loss: 0.868112] time: 0:09:43.369273\n",
      "0.9672913\n",
      "[Epoch 6/50] [Batch 150/300] [D loss: 0.754659] [G loss: 0.816059] time: 0:09:43.692544\n",
      "0.9376859\n",
      "[Epoch 6/50] [Batch 151/300] [D loss: 0.754564] [G loss: 0.850298] time: 0:09:43.978730\n",
      "0.91896373\n",
      "[Epoch 6/50] [Batch 152/300] [D loss: 0.754544] [G loss: 0.871616] time: 0:09:44.266959\n",
      "0.8919297\n",
      "[Epoch 6/50] [Batch 153/300] [D loss: 0.754575] [G loss: 0.989240] time: 0:09:44.550585\n",
      "0.93279785\n",
      "[Epoch 6/50] [Batch 154/300] [D loss: 0.754644] [G loss: 0.786748] time: 0:09:44.849836\n",
      "0.8879657\n",
      "[Epoch 6/50] [Batch 155/300] [D loss: 0.754592] [G loss: 0.845569] time: 0:09:45.140769\n",
      "0.9096372\n",
      "[Epoch 6/50] [Batch 156/300] [D loss: 0.754600] [G loss: 0.832360] time: 0:09:45.437642\n",
      "0.90352577\n",
      "[Epoch 6/50] [Batch 157/300] [D loss: 0.754611] [G loss: 0.750776] time: 0:09:45.738431\n",
      "0.8730548\n",
      "[Epoch 6/50] [Batch 158/300] [D loss: 0.754598] [G loss: 0.752984] time: 0:09:46.042407\n",
      "0.9567283\n",
      "[Epoch 6/50] [Batch 159/300] [D loss: 0.754628] [G loss: 0.839121] time: 0:09:46.330209\n",
      "0.9344457\n",
      "[Epoch 6/50] [Batch 160/300] [D loss: 0.754535] [G loss: 0.742323] time: 0:09:46.626247\n",
      "0.9463064\n",
      "[Epoch 6/50] [Batch 161/300] [D loss: 0.754507] [G loss: 0.821095] time: 0:09:46.934986\n",
      "0.8624668\n",
      "[Epoch 6/50] [Batch 162/300] [D loss: 0.754614] [G loss: 0.751796] time: 0:09:47.229953\n",
      "0.88451356\n",
      "[Epoch 6/50] [Batch 163/300] [D loss: 0.754511] [G loss: 0.784520] time: 0:09:47.528670\n",
      "0.9332392\n",
      "[Epoch 6/50] [Batch 164/300] [D loss: 0.754603] [G loss: 0.844664] time: 0:09:47.824425\n",
      "0.8995018\n",
      "[Epoch 6/50] [Batch 165/300] [D loss: 0.754603] [G loss: 0.798699] time: 0:09:48.119561\n",
      "0.9125683\n",
      "[Epoch 6/50] [Batch 166/300] [D loss: 0.754627] [G loss: 0.782551] time: 0:09:48.428478\n",
      "0.92587095\n",
      "[Epoch 6/50] [Batch 167/300] [D loss: 0.754671] [G loss: 0.784506] time: 0:09:48.731073\n",
      "0.9056007\n",
      "[Epoch 6/50] [Batch 168/300] [D loss: 0.754693] [G loss: 0.769202] time: 0:09:49.024239\n",
      "0.9036401\n",
      "[Epoch 6/50] [Batch 169/300] [D loss: 0.754489] [G loss: 0.852000] time: 0:09:49.319979\n",
      "0.9090624\n",
      "[Epoch 6/50] [Batch 170/300] [D loss: 0.754546] [G loss: 0.751363] time: 0:09:49.619388\n",
      "0.89358777\n",
      "[Epoch 6/50] [Batch 171/300] [D loss: 0.754521] [G loss: 0.830174] time: 0:09:49.917959\n",
      "0.93822783\n",
      "[Epoch 6/50] [Batch 172/300] [D loss: 0.754641] [G loss: 0.928371] time: 0:09:50.210750\n",
      "0.907541\n",
      "[Epoch 6/50] [Batch 173/300] [D loss: 0.754628] [G loss: 0.713700] time: 0:09:50.511413\n",
      "0.9485279\n",
      "[Epoch 6/50] [Batch 174/300] [D loss: 0.754530] [G loss: 0.742437] time: 0:09:50.804582\n",
      "0.9187892\n",
      "[Epoch 6/50] [Batch 175/300] [D loss: 0.754589] [G loss: 0.732713] time: 0:09:51.098857\n",
      "0.9011326\n",
      "[Epoch 6/50] [Batch 176/300] [D loss: 0.754547] [G loss: 0.782828] time: 0:09:51.406534\n",
      "0.89536315\n",
      "[Epoch 6/50] [Batch 177/300] [D loss: 0.754503] [G loss: 0.804137] time: 0:09:51.706774\n",
      "0.86529714\n",
      "[Epoch 6/50] [Batch 178/300] [D loss: 0.754544] [G loss: 0.785198] time: 0:09:52.014636\n",
      "0.90604234\n",
      "[Epoch 6/50] [Batch 179/300] [D loss: 0.754524] [G loss: 0.802781] time: 0:09:52.315311\n",
      "0.8899881\n",
      "[Epoch 6/50] [Batch 180/300] [D loss: 0.754571] [G loss: 0.718370] time: 0:09:52.631198\n",
      "0.9008543\n",
      "[Epoch 6/50] [Batch 181/300] [D loss: 0.754500] [G loss: 0.767897] time: 0:09:52.928931\n",
      "0.9272213\n",
      "[Epoch 6/50] [Batch 182/300] [D loss: 0.754570] [G loss: 0.893003] time: 0:09:53.217192\n",
      "0.96088773\n",
      "[Epoch 6/50] [Batch 183/300] [D loss: 0.754452] [G loss: 0.871480] time: 0:09:53.521980\n",
      "0.9192639\n",
      "[Epoch 6/50] [Batch 184/300] [D loss: 0.754530] [G loss: 0.784587] time: 0:09:53.819412\n",
      "0.93335867\n",
      "[Epoch 6/50] [Batch 185/300] [D loss: 0.754561] [G loss: 0.766749] time: 0:09:54.126443\n",
      "0.9138837\n",
      "[Epoch 6/50] [Batch 186/300] [D loss: 0.754511] [G loss: 0.792296] time: 0:09:54.423090\n",
      "0.9349062\n",
      "[Epoch 6/50] [Batch 187/300] [D loss: 0.754504] [G loss: 0.724499] time: 0:09:54.719340\n",
      "0.90606743\n",
      "[Epoch 6/50] [Batch 188/300] [D loss: 0.754493] [G loss: 0.803361] time: 0:09:55.026700\n",
      "0.93731683\n",
      "[Epoch 6/50] [Batch 189/300] [D loss: 0.754548] [G loss: 0.780095] time: 0:09:55.339887\n",
      "0.93263865\n",
      "[Epoch 6/50] [Batch 190/300] [D loss: 0.754547] [G loss: 0.945566] time: 0:09:55.632136\n",
      "0.8721052\n",
      "[Epoch 6/50] [Batch 191/300] [D loss: 0.754549] [G loss: 0.743173] time: 0:09:55.911342\n",
      "0.92985326\n",
      "[Epoch 6/50] [Batch 192/300] [D loss: 0.754493] [G loss: 0.729764] time: 0:09:56.208102\n",
      "0.9355418\n",
      "[Epoch 6/50] [Batch 193/300] [D loss: 0.754520] [G loss: 0.963202] time: 0:09:56.511847\n",
      "0.9378217\n",
      "[Epoch 6/50] [Batch 194/300] [D loss: 0.754570] [G loss: 0.703223] time: 0:09:56.810309\n",
      "0.9370695\n",
      "[Epoch 6/50] [Batch 195/300] [D loss: 0.754569] [G loss: 0.682437] time: 0:09:57.117596\n",
      "0.87055975\n",
      "[Epoch 6/50] [Batch 196/300] [D loss: 0.754485] [G loss: 0.670799] time: 0:09:57.415674\n",
      "0.86333555\n",
      "[Epoch 6/50] [Batch 197/300] [D loss: 0.754456] [G loss: 0.755891] time: 0:09:57.710012\n",
      "0.9069288\n",
      "[Epoch 6/50] [Batch 198/300] [D loss: 0.754534] [G loss: 0.833944] time: 0:09:58.024768\n",
      "0.88747764\n",
      "[Epoch 6/50] [Batch 199/300] [D loss: 0.754555] [G loss: 0.798613] time: 0:09:58.308575\n",
      "0.87211436\n",
      "[Epoch 6/50] [Batch 200/300] [D loss: 0.754552] [G loss: 0.855625] time: 0:09:58.592524\n",
      "0.896885\n",
      "[Epoch 6/50] [Batch 201/300] [D loss: 0.754486] [G loss: 0.846961] time: 0:09:58.888375\n",
      "0.9517395\n",
      "[Epoch 6/50] [Batch 202/300] [D loss: 0.754539] [G loss: 0.783127] time: 0:09:59.201932\n",
      "0.91878176\n",
      "[Epoch 6/50] [Batch 203/300] [D loss: 0.754483] [G loss: 0.940745] time: 0:09:59.501067\n",
      "0.8889501\n",
      "[Epoch 6/50] [Batch 204/300] [D loss: 0.754574] [G loss: 0.791884] time: 0:09:59.822343\n",
      "0.90680987\n",
      "[Epoch 6/50] [Batch 205/300] [D loss: 0.754615] [G loss: 0.783452] time: 0:10:00.107901\n",
      "0.9205707\n",
      "[Epoch 6/50] [Batch 206/300] [D loss: 0.754609] [G loss: 0.814937] time: 0:10:00.388436\n",
      "0.929976\n",
      "[Epoch 6/50] [Batch 207/300] [D loss: 0.754509] [G loss: 0.760475] time: 0:10:00.683744\n",
      "0.94581294\n",
      "[Epoch 6/50] [Batch 208/300] [D loss: 0.754431] [G loss: 0.916053] time: 0:10:00.981778\n",
      "0.8979778\n",
      "[Epoch 6/50] [Batch 209/300] [D loss: 0.754447] [G loss: 0.792984] time: 0:10:01.282554\n",
      "0.88833976\n",
      "[Epoch 6/50] [Batch 210/300] [D loss: 0.754591] [G loss: 0.876926] time: 0:10:01.582559\n",
      "0.97344637\n",
      "[Epoch 6/50] [Batch 211/300] [D loss: 0.754451] [G loss: 0.875653] time: 0:10:01.872648\n",
      "0.9097671\n",
      "[Epoch 6/50] [Batch 212/300] [D loss: 0.754573] [G loss: 0.862451] time: 0:10:02.178733\n",
      "0.9048402\n",
      "[Epoch 6/50] [Batch 213/300] [D loss: 0.754497] [G loss: 0.697761] time: 0:10:02.483730\n",
      "0.9108469\n",
      "[Epoch 6/50] [Batch 214/300] [D loss: 0.754408] [G loss: 0.809770] time: 0:10:02.765939\n",
      "0.9181931\n",
      "[Epoch 6/50] [Batch 215/300] [D loss: 0.754596] [G loss: 0.843644] time: 0:10:03.066663\n",
      "0.9451168\n",
      "[Epoch 6/50] [Batch 216/300] [D loss: 0.754546] [G loss: 0.867601] time: 0:10:03.359246\n",
      "0.90005827\n",
      "[Epoch 6/50] [Batch 217/300] [D loss: 0.754623] [G loss: 0.691462] time: 0:10:03.673662\n",
      "0.9349437\n",
      "[Epoch 6/50] [Batch 218/300] [D loss: 0.754579] [G loss: 0.807402] time: 0:10:03.960090\n",
      "0.9326558\n",
      "[Epoch 6/50] [Batch 219/300] [D loss: 0.754493] [G loss: 0.702974] time: 0:10:04.261031\n",
      "0.9548877\n",
      "[Epoch 6/50] [Batch 220/300] [D loss: 0.754453] [G loss: 0.793065] time: 0:10:04.564086\n",
      "0.86896664\n",
      "[Epoch 6/50] [Batch 221/300] [D loss: 0.754477] [G loss: 0.857319] time: 0:10:04.860800\n",
      "0.899877\n",
      "[Epoch 6/50] [Batch 222/300] [D loss: 0.754490] [G loss: 0.889546] time: 0:10:05.147241\n",
      "0.9135628\n",
      "[Epoch 6/50] [Batch 223/300] [D loss: 0.754482] [G loss: 0.834025] time: 0:10:05.462237\n",
      "0.91757727\n",
      "[Epoch 6/50] [Batch 224/300] [D loss: 0.754610] [G loss: 0.865174] time: 0:10:05.758381\n",
      "0.912052\n",
      "[Epoch 6/50] [Batch 225/300] [D loss: 0.754419] [G loss: 0.861754] time: 0:10:06.070568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88456106\n",
      "[Epoch 6/50] [Batch 226/300] [D loss: 0.754477] [G loss: 0.805868] time: 0:10:06.358924\n",
      "0.90713793\n",
      "[Epoch 6/50] [Batch 227/300] [D loss: 0.754423] [G loss: 0.867089] time: 0:10:06.664035\n",
      "0.9712464\n",
      "[Epoch 6/50] [Batch 228/300] [D loss: 0.754363] [G loss: 0.828650] time: 0:10:06.978204\n",
      "0.92240095\n",
      "[Epoch 6/50] [Batch 229/300] [D loss: 0.754429] [G loss: 0.832584] time: 0:10:07.274968\n",
      "0.8646024\n",
      "[Epoch 6/50] [Batch 230/300] [D loss: 0.754461] [G loss: 0.739618] time: 0:10:07.554880\n",
      "0.87837106\n",
      "[Epoch 6/50] [Batch 231/300] [D loss: 0.754527] [G loss: 0.888047] time: 0:10:07.854030\n",
      "0.9044809\n",
      "[Epoch 6/50] [Batch 232/300] [D loss: 0.754579] [G loss: 0.691277] time: 0:10:08.162748\n",
      "0.9340947\n",
      "[Epoch 6/50] [Batch 233/300] [D loss: 0.754463] [G loss: 0.755303] time: 0:10:08.463043\n",
      "0.878514\n",
      "[Epoch 6/50] [Batch 234/300] [D loss: 0.754531] [G loss: 0.862370] time: 0:10:08.736751\n",
      "0.8667186\n",
      "[Epoch 6/50] [Batch 235/300] [D loss: 0.754470] [G loss: 0.780903] time: 0:10:09.048854\n",
      "0.90041465\n",
      "[Epoch 6/50] [Batch 236/300] [D loss: 0.754436] [G loss: 0.740931] time: 0:10:09.341351\n",
      "0.8944699\n",
      "[Epoch 6/50] [Batch 237/300] [D loss: 0.754492] [G loss: 0.759640] time: 0:10:09.644420\n",
      "0.88478667\n",
      "[Epoch 6/50] [Batch 238/300] [D loss: 0.754496] [G loss: 0.909248] time: 0:10:09.948447\n",
      "0.9076316\n",
      "[Epoch 6/50] [Batch 239/300] [D loss: 0.754409] [G loss: 0.806554] time: 0:10:10.229077\n",
      "0.9019179\n",
      "[Epoch 6/50] [Batch 240/300] [D loss: 0.754335] [G loss: 0.883887] time: 0:10:10.541389\n",
      "0.88873595\n",
      "[Epoch 6/50] [Batch 241/300] [D loss: 0.754423] [G loss: 0.825939] time: 0:10:10.835224\n",
      "0.9449741\n",
      "[Epoch 6/50] [Batch 242/300] [D loss: 0.754421] [G loss: 0.824202] time: 0:10:11.126981\n",
      "0.8853342\n",
      "[Epoch 6/50] [Batch 243/300] [D loss: 0.754353] [G loss: 0.766835] time: 0:10:11.426866\n",
      "0.95303136\n",
      "[Epoch 6/50] [Batch 244/300] [D loss: 0.754399] [G loss: 0.940803] time: 0:10:11.709455\n",
      "0.89160246\n",
      "[Epoch 6/50] [Batch 245/300] [D loss: 0.754385] [G loss: 1.034825] time: 0:10:11.985295\n",
      "0.93652576\n",
      "[Epoch 6/50] [Batch 246/300] [D loss: 0.754483] [G loss: 0.817869] time: 0:10:12.277574\n",
      "0.88561064\n",
      "[Epoch 6/50] [Batch 247/300] [D loss: 0.754518] [G loss: 0.785387] time: 0:10:12.562667\n",
      "0.92231697\n",
      "[Epoch 6/50] [Batch 248/300] [D loss: 0.754479] [G loss: 0.789978] time: 0:10:12.876781\n",
      "0.8823374\n",
      "[Epoch 6/50] [Batch 249/300] [D loss: 0.754462] [G loss: 0.763672] time: 0:10:13.177264\n",
      "0.9438336\n",
      "[Epoch 6/50] [Batch 250/300] [D loss: 0.754488] [G loss: 0.785181] time: 0:10:13.480443\n",
      "0.87504035\n",
      "[Epoch 6/50] [Batch 251/300] [D loss: 0.754462] [G loss: 0.741778] time: 0:10:13.768579\n",
      "0.89642483\n",
      "[Epoch 6/50] [Batch 252/300] [D loss: 0.754376] [G loss: 0.755992] time: 0:10:14.060409\n",
      "0.9567773\n",
      "[Epoch 6/50] [Batch 253/300] [D loss: 0.754360] [G loss: 0.828783] time: 0:10:14.356232\n",
      "0.92143935\n",
      "[Epoch 6/50] [Batch 254/300] [D loss: 0.754529] [G loss: 0.799203] time: 0:10:14.636481\n",
      "0.9209425\n",
      "[Epoch 6/50] [Batch 255/300] [D loss: 0.754449] [G loss: 0.777671] time: 0:10:14.949476\n",
      "0.9239712\n",
      "[Epoch 6/50] [Batch 256/300] [D loss: 0.754517] [G loss: 0.728268] time: 0:10:15.256861\n",
      "0.9285037\n",
      "[Epoch 6/50] [Batch 257/300] [D loss: 0.754400] [G loss: 0.743822] time: 0:10:15.565577\n",
      "0.8963241\n",
      "[Epoch 6/50] [Batch 258/300] [D loss: 0.754382] [G loss: 0.754062] time: 0:10:15.859769\n",
      "0.88415223\n",
      "[Epoch 6/50] [Batch 259/300] [D loss: 0.754367] [G loss: 0.816930] time: 0:10:16.155300\n",
      "0.92604154\n",
      "[Epoch 6/50] [Batch 260/300] [D loss: 0.754460] [G loss: 0.733003] time: 0:10:16.452695\n",
      "0.9076083\n",
      "[Epoch 6/50] [Batch 261/300] [D loss: 0.754382] [G loss: 0.833071] time: 0:10:16.744307\n",
      "0.90522736\n",
      "[Epoch 6/50] [Batch 262/300] [D loss: 0.754421] [G loss: 0.721482] time: 0:10:17.060084\n",
      "0.9181054\n",
      "[Epoch 6/50] [Batch 263/300] [D loss: 0.754384] [G loss: 0.736664] time: 0:10:17.364329\n",
      "0.9096777\n",
      "[Epoch 6/50] [Batch 264/300] [D loss: 0.754434] [G loss: 0.732772] time: 0:10:17.647622\n",
      "0.9613068\n",
      "[Epoch 6/50] [Batch 265/300] [D loss: 0.754421] [G loss: 0.910013] time: 0:10:17.932392\n",
      "0.9061027\n",
      "[Epoch 6/50] [Batch 266/300] [D loss: 0.754424] [G loss: 0.841366] time: 0:10:18.212268\n",
      "0.8979623\n",
      "[Epoch 6/50] [Batch 267/300] [D loss: 0.754390] [G loss: 0.892594] time: 0:10:18.507689\n",
      "0.9336135\n",
      "[Epoch 6/50] [Batch 268/300] [D loss: 0.754368] [G loss: 0.768235] time: 0:10:18.829199\n",
      "0.95061356\n",
      "[Epoch 6/50] [Batch 269/300] [D loss: 0.754380] [G loss: 0.902683] time: 0:10:19.147494\n",
      "0.90480644\n",
      "[Epoch 6/50] [Batch 270/300] [D loss: 0.754480] [G loss: 0.690094] time: 0:10:19.435462\n",
      "0.9579695\n",
      "[Epoch 6/50] [Batch 271/300] [D loss: 0.754394] [G loss: 0.753946] time: 0:10:19.723688\n",
      "0.9359374\n",
      "[Epoch 6/50] [Batch 272/300] [D loss: 0.754489] [G loss: 0.809862] time: 0:10:20.026236\n",
      "0.93209857\n",
      "[Epoch 6/50] [Batch 273/300] [D loss: 0.754373] [G loss: 0.762962] time: 0:10:20.320798\n",
      "0.9326014\n",
      "[Epoch 6/50] [Batch 274/300] [D loss: 0.754376] [G loss: 0.827159] time: 0:10:20.608626\n",
      "0.934726\n",
      "[Epoch 6/50] [Batch 275/300] [D loss: 0.754471] [G loss: 0.748751] time: 0:10:20.898124\n",
      "0.93003947\n",
      "[Epoch 6/50] [Batch 276/300] [D loss: 0.754485] [G loss: 0.825586] time: 0:10:21.190348\n",
      "0.9133218\n",
      "[Epoch 6/50] [Batch 277/300] [D loss: 0.754428] [G loss: 0.814384] time: 0:10:21.478143\n",
      "0.89700776\n",
      "[Epoch 6/50] [Batch 278/300] [D loss: 0.754398] [G loss: 0.915306] time: 0:10:21.798635\n",
      "0.9052116\n",
      "[Epoch 6/50] [Batch 279/300] [D loss: 0.754428] [G loss: 0.784379] time: 0:10:22.102370\n",
      "0.9457083\n",
      "[Epoch 6/50] [Batch 280/300] [D loss: 0.754499] [G loss: 0.943858] time: 0:10:22.396605\n",
      "0.9376736\n",
      "[Epoch 6/50] [Batch 281/300] [D loss: 0.754349] [G loss: 0.853703] time: 0:10:22.681135\n",
      "0.9173401\n",
      "[Epoch 6/50] [Batch 282/300] [D loss: 0.754462] [G loss: 0.731317] time: 0:10:22.985272\n",
      "0.959064\n",
      "[Epoch 6/50] [Batch 283/300] [D loss: 0.754392] [G loss: 0.867666] time: 0:10:23.255625\n",
      "0.8579788\n",
      "[Epoch 6/50] [Batch 284/300] [D loss: 0.754399] [G loss: 0.812228] time: 0:10:23.541320\n",
      "0.87862426\n",
      "[Epoch 6/50] [Batch 285/300] [D loss: 0.754385] [G loss: 0.829745] time: 0:10:23.849974\n",
      "0.86640066\n",
      "[Epoch 6/50] [Batch 286/300] [D loss: 0.754400] [G loss: 0.784044] time: 0:10:24.135677\n",
      "0.94482714\n",
      "[Epoch 6/50] [Batch 287/300] [D loss: 0.754390] [G loss: 0.895969] time: 0:10:24.425475\n",
      "0.91103035\n",
      "[Epoch 6/50] [Batch 288/300] [D loss: 0.754308] [G loss: 0.876476] time: 0:10:24.714924\n",
      "0.92586464\n",
      "[Epoch 6/50] [Batch 289/300] [D loss: 0.754423] [G loss: 0.856474] time: 0:10:24.997779\n",
      "0.9388588\n",
      "[Epoch 6/50] [Batch 290/300] [D loss: 0.754355] [G loss: 0.816355] time: 0:10:25.297599\n",
      "0.93794566\n",
      "[Epoch 6/50] [Batch 291/300] [D loss: 0.754434] [G loss: 0.681987] time: 0:10:25.598784\n",
      "0.87875646\n",
      "[Epoch 6/50] [Batch 292/300] [D loss: 0.754512] [G loss: 0.767574] time: 0:10:25.904486\n",
      "0.8877961\n",
      "[Epoch 6/50] [Batch 293/300] [D loss: 0.754457] [G loss: 0.684941] time: 0:10:26.195839\n",
      "0.9059584\n",
      "[Epoch 6/50] [Batch 294/300] [D loss: 0.754364] [G loss: 0.775639] time: 0:10:26.488303\n",
      "0.92761725\n",
      "[Epoch 6/50] [Batch 295/300] [D loss: 0.754405] [G loss: 0.784850] time: 0:10:26.787123\n",
      "0.910429\n",
      "[Epoch 6/50] [Batch 296/300] [D loss: 0.754397] [G loss: 0.863102] time: 0:10:27.091865\n",
      "0.91810894\n",
      "[Epoch 6/50] [Batch 297/300] [D loss: 0.754370] [G loss: 0.758039] time: 0:10:27.390464\n",
      "0.9499032\n",
      "[Epoch 6/50] [Batch 298/300] [D loss: 0.754300] [G loss: 0.742552] time: 0:10:27.687178\n",
      "0.8982756\n",
      "[Epoch 6/50] [Batch 299/300] [D loss: 0.754381] [G loss: 0.792494] time: 0:10:27.981313\n",
      "0.89725584\n",
      "[Epoch 7/50] [Batch 0/300] [D loss: 0.754318] [G loss: 0.760352] time: 0:10:28.289892\n",
      "0.9291212\n",
      "[Epoch 7/50] [Batch 1/300] [D loss: 0.754471] [G loss: 0.816073] time: 0:10:28.583100\n",
      "0.92292166\n",
      "[Epoch 7/50] [Batch 2/300] [D loss: 0.754397] [G loss: 0.715642] time: 0:10:28.877056\n",
      "0.891819\n",
      "[Epoch 7/50] [Batch 3/300] [D loss: 0.754379] [G loss: 0.777500] time: 0:10:29.190715\n",
      "0.9414653\n",
      "[Epoch 7/50] [Batch 4/300] [D loss: 0.754286] [G loss: 0.758176] time: 0:10:29.473869\n",
      "0.8928476\n",
      "[Epoch 7/50] [Batch 5/300] [D loss: 0.754333] [G loss: 0.709372] time: 0:10:29.783853\n",
      "0.9161146\n",
      "[Epoch 7/50] [Batch 7/300] [D loss: 0.754381] [G loss: 0.768487] time: 0:10:30.097569\n",
      "0.93490076\n",
      "[Epoch 7/50] [Batch 8/300] [D loss: 0.754344] [G loss: 0.850778] time: 0:10:30.381657\n",
      "0.91430455\n",
      "[Epoch 7/50] [Batch 9/300] [D loss: 0.754343] [G loss: 0.730095] time: 0:10:30.684367\n",
      "0.9231649\n",
      "[Epoch 7/50] [Batch 10/300] [D loss: 0.754367] [G loss: 0.716026] time: 0:10:30.980045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95247465\n",
      "[Epoch 7/50] [Batch 11/300] [D loss: 0.754389] [G loss: 0.775473] time: 0:10:31.294812\n",
      "0.90452313\n",
      "[Epoch 7/50] [Batch 12/300] [D loss: 0.754278] [G loss: 0.842858] time: 0:10:31.595031\n",
      "0.91946536\n",
      "[Epoch 7/50] [Batch 13/300] [D loss: 0.754302] [G loss: 0.756993] time: 0:10:31.891832\n",
      "0.93472284\n",
      "[Epoch 7/50] [Batch 14/300] [D loss: 0.754413] [G loss: 0.903684] time: 0:10:32.205127\n",
      "0.93662816\n",
      "[Epoch 7/50] [Batch 15/300] [D loss: 0.754330] [G loss: 0.843011] time: 0:10:32.501285\n",
      "0.9254404\n",
      "[Epoch 7/50] [Batch 16/300] [D loss: 0.754291] [G loss: 0.962092] time: 0:10:32.807962\n",
      "0.90356463\n",
      "[Epoch 7/50] [Batch 17/300] [D loss: 0.754290] [G loss: 0.736240] time: 0:10:33.106728\n",
      "0.90954304\n",
      "[Epoch 7/50] [Batch 18/300] [D loss: 0.754344] [G loss: 0.765036] time: 0:10:33.414672\n",
      "0.934931\n",
      "[Epoch 7/50] [Batch 19/300] [D loss: 0.754377] [G loss: 0.729274] time: 0:10:33.717730\n",
      "0.9308426\n",
      "[Epoch 7/50] [Batch 20/300] [D loss: 0.754425] [G loss: 0.829449] time: 0:10:34.032621\n",
      "0.93288636\n",
      "[Epoch 7/50] [Batch 21/300] [D loss: 0.754254] [G loss: 0.736189] time: 0:10:34.337007\n",
      "0.9155634\n",
      "[Epoch 7/50] [Batch 22/300] [D loss: 0.754371] [G loss: 0.802329] time: 0:10:34.632945\n",
      "0.8862989\n",
      "[Epoch 7/50] [Batch 23/300] [D loss: 0.754304] [G loss: 0.844718] time: 0:10:34.940328\n",
      "0.9538694\n",
      "[Epoch 7/50] [Batch 24/300] [D loss: 0.754437] [G loss: 0.713498] time: 0:10:35.238015\n",
      "0.93205136\n",
      "[Epoch 7/50] [Batch 25/300] [D loss: 0.754334] [G loss: 0.793185] time: 0:10:35.522655\n",
      "0.91712886\n",
      "[Epoch 7/50] [Batch 26/300] [D loss: 0.754397] [G loss: 0.682277] time: 0:10:35.832185\n",
      "0.9359941\n",
      "[Epoch 7/50] [Batch 27/300] [D loss: 0.754363] [G loss: 0.800939] time: 0:10:36.118853\n",
      "0.93925434\n",
      "[Epoch 7/50] [Batch 28/300] [D loss: 0.754337] [G loss: 0.784374] time: 0:10:36.418188\n",
      "0.9099529\n",
      "[Epoch 7/50] [Batch 29/300] [D loss: 0.754315] [G loss: 0.760353] time: 0:10:36.722852\n",
      "0.92846686\n",
      "[Epoch 7/50] [Batch 30/300] [D loss: 0.754363] [G loss: 0.801359] time: 0:10:37.025179\n",
      "0.885717\n",
      "[Epoch 7/50] [Batch 31/300] [D loss: 0.754362] [G loss: 0.698695] time: 0:10:37.329158\n",
      "0.94625306\n",
      "[Epoch 7/50] [Batch 32/300] [D loss: 0.754388] [G loss: 0.798119] time: 0:10:37.619627\n",
      "0.95567757\n",
      "[Epoch 7/50] [Batch 33/300] [D loss: 0.754303] [G loss: 0.695081] time: 0:10:37.923997\n",
      "0.9438135\n",
      "[Epoch 7/50] [Batch 34/300] [D loss: 0.754399] [G loss: 0.700195] time: 0:10:38.236777\n",
      "0.88056284\n",
      "[Epoch 7/50] [Batch 35/300] [D loss: 0.754324] [G loss: 0.789196] time: 0:10:38.527443\n",
      "0.94624\n",
      "[Epoch 7/50] [Batch 36/300] [D loss: 0.754340] [G loss: 0.675644] time: 0:10:38.832057\n",
      "0.939775\n",
      "[Epoch 7/50] [Batch 37/300] [D loss: 0.754375] [G loss: 0.701140] time: 0:10:39.134797\n",
      "0.92265505\n",
      "[Epoch 7/50] [Batch 38/300] [D loss: 0.754311] [G loss: 0.757006] time: 0:10:39.411501\n",
      "0.8827626\n",
      "[Epoch 7/50] [Batch 39/300] [D loss: 0.754362] [G loss: 0.759402] time: 0:10:39.717314\n",
      "0.8944774\n",
      "[Epoch 7/50] [Batch 40/300] [D loss: 0.754277] [G loss: 0.845376] time: 0:10:40.019475\n",
      "0.9562879\n",
      "[Epoch 7/50] [Batch 41/300] [D loss: 0.754194] [G loss: 0.805909] time: 0:10:40.329287\n",
      "0.92907506\n",
      "[Epoch 7/50] [Batch 42/300] [D loss: 0.754327] [G loss: 0.796742] time: 0:10:40.623072\n",
      "0.9366917\n",
      "[Epoch 7/50] [Batch 43/300] [D loss: 0.754333] [G loss: 0.773467] time: 0:10:40.904211\n",
      "0.95509744\n",
      "[Epoch 7/50] [Batch 44/300] [D loss: 0.754367] [G loss: 0.749543] time: 0:10:41.187595\n",
      "0.9066243\n",
      "[Epoch 7/50] [Batch 45/300] [D loss: 0.754318] [G loss: 0.883856] time: 0:10:41.478195\n",
      "0.932913\n",
      "[Epoch 7/50] [Batch 46/300] [D loss: 0.754330] [G loss: 0.734679] time: 0:10:41.784815\n",
      "0.9672596\n",
      "[Epoch 7/50] [Batch 47/300] [D loss: 0.754379] [G loss: 0.818681] time: 0:10:42.085451\n",
      "0.9478259\n",
      "[Epoch 7/50] [Batch 48/300] [D loss: 0.754292] [G loss: 0.793761] time: 0:10:42.384166\n",
      "0.9548504\n",
      "[Epoch 7/50] [Batch 49/300] [D loss: 0.754320] [G loss: 0.754228] time: 0:10:42.687627\n",
      "0.9134975\n",
      "[Epoch 7/50] [Batch 50/300] [D loss: 0.754341] [G loss: 0.867898] time: 0:10:42.987932\n",
      "0.9326344\n",
      "[Epoch 7/50] [Batch 51/300] [D loss: 0.754285] [G loss: 0.827076] time: 0:10:43.298002\n",
      "0.9007606\n",
      "[Epoch 7/50] [Batch 52/300] [D loss: 0.754274] [G loss: 0.885949] time: 0:10:43.600887\n",
      "0.89712137\n",
      "[Epoch 7/50] [Batch 53/300] [D loss: 0.754326] [G loss: 0.691474] time: 0:10:43.886705\n",
      "0.9269306\n",
      "[Epoch 7/50] [Batch 54/300] [D loss: 0.754366] [G loss: 0.807167] time: 0:10:44.181431\n",
      "0.91912967\n",
      "[Epoch 7/50] [Batch 55/300] [D loss: 0.754326] [G loss: 0.777417] time: 0:10:44.477361\n",
      "0.9027479\n",
      "[Epoch 7/50] [Batch 56/300] [D loss: 0.754196] [G loss: 0.840191] time: 0:10:44.779582\n",
      "0.94104576\n",
      "[Epoch 7/50] [Batch 57/300] [D loss: 0.754376] [G loss: 0.763425] time: 0:10:45.072527\n",
      "0.9106237\n",
      "[Epoch 7/50] [Batch 58/300] [D loss: 0.754318] [G loss: 0.766952] time: 0:10:45.381655\n",
      "0.90124464\n",
      "[Epoch 7/50] [Batch 59/300] [D loss: 0.754281] [G loss: 0.790363] time: 0:10:45.706033\n",
      "0.97736764\n",
      "[Epoch 7/50] [Batch 60/300] [D loss: 0.754329] [G loss: 0.786668] time: 0:10:45.994141\n",
      "0.9750369\n",
      "[Epoch 7/50] [Batch 61/300] [D loss: 0.754218] [G loss: 0.701196] time: 0:10:46.273162\n",
      "0.9473091\n",
      "[Epoch 7/50] [Batch 62/300] [D loss: 0.754299] [G loss: 0.654998] time: 0:10:46.561395\n",
      "0.9187388\n",
      "[Epoch 7/50] [Batch 63/300] [D loss: 0.754252] [G loss: 0.767790] time: 0:10:46.864016\n",
      "0.9389667\n",
      "[Epoch 7/50] [Batch 64/300] [D loss: 0.754309] [G loss: 0.858391] time: 0:10:47.165805\n",
      "0.88125545\n",
      "[Epoch 7/50] [Batch 65/300] [D loss: 0.754252] [G loss: 0.777330] time: 0:10:47.483601\n",
      "0.91396755\n",
      "[Epoch 7/50] [Batch 66/300] [D loss: 0.754237] [G loss: 0.729338] time: 0:10:47.777384\n",
      "0.92936736\n",
      "[Epoch 7/50] [Batch 67/300] [D loss: 0.754329] [G loss: 0.750698] time: 0:10:48.066498\n",
      "0.9446005\n",
      "[Epoch 7/50] [Batch 68/300] [D loss: 0.754389] [G loss: 0.821352] time: 0:10:48.379548\n",
      "0.94685966\n",
      "[Epoch 7/50] [Batch 69/300] [D loss: 0.754264] [G loss: 0.913569] time: 0:10:48.686599\n",
      "0.9147715\n",
      "[Epoch 7/50] [Batch 70/300] [D loss: 0.754259] [G loss: 0.791521] time: 0:10:48.985227\n",
      "0.8915079\n",
      "[Epoch 7/50] [Batch 71/300] [D loss: 0.754280] [G loss: 0.803996] time: 0:10:49.299388\n",
      "0.92692024\n",
      "[Epoch 7/50] [Batch 72/300] [D loss: 0.754270] [G loss: 0.788009] time: 0:10:49.607502\n",
      "0.9477451\n",
      "[Epoch 7/50] [Batch 73/300] [D loss: 0.754190] [G loss: 0.830611] time: 0:10:49.906556\n",
      "0.91084784\n",
      "[Epoch 7/50] [Batch 74/300] [D loss: 0.754308] [G loss: 0.807167] time: 0:10:50.198082\n",
      "0.9096152\n",
      "[Epoch 7/50] [Batch 75/300] [D loss: 0.754254] [G loss: 0.829073] time: 0:10:50.509291\n",
      "0.9592721\n",
      "[Epoch 7/50] [Batch 76/300] [D loss: 0.754248] [G loss: 0.885901] time: 0:10:50.829490\n",
      "0.9329663\n",
      "[Epoch 7/50] [Batch 77/300] [D loss: 0.754276] [G loss: 0.750248] time: 0:10:51.118943\n",
      "0.94211775\n",
      "[Epoch 7/50] [Batch 78/300] [D loss: 0.754205] [G loss: 0.911648] time: 0:10:51.396159\n",
      "0.913385\n",
      "[Epoch 7/50] [Batch 79/300] [D loss: 0.754227] [G loss: 0.806511] time: 0:10:51.706702\n",
      "0.9206616\n",
      "[Epoch 7/50] [Batch 80/300] [D loss: 0.754230] [G loss: 0.759836] time: 0:10:51.990803\n",
      "0.90426975\n",
      "[Epoch 7/50] [Batch 81/300] [D loss: 0.754323] [G loss: 0.683430] time: 0:10:52.299495\n",
      "0.9130474\n",
      "[Epoch 7/50] [Batch 82/300] [D loss: 0.754198] [G loss: 0.924567] time: 0:10:52.598236\n",
      "0.8860567\n",
      "[Epoch 7/50] [Batch 83/300] [D loss: 0.754195] [G loss: 0.715422] time: 0:10:52.899129\n",
      "0.87412685\n",
      "[Epoch 7/50] [Batch 84/300] [D loss: 0.754230] [G loss: 0.839988] time: 0:10:53.186444\n",
      "0.8982424\n",
      "[Epoch 7/50] [Batch 85/300] [D loss: 0.754371] [G loss: 0.784758] time: 0:10:53.475404\n",
      "0.92698556\n",
      "[Epoch 7/50] [Batch 86/300] [D loss: 0.754284] [G loss: 0.773517] time: 0:10:53.765963\n",
      "0.9036166\n",
      "[Epoch 7/50] [Batch 87/300] [D loss: 0.754215] [G loss: 0.752486] time: 0:10:54.076748\n",
      "0.91288596\n",
      "[Epoch 7/50] [Batch 88/300] [D loss: 0.754266] [G loss: 0.748606] time: 0:10:54.362554\n",
      "0.9236765\n",
      "[Epoch 7/50] [Batch 89/300] [D loss: 0.754251] [G loss: 0.782323] time: 0:10:54.656577\n",
      "0.8920267\n",
      "[Epoch 7/50] [Batch 90/300] [D loss: 0.754275] [G loss: 0.825884] time: 0:10:54.955477\n",
      "0.8715144\n",
      "[Epoch 7/50] [Batch 91/300] [D loss: 0.754163] [G loss: 0.717398] time: 0:10:55.251207\n",
      "0.9167483\n",
      "[Epoch 7/50] [Batch 92/300] [D loss: 0.754286] [G loss: 0.740827] time: 0:10:55.527077\n",
      "0.93783474\n",
      "[Epoch 7/50] [Batch 93/300] [D loss: 0.754203] [G loss: 0.816271] time: 0:10:55.838664\n",
      "0.8995201\n",
      "[Epoch 7/50] [Batch 94/300] [D loss: 0.754136] [G loss: 0.849852] time: 0:10:56.144127\n",
      "0.9093537\n",
      "[Epoch 7/50] [Batch 95/300] [D loss: 0.754187] [G loss: 0.697753] time: 0:10:56.466599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85681933\n",
      "[Epoch 7/50] [Batch 96/300] [D loss: 0.754189] [G loss: 0.967385] time: 0:10:56.788450\n",
      "0.8974607\n",
      "[Epoch 7/50] [Batch 97/300] [D loss: 0.754283] [G loss: 0.758921] time: 0:10:57.084039\n",
      "0.90493655\n",
      "[Epoch 7/50] [Batch 98/300] [D loss: 0.754306] [G loss: 0.791124] time: 0:10:57.372875\n",
      "0.92773294\n",
      "[Epoch 7/50] [Batch 99/300] [D loss: 0.754222] [G loss: 0.814436] time: 0:10:57.678972\n",
      "0.92550904\n",
      "[Epoch 7/50] [Batch 100/300] [D loss: 0.754244] [G loss: 0.797374] time: 0:10:57.977329\n",
      "0.82551605\n",
      "[Epoch 7/50] [Batch 101/300] [D loss: 0.754238] [G loss: 0.814277] time: 0:10:58.295731\n",
      "0.9308632\n",
      "[Epoch 7/50] [Batch 102/300] [D loss: 0.754236] [G loss: 0.810282] time: 0:10:58.593463\n",
      "0.92490023\n",
      "[Epoch 7/50] [Batch 103/300] [D loss: 0.754221] [G loss: 0.756100] time: 0:10:58.903975\n",
      "0.94241977\n",
      "[Epoch 7/50] [Batch 104/300] [D loss: 0.754337] [G loss: 0.773894] time: 0:10:59.188158\n",
      "0.93506366\n",
      "[Epoch 7/50] [Batch 105/300] [D loss: 0.754301] [G loss: 0.798064] time: 0:10:59.502399\n",
      "0.9071781\n",
      "[Epoch 7/50] [Batch 106/300] [D loss: 0.754288] [G loss: 0.719847] time: 0:10:59.806348\n",
      "0.9507343\n",
      "[Epoch 7/50] [Batch 107/300] [D loss: 0.754181] [G loss: 0.710981] time: 0:11:00.099930\n",
      "0.87101936\n",
      "[Epoch 7/50] [Batch 108/300] [D loss: 0.754351] [G loss: 0.691052] time: 0:11:00.395346\n",
      "0.9234898\n",
      "[Epoch 7/50] [Batch 109/300] [D loss: 0.754190] [G loss: 0.908760] time: 0:11:00.701195\n",
      "0.9070361\n",
      "[Epoch 7/50] [Batch 110/300] [D loss: 0.754185] [G loss: 0.775419] time: 0:11:01.009935\n",
      "0.9321311\n",
      "[Epoch 7/50] [Batch 111/300] [D loss: 0.754089] [G loss: 0.830673] time: 0:11:01.292379\n",
      "0.87364215\n",
      "[Epoch 7/50] [Batch 112/300] [D loss: 0.754182] [G loss: 0.739723] time: 0:11:01.587925\n",
      "0.94121504\n",
      "[Epoch 7/50] [Batch 113/300] [D loss: 0.754178] [G loss: 0.790785] time: 0:11:01.922846\n",
      "0.8990608\n",
      "[Epoch 7/50] [Batch 114/300] [D loss: 0.754171] [G loss: 0.818349] time: 0:11:02.212347\n",
      "0.8702225\n",
      "[Epoch 7/50] [Batch 115/300] [D loss: 0.754214] [G loss: 0.880045] time: 0:11:02.513430\n",
      "0.94752187\n",
      "[Epoch 7/50] [Batch 116/300] [D loss: 0.754242] [G loss: 0.738433] time: 0:11:02.823974\n",
      "0.9388478\n",
      "[Epoch 7/50] [Batch 117/300] [D loss: 0.754166] [G loss: 0.746088] time: 0:11:03.120526\n",
      "0.9202371\n",
      "[Epoch 7/50] [Batch 118/300] [D loss: 0.754154] [G loss: 0.826693] time: 0:11:03.423786\n",
      "0.9256315\n",
      "[Epoch 7/50] [Batch 119/300] [D loss: 0.754189] [G loss: 0.841318] time: 0:11:03.723073\n",
      "0.8966866\n",
      "[Epoch 7/50] [Batch 120/300] [D loss: 0.754350] [G loss: 0.777988] time: 0:11:04.025486\n",
      "0.9380493\n",
      "[Epoch 7/50] [Batch 121/300] [D loss: 0.754228] [G loss: 0.794267] time: 0:11:04.333814\n",
      "0.9157048\n",
      "[Epoch 7/50] [Batch 122/300] [D loss: 0.754094] [G loss: 0.888231] time: 0:11:04.643509\n",
      "0.853784\n",
      "[Epoch 7/50] [Batch 123/300] [D loss: 0.754156] [G loss: 0.843208] time: 0:11:04.945815\n",
      "0.9533108\n",
      "[Epoch 7/50] [Batch 124/300] [D loss: 0.754268] [G loss: 0.826047] time: 0:11:05.242346\n",
      "0.8847615\n",
      "[Epoch 7/50] [Batch 125/300] [D loss: 0.754196] [G loss: 0.729081] time: 0:11:05.556565\n",
      "0.96309906\n",
      "[Epoch 7/50] [Batch 126/300] [D loss: 0.754264] [G loss: 0.732481] time: 0:11:05.867226\n",
      "0.9005907\n",
      "[Epoch 7/50] [Batch 127/300] [D loss: 0.754172] [G loss: 0.905001] time: 0:11:06.175794\n",
      "0.9091281\n",
      "[Epoch 7/50] [Batch 128/300] [D loss: 0.754064] [G loss: 0.738389] time: 0:11:06.448631\n",
      "0.9443428\n",
      "[Epoch 7/50] [Batch 129/300] [D loss: 0.754192] [G loss: 0.799272] time: 0:11:06.733620\n",
      "0.9170816\n",
      "[Epoch 7/50] [Batch 130/300] [D loss: 0.754231] [G loss: 0.880138] time: 0:11:07.023097\n",
      "0.96615154\n",
      "[Epoch 7/50] [Batch 131/300] [D loss: 0.754241] [G loss: 0.800543] time: 0:11:07.310930\n",
      "0.9060827\n",
      "[Epoch 7/50] [Batch 132/300] [D loss: 0.754179] [G loss: 0.689083] time: 0:11:07.608267\n",
      "0.9308775\n",
      "[Epoch 7/50] [Batch 133/300] [D loss: 0.754156] [G loss: 0.806268] time: 0:11:07.908167\n",
      "0.92498213\n",
      "[Epoch 7/50] [Batch 134/300] [D loss: 0.754211] [G loss: 0.711263] time: 0:11:08.204815\n",
      "0.86662847\n",
      "[Epoch 7/50] [Batch 135/300] [D loss: 0.754195] [G loss: 0.694106] time: 0:11:08.510556\n",
      "0.90041727\n",
      "[Epoch 7/50] [Batch 136/300] [D loss: 0.754225] [G loss: 0.713809] time: 0:11:08.807972\n",
      "0.91686136\n",
      "[Epoch 7/50] [Batch 137/300] [D loss: 0.754104] [G loss: 0.757318] time: 0:11:09.106064\n",
      "0.8920772\n",
      "[Epoch 7/50] [Batch 138/300] [D loss: 0.754217] [G loss: 0.758414] time: 0:11:09.405062\n",
      "0.96025056\n",
      "[Epoch 7/50] [Batch 139/300] [D loss: 0.754159] [G loss: 0.772032] time: 0:11:09.687819\n",
      "0.9422948\n",
      "[Epoch 7/50] [Batch 140/300] [D loss: 0.754186] [G loss: 0.933344] time: 0:11:09.984009\n",
      "0.94744414\n",
      "[Epoch 7/50] [Batch 141/300] [D loss: 0.754185] [G loss: 0.807376] time: 0:11:10.289055\n",
      "0.9241216\n",
      "[Epoch 7/50] [Batch 142/300] [D loss: 0.754110] [G loss: 0.751783] time: 0:11:10.592801\n",
      "0.92867213\n",
      "[Epoch 7/50] [Batch 143/300] [D loss: 0.754182] [G loss: 0.837412] time: 0:11:10.876837\n",
      "0.8688671\n",
      "[Epoch 7/50] [Batch 144/300] [D loss: 0.754208] [G loss: 0.763963] time: 0:11:11.164683\n",
      "0.8979266\n",
      "[Epoch 7/50] [Batch 145/300] [D loss: 0.754225] [G loss: 0.697317] time: 0:11:11.462550\n",
      "0.8847031\n",
      "[Epoch 7/50] [Batch 146/300] [D loss: 0.754196] [G loss: 0.789121] time: 0:11:11.770504\n",
      "0.9375047\n",
      "[Epoch 7/50] [Batch 147/300] [D loss: 0.754161] [G loss: 0.741199] time: 0:11:12.072902\n",
      "0.8815958\n",
      "[Epoch 7/50] [Batch 148/300] [D loss: 0.754259] [G loss: 0.785387] time: 0:11:12.372538\n",
      "0.92861104\n",
      "[Epoch 7/50] [Batch 149/300] [D loss: 0.754190] [G loss: 0.758682] time: 0:11:12.660643\n",
      "0.8717885\n",
      "[Epoch 7/50] [Batch 150/300] [D loss: 0.754171] [G loss: 0.681959] time: 0:11:12.959105\n",
      "0.87439585\n",
      "[Epoch 7/50] [Batch 151/300] [D loss: 0.754177] [G loss: 0.736725] time: 0:11:13.255749\n",
      "0.9085733\n",
      "[Epoch 7/50] [Batch 152/300] [D loss: 0.754224] [G loss: 0.716353] time: 0:11:13.555179\n",
      "0.9064173\n",
      "[Epoch 7/50] [Batch 153/300] [D loss: 0.754191] [G loss: 0.939066] time: 0:11:13.859581\n",
      "0.95614433\n",
      "[Epoch 7/50] [Batch 154/300] [D loss: 0.754104] [G loss: 0.712812] time: 0:11:14.160877\n",
      "0.8923369\n",
      "[Epoch 7/50] [Batch 155/300] [D loss: 0.754180] [G loss: 0.710869] time: 0:11:14.460151\n",
      "0.95241135\n",
      "[Epoch 7/50] [Batch 156/300] [D loss: 0.754170] [G loss: 0.766740] time: 0:11:14.754401\n",
      "0.94697267\n",
      "[Epoch 7/50] [Batch 157/300] [D loss: 0.754242] [G loss: 0.733561] time: 0:11:15.047504\n",
      "0.91852593\n",
      "[Epoch 7/50] [Batch 158/300] [D loss: 0.754122] [G loss: 0.838211] time: 0:11:15.349208\n",
      "0.9046828\n",
      "[Epoch 7/50] [Batch 159/300] [D loss: 0.754110] [G loss: 0.821625] time: 0:11:15.648326\n",
      "0.9073115\n",
      "[Epoch 7/50] [Batch 160/300] [D loss: 0.754137] [G loss: 0.803338] time: 0:11:15.964217\n",
      "0.91565007\n",
      "[Epoch 7/50] [Batch 161/300] [D loss: 0.754086] [G loss: 0.910629] time: 0:11:16.392610\n",
      "0.8954211\n",
      "[Epoch 7/50] [Batch 162/300] [D loss: 0.754226] [G loss: 0.713052] time: 0:11:16.698646\n",
      "0.89515585\n",
      "[Epoch 7/50] [Batch 163/300] [D loss: 0.754207] [G loss: 0.730583] time: 0:11:16.992773\n",
      "0.89038926\n",
      "[Epoch 7/50] [Batch 164/300] [D loss: 0.754175] [G loss: 0.961719] time: 0:11:17.311193\n",
      "0.90574056\n",
      "[Epoch 7/50] [Batch 165/300] [D loss: 0.754156] [G loss: 0.815524] time: 0:11:17.611438\n",
      "0.91642076\n",
      "[Epoch 7/50] [Batch 166/300] [D loss: 0.754160] [G loss: 0.869716] time: 0:11:17.908350\n",
      "0.9458701\n",
      "[Epoch 7/50] [Batch 167/300] [D loss: 0.754209] [G loss: 0.742522] time: 0:11:18.213275\n",
      "0.8928611\n",
      "[Epoch 7/50] [Batch 168/300] [D loss: 0.754107] [G loss: 0.813522] time: 0:11:18.509602\n",
      "0.9459637\n",
      "[Epoch 7/50] [Batch 169/300] [D loss: 0.754105] [G loss: 0.783133] time: 0:11:18.821385\n",
      "0.89652985\n",
      "[Epoch 7/50] [Batch 170/300] [D loss: 0.754113] [G loss: 0.840285] time: 0:11:19.138123\n",
      "0.9143979\n",
      "[Epoch 7/50] [Batch 171/300] [D loss: 0.754176] [G loss: 0.872617] time: 0:11:19.437070\n",
      "0.8978736\n",
      "[Epoch 7/50] [Batch 172/300] [D loss: 0.754165] [G loss: 0.842251] time: 0:11:19.722308\n",
      "0.9665215\n",
      "[Epoch 7/50] [Batch 173/300] [D loss: 0.754209] [G loss: 0.795060] time: 0:11:20.010917\n",
      "0.9161381\n",
      "[Epoch 7/50] [Batch 174/300] [D loss: 0.754174] [G loss: 0.792183] time: 0:11:20.311856\n",
      "0.93287945\n",
      "[Epoch 7/50] [Batch 175/300] [D loss: 0.754107] [G loss: 0.760710] time: 0:11:20.601166\n",
      "0.90844584\n",
      "[Epoch 7/50] [Batch 176/300] [D loss: 0.754094] [G loss: 0.923817] time: 0:11:20.908435\n",
      "0.9297273\n",
      "[Epoch 7/50] [Batch 177/300] [D loss: 0.754188] [G loss: 0.749555] time: 0:11:21.224761\n",
      "0.8832998\n",
      "[Epoch 7/50] [Batch 178/300] [D loss: 0.754204] [G loss: 0.784798] time: 0:11:21.514851\n",
      "0.89449215\n",
      "[Epoch 7/50] [Batch 179/300] [D loss: 0.754175] [G loss: 0.930830] time: 0:11:21.807153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9032996\n",
      "[Epoch 7/50] [Batch 180/300] [D loss: 0.754142] [G loss: 0.790801] time: 0:11:22.102905\n",
      "0.95060587\n",
      "[Epoch 7/50] [Batch 181/300] [D loss: 0.754159] [G loss: 0.685462] time: 0:11:22.399838\n",
      "0.94424635\n",
      "[Epoch 7/50] [Batch 182/300] [D loss: 0.754196] [G loss: 0.851033] time: 0:11:22.696193\n",
      "0.9012634\n",
      "[Epoch 7/50] [Batch 183/300] [D loss: 0.754153] [G loss: 0.873517] time: 0:11:22.998778\n",
      "0.8952985\n",
      "[Epoch 7/50] [Batch 184/300] [D loss: 0.754039] [G loss: 0.815028] time: 0:11:23.291672\n",
      "0.8918466\n",
      "[Epoch 7/50] [Batch 185/300] [D loss: 0.754192] [G loss: 0.794438] time: 0:11:23.592864\n",
      "0.91784525\n",
      "[Epoch 7/50] [Batch 186/300] [D loss: 0.754071] [G loss: 0.756595] time: 0:11:23.902832\n",
      "0.9068431\n",
      "[Epoch 7/50] [Batch 187/300] [D loss: 0.754092] [G loss: 0.796886] time: 0:11:24.208700\n",
      "0.8987501\n",
      "[Epoch 7/50] [Batch 188/300] [D loss: 0.754138] [G loss: 0.775525] time: 0:11:24.497868\n",
      "0.8872246\n",
      "[Epoch 7/50] [Batch 189/300] [D loss: 0.754092] [G loss: 0.842641] time: 0:11:24.820782\n",
      "0.96729255\n",
      "[Epoch 7/50] [Batch 190/300] [D loss: 0.754164] [G loss: 0.832595] time: 0:11:25.121338\n",
      "0.8904462\n",
      "[Epoch 7/50] [Batch 191/300] [D loss: 0.754237] [G loss: 0.707909] time: 0:11:25.429731\n",
      "0.9745023\n",
      "[Epoch 7/50] [Batch 192/300] [D loss: 0.754113] [G loss: 0.775488] time: 0:11:25.718962\n",
      "0.933573\n",
      "[Epoch 7/50] [Batch 193/300] [D loss: 0.754222] [G loss: 0.833689] time: 0:11:26.018105\n",
      "0.91024846\n",
      "[Epoch 7/50] [Batch 194/300] [D loss: 0.754251] [G loss: 0.824766] time: 0:11:26.324131\n",
      "0.9132559\n",
      "[Epoch 7/50] [Batch 195/300] [D loss: 0.754211] [G loss: 0.769075] time: 0:11:26.621560\n",
      "0.9307025\n",
      "[Epoch 7/50] [Batch 196/300] [D loss: 0.754138] [G loss: 0.709706] time: 0:11:26.933529\n",
      "0.92079026\n",
      "[Epoch 7/50] [Batch 197/300] [D loss: 0.754071] [G loss: 0.773191] time: 0:11:27.229969\n",
      "0.86783046\n",
      "[Epoch 7/50] [Batch 198/300] [D loss: 0.754143] [G loss: 0.669044] time: 0:11:27.526364\n",
      "0.8953691\n",
      "[Epoch 7/50] [Batch 199/300] [D loss: 0.754112] [G loss: 0.708971] time: 0:11:27.829231\n",
      "0.91406184\n",
      "[Epoch 7/50] [Batch 200/300] [D loss: 0.754158] [G loss: 0.652162] time: 0:11:28.139914\n",
      "0.89747924\n",
      "[Epoch 7/50] [Batch 201/300] [D loss: 0.754131] [G loss: 0.783265] time: 0:11:28.446700\n",
      "0.9000335\n",
      "[Epoch 7/50] [Batch 202/300] [D loss: 0.754165] [G loss: 0.769164] time: 0:11:28.747130\n",
      "0.90101165\n",
      "[Epoch 7/50] [Batch 203/300] [D loss: 0.754131] [G loss: 0.720529] time: 0:11:29.053109\n",
      "0.9002293\n",
      "[Epoch 7/50] [Batch 204/300] [D loss: 0.754078] [G loss: 0.704304] time: 0:11:29.342840\n",
      "0.95034665\n",
      "[Epoch 7/50] [Batch 205/300] [D loss: 0.754080] [G loss: 0.800913] time: 0:11:29.648926\n",
      "0.9192874\n",
      "[Epoch 7/50] [Batch 206/300] [D loss: 0.754100] [G loss: 0.873546] time: 0:11:29.942606\n",
      "0.9430464\n",
      "[Epoch 7/50] [Batch 207/300] [D loss: 0.754173] [G loss: 0.696452] time: 0:11:30.245766\n",
      "0.8969659\n",
      "[Epoch 7/50] [Batch 208/300] [D loss: 0.754125] [G loss: 0.757514] time: 0:11:30.536674\n",
      "0.8973741\n",
      "[Epoch 7/50] [Batch 209/300] [D loss: 0.754098] [G loss: 0.807530] time: 0:11:30.841585\n",
      "0.9204166\n",
      "[Epoch 7/50] [Batch 210/300] [D loss: 0.754185] [G loss: 0.735853] time: 0:11:31.151903\n",
      "0.94600874\n",
      "[Epoch 7/50] [Batch 211/300] [D loss: 0.754073] [G loss: 0.808600] time: 0:11:31.449698\n",
      "0.9135216\n",
      "[Epoch 7/50] [Batch 212/300] [D loss: 0.754152] [G loss: 0.784163] time: 0:11:31.750910\n",
      "0.95888275\n",
      "[Epoch 7/50] [Batch 213/300] [D loss: 0.754130] [G loss: 0.732887] time: 0:11:32.048856\n",
      "0.902281\n",
      "[Epoch 7/50] [Batch 214/300] [D loss: 0.754074] [G loss: 0.792161] time: 0:11:32.349802\n",
      "0.91412944\n",
      "[Epoch 7/50] [Batch 215/300] [D loss: 0.754231] [G loss: 0.815308] time: 0:11:32.668251\n",
      "0.88220996\n",
      "[Epoch 7/50] [Batch 216/300] [D loss: 0.754148] [G loss: 0.675641] time: 0:11:32.973776\n",
      "0.9338607\n",
      "[Epoch 7/50] [Batch 217/300] [D loss: 0.754124] [G loss: 0.676299] time: 0:11:33.245927\n",
      "0.95203394\n",
      "[Epoch 7/50] [Batch 218/300] [D loss: 0.754059] [G loss: 0.874178] time: 0:11:33.545288\n",
      "0.9170055\n",
      "[Epoch 7/50] [Batch 219/300] [D loss: 0.754154] [G loss: 0.776141] time: 0:11:33.849706\n",
      "0.93866086\n",
      "[Epoch 7/50] [Batch 220/300] [D loss: 0.754089] [G loss: 0.673194] time: 0:11:34.160672\n",
      "0.9200532\n",
      "[Epoch 7/50] [Batch 221/300] [D loss: 0.754119] [G loss: 0.781555] time: 0:11:34.454040\n",
      "0.96800256\n",
      "[Epoch 7/50] [Batch 222/300] [D loss: 0.754079] [G loss: 0.804245] time: 0:11:34.758564\n",
      "0.8881335\n",
      "[Epoch 7/50] [Batch 223/300] [D loss: 0.754036] [G loss: 0.761850] time: 0:11:35.059929\n",
      "0.8942892\n",
      "[Epoch 7/50] [Batch 224/300] [D loss: 0.754140] [G loss: 0.669123] time: 0:11:35.359469\n",
      "0.8970826\n",
      "[Epoch 7/50] [Batch 225/300] [D loss: 0.754076] [G loss: 0.731050] time: 0:11:35.654345\n",
      "0.9162796\n",
      "[Epoch 7/50] [Batch 226/300] [D loss: 0.754098] [G loss: 0.727363] time: 0:11:35.972509\n",
      "0.894224\n",
      "[Epoch 7/50] [Batch 227/300] [D loss: 0.754087] [G loss: 0.658196] time: 0:11:36.266106\n",
      "0.89148396\n",
      "[Epoch 7/50] [Batch 228/300] [D loss: 0.754111] [G loss: 0.698533] time: 0:11:36.558231\n",
      "0.93371916\n",
      "[Epoch 7/50] [Batch 229/300] [D loss: 0.754091] [G loss: 0.862024] time: 0:11:36.864074\n",
      "0.91317385\n",
      "[Epoch 7/50] [Batch 230/300] [D loss: 0.754081] [G loss: 0.683248] time: 0:11:37.144082\n",
      "0.93268484\n",
      "[Epoch 7/50] [Batch 231/300] [D loss: 0.754143] [G loss: 0.735573] time: 0:11:37.441486\n",
      "0.9034991\n",
      "[Epoch 7/50] [Batch 232/300] [D loss: 0.754103] [G loss: 0.803357] time: 0:11:37.728116\n",
      "0.8601888\n",
      "[Epoch 7/50] [Batch 233/300] [D loss: 0.754079] [G loss: 0.913280] time: 0:11:38.024003\n",
      "0.9276239\n",
      "[Epoch 7/50] [Batch 234/300] [D loss: 0.754056] [G loss: 0.609268] time: 0:11:38.313778\n",
      "0.90162605\n",
      "[Epoch 7/50] [Batch 235/300] [D loss: 0.754064] [G loss: 0.892323] time: 0:11:38.622200\n",
      "0.97460073\n",
      "[Epoch 7/50] [Batch 236/300] [D loss: 0.754029] [G loss: 0.803114] time: 0:11:38.933071\n",
      "0.86864537\n",
      "[Epoch 7/50] [Batch 237/300] [D loss: 0.754079] [G loss: 0.840760] time: 0:11:39.227214\n",
      "0.9023811\n",
      "[Epoch 7/50] [Batch 238/300] [D loss: 0.754071] [G loss: 0.677208] time: 0:11:39.514832\n",
      "0.89133316\n",
      "[Epoch 7/50] [Batch 239/300] [D loss: 0.754105] [G loss: 0.780994] time: 0:11:39.808358\n",
      "0.8881845\n",
      "[Epoch 7/50] [Batch 240/300] [D loss: 0.754081] [G loss: 0.710469] time: 0:11:40.114242\n",
      "0.90825194\n",
      "[Epoch 7/50] [Batch 241/300] [D loss: 0.754157] [G loss: 0.725934] time: 0:11:40.402735\n",
      "0.872889\n",
      "[Epoch 7/50] [Batch 242/300] [D loss: 0.754085] [G loss: 0.684688] time: 0:11:40.717657\n",
      "0.8884163\n",
      "[Epoch 7/50] [Batch 243/300] [D loss: 0.754089] [G loss: 0.691671] time: 0:11:41.011060\n",
      "0.9351301\n",
      "[Epoch 7/50] [Batch 244/300] [D loss: 0.754078] [G loss: 0.851445] time: 0:11:41.324519\n",
      "0.9343868\n",
      "[Epoch 7/50] [Batch 245/300] [D loss: 0.754065] [G loss: 0.923951] time: 0:11:41.597727\n",
      "0.90840834\n",
      "[Epoch 7/50] [Batch 246/300] [D loss: 0.754012] [G loss: 0.747429] time: 0:11:41.901837\n",
      "0.8863246\n",
      "[Epoch 7/50] [Batch 247/300] [D loss: 0.754108] [G loss: 0.859999] time: 0:11:42.196250\n",
      "0.9708542\n",
      "[Epoch 7/50] [Batch 248/300] [D loss: 0.754045] [G loss: 0.734333] time: 0:11:42.481667\n",
      "0.9528329\n",
      "[Epoch 7/50] [Batch 249/300] [D loss: 0.754019] [G loss: 0.727803] time: 0:11:42.776777\n",
      "0.93072313\n",
      "[Epoch 7/50] [Batch 250/300] [D loss: 0.754178] [G loss: 0.727904] time: 0:11:43.070964\n",
      "0.92400527\n",
      "[Epoch 7/50] [Batch 251/300] [D loss: 0.754042] [G loss: 0.759737] time: 0:11:43.388348\n",
      "0.88803214\n",
      "[Epoch 7/50] [Batch 252/300] [D loss: 0.754067] [G loss: 0.699940] time: 0:11:43.681980\n",
      "0.9098031\n",
      "[Epoch 7/50] [Batch 253/300] [D loss: 0.754110] [G loss: 0.665045] time: 0:11:43.971631\n",
      "0.9028842\n",
      "[Epoch 7/50] [Batch 254/300] [D loss: 0.754110] [G loss: 0.703748] time: 0:11:44.259525\n",
      "0.9193804\n",
      "[Epoch 7/50] [Batch 255/300] [D loss: 0.754058] [G loss: 0.634452] time: 0:11:44.559160\n",
      "0.94643706\n",
      "[Epoch 7/50] [Batch 256/300] [D loss: 0.754043] [G loss: 0.824230] time: 0:11:44.856314\n",
      "0.89208764\n",
      "[Epoch 7/50] [Batch 257/300] [D loss: 0.754177] [G loss: 0.677003] time: 0:11:45.174249\n",
      "0.9009215\n",
      "[Epoch 7/50] [Batch 258/300] [D loss: 0.754126] [G loss: 0.742857] time: 0:11:45.472860\n",
      "0.9820191\n",
      "[Epoch 7/50] [Batch 259/300] [D loss: 0.754044] [G loss: 0.855776] time: 0:11:45.761930\n",
      "0.9327586\n",
      "[Epoch 7/50] [Batch 260/300] [D loss: 0.754044] [G loss: 0.798207] time: 0:11:46.062096\n",
      "0.93361264\n",
      "[Epoch 7/50] [Batch 261/300] [D loss: 0.754127] [G loss: 0.784026] time: 0:11:46.365859\n",
      "0.8808604\n",
      "[Epoch 7/50] [Batch 262/300] [D loss: 0.754093] [G loss: 0.703122] time: 0:11:46.683763\n",
      "0.92880994\n",
      "[Epoch 7/50] [Batch 263/300] [D loss: 0.754081] [G loss: 0.809478] time: 0:11:46.991005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9068074\n",
      "[Epoch 7/50] [Batch 264/300] [D loss: 0.754032] [G loss: 0.727915] time: 0:11:47.294330\n",
      "0.9426642\n",
      "[Epoch 7/50] [Batch 265/300] [D loss: 0.754114] [G loss: 0.770480] time: 0:11:47.587848\n",
      "0.935764\n",
      "[Epoch 7/50] [Batch 266/300] [D loss: 0.754065] [G loss: 0.697736] time: 0:11:47.914504\n",
      "0.9475946\n",
      "[Epoch 7/50] [Batch 267/300] [D loss: 0.754118] [G loss: 0.816580] time: 0:11:48.224864\n",
      "0.9353362\n",
      "[Epoch 7/50] [Batch 268/300] [D loss: 0.753999] [G loss: 0.677943] time: 0:11:48.516036\n",
      "0.8811272\n",
      "[Epoch 7/50] [Batch 269/300] [D loss: 0.754005] [G loss: 0.817927] time: 0:11:48.782309\n",
      "0.9592853\n",
      "[Epoch 7/50] [Batch 270/300] [D loss: 0.754057] [G loss: 0.791241] time: 0:11:49.089883\n",
      "0.9100318\n",
      "[Epoch 7/50] [Batch 271/300] [D loss: 0.754053] [G loss: 0.770831] time: 0:11:49.383487\n",
      "0.8762548\n",
      "[Epoch 7/50] [Batch 272/300] [D loss: 0.754052] [G loss: 0.665547] time: 0:11:49.700534\n",
      "0.91382295\n",
      "[Epoch 7/50] [Batch 273/300] [D loss: 0.754052] [G loss: 0.691366] time: 0:11:50.006322\n",
      "0.9046407\n",
      "[Epoch 7/50] [Batch 274/300] [D loss: 0.754095] [G loss: 0.870068] time: 0:11:50.301282\n",
      "0.91979295\n",
      "[Epoch 7/50] [Batch 275/300] [D loss: 0.753991] [G loss: 0.709380] time: 0:11:50.591080\n",
      "0.891232\n",
      "[Epoch 7/50] [Batch 276/300] [D loss: 0.754011] [G loss: 0.853733] time: 0:11:50.905289\n",
      "0.91421866\n",
      "[Epoch 7/50] [Batch 277/300] [D loss: 0.754007] [G loss: 0.789524] time: 0:11:51.204982\n",
      "0.9330759\n",
      "[Epoch 7/50] [Batch 278/300] [D loss: 0.754043] [G loss: 0.693268] time: 0:11:51.484504\n",
      "0.90890855\n",
      "[Epoch 7/50] [Batch 279/300] [D loss: 0.754013] [G loss: 0.783740] time: 0:11:51.791834\n",
      "0.9163918\n",
      "[Epoch 7/50] [Batch 280/300] [D loss: 0.754062] [G loss: 0.745961] time: 0:11:52.106976\n",
      "0.9228366\n",
      "[Epoch 7/50] [Batch 281/300] [D loss: 0.754008] [G loss: 0.689907] time: 0:11:52.427788\n",
      "0.9489763\n",
      "[Epoch 7/50] [Batch 282/300] [D loss: 0.754030] [G loss: 0.820730] time: 0:11:52.726804\n",
      "0.9531608\n",
      "[Epoch 7/50] [Batch 283/300] [D loss: 0.753992] [G loss: 0.702327] time: 0:11:53.029907\n",
      "0.89315444\n",
      "[Epoch 7/50] [Batch 284/300] [D loss: 0.754050] [G loss: 0.817349] time: 0:11:53.333271\n",
      "0.9341492\n",
      "[Epoch 7/50] [Batch 285/300] [D loss: 0.754061] [G loss: 0.674575] time: 0:11:53.638992\n",
      "0.929826\n",
      "[Epoch 7/50] [Batch 286/300] [D loss: 0.754028] [G loss: 0.728572] time: 0:11:53.925903\n",
      "0.89550024\n",
      "[Epoch 7/50] [Batch 287/300] [D loss: 0.754022] [G loss: 0.700232] time: 0:11:54.227623\n",
      "0.95278436\n",
      "[Epoch 7/50] [Batch 288/300] [D loss: 0.754015] [G loss: 0.725003] time: 0:11:54.537744\n",
      "0.9412516\n",
      "[Epoch 7/50] [Batch 289/300] [D loss: 0.754006] [G loss: 0.818130] time: 0:11:54.834300\n",
      "0.9113426\n",
      "[Epoch 7/50] [Batch 290/300] [D loss: 0.754040] [G loss: 0.738036] time: 0:11:55.121233\n",
      "0.90728813\n",
      "[Epoch 7/50] [Batch 291/300] [D loss: 0.754124] [G loss: 0.689864] time: 0:11:55.409636\n",
      "0.85989046\n",
      "[Epoch 7/50] [Batch 292/300] [D loss: 0.754046] [G loss: 0.908503] time: 0:11:55.712385\n",
      "0.93776053\n",
      "[Epoch 7/50] [Batch 293/300] [D loss: 0.754005] [G loss: 0.733766] time: 0:11:56.016916\n",
      "0.9417235\n",
      "[Epoch 7/50] [Batch 294/300] [D loss: 0.754002] [G loss: 0.695552] time: 0:11:56.325749\n",
      "0.9103589\n",
      "[Epoch 7/50] [Batch 295/300] [D loss: 0.754064] [G loss: 0.780034] time: 0:11:56.616557\n",
      "0.8329733\n",
      "[Epoch 7/50] [Batch 296/300] [D loss: 0.753987] [G loss: 0.838689] time: 0:11:56.924484\n",
      "0.8704674\n",
      "[Epoch 7/50] [Batch 297/300] [D loss: 0.754029] [G loss: 0.797753] time: 0:11:57.232345\n",
      "0.8975722\n",
      "[Epoch 7/50] [Batch 298/300] [D loss: 0.754017] [G loss: 0.715395] time: 0:11:57.547943\n",
      "0.8872135\n",
      "[Epoch 7/50] [Batch 299/300] [D loss: 0.754129] [G loss: 0.694946] time: 0:11:57.870819\n",
      "0.88483024\n",
      "[Epoch 8/50] [Batch 0/300] [D loss: 0.754012] [G loss: 0.738585] time: 0:11:58.173616\n",
      "0.91069204\n",
      "[Epoch 8/50] [Batch 1/300] [D loss: 0.754020] [G loss: 0.760565] time: 0:11:58.475429\n",
      "0.9082293\n",
      "[Epoch 8/50] [Batch 2/300] [D loss: 0.754038] [G loss: 0.783796] time: 0:11:58.771012\n",
      "0.93519217\n",
      "[Epoch 8/50] [Batch 3/300] [D loss: 0.754068] [G loss: 0.725005] time: 0:11:59.085977\n",
      "0.9021314\n",
      "[Epoch 8/50] [Batch 4/300] [D loss: 0.753918] [G loss: 0.846741] time: 0:11:59.388628\n",
      "0.9417917\n",
      "[Epoch 8/50] [Batch 5/300] [D loss: 0.753994] [G loss: 0.672607] time: 0:11:59.675205\n",
      "0.9144606\n",
      "[Epoch 8/50] [Batch 6/300] [D loss: 0.753949] [G loss: 0.703361] time: 0:11:59.998064\n",
      "0.92701435\n",
      "[Epoch 8/50] [Batch 8/300] [D loss: 0.754007] [G loss: 0.764491] time: 0:12:00.316305\n",
      "0.86967295\n",
      "[Epoch 8/50] [Batch 9/300] [D loss: 0.753982] [G loss: 0.784999] time: 0:12:00.613997\n",
      "0.9112611\n",
      "[Epoch 8/50] [Batch 10/300] [D loss: 0.753930] [G loss: 0.737418] time: 0:12:00.914839\n",
      "0.8477745\n",
      "[Epoch 8/50] [Batch 11/300] [D loss: 0.754022] [G loss: 0.812327] time: 0:12:01.226317\n",
      "0.91098756\n",
      "[Epoch 8/50] [Batch 12/300] [D loss: 0.753946] [G loss: 0.739780] time: 0:12:01.545993\n",
      "0.93907326\n",
      "[Epoch 8/50] [Batch 13/300] [D loss: 0.753969] [G loss: 0.764283] time: 0:12:01.856541\n",
      "0.9240064\n",
      "[Epoch 8/50] [Batch 14/300] [D loss: 0.753991] [G loss: 0.706214] time: 0:12:02.180989\n",
      "0.90767187\n",
      "[Epoch 8/50] [Batch 15/300] [D loss: 0.753935] [G loss: 0.843880] time: 0:12:02.457878\n",
      "0.92026454\n",
      "[Epoch 8/50] [Batch 16/300] [D loss: 0.754029] [G loss: 0.793791] time: 0:12:02.767779\n",
      "0.90307164\n",
      "[Epoch 8/50] [Batch 17/300] [D loss: 0.754000] [G loss: 0.773910] time: 0:12:03.081044\n",
      "0.8986942\n",
      "[Epoch 8/50] [Batch 18/300] [D loss: 0.753976] [G loss: 0.789077] time: 0:12:03.374788\n",
      "0.90405726\n",
      "[Epoch 8/50] [Batch 19/300] [D loss: 0.754037] [G loss: 0.784627] time: 0:12:03.689964\n",
      "0.9345994\n",
      "[Epoch 8/50] [Batch 20/300] [D loss: 0.753974] [G loss: 0.775477] time: 0:12:04.000280\n",
      "0.9609396\n",
      "[Epoch 8/50] [Batch 21/300] [D loss: 0.753966] [G loss: 0.807294] time: 0:12:04.294072\n",
      "0.95397276\n",
      "[Epoch 8/50] [Batch 22/300] [D loss: 0.754042] [G loss: 0.700317] time: 0:12:04.583940\n",
      "0.92766047\n",
      "[Epoch 8/50] [Batch 23/300] [D loss: 0.754031] [G loss: 0.831399] time: 0:12:04.875996\n",
      "0.88810843\n",
      "[Epoch 8/50] [Batch 24/300] [D loss: 0.753974] [G loss: 0.737927] time: 0:12:05.172776\n",
      "0.89910316\n",
      "[Epoch 8/50] [Batch 25/300] [D loss: 0.754003] [G loss: 0.805069] time: 0:12:05.482006\n",
      "0.9381824\n",
      "[Epoch 8/50] [Batch 26/300] [D loss: 0.753959] [G loss: 0.695411] time: 0:12:05.773515\n",
      "0.90897125\n",
      "[Epoch 8/50] [Batch 27/300] [D loss: 0.753960] [G loss: 0.757023] time: 0:12:06.075710\n",
      "0.88634974\n",
      "[Epoch 8/50] [Batch 28/300] [D loss: 0.753992] [G loss: 0.648052] time: 0:12:06.370500\n",
      "0.8945825\n",
      "[Epoch 8/50] [Batch 29/300] [D loss: 0.753996] [G loss: 0.842061] time: 0:12:06.673534\n",
      "0.90706426\n",
      "[Epoch 8/50] [Batch 30/300] [D loss: 0.753958] [G loss: 0.740107] time: 0:12:06.970178\n",
      "0.9403393\n",
      "[Epoch 8/50] [Batch 31/300] [D loss: 0.753951] [G loss: 0.699695] time: 0:12:07.272105\n",
      "0.9149134\n",
      "[Epoch 8/50] [Batch 32/300] [D loss: 0.753932] [G loss: 0.649035] time: 0:12:07.545758\n",
      "0.90474194\n",
      "[Epoch 8/50] [Batch 33/300] [D loss: 0.753989] [G loss: 0.782230] time: 0:12:07.837661\n",
      "0.9088616\n",
      "[Epoch 8/50] [Batch 34/300] [D loss: 0.753932] [G loss: 0.666795] time: 0:12:08.164002\n",
      "0.883189\n",
      "[Epoch 8/50] [Batch 35/300] [D loss: 0.753965] [G loss: 0.839401] time: 0:12:08.468516\n",
      "0.9295883\n",
      "[Epoch 8/50] [Batch 36/300] [D loss: 0.753960] [G loss: 0.822032] time: 0:12:08.758979\n",
      "0.9279942\n",
      "[Epoch 8/50] [Batch 37/300] [D loss: 0.753989] [G loss: 0.731670] time: 0:12:09.047660\n",
      "0.9111798\n",
      "[Epoch 8/50] [Batch 38/300] [D loss: 0.753911] [G loss: 0.840470] time: 0:12:09.346696\n",
      "0.95250535\n",
      "[Epoch 8/50] [Batch 39/300] [D loss: 0.754011] [G loss: 0.719495] time: 0:12:09.629107\n",
      "0.9016149\n",
      "[Epoch 8/50] [Batch 40/300] [D loss: 0.753991] [G loss: 0.690224] time: 0:12:09.914756\n",
      "0.9024412\n",
      "[Epoch 8/50] [Batch 41/300] [D loss: 0.753998] [G loss: 0.792622] time: 0:12:10.219283\n",
      "0.90563184\n",
      "[Epoch 8/50] [Batch 42/300] [D loss: 0.753971] [G loss: 0.792716] time: 0:12:10.543587\n",
      "0.92466384\n",
      "[Epoch 8/50] [Batch 43/300] [D loss: 0.753923] [G loss: 0.685269] time: 0:12:10.850716\n",
      "0.8963063\n",
      "[Epoch 8/50] [Batch 44/300] [D loss: 0.753954] [G loss: 0.786397] time: 0:12:11.146555\n",
      "0.9338885\n",
      "[Epoch 8/50] [Batch 45/300] [D loss: 0.753965] [G loss: 0.722454] time: 0:12:11.452321\n",
      "0.92287606\n",
      "[Epoch 8/50] [Batch 46/300] [D loss: 0.753978] [G loss: 0.745955] time: 0:12:11.765586\n",
      "0.92382413\n",
      "[Epoch 8/50] [Batch 47/300] [D loss: 0.754036] [G loss: 0.718456] time: 0:12:12.065093\n",
      "0.9210854\n",
      "[Epoch 8/50] [Batch 48/300] [D loss: 0.753933] [G loss: 0.687388] time: 0:12:12.367065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87843204\n",
      "[Epoch 8/50] [Batch 49/300] [D loss: 0.753975] [G loss: 0.733488] time: 0:12:12.693949\n",
      "0.9726579\n",
      "[Epoch 8/50] [Batch 50/300] [D loss: 0.754045] [G loss: 0.700504] time: 0:12:12.982433\n",
      "0.8890709\n",
      "[Epoch 8/50] [Batch 51/300] [D loss: 0.753945] [G loss: 0.749326] time: 0:12:13.289156\n",
      "0.9538107\n",
      "[Epoch 8/50] [Batch 52/300] [D loss: 0.753971] [G loss: 0.758309] time: 0:12:13.585112\n",
      "0.91063356\n",
      "[Epoch 8/50] [Batch 53/300] [D loss: 0.754018] [G loss: 0.667142] time: 0:12:13.869776\n",
      "0.9493463\n",
      "[Epoch 8/50] [Batch 54/300] [D loss: 0.753956] [G loss: 0.752178] time: 0:12:14.177178\n",
      "0.93208474\n",
      "[Epoch 8/50] [Batch 55/300] [D loss: 0.753965] [G loss: 0.740743] time: 0:12:14.475080\n",
      "0.9135391\n",
      "[Epoch 8/50] [Batch 56/300] [D loss: 0.753965] [G loss: 0.756354] time: 0:12:14.769886\n",
      "0.9387889\n",
      "[Epoch 8/50] [Batch 57/300] [D loss: 0.754031] [G loss: 0.732038] time: 0:12:15.057830\n",
      "0.9690392\n",
      "[Epoch 8/50] [Batch 58/300] [D loss: 0.753996] [G loss: 0.780879] time: 0:12:15.370393\n",
      "0.8597602\n",
      "[Epoch 8/50] [Batch 59/300] [D loss: 0.754001] [G loss: 0.799589] time: 0:12:15.646288\n",
      "0.8996775\n",
      "[Epoch 8/50] [Batch 60/300] [D loss: 0.753967] [G loss: 0.737691] time: 0:12:15.948619\n",
      "0.94850403\n",
      "[Epoch 8/50] [Batch 61/300] [D loss: 0.753939] [G loss: 0.754546] time: 0:12:16.253569\n",
      "0.9215782\n",
      "[Epoch 8/50] [Batch 62/300] [D loss: 0.754018] [G loss: 0.680277] time: 0:12:16.548404\n",
      "0.88601774\n",
      "[Epoch 8/50] [Batch 63/300] [D loss: 0.753918] [G loss: 0.698068] time: 0:12:16.865474\n",
      "0.9187629\n",
      "[Epoch 8/50] [Batch 64/300] [D loss: 0.754028] [G loss: 0.707433] time: 0:12:17.163367\n",
      "0.9034686\n",
      "[Epoch 8/50] [Batch 65/300] [D loss: 0.753949] [G loss: 0.769493] time: 0:12:17.481308\n",
      "0.86698717\n",
      "[Epoch 8/50] [Batch 66/300] [D loss: 0.753961] [G loss: 0.732607] time: 0:12:17.775664\n",
      "0.87353045\n",
      "[Epoch 8/50] [Batch 67/300] [D loss: 0.753923] [G loss: 0.676669] time: 0:12:18.077506\n",
      "0.9060233\n",
      "[Epoch 8/50] [Batch 68/300] [D loss: 0.753984] [G loss: 0.769062] time: 0:12:18.364567\n",
      "0.9138398\n",
      "[Epoch 8/50] [Batch 69/300] [D loss: 0.754014] [G loss: 0.670925] time: 0:12:18.671676\n",
      "0.96353674\n",
      "[Epoch 8/50] [Batch 70/300] [D loss: 0.753924] [G loss: 0.766739] time: 0:12:18.952437\n",
      "0.8787499\n",
      "[Epoch 8/50] [Batch 71/300] [D loss: 0.754024] [G loss: 0.700865] time: 0:12:19.257479\n",
      "0.8951313\n",
      "[Epoch 8/50] [Batch 72/300] [D loss: 0.753910] [G loss: 0.736795] time: 0:12:19.554335\n",
      "0.9536435\n",
      "[Epoch 8/50] [Batch 73/300] [D loss: 0.753996] [G loss: 0.687576] time: 0:12:19.869048\n",
      "0.90850645\n",
      "[Epoch 8/50] [Batch 74/300] [D loss: 0.753992] [G loss: 0.679314] time: 0:12:20.171708\n",
      "0.89722234\n",
      "[Epoch 8/50] [Batch 75/300] [D loss: 0.753913] [G loss: 0.713140] time: 0:12:20.471991\n",
      "0.8923845\n",
      "[Epoch 8/50] [Batch 76/300] [D loss: 0.753939] [G loss: 0.767564] time: 0:12:20.776269\n",
      "0.9176406\n",
      "[Epoch 8/50] [Batch 77/300] [D loss: 0.753961] [G loss: 0.845742] time: 0:12:21.075503\n",
      "0.919748\n",
      "[Epoch 8/50] [Batch 78/300] [D loss: 0.753921] [G loss: 0.769042] time: 0:12:21.383225\n",
      "0.9396934\n",
      "[Epoch 8/50] [Batch 79/300] [D loss: 0.753919] [G loss: 0.745917] time: 0:12:21.684357\n",
      "0.8926594\n",
      "[Epoch 8/50] [Batch 80/300] [D loss: 0.753998] [G loss: 0.646839] time: 0:12:22.007006\n",
      "0.9202764\n",
      "[Epoch 8/50] [Batch 81/300] [D loss: 0.753963] [G loss: 0.756015] time: 0:12:22.318190\n",
      "0.91359335\n",
      "[Epoch 8/50] [Batch 82/300] [D loss: 0.753889] [G loss: 0.841746] time: 0:12:22.616296\n",
      "0.9348648\n",
      "[Epoch 8/50] [Batch 83/300] [D loss: 0.754010] [G loss: 0.782779] time: 0:12:22.915015\n",
      "0.8678749\n",
      "[Epoch 8/50] [Batch 84/300] [D loss: 0.754028] [G loss: 0.765079] time: 0:12:23.200136\n",
      "0.88371444\n",
      "[Epoch 8/50] [Batch 85/300] [D loss: 0.753877] [G loss: 0.778098] time: 0:12:23.501802\n",
      "0.92108995\n",
      "[Epoch 8/50] [Batch 86/300] [D loss: 0.753857] [G loss: 0.823026] time: 0:12:23.802902\n",
      "0.943814\n",
      "[Epoch 8/50] [Batch 87/300] [D loss: 0.753947] [G loss: 0.744780] time: 0:12:24.090708\n",
      "0.92157793\n",
      "[Epoch 8/50] [Batch 88/300] [D loss: 0.753934] [G loss: 0.767919] time: 0:12:24.395851\n",
      "0.957468\n",
      "[Epoch 8/50] [Batch 89/300] [D loss: 0.753912] [G loss: 0.797001] time: 0:12:24.697149\n",
      "0.92809504\n",
      "[Epoch 8/50] [Batch 90/300] [D loss: 0.753902] [G loss: 0.719802] time: 0:12:25.012175\n",
      "0.91351336\n",
      "[Epoch 8/50] [Batch 91/300] [D loss: 0.753970] [G loss: 0.746757] time: 0:12:25.317291\n",
      "0.9199202\n",
      "[Epoch 8/50] [Batch 92/300] [D loss: 0.753916] [G loss: 0.894530] time: 0:12:25.631179\n",
      "0.9050006\n",
      "[Epoch 8/50] [Batch 93/300] [D loss: 0.753891] [G loss: 0.774386] time: 0:12:25.928155\n",
      "0.92679286\n",
      "[Epoch 8/50] [Batch 94/300] [D loss: 0.753914] [G loss: 0.748965] time: 0:12:26.230530\n",
      "0.9475043\n",
      "[Epoch 8/50] [Batch 95/300] [D loss: 0.753968] [G loss: 0.641293] time: 0:12:26.547778\n",
      "0.91449076\n",
      "[Epoch 8/50] [Batch 96/300] [D loss: 0.754001] [G loss: 0.724438] time: 0:12:26.847990\n",
      "0.8911306\n",
      "[Epoch 8/50] [Batch 97/300] [D loss: 0.753971] [G loss: 0.691753] time: 0:12:27.131003\n",
      "0.8832109\n",
      "[Epoch 8/50] [Batch 98/300] [D loss: 0.753990] [G loss: 0.782347] time: 0:12:27.435256\n",
      "0.8989976\n",
      "[Epoch 8/50] [Batch 99/300] [D loss: 0.753962] [G loss: 0.894861] time: 0:12:27.726105\n",
      "0.91479653\n",
      "[Epoch 8/50] [Batch 100/300] [D loss: 0.753869] [G loss: 0.833827] time: 0:12:28.022497\n",
      "0.90427464\n",
      "[Epoch 8/50] [Batch 101/300] [D loss: 0.753927] [G loss: 0.733194] time: 0:12:28.313169\n",
      "0.89800215\n",
      "[Epoch 8/50] [Batch 102/300] [D loss: 0.753935] [G loss: 0.632235] time: 0:12:28.604812\n",
      "0.9674333\n",
      "[Epoch 8/50] [Batch 103/300] [D loss: 0.753900] [G loss: 0.737293] time: 0:12:28.900571\n",
      "0.8844059\n",
      "[Epoch 8/50] [Batch 104/300] [D loss: 0.753869] [G loss: 0.677573] time: 0:12:29.204459\n",
      "0.90565723\n",
      "[Epoch 8/50] [Batch 105/300] [D loss: 0.753913] [G loss: 0.763691] time: 0:12:29.501274\n",
      "0.91719264\n",
      "[Epoch 8/50] [Batch 106/300] [D loss: 0.753899] [G loss: 0.799371] time: 0:12:29.798385\n",
      "0.9468365\n",
      "[Epoch 8/50] [Batch 107/300] [D loss: 0.753981] [G loss: 0.691454] time: 0:12:30.108185\n",
      "0.9125592\n",
      "[Epoch 8/50] [Batch 108/300] [D loss: 0.753878] [G loss: 0.663242] time: 0:12:30.406445\n",
      "0.92050046\n",
      "[Epoch 8/50] [Batch 109/300] [D loss: 0.753920] [G loss: 0.738308] time: 0:12:30.706512\n",
      "0.9262149\n",
      "[Epoch 8/50] [Batch 110/300] [D loss: 0.753837] [G loss: 0.808662] time: 0:12:30.992672\n",
      "0.92809993\n",
      "[Epoch 8/50] [Batch 111/300] [D loss: 0.753886] [G loss: 0.756429] time: 0:12:31.302838\n",
      "0.8841555\n",
      "[Epoch 8/50] [Batch 112/300] [D loss: 0.753886] [G loss: 0.651473] time: 0:12:31.605842\n",
      "0.9239641\n",
      "[Epoch 8/50] [Batch 113/300] [D loss: 0.753911] [G loss: 0.768631] time: 0:12:31.904554\n",
      "0.9204667\n",
      "[Epoch 8/50] [Batch 114/300] [D loss: 0.753837] [G loss: 0.776343] time: 0:12:32.197600\n",
      "0.930007\n",
      "[Epoch 8/50] [Batch 115/300] [D loss: 0.753946] [G loss: 0.763879] time: 0:12:32.510997\n",
      "0.93734884\n",
      "[Epoch 8/50] [Batch 116/300] [D loss: 0.753900] [G loss: 0.798073] time: 0:12:32.806203\n",
      "0.9288723\n",
      "[Epoch 8/50] [Batch 117/300] [D loss: 0.753984] [G loss: 0.754189] time: 0:12:33.116263\n",
      "0.9090697\n",
      "[Epoch 8/50] [Batch 118/300] [D loss: 0.753879] [G loss: 0.754869] time: 0:12:33.438380\n",
      "0.9314781\n",
      "[Epoch 8/50] [Batch 119/300] [D loss: 0.753889] [G loss: 0.727004] time: 0:12:33.743951\n",
      "0.9177957\n",
      "[Epoch 8/50] [Batch 120/300] [D loss: 0.753910] [G loss: 0.718435] time: 0:12:34.051579\n",
      "0.938998\n",
      "[Epoch 8/50] [Batch 121/300] [D loss: 0.753879] [G loss: 0.844953] time: 0:12:34.348714\n",
      "0.9258879\n",
      "[Epoch 8/50] [Batch 122/300] [D loss: 0.753877] [G loss: 0.719727] time: 0:12:34.650849\n",
      "0.95054626\n",
      "[Epoch 8/50] [Batch 123/300] [D loss: 0.753905] [G loss: 0.726577] time: 0:12:34.965644\n",
      "0.9057947\n",
      "[Epoch 8/50] [Batch 124/300] [D loss: 0.753866] [G loss: 0.771413] time: 0:12:35.278488\n",
      "0.8591995\n",
      "[Epoch 8/50] [Batch 125/300] [D loss: 0.753843] [G loss: 0.751660] time: 0:12:35.584460\n",
      "0.92588735\n",
      "[Epoch 8/50] [Batch 126/300] [D loss: 0.753913] [G loss: 0.690322] time: 0:12:35.888352\n",
      "0.96099156\n",
      "[Epoch 8/50] [Batch 127/300] [D loss: 0.753883] [G loss: 0.818856] time: 0:12:36.189202\n",
      "0.9385728\n",
      "[Epoch 8/50] [Batch 128/300] [D loss: 0.753923] [G loss: 0.649729] time: 0:12:36.482781\n",
      "0.920185\n",
      "[Epoch 8/50] [Batch 129/300] [D loss: 0.753935] [G loss: 0.796647] time: 0:12:36.784679\n",
      "0.9259374\n",
      "[Epoch 8/50] [Batch 130/300] [D loss: 0.753838] [G loss: 0.770647] time: 0:12:37.073679\n",
      "0.9124868\n",
      "[Epoch 8/50] [Batch 131/300] [D loss: 0.753876] [G loss: 0.829921] time: 0:12:37.376243\n",
      "0.92436534\n",
      "[Epoch 8/50] [Batch 132/300] [D loss: 0.753918] [G loss: 0.833450] time: 0:12:37.680653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9175175\n",
      "[Epoch 8/50] [Batch 133/300] [D loss: 0.753881] [G loss: 0.792314] time: 0:12:37.992253\n",
      "0.9387305\n",
      "[Epoch 8/50] [Batch 134/300] [D loss: 0.753867] [G loss: 0.760035] time: 0:12:38.294565\n",
      "0.9234819\n",
      "[Epoch 8/50] [Batch 135/300] [D loss: 0.753884] [G loss: 0.771279] time: 0:12:38.596838\n",
      "0.9616594\n",
      "[Epoch 8/50] [Batch 136/300] [D loss: 0.753867] [G loss: 0.765578] time: 0:12:38.907968\n",
      "0.91144055\n",
      "[Epoch 8/50] [Batch 137/300] [D loss: 0.753879] [G loss: 0.714932] time: 0:12:39.232622\n",
      "0.9295972\n",
      "[Epoch 8/50] [Batch 138/300] [D loss: 0.753926] [G loss: 0.708696] time: 0:12:39.559861\n",
      "0.94469315\n",
      "[Epoch 8/50] [Batch 139/300] [D loss: 0.753824] [G loss: 0.764649] time: 0:12:39.852422\n",
      "0.9254671\n",
      "[Epoch 8/50] [Batch 140/300] [D loss: 0.753961] [G loss: 0.778515] time: 0:12:40.137844\n",
      "0.9366052\n",
      "[Epoch 8/50] [Batch 141/300] [D loss: 0.753820] [G loss: 0.753113] time: 0:12:40.445127\n",
      "0.9039607\n",
      "[Epoch 8/50] [Batch 142/300] [D loss: 0.753872] [G loss: 0.655260] time: 0:12:40.761788\n",
      "0.87129647\n",
      "[Epoch 8/50] [Batch 143/300] [D loss: 0.753838] [G loss: 0.785555] time: 0:12:41.072395\n",
      "0.90927243\n",
      "[Epoch 8/50] [Batch 144/300] [D loss: 0.753843] [G loss: 0.862256] time: 0:12:41.374401\n",
      "0.91841394\n",
      "[Epoch 8/50] [Batch 145/300] [D loss: 0.753872] [G loss: 0.624578] time: 0:12:41.681166\n",
      "0.9506178\n",
      "[Epoch 8/50] [Batch 146/300] [D loss: 0.753874] [G loss: 0.770038] time: 0:12:41.998615\n",
      "0.91407114\n",
      "[Epoch 8/50] [Batch 147/300] [D loss: 0.753790] [G loss: 0.736303] time: 0:12:42.285947\n",
      "0.9557448\n",
      "[Epoch 8/50] [Batch 148/300] [D loss: 0.753836] [G loss: 0.844811] time: 0:12:42.579064\n",
      "0.9219888\n",
      "[Epoch 8/50] [Batch 149/300] [D loss: 0.753881] [G loss: 0.723109] time: 0:12:42.885979\n",
      "0.9462854\n",
      "[Epoch 8/50] [Batch 150/300] [D loss: 0.753930] [G loss: 0.756901] time: 0:12:43.178338\n",
      "0.87552196\n",
      "[Epoch 8/50] [Batch 151/300] [D loss: 0.753952] [G loss: 0.679312] time: 0:12:43.476463\n",
      "0.9172798\n",
      "[Epoch 8/50] [Batch 152/300] [D loss: 0.753826] [G loss: 0.786542] time: 0:12:43.781094\n",
      "0.899393\n",
      "[Epoch 8/50] [Batch 153/300] [D loss: 0.753779] [G loss: 0.850533] time: 0:12:44.086004\n",
      "0.90480953\n",
      "[Epoch 8/50] [Batch 154/300] [D loss: 0.753893] [G loss: 0.668311] time: 0:12:44.379784\n",
      "0.94469523\n",
      "[Epoch 8/50] [Batch 155/300] [D loss: 0.753767] [G loss: 0.781130] time: 0:12:44.676685\n",
      "0.90221214\n",
      "[Epoch 8/50] [Batch 156/300] [D loss: 0.753888] [G loss: 0.776191] time: 0:12:44.975337\n",
      "0.9226069\n",
      "[Epoch 8/50] [Batch 157/300] [D loss: 0.753908] [G loss: 0.678511] time: 0:12:45.291232\n",
      "0.9018621\n",
      "[Epoch 8/50] [Batch 158/300] [D loss: 0.753919] [G loss: 0.767127] time: 0:12:45.595112\n",
      "0.88770443\n",
      "[Epoch 8/50] [Batch 159/300] [D loss: 0.753919] [G loss: 0.752186] time: 0:12:45.904175\n",
      "0.87204164\n",
      "[Epoch 8/50] [Batch 160/300] [D loss: 0.753823] [G loss: 0.844436] time: 0:12:46.209831\n",
      "0.911172\n",
      "[Epoch 8/50] [Batch 161/300] [D loss: 0.753839] [G loss: 0.812785] time: 0:12:46.538335\n",
      "0.90374094\n",
      "[Epoch 8/50] [Batch 162/300] [D loss: 0.753928] [G loss: 0.655202] time: 0:12:46.848128\n",
      "0.91898483\n",
      "[Epoch 8/50] [Batch 163/300] [D loss: 0.753825] [G loss: 0.736185] time: 0:12:47.147950\n",
      "0.86863375\n",
      "[Epoch 8/50] [Batch 164/300] [D loss: 0.753840] [G loss: 0.748863] time: 0:12:47.450314\n",
      "0.93282866\n",
      "[Epoch 8/50] [Batch 165/300] [D loss: 0.753824] [G loss: 0.696058] time: 0:12:47.762020\n",
      "0.9434077\n",
      "[Epoch 8/50] [Batch 166/300] [D loss: 0.753852] [G loss: 0.797692] time: 0:12:48.071133\n",
      "0.9382801\n",
      "[Epoch 8/50] [Batch 167/300] [D loss: 0.753862] [G loss: 0.705118] time: 0:12:48.357597\n",
      "0.8672645\n",
      "[Epoch 8/50] [Batch 168/300] [D loss: 0.753883] [G loss: 0.799536] time: 0:12:48.661158\n",
      "0.8713121\n",
      "[Epoch 8/50] [Batch 169/300] [D loss: 0.753857] [G loss: 0.668199] time: 0:12:48.948314\n",
      "0.90956503\n",
      "[Epoch 8/50] [Batch 170/300] [D loss: 0.753871] [G loss: 0.890521] time: 0:12:49.259270\n",
      "0.8904993\n",
      "[Epoch 8/50] [Batch 171/300] [D loss: 0.753833] [G loss: 0.657019] time: 0:12:49.569754\n",
      "0.9373084\n",
      "[Epoch 8/50] [Batch 172/300] [D loss: 0.753744] [G loss: 0.701985] time: 0:12:49.879683\n",
      "0.87341124\n",
      "[Epoch 8/50] [Batch 173/300] [D loss: 0.753848] [G loss: 0.810764] time: 0:12:50.183899\n",
      "0.9270455\n",
      "[Epoch 8/50] [Batch 174/300] [D loss: 0.753894] [G loss: 0.651218] time: 0:12:50.484162\n",
      "0.95988756\n",
      "[Epoch 8/50] [Batch 175/300] [D loss: 0.753854] [G loss: 0.779361] time: 0:12:50.796542\n",
      "0.92785454\n",
      "[Epoch 8/50] [Batch 176/300] [D loss: 0.753836] [G loss: 0.647614] time: 0:12:51.095884\n",
      "0.90796226\n",
      "[Epoch 8/50] [Batch 177/300] [D loss: 0.753812] [G loss: 0.712037] time: 0:12:51.394076\n",
      "0.9211812\n",
      "[Epoch 8/50] [Batch 178/300] [D loss: 0.753777] [G loss: 0.832106] time: 0:12:51.702188\n",
      "0.93450814\n",
      "[Epoch 8/50] [Batch 179/300] [D loss: 0.753842] [G loss: 0.649647] time: 0:12:52.024731\n",
      "0.92446524\n",
      "[Epoch 8/50] [Batch 180/300] [D loss: 0.753866] [G loss: 0.716765] time: 0:12:52.334014\n",
      "0.9057961\n",
      "[Epoch 8/50] [Batch 181/300] [D loss: 0.753830] [G loss: 0.794962] time: 0:12:52.633979\n",
      "0.9535137\n",
      "[Epoch 8/50] [Batch 182/300] [D loss: 0.753732] [G loss: 0.767981] time: 0:12:52.945176\n",
      "0.8921864\n",
      "[Epoch 8/50] [Batch 183/300] [D loss: 0.753808] [G loss: 0.750780] time: 0:12:53.248213\n",
      "0.91918325\n",
      "[Epoch 8/50] [Batch 184/300] [D loss: 0.753878] [G loss: 0.762909] time: 0:12:53.572300\n",
      "0.93391395\n",
      "[Epoch 8/50] [Batch 185/300] [D loss: 0.753934] [G loss: 0.720111] time: 0:12:53.868369\n",
      "0.9172471\n",
      "[Epoch 8/50] [Batch 186/300] [D loss: 0.753899] [G loss: 0.704853] time: 0:12:54.169970\n",
      "0.91522986\n",
      "[Epoch 8/50] [Batch 187/300] [D loss: 0.753804] [G loss: 0.813077] time: 0:12:54.464651\n",
      "0.86686784\n",
      "[Epoch 8/50] [Batch 188/300] [D loss: 0.753847] [G loss: 0.716696] time: 0:12:54.764120\n",
      "0.91798997\n",
      "[Epoch 8/50] [Batch 189/300] [D loss: 0.753866] [G loss: 0.682024] time: 0:12:55.040289\n",
      "0.9220524\n",
      "[Epoch 8/50] [Batch 190/300] [D loss: 0.753935] [G loss: 0.711131] time: 0:12:55.321537\n",
      "0.93608636\n",
      "[Epoch 8/50] [Batch 191/300] [D loss: 0.753868] [G loss: 0.804133] time: 0:12:55.640145\n",
      "0.8725068\n",
      "[Epoch 8/50] [Batch 192/300] [D loss: 0.753822] [G loss: 0.766112] time: 0:12:55.939181\n",
      "0.97245455\n",
      "[Epoch 8/50] [Batch 193/300] [D loss: 0.753905] [G loss: 0.724001] time: 0:12:56.381806\n",
      "0.9239872\n",
      "[Epoch 8/50] [Batch 194/300] [D loss: 0.753831] [G loss: 0.680884] time: 0:12:56.698857\n",
      "0.95113325\n",
      "[Epoch 8/50] [Batch 195/300] [D loss: 0.753825] [G loss: 0.707598] time: 0:12:56.995268\n",
      "0.9132445\n",
      "[Epoch 8/50] [Batch 196/300] [D loss: 0.753794] [G loss: 0.764289] time: 0:12:57.287952\n",
      "0.9089675\n",
      "[Epoch 8/50] [Batch 197/300] [D loss: 0.753756] [G loss: 0.767934] time: 0:12:57.593469\n",
      "0.94711924\n",
      "[Epoch 8/50] [Batch 198/300] [D loss: 0.753849] [G loss: 0.821967] time: 0:12:57.878180\n",
      "0.9391775\n",
      "[Epoch 8/50] [Batch 199/300] [D loss: 0.753791] [G loss: 0.722774] time: 0:12:58.170835\n",
      "0.91038775\n",
      "[Epoch 8/50] [Batch 200/300] [D loss: 0.753859] [G loss: 0.710922] time: 0:12:58.466839\n",
      "0.8721559\n",
      "[Epoch 8/50] [Batch 201/300] [D loss: 0.753865] [G loss: 0.857185] time: 0:12:58.758857\n",
      "0.94103545\n",
      "[Epoch 8/50] [Batch 202/300] [D loss: 0.753830] [G loss: 0.730222] time: 0:12:59.063911\n",
      "0.92952913\n",
      "[Epoch 8/50] [Batch 203/300] [D loss: 0.753705] [G loss: 0.724940] time: 0:12:59.367984\n",
      "0.9383798\n",
      "[Epoch 8/50] [Batch 204/300] [D loss: 0.753879] [G loss: 0.764446] time: 0:12:59.683067\n",
      "0.89517456\n",
      "[Epoch 8/50] [Batch 205/300] [D loss: 0.753892] [G loss: 0.662840] time: 0:12:59.973045\n",
      "0.9084043\n",
      "[Epoch 8/50] [Batch 206/300] [D loss: 0.753886] [G loss: 0.837656] time: 0:13:00.284509\n",
      "0.91789204\n",
      "[Epoch 8/50] [Batch 207/300] [D loss: 0.753814] [G loss: 0.821185] time: 0:13:00.577674\n",
      "0.923944\n",
      "[Epoch 8/50] [Batch 208/300] [D loss: 0.753842] [G loss: 0.640190] time: 0:13:00.881291\n",
      "0.8791807\n",
      "[Epoch 8/50] [Batch 209/300] [D loss: 0.753822] [G loss: 0.664806] time: 0:13:01.180702\n",
      "0.9035466\n",
      "[Epoch 8/50] [Batch 210/300] [D loss: 0.753814] [G loss: 0.734244] time: 0:13:01.503220\n",
      "0.94063073\n",
      "[Epoch 8/50] [Batch 211/300] [D loss: 0.753870] [G loss: 0.705428] time: 0:13:01.801873\n",
      "0.92540926\n",
      "[Epoch 8/50] [Batch 212/300] [D loss: 0.753825] [G loss: 0.675544] time: 0:13:02.108002\n",
      "0.9801972\n",
      "[Epoch 8/50] [Batch 213/300] [D loss: 0.753796] [G loss: 0.722068] time: 0:13:02.398660\n",
      "0.9140466\n",
      "[Epoch 8/50] [Batch 214/300] [D loss: 0.753762] [G loss: 0.718658] time: 0:13:02.691508\n",
      "0.9562678\n",
      "[Epoch 8/50] [Batch 215/300] [D loss: 0.753851] [G loss: 0.698907] time: 0:13:02.993596\n",
      "0.8671198\n",
      "[Epoch 8/50] [Batch 216/300] [D loss: 0.753778] [G loss: 0.910802] time: 0:13:03.290615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177074\n",
      "[Epoch 8/50] [Batch 217/300] [D loss: 0.753770] [G loss: 0.792011] time: 0:13:03.580282\n",
      "0.8936939\n",
      "[Epoch 8/50] [Batch 218/300] [D loss: 0.753827] [G loss: 0.712659] time: 0:13:03.886939\n",
      "0.9559352\n",
      "[Epoch 8/50] [Batch 219/300] [D loss: 0.753820] [G loss: 0.721632] time: 0:13:04.187195\n",
      "0.8843541\n",
      "[Epoch 8/50] [Batch 220/300] [D loss: 0.753839] [G loss: 0.669228] time: 0:13:04.479673\n",
      "0.8862901\n",
      "[Epoch 8/50] [Batch 221/300] [D loss: 0.753801] [G loss: 0.675719] time: 0:13:04.785479\n",
      "0.957225\n",
      "[Epoch 8/50] [Batch 222/300] [D loss: 0.753800] [G loss: 0.683868] time: 0:13:05.095464\n",
      "0.87307835\n",
      "[Epoch 8/50] [Batch 223/300] [D loss: 0.753832] [G loss: 0.811541] time: 0:13:05.403329\n",
      "0.8857544\n",
      "[Epoch 8/50] [Batch 224/300] [D loss: 0.753823] [G loss: 0.684970] time: 0:13:05.695695\n",
      "0.9155833\n",
      "[Epoch 8/50] [Batch 225/300] [D loss: 0.753786] [G loss: 0.835307] time: 0:13:05.987903\n",
      "0.90538263\n",
      "[Epoch 8/50] [Batch 226/300] [D loss: 0.753744] [G loss: 0.681037] time: 0:13:06.276027\n",
      "0.8978791\n",
      "[Epoch 8/50] [Batch 227/300] [D loss: 0.753759] [G loss: 0.820040] time: 0:13:06.587500\n",
      "0.9167034\n",
      "[Epoch 8/50] [Batch 228/300] [D loss: 0.753822] [G loss: 0.754826] time: 0:13:06.885092\n",
      "0.8984727\n",
      "[Epoch 8/50] [Batch 229/300] [D loss: 0.753752] [G loss: 0.801607] time: 0:13:07.183936\n",
      "0.85931605\n",
      "[Epoch 8/50] [Batch 230/300] [D loss: 0.753829] [G loss: 0.666468] time: 0:13:07.482825\n",
      "0.9001003\n",
      "[Epoch 8/50] [Batch 231/300] [D loss: 0.753793] [G loss: 0.742061] time: 0:13:07.787632\n",
      "0.8849936\n",
      "[Epoch 8/50] [Batch 232/300] [D loss: 0.753801] [G loss: 0.792961] time: 0:13:08.089684\n",
      "0.9195861\n",
      "[Epoch 8/50] [Batch 233/300] [D loss: 0.753759] [G loss: 0.750426] time: 0:13:08.392950\n",
      "0.8877392\n",
      "[Epoch 8/50] [Batch 234/300] [D loss: 0.753800] [G loss: 0.709141] time: 0:13:08.702494\n",
      "0.9198739\n",
      "[Epoch 8/50] [Batch 235/300] [D loss: 0.753764] [G loss: 0.809418] time: 0:13:08.997454\n",
      "0.93354493\n",
      "[Epoch 8/50] [Batch 236/300] [D loss: 0.753879] [G loss: 0.757294] time: 0:13:09.284720\n",
      "0.8868623\n",
      "[Epoch 8/50] [Batch 237/300] [D loss: 0.753796] [G loss: 0.860422] time: 0:13:09.580802\n",
      "0.9739352\n",
      "[Epoch 8/50] [Batch 238/300] [D loss: 0.753781] [G loss: 0.862621] time: 0:13:09.884265\n",
      "0.9213001\n",
      "[Epoch 8/50] [Batch 239/300] [D loss: 0.753803] [G loss: 0.658219] time: 0:13:10.177951\n",
      "0.89304036\n",
      "[Epoch 8/50] [Batch 240/300] [D loss: 0.753815] [G loss: 0.740398] time: 0:13:10.458309\n",
      "0.9324434\n",
      "[Epoch 8/50] [Batch 241/300] [D loss: 0.753793] [G loss: 0.719960] time: 0:13:10.768210\n",
      "0.9459245\n",
      "[Epoch 8/50] [Batch 242/300] [D loss: 0.753780] [G loss: 0.685175] time: 0:13:11.086008\n",
      "0.87955946\n",
      "[Epoch 8/50] [Batch 243/300] [D loss: 0.753744] [G loss: 0.697254] time: 0:13:11.382592\n",
      "0.91392654\n",
      "[Epoch 8/50] [Batch 244/300] [D loss: 0.753823] [G loss: 0.762109] time: 0:13:11.683130\n",
      "0.91138226\n",
      "[Epoch 8/50] [Batch 245/300] [D loss: 0.753798] [G loss: 0.694495] time: 0:13:11.984063\n",
      "0.9221411\n",
      "[Epoch 8/50] [Batch 246/300] [D loss: 0.753768] [G loss: 0.721476] time: 0:13:12.283941\n",
      "0.947573\n",
      "[Epoch 8/50] [Batch 247/300] [D loss: 0.753832] [G loss: 0.890739] time: 0:13:12.593368\n",
      "0.9516845\n",
      "[Epoch 8/50] [Batch 248/300] [D loss: 0.753808] [G loss: 0.799651] time: 0:13:12.894182\n",
      "0.91490054\n",
      "[Epoch 8/50] [Batch 249/300] [D loss: 0.753758] [G loss: 0.783083] time: 0:13:13.197633\n",
      "0.9032909\n",
      "[Epoch 8/50] [Batch 250/300] [D loss: 0.753747] [G loss: 0.800182] time: 0:13:13.484598\n",
      "0.878666\n",
      "[Epoch 8/50] [Batch 251/300] [D loss: 0.753760] [G loss: 0.729121] time: 0:13:13.764910\n",
      "0.8952392\n",
      "[Epoch 8/50] [Batch 252/300] [D loss: 0.753761] [G loss: 0.664836] time: 0:13:14.056603\n",
      "0.94672376\n",
      "[Epoch 8/50] [Batch 253/300] [D loss: 0.753767] [G loss: 0.753928] time: 0:13:14.354964\n",
      "0.8759369\n",
      "[Epoch 8/50] [Batch 254/300] [D loss: 0.753767] [G loss: 0.684373] time: 0:13:14.654785\n",
      "0.90875316\n",
      "[Epoch 8/50] [Batch 255/300] [D loss: 0.753900] [G loss: 0.703091] time: 0:13:14.944084\n",
      "0.88416195\n",
      "[Epoch 8/50] [Batch 256/300] [D loss: 0.753787] [G loss: 0.730968] time: 0:13:15.259739\n",
      "0.90913844\n",
      "[Epoch 8/50] [Batch 257/300] [D loss: 0.753764] [G loss: 0.771483] time: 0:13:15.568036\n",
      "0.88721675\n",
      "[Epoch 8/50] [Batch 258/300] [D loss: 0.753821] [G loss: 0.674589] time: 0:13:15.873564\n",
      "0.9124144\n",
      "[Epoch 8/50] [Batch 259/300] [D loss: 0.753765] [G loss: 0.726448] time: 0:13:16.174504\n",
      "0.92538923\n",
      "[Epoch 8/50] [Batch 260/300] [D loss: 0.753787] [G loss: 0.779390] time: 0:13:16.469801\n",
      "0.93549854\n",
      "[Epoch 8/50] [Batch 261/300] [D loss: 0.753790] [G loss: 0.819420] time: 0:13:16.763756\n",
      "0.9023917\n",
      "[Epoch 8/50] [Batch 262/300] [D loss: 0.753827] [G loss: 0.692760] time: 0:13:17.064054\n",
      "0.9167375\n",
      "[Epoch 8/50] [Batch 263/300] [D loss: 0.753789] [G loss: 0.696458] time: 0:13:17.360358\n",
      "0.95328635\n",
      "[Epoch 8/50] [Batch 264/300] [D loss: 0.753805] [G loss: 0.803717] time: 0:13:17.676953\n",
      "0.89102936\n",
      "[Epoch 8/50] [Batch 265/300] [D loss: 0.753713] [G loss: 0.792805] time: 0:13:17.975734\n",
      "0.8999134\n",
      "[Epoch 8/50] [Batch 266/300] [D loss: 0.753772] [G loss: 0.762391] time: 0:13:18.254738\n",
      "0.9284913\n",
      "[Epoch 8/50] [Batch 267/300] [D loss: 0.753771] [G loss: 0.758983] time: 0:13:18.558154\n",
      "0.93428487\n",
      "[Epoch 8/50] [Batch 268/300] [D loss: 0.753797] [G loss: 0.798021] time: 0:13:18.846656\n",
      "0.93580794\n",
      "[Epoch 8/50] [Batch 269/300] [D loss: 0.753833] [G loss: 0.752875] time: 0:13:19.151274\n",
      "0.9097777\n",
      "[Epoch 8/50] [Batch 270/300] [D loss: 0.753807] [G loss: 0.672379] time: 0:13:19.453103\n",
      "0.8875122\n",
      "[Epoch 8/50] [Batch 271/300] [D loss: 0.753836] [G loss: 0.677541] time: 0:13:19.764248\n",
      "0.93382627\n",
      "[Epoch 8/50] [Batch 272/300] [D loss: 0.753785] [G loss: 0.803281] time: 0:13:20.071696\n",
      "0.9220045\n",
      "[Epoch 8/50] [Batch 273/300] [D loss: 0.753797] [G loss: 0.618381] time: 0:13:20.374112\n",
      "0.95214146\n",
      "[Epoch 8/50] [Batch 274/300] [D loss: 0.753729] [G loss: 0.720381] time: 0:13:20.685393\n",
      "0.9266992\n",
      "[Epoch 8/50] [Batch 275/300] [D loss: 0.753785] [G loss: 0.698578] time: 0:13:20.984561\n",
      "0.8852914\n",
      "[Epoch 8/50] [Batch 276/300] [D loss: 0.753721] [G loss: 0.761012] time: 0:13:21.281155\n",
      "0.93981487\n",
      "[Epoch 8/50] [Batch 277/300] [D loss: 0.753802] [G loss: 0.735198] time: 0:13:21.574785\n",
      "0.91451645\n",
      "[Epoch 8/50] [Batch 278/300] [D loss: 0.753795] [G loss: 0.697219] time: 0:13:21.873281\n",
      "0.91375923\n",
      "[Epoch 8/50] [Batch 279/300] [D loss: 0.753797] [G loss: 0.684787] time: 0:13:22.152661\n",
      "0.9366638\n",
      "[Epoch 8/50] [Batch 280/300] [D loss: 0.753788] [G loss: 0.793993] time: 0:13:22.458268\n",
      "0.9397366\n",
      "[Epoch 8/50] [Batch 281/300] [D loss: 0.753787] [G loss: 0.783521] time: 0:13:22.776063\n",
      "0.94908065\n",
      "[Epoch 8/50] [Batch 282/300] [D loss: 0.753791] [G loss: 0.798548] time: 0:13:23.087533\n",
      "0.92450756\n",
      "[Epoch 8/50] [Batch 283/300] [D loss: 0.753681] [G loss: 0.744596] time: 0:13:23.382905\n",
      "0.9553437\n",
      "[Epoch 8/50] [Batch 284/300] [D loss: 0.753789] [G loss: 0.652470] time: 0:13:23.665081\n",
      "0.9058817\n",
      "[Epoch 8/50] [Batch 285/300] [D loss: 0.753712] [G loss: 0.803374] time: 0:13:23.963554\n",
      "0.9035247\n",
      "[Epoch 8/50] [Batch 286/300] [D loss: 0.753750] [G loss: 0.683733] time: 0:13:24.282649\n",
      "0.9383821\n",
      "[Epoch 8/50] [Batch 287/300] [D loss: 0.753776] [G loss: 0.637110] time: 0:13:24.578576\n",
      "0.91792345\n",
      "[Epoch 8/50] [Batch 288/300] [D loss: 0.753704] [G loss: 0.758097] time: 0:13:24.899384\n",
      "0.87741154\n",
      "[Epoch 8/50] [Batch 289/300] [D loss: 0.753806] [G loss: 0.668915] time: 0:13:25.190378\n",
      "0.8498995\n",
      "[Epoch 8/50] [Batch 290/300] [D loss: 0.753749] [G loss: 0.776267] time: 0:13:25.495344\n",
      "0.9842283\n",
      "[Epoch 8/50] [Batch 291/300] [D loss: 0.753732] [G loss: 0.723803] time: 0:13:25.797257\n",
      "0.9579234\n",
      "[Epoch 8/50] [Batch 292/300] [D loss: 0.753803] [G loss: 0.757215] time: 0:13:26.101068\n",
      "0.9188292\n",
      "[Epoch 8/50] [Batch 293/300] [D loss: 0.753767] [G loss: 0.672647] time: 0:13:26.400474\n",
      "0.947625\n",
      "[Epoch 8/50] [Batch 294/300] [D loss: 0.753822] [G loss: 0.806195] time: 0:13:26.695549\n",
      "0.9598085\n",
      "[Epoch 8/50] [Batch 295/300] [D loss: 0.753730] [G loss: 0.710911] time: 0:13:26.998525\n",
      "0.968254\n",
      "[Epoch 8/50] [Batch 296/300] [D loss: 0.753728] [G loss: 0.709801] time: 0:13:27.305436\n",
      "0.9106181\n",
      "[Epoch 8/50] [Batch 297/300] [D loss: 0.753704] [G loss: 0.766321] time: 0:13:27.612227\n",
      "0.9037574\n",
      "[Epoch 8/50] [Batch 298/300] [D loss: 0.753860] [G loss: 0.683921] time: 0:13:27.914509\n",
      "0.92521405\n",
      "[Epoch 8/50] [Batch 299/300] [D loss: 0.753802] [G loss: 0.730791] time: 0:13:28.206209\n",
      "0.9302524\n",
      "[Epoch 9/50] [Batch 0/300] [D loss: 0.753699] [G loss: 0.669887] time: 0:13:28.507980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95096\n",
      "[Epoch 9/50] [Batch 1/300] [D loss: 0.753681] [G loss: 0.716119] time: 0:13:28.813432\n",
      "0.9287532\n",
      "[Epoch 9/50] [Batch 2/300] [D loss: 0.753761] [G loss: 0.661492] time: 0:13:29.121195\n",
      "0.86711866\n",
      "[Epoch 9/50] [Batch 3/300] [D loss: 0.753771] [G loss: 0.691017] time: 0:13:29.427933\n",
      "0.92546296\n",
      "[Epoch 9/50] [Batch 4/300] [D loss: 0.753746] [G loss: 0.740481] time: 0:13:29.723976\n",
      "0.8749477\n",
      "[Epoch 9/50] [Batch 5/300] [D loss: 0.753806] [G loss: 0.709421] time: 0:13:30.020873\n",
      "0.8944467\n",
      "[Epoch 9/50] [Batch 6/300] [D loss: 0.753754] [G loss: 0.652980] time: 0:13:30.323986\n",
      "0.91672546\n",
      "[Epoch 9/50] [Batch 7/300] [D loss: 0.753682] [G loss: 0.754331] time: 0:13:30.652637\n",
      "0.880944\n",
      "[Epoch 9/50] [Batch 9/300] [D loss: 0.753773] [G loss: 0.681962] time: 0:13:30.957675\n",
      "0.88695496\n",
      "[Epoch 9/50] [Batch 10/300] [D loss: 0.753783] [G loss: 0.718892] time: 0:13:31.267403\n",
      "0.8692782\n",
      "[Epoch 9/50] [Batch 11/300] [D loss: 0.753748] [G loss: 0.742529] time: 0:13:31.557868\n",
      "0.98113984\n",
      "[Epoch 9/50] [Batch 12/300] [D loss: 0.753762] [G loss: 0.718082] time: 0:13:31.863184\n",
      "0.9503401\n",
      "[Epoch 9/50] [Batch 13/300] [D loss: 0.753811] [G loss: 0.673215] time: 0:13:32.136205\n",
      "0.8826094\n",
      "[Epoch 9/50] [Batch 14/300] [D loss: 0.753745] [G loss: 0.622508] time: 0:13:32.452337\n",
      "0.8964019\n",
      "[Epoch 9/50] [Batch 15/300] [D loss: 0.753717] [G loss: 0.736579] time: 0:13:32.762312\n",
      "0.94278556\n",
      "[Epoch 9/50] [Batch 16/300] [D loss: 0.753712] [G loss: 0.585294] time: 0:13:33.065582\n",
      "0.94907933\n",
      "[Epoch 9/50] [Batch 17/300] [D loss: 0.753719] [G loss: 0.828596] time: 0:13:33.372675\n",
      "0.88887167\n",
      "[Epoch 9/50] [Batch 18/300] [D loss: 0.753710] [G loss: 0.723330] time: 0:13:33.668037\n",
      "0.9380489\n",
      "[Epoch 9/50] [Batch 19/300] [D loss: 0.753725] [G loss: 0.733210] time: 0:13:33.963998\n",
      "0.90162134\n",
      "[Epoch 9/50] [Batch 20/300] [D loss: 0.753762] [G loss: 0.737360] time: 0:13:34.258182\n",
      "0.9735392\n",
      "[Epoch 9/50] [Batch 21/300] [D loss: 0.753755] [G loss: 0.656150] time: 0:13:34.560732\n",
      "0.90729356\n",
      "[Epoch 9/50] [Batch 22/300] [D loss: 0.753768] [G loss: 0.759800] time: 0:13:34.846190\n",
      "0.96524125\n",
      "[Epoch 9/50] [Batch 23/300] [D loss: 0.753707] [G loss: 0.711601] time: 0:13:35.151050\n",
      "0.91791075\n",
      "[Epoch 9/50] [Batch 24/300] [D loss: 0.753691] [G loss: 0.703473] time: 0:13:35.448900\n",
      "0.95404404\n",
      "[Epoch 9/50] [Batch 25/300] [D loss: 0.753634] [G loss: 0.668654] time: 0:13:35.756146\n",
      "0.90221673\n",
      "[Epoch 9/50] [Batch 26/300] [D loss: 0.753722] [G loss: 0.674184] time: 0:13:36.049053\n",
      "0.92979187\n",
      "[Epoch 9/50] [Batch 27/300] [D loss: 0.753783] [G loss: 0.718736] time: 0:13:36.340315\n",
      "0.8967436\n",
      "[Epoch 9/50] [Batch 28/300] [D loss: 0.753720] [G loss: 0.778928] time: 0:13:36.641078\n",
      "0.8926762\n",
      "[Epoch 9/50] [Batch 29/300] [D loss: 0.753728] [G loss: 0.689491] time: 0:13:36.944603\n",
      "0.9064107\n",
      "[Epoch 9/50] [Batch 30/300] [D loss: 0.753673] [G loss: 0.734030] time: 0:13:37.255147\n",
      "0.9192362\n",
      "[Epoch 9/50] [Batch 31/300] [D loss: 0.753725] [G loss: 0.748247] time: 0:13:37.556270\n",
      "0.93729496\n",
      "[Epoch 9/50] [Batch 32/300] [D loss: 0.753723] [G loss: 0.740228] time: 0:13:37.853369\n",
      "0.9211306\n",
      "[Epoch 9/50] [Batch 33/300] [D loss: 0.753684] [G loss: 0.776478] time: 0:13:38.150311\n",
      "0.941324\n",
      "[Epoch 9/50] [Batch 34/300] [D loss: 0.753786] [G loss: 0.688270] time: 0:13:38.449288\n",
      "0.9354809\n",
      "[Epoch 9/50] [Batch 35/300] [D loss: 0.753686] [G loss: 0.671221] time: 0:13:38.739060\n",
      "0.95927715\n",
      "[Epoch 9/50] [Batch 36/300] [D loss: 0.753677] [G loss: 0.673925] time: 0:13:39.020376\n",
      "0.94967204\n",
      "[Epoch 9/50] [Batch 37/300] [D loss: 0.753759] [G loss: 0.781833] time: 0:13:39.317805\n",
      "0.9240673\n",
      "[Epoch 9/50] [Batch 38/300] [D loss: 0.753673] [G loss: 0.676582] time: 0:13:39.618464\n",
      "0.92596513\n",
      "[Epoch 9/50] [Batch 39/300] [D loss: 0.753773] [G loss: 0.680386] time: 0:13:39.918116\n",
      "0.9327197\n",
      "[Epoch 9/50] [Batch 40/300] [D loss: 0.753676] [G loss: 0.675432] time: 0:13:40.206072\n",
      "0.91498685\n",
      "[Epoch 9/50] [Batch 41/300] [D loss: 0.753725] [G loss: 0.726209] time: 0:13:40.492808\n",
      "0.8870279\n",
      "[Epoch 9/50] [Batch 42/300] [D loss: 0.753711] [G loss: 0.687617] time: 0:13:40.795759\n",
      "0.95641977\n",
      "[Epoch 9/50] [Batch 43/300] [D loss: 0.753669] [G loss: 0.727323] time: 0:13:41.109170\n",
      "0.883663\n",
      "[Epoch 9/50] [Batch 44/300] [D loss: 0.753701] [G loss: 0.720100] time: 0:13:41.410947\n",
      "0.92415595\n",
      "[Epoch 9/50] [Batch 45/300] [D loss: 0.753707] [G loss: 0.743690] time: 0:13:41.717074\n",
      "0.95601326\n",
      "[Epoch 9/50] [Batch 46/300] [D loss: 0.753676] [G loss: 0.820151] time: 0:13:41.998498\n",
      "0.90790933\n",
      "[Epoch 9/50] [Batch 47/300] [D loss: 0.753677] [G loss: 0.796644] time: 0:13:42.299836\n",
      "0.9323086\n",
      "[Epoch 9/50] [Batch 48/300] [D loss: 0.753714] [G loss: 0.635780] time: 0:13:42.607873\n",
      "0.91036004\n",
      "[Epoch 9/50] [Batch 49/300] [D loss: 0.753683] [G loss: 0.781036] time: 0:13:42.909017\n",
      "0.9017956\n",
      "[Epoch 9/50] [Batch 50/300] [D loss: 0.753731] [G loss: 0.730580] time: 0:13:43.210850\n",
      "0.9594775\n",
      "[Epoch 9/50] [Batch 51/300] [D loss: 0.753730] [G loss: 0.690080] time: 0:13:43.504184\n",
      "0.9124182\n",
      "[Epoch 9/50] [Batch 52/300] [D loss: 0.753793] [G loss: 0.667470] time: 0:13:43.806410\n",
      "0.8797663\n",
      "[Epoch 9/50] [Batch 53/300] [D loss: 0.753710] [G loss: 0.766139] time: 0:13:44.106973\n",
      "0.86593705\n",
      "[Epoch 9/50] [Batch 54/300] [D loss: 0.753666] [G loss: 0.761189] time: 0:13:44.405030\n",
      "0.9817012\n",
      "[Epoch 9/50] [Batch 55/300] [D loss: 0.753705] [G loss: 0.842543] time: 0:13:44.695471\n",
      "0.94880515\n",
      "[Epoch 9/50] [Batch 56/300] [D loss: 0.753672] [G loss: 0.819244] time: 0:13:44.981951\n",
      "0.9419777\n",
      "[Epoch 9/50] [Batch 57/300] [D loss: 0.753697] [G loss: 0.702979] time: 0:13:45.269143\n",
      "0.94050723\n",
      "[Epoch 9/50] [Batch 58/300] [D loss: 0.753675] [G loss: 0.703872] time: 0:13:45.569320\n",
      "0.88218576\n",
      "[Epoch 9/50] [Batch 59/300] [D loss: 0.753726] [G loss: 0.766003] time: 0:13:45.874686\n",
      "0.9345115\n",
      "[Epoch 9/50] [Batch 60/300] [D loss: 0.753738] [G loss: 0.717384] time: 0:13:46.176999\n",
      "0.90877914\n",
      "[Epoch 9/50] [Batch 61/300] [D loss: 0.753687] [G loss: 0.714193] time: 0:13:46.478299\n",
      "0.943054\n",
      "[Epoch 9/50] [Batch 62/300] [D loss: 0.753763] [G loss: 0.701730] time: 0:13:46.772753\n",
      "0.93712074\n",
      "[Epoch 9/50] [Batch 63/300] [D loss: 0.753669] [G loss: 0.749499] time: 0:13:47.064759\n",
      "0.89217657\n",
      "[Epoch 9/50] [Batch 64/300] [D loss: 0.753668] [G loss: 0.720394] time: 0:13:47.368365\n",
      "0.9125199\n",
      "[Epoch 9/50] [Batch 65/300] [D loss: 0.753720] [G loss: 0.736692] time: 0:13:47.656859\n",
      "0.91719586\n",
      "[Epoch 9/50] [Batch 66/300] [D loss: 0.753785] [G loss: 0.828704] time: 0:13:47.938470\n",
      "0.8798306\n",
      "[Epoch 9/50] [Batch 67/300] [D loss: 0.753769] [G loss: 0.722585] time: 0:13:48.237190\n",
      "0.895552\n",
      "[Epoch 9/50] [Batch 68/300] [D loss: 0.753771] [G loss: 0.674973] time: 0:13:48.538412\n",
      "0.93523747\n",
      "[Epoch 9/50] [Batch 69/300] [D loss: 0.753697] [G loss: 0.745898] time: 0:13:48.836924\n",
      "0.89832395\n",
      "[Epoch 9/50] [Batch 70/300] [D loss: 0.753768] [G loss: 0.714045] time: 0:13:49.140921\n",
      "0.8671651\n",
      "[Epoch 9/50] [Batch 71/300] [D loss: 0.753694] [G loss: 0.703823] time: 0:13:49.436662\n",
      "0.937121\n",
      "[Epoch 9/50] [Batch 72/300] [D loss: 0.753694] [G loss: 0.759077] time: 0:13:49.790688\n",
      "0.92805105\n",
      "[Epoch 9/50] [Batch 73/300] [D loss: 0.753651] [G loss: 0.750485] time: 0:13:50.100220\n",
      "0.9254155\n",
      "[Epoch 9/50] [Batch 74/300] [D loss: 0.753642] [G loss: 0.786780] time: 0:13:50.409965\n",
      "0.94261545\n",
      "[Epoch 9/50] [Batch 75/300] [D loss: 0.753704] [G loss: 0.733612] time: 0:13:50.728795\n",
      "0.8989885\n",
      "[Epoch 9/50] [Batch 76/300] [D loss: 0.753694] [G loss: 0.639418] time: 0:13:51.020573\n",
      "0.9469745\n",
      "[Epoch 9/50] [Batch 77/300] [D loss: 0.753709] [G loss: 0.695680] time: 0:13:51.326759\n",
      "0.92518777\n",
      "[Epoch 9/50] [Batch 78/300] [D loss: 0.753712] [G loss: 0.650182] time: 0:13:51.652287\n",
      "0.90925187\n",
      "[Epoch 9/50] [Batch 79/300] [D loss: 0.753726] [G loss: 0.720530] time: 0:13:51.957389\n",
      "0.9269617\n",
      "[Epoch 9/50] [Batch 80/300] [D loss: 0.753706] [G loss: 0.719620] time: 0:13:52.268941\n",
      "0.94566566\n",
      "[Epoch 9/50] [Batch 81/300] [D loss: 0.753641] [G loss: 0.680111] time: 0:13:52.587077\n",
      "0.8818071\n",
      "[Epoch 9/50] [Batch 82/300] [D loss: 0.753611] [G loss: 0.666566] time: 0:13:52.889731\n",
      "0.8988603\n",
      "[Epoch 9/50] [Batch 83/300] [D loss: 0.753706] [G loss: 0.727460] time: 0:13:53.199630\n",
      "0.9295222\n",
      "[Epoch 9/50] [Batch 84/300] [D loss: 0.753680] [G loss: 0.790310] time: 0:13:53.505477\n",
      "0.8843682\n",
      "[Epoch 9/50] [Batch 85/300] [D loss: 0.753675] [G loss: 0.754787] time: 0:13:53.808345\n",
      "0.9250873\n",
      "[Epoch 9/50] [Batch 86/300] [D loss: 0.753686] [G loss: 0.727392] time: 0:13:54.103555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9382188\n",
      "[Epoch 9/50] [Batch 87/300] [D loss: 0.753715] [G loss: 0.710646] time: 0:13:54.402524\n",
      "0.91078305\n",
      "[Epoch 9/50] [Batch 88/300] [D loss: 0.753682] [G loss: 0.746422] time: 0:13:54.695365\n",
      "0.9241119\n",
      "[Epoch 9/50] [Batch 89/300] [D loss: 0.753635] [G loss: 0.755441] time: 0:13:54.982892\n",
      "0.9663636\n",
      "[Epoch 9/50] [Batch 90/300] [D loss: 0.753704] [G loss: 0.694936] time: 0:13:55.272916\n",
      "0.9239736\n",
      "[Epoch 9/50] [Batch 91/300] [D loss: 0.753714] [G loss: 0.670754] time: 0:13:55.597984\n",
      "0.9372979\n",
      "[Epoch 9/50] [Batch 92/300] [D loss: 0.753642] [G loss: 0.614255] time: 0:13:55.898114\n",
      "0.873916\n",
      "[Epoch 9/50] [Batch 93/300] [D loss: 0.753715] [G loss: 0.682289] time: 0:13:56.212115\n",
      "0.94275683\n",
      "[Epoch 9/50] [Batch 94/300] [D loss: 0.753654] [G loss: 0.735245] time: 0:13:56.505331\n",
      "0.88571185\n",
      "[Epoch 9/50] [Batch 95/300] [D loss: 0.753669] [G loss: 0.752628] time: 0:13:56.790516\n",
      "0.8687772\n",
      "[Epoch 9/50] [Batch 96/300] [D loss: 0.753661] [G loss: 0.658854] time: 0:13:57.090922\n",
      "0.9292342\n",
      "[Epoch 9/50] [Batch 97/300] [D loss: 0.753750] [G loss: 0.761811] time: 0:13:57.373682\n",
      "0.8932269\n",
      "[Epoch 9/50] [Batch 98/300] [D loss: 0.753615] [G loss: 0.772927] time: 0:13:57.684919\n",
      "0.92876196\n",
      "[Epoch 9/50] [Batch 99/300] [D loss: 0.753721] [G loss: 0.696521] time: 0:13:57.988976\n",
      "0.9252092\n",
      "[Epoch 9/50] [Batch 100/300] [D loss: 0.753682] [G loss: 0.761902] time: 0:13:58.291283\n",
      "0.9528648\n",
      "[Epoch 9/50] [Batch 101/300] [D loss: 0.753721] [G loss: 0.764022] time: 0:13:58.593609\n",
      "0.9720636\n",
      "[Epoch 9/50] [Batch 102/300] [D loss: 0.753638] [G loss: 0.739484] time: 0:13:58.875388\n",
      "0.94913834\n",
      "[Epoch 9/50] [Batch 103/300] [D loss: 0.753628] [G loss: 0.780995] time: 0:13:59.170092\n",
      "0.97265667\n",
      "[Epoch 9/50] [Batch 104/300] [D loss: 0.753650] [G loss: 0.723506] time: 0:13:59.495729\n",
      "0.94253904\n",
      "[Epoch 9/50] [Batch 105/300] [D loss: 0.753710] [G loss: 0.719372] time: 0:13:59.785769\n",
      "0.9104244\n",
      "[Epoch 9/50] [Batch 106/300] [D loss: 0.753667] [G loss: 0.734940] time: 0:14:00.052928\n",
      "0.9764767\n",
      "[Epoch 9/50] [Batch 107/300] [D loss: 0.753677] [G loss: 0.658694] time: 0:14:00.348825\n",
      "0.8697238\n",
      "[Epoch 9/50] [Batch 108/300] [D loss: 0.753676] [G loss: 0.793300] time: 0:14:00.652362\n",
      "0.9795044\n",
      "[Epoch 9/50] [Batch 109/300] [D loss: 0.753638] [G loss: 0.676087] time: 0:14:00.941985\n",
      "0.89401364\n",
      "[Epoch 9/50] [Batch 110/300] [D loss: 0.753657] [G loss: 0.684240] time: 0:14:01.229686\n",
      "0.91318154\n",
      "[Epoch 9/50] [Batch 111/300] [D loss: 0.753680] [G loss: 0.758096] time: 0:14:01.528134\n",
      "0.9037366\n",
      "[Epoch 9/50] [Batch 112/300] [D loss: 0.753635] [G loss: 0.879668] time: 0:14:01.833148\n",
      "0.952619\n",
      "[Epoch 9/50] [Batch 113/300] [D loss: 0.753713] [G loss: 0.717471] time: 0:14:02.114286\n",
      "0.9574749\n",
      "[Epoch 9/50] [Batch 114/300] [D loss: 0.753679] [G loss: 0.648951] time: 0:14:02.415040\n",
      "0.89077806\n",
      "[Epoch 9/50] [Batch 115/300] [D loss: 0.753672] [G loss: 0.654716] time: 0:14:02.721628\n",
      "0.9365411\n",
      "[Epoch 9/50] [Batch 116/300] [D loss: 0.753677] [G loss: 0.653030] time: 0:14:03.022765\n",
      "0.9636224\n",
      "[Epoch 9/50] [Batch 117/300] [D loss: 0.753738] [G loss: 0.676685] time: 0:14:03.314565\n",
      "0.93732643\n",
      "[Epoch 9/50] [Batch 118/300] [D loss: 0.753663] [G loss: 0.758634] time: 0:14:03.595957\n",
      "0.915314\n",
      "[Epoch 9/50] [Batch 119/300] [D loss: 0.753657] [G loss: 0.678608] time: 0:14:03.903549\n",
      "0.9115829\n",
      "[Epoch 9/50] [Batch 120/300] [D loss: 0.753611] [G loss: 0.790200] time: 0:14:04.221834\n",
      "0.89483935\n",
      "[Epoch 9/50] [Batch 121/300] [D loss: 0.753676] [G loss: 0.759456] time: 0:14:04.517046\n",
      "0.89421177\n",
      "[Epoch 9/50] [Batch 122/300] [D loss: 0.753612] [G loss: 0.673913] time: 0:14:04.823079\n",
      "0.953916\n",
      "[Epoch 9/50] [Batch 123/300] [D loss: 0.753657] [G loss: 0.720806] time: 0:14:05.126599\n",
      "0.97814775\n",
      "[Epoch 9/50] [Batch 124/300] [D loss: 0.753646] [G loss: 0.730543] time: 0:14:05.415991\n",
      "0.9196499\n",
      "[Epoch 9/50] [Batch 125/300] [D loss: 0.753660] [G loss: 0.695249] time: 0:14:05.714246\n",
      "0.94510585\n",
      "[Epoch 9/50] [Batch 126/300] [D loss: 0.753632] [G loss: 0.700495] time: 0:14:06.015592\n",
      "0.9313538\n",
      "[Epoch 9/50] [Batch 127/300] [D loss: 0.753685] [G loss: 0.662178] time: 0:14:06.309834\n",
      "0.91662025\n",
      "[Epoch 9/50] [Batch 128/300] [D loss: 0.753631] [G loss: 0.668765] time: 0:14:06.605513\n",
      "0.91606855\n",
      "[Epoch 9/50] [Batch 129/300] [D loss: 0.753622] [G loss: 0.643416] time: 0:14:06.915296\n",
      "0.93763524\n",
      "[Epoch 9/50] [Batch 130/300] [D loss: 0.753621] [G loss: 0.734493] time: 0:14:07.240586\n",
      "0.8960938\n",
      "[Epoch 9/50] [Batch 131/300] [D loss: 0.753673] [G loss: 0.629303] time: 0:14:07.547061\n",
      "0.95829314\n",
      "[Epoch 9/50] [Batch 132/300] [D loss: 0.753682] [G loss: 0.741455] time: 0:14:07.837433\n",
      "0.95557374\n",
      "[Epoch 9/50] [Batch 133/300] [D loss: 0.753639] [G loss: 0.823445] time: 0:14:08.127609\n",
      "0.8800955\n",
      "[Epoch 9/50] [Batch 134/300] [D loss: 0.753627] [G loss: 0.685719] time: 0:14:08.441255\n",
      "0.9485922\n",
      "[Epoch 9/50] [Batch 135/300] [D loss: 0.753640] [G loss: 0.709050] time: 0:14:08.750668\n",
      "0.91941005\n",
      "[Epoch 9/50] [Batch 136/300] [D loss: 0.753638] [G loss: 0.693548] time: 0:14:09.036635\n",
      "0.92978317\n",
      "[Epoch 9/50] [Batch 137/300] [D loss: 0.753672] [G loss: 0.621452] time: 0:14:09.334385\n",
      "0.93351334\n",
      "[Epoch 9/50] [Batch 138/300] [D loss: 0.753665] [G loss: 0.654802] time: 0:14:09.636182\n",
      "0.91892797\n",
      "[Epoch 9/50] [Batch 139/300] [D loss: 0.753757] [G loss: 0.668876] time: 0:14:09.941027\n",
      "0.9377071\n",
      "[Epoch 9/50] [Batch 140/300] [D loss: 0.753587] [G loss: 0.697284] time: 0:14:10.221706\n",
      "0.89568835\n",
      "[Epoch 9/50] [Batch 141/300] [D loss: 0.753556] [G loss: 0.818582] time: 0:14:10.511458\n",
      "0.95238847\n",
      "[Epoch 9/50] [Batch 142/300] [D loss: 0.753599] [G loss: 0.675494] time: 0:14:10.818941\n",
      "0.8953967\n",
      "[Epoch 9/50] [Batch 143/300] [D loss: 0.753626] [G loss: 0.667629] time: 0:14:11.127813\n",
      "0.9161282\n",
      "[Epoch 9/50] [Batch 144/300] [D loss: 0.753613] [G loss: 0.677474] time: 0:14:11.438201\n",
      "0.9824613\n",
      "[Epoch 9/50] [Batch 145/300] [D loss: 0.753686] [G loss: 0.717015] time: 0:14:11.769526\n",
      "0.9303498\n",
      "[Epoch 9/50] [Batch 146/300] [D loss: 0.753705] [G loss: 0.730606] time: 0:14:12.063290\n",
      "0.9053974\n",
      "[Epoch 9/50] [Batch 147/300] [D loss: 0.753603] [G loss: 0.851414] time: 0:14:12.364746\n",
      "0.8896646\n",
      "[Epoch 9/50] [Batch 148/300] [D loss: 0.753674] [G loss: 0.708992] time: 0:14:12.652265\n",
      "0.90788245\n",
      "[Epoch 9/50] [Batch 149/300] [D loss: 0.753577] [G loss: 0.726131] time: 0:14:12.949700\n",
      "0.8852559\n",
      "[Epoch 9/50] [Batch 150/300] [D loss: 0.753687] [G loss: 0.685045] time: 0:14:13.258261\n",
      "0.9163149\n",
      "[Epoch 9/50] [Batch 151/300] [D loss: 0.753630] [G loss: 0.838613] time: 0:14:13.565323\n",
      "0.89169914\n",
      "[Epoch 9/50] [Batch 152/300] [D loss: 0.753588] [G loss: 0.757625] time: 0:14:13.877946\n",
      "0.8887051\n",
      "[Epoch 9/50] [Batch 153/300] [D loss: 0.753674] [G loss: 0.673678] time: 0:14:14.171133\n",
      "0.90203476\n",
      "[Epoch 9/50] [Batch 154/300] [D loss: 0.753650] [G loss: 0.839426] time: 0:14:14.487342\n",
      "0.94808644\n",
      "[Epoch 9/50] [Batch 155/300] [D loss: 0.753644] [G loss: 0.678511] time: 0:14:14.786870\n",
      "0.9046242\n",
      "[Epoch 9/50] [Batch 156/300] [D loss: 0.753580] [G loss: 0.693096] time: 0:14:15.080527\n",
      "0.89017564\n",
      "[Epoch 9/50] [Batch 157/300] [D loss: 0.753548] [G loss: 0.777215] time: 0:14:15.399189\n",
      "0.89841264\n",
      "[Epoch 9/50] [Batch 158/300] [D loss: 0.753597] [G loss: 0.749120] time: 0:14:15.699526\n",
      "0.9397536\n",
      "[Epoch 9/50] [Batch 159/300] [D loss: 0.753670] [G loss: 0.684649] time: 0:14:15.980976\n",
      "0.8707304\n",
      "[Epoch 9/50] [Batch 160/300] [D loss: 0.753639] [G loss: 0.687374] time: 0:14:16.281690\n",
      "0.8809943\n",
      "[Epoch 9/50] [Batch 161/300] [D loss: 0.753600] [G loss: 0.716490] time: 0:14:16.574548\n",
      "0.8877323\n",
      "[Epoch 9/50] [Batch 162/300] [D loss: 0.753586] [G loss: 0.674331] time: 0:14:16.871891\n",
      "0.9207557\n",
      "[Epoch 9/50] [Batch 163/300] [D loss: 0.753641] [G loss: 0.612005] time: 0:14:17.154250\n",
      "0.907186\n",
      "[Epoch 9/50] [Batch 164/300] [D loss: 0.753700] [G loss: 0.712716] time: 0:14:17.436554\n",
      "0.94880843\n",
      "[Epoch 9/50] [Batch 165/300] [D loss: 0.753606] [G loss: 0.659407] time: 0:14:17.729216\n",
      "0.90068007\n",
      "[Epoch 9/50] [Batch 166/300] [D loss: 0.753615] [G loss: 0.699537] time: 0:14:18.028707\n",
      "0.872878\n",
      "[Epoch 9/50] [Batch 167/300] [D loss: 0.753633] [G loss: 0.715939] time: 0:14:18.342096\n",
      "0.922803\n",
      "[Epoch 9/50] [Batch 168/300] [D loss: 0.753659] [G loss: 0.684911] time: 0:14:18.658429\n",
      "0.89165187\n",
      "[Epoch 9/50] [Batch 169/300] [D loss: 0.753750] [G loss: 0.749328] time: 0:14:18.958954\n",
      "0.9390864\n",
      "[Epoch 9/50] [Batch 170/300] [D loss: 0.753593] [G loss: 0.617168] time: 0:14:19.244602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925358\n",
      "[Epoch 9/50] [Batch 171/300] [D loss: 0.753543] [G loss: 0.813364] time: 0:14:19.558520\n",
      "0.94094443\n",
      "[Epoch 9/50] [Batch 172/300] [D loss: 0.753622] [G loss: 0.737168] time: 0:14:19.856254\n",
      "0.9264961\n",
      "[Epoch 9/50] [Batch 173/300] [D loss: 0.753652] [G loss: 0.773565] time: 0:14:20.135577\n",
      "0.9220889\n",
      "[Epoch 9/50] [Batch 174/300] [D loss: 0.753630] [G loss: 0.753160] time: 0:14:20.422822\n",
      "0.882479\n",
      "[Epoch 9/50] [Batch 175/300] [D loss: 0.753620] [G loss: 0.660103] time: 0:14:20.721848\n",
      "0.9279237\n",
      "[Epoch 9/50] [Batch 176/300] [D loss: 0.753664] [G loss: 0.749645] time: 0:14:21.024475\n",
      "0.89010406\n",
      "[Epoch 9/50] [Batch 177/300] [D loss: 0.753600] [G loss: 0.631966] time: 0:14:21.342104\n",
      "0.9348224\n",
      "[Epoch 9/50] [Batch 178/300] [D loss: 0.753626] [G loss: 0.779479] time: 0:14:21.650948\n",
      "0.97311926\n",
      "[Epoch 9/50] [Batch 179/300] [D loss: 0.753676] [G loss: 0.612261] time: 0:14:21.953281\n",
      "0.9688144\n",
      "[Epoch 9/50] [Batch 180/300] [D loss: 0.753682] [G loss: 0.702181] time: 0:14:22.255709\n",
      "0.9375892\n",
      "[Epoch 9/50] [Batch 181/300] [D loss: 0.753634] [G loss: 0.665465] time: 0:14:22.551662\n",
      "0.87735444\n",
      "[Epoch 9/50] [Batch 182/300] [D loss: 0.753586] [G loss: 0.779239] time: 0:14:22.833580\n",
      "0.8960347\n",
      "[Epoch 9/50] [Batch 183/300] [D loss: 0.753644] [G loss: 0.692863] time: 0:14:23.127615\n",
      "0.983052\n",
      "[Epoch 9/50] [Batch 184/300] [D loss: 0.753680] [G loss: 0.769940] time: 0:14:23.435114\n",
      "0.9045902\n",
      "[Epoch 9/50] [Batch 185/300] [D loss: 0.753665] [G loss: 0.681589] time: 0:14:23.713925\n",
      "0.92141104\n",
      "[Epoch 9/50] [Batch 186/300] [D loss: 0.753571] [G loss: 0.785293] time: 0:14:23.999536\n",
      "0.9062312\n",
      "[Epoch 9/50] [Batch 187/300] [D loss: 0.753562] [G loss: 0.602237] time: 0:14:24.303859\n",
      "0.8903411\n",
      "[Epoch 9/50] [Batch 188/300] [D loss: 0.753595] [G loss: 0.695460] time: 0:14:24.575617\n",
      "0.8703203\n",
      "[Epoch 9/50] [Batch 189/300] [D loss: 0.753658] [G loss: 0.668378] time: 0:14:24.878073\n",
      "0.9572988\n",
      "[Epoch 9/50] [Batch 190/300] [D loss: 0.753521] [G loss: 0.679034] time: 0:14:25.150402\n",
      "0.9592335\n",
      "[Epoch 9/50] [Batch 191/300] [D loss: 0.753605] [G loss: 0.669636] time: 0:14:25.430890\n",
      "0.8873581\n",
      "[Epoch 9/50] [Batch 192/300] [D loss: 0.753660] [G loss: 0.618355] time: 0:14:25.741244\n",
      "0.9139152\n",
      "[Epoch 9/50] [Batch 193/300] [D loss: 0.753607] [G loss: 0.731923] time: 0:14:26.061639\n",
      "0.8764889\n",
      "[Epoch 9/50] [Batch 194/300] [D loss: 0.753617] [G loss: 0.716292] time: 0:14:26.350145\n",
      "0.89697295\n",
      "[Epoch 9/50] [Batch 195/300] [D loss: 0.753624] [G loss: 0.660335] time: 0:14:26.658768\n",
      "0.93852884\n",
      "[Epoch 9/50] [Batch 196/300] [D loss: 0.753583] [G loss: 0.766899] time: 0:14:26.931671\n",
      "0.90914375\n",
      "[Epoch 9/50] [Batch 197/300] [D loss: 0.753609] [G loss: 0.714371] time: 0:14:27.235420\n",
      "0.9070696\n",
      "[Epoch 9/50] [Batch 198/300] [D loss: 0.753635] [G loss: 0.589199] time: 0:14:27.530192\n",
      "0.92911166\n",
      "[Epoch 9/50] [Batch 199/300] [D loss: 0.753555] [G loss: 0.780825] time: 0:14:27.833366\n",
      "0.9265979\n",
      "[Epoch 9/50] [Batch 200/300] [D loss: 0.753599] [G loss: 0.744424] time: 0:14:28.128033\n",
      "0.9372106\n",
      "[Epoch 9/50] [Batch 201/300] [D loss: 0.753607] [G loss: 0.633812] time: 0:14:28.422901\n",
      "0.8992712\n",
      "[Epoch 9/50] [Batch 202/300] [D loss: 0.753603] [G loss: 0.681428] time: 0:14:28.732344\n",
      "0.9226448\n",
      "[Epoch 9/50] [Batch 203/300] [D loss: 0.753570] [G loss: 0.654890] time: 0:14:29.046823\n",
      "0.87308335\n",
      "[Epoch 9/50] [Batch 204/300] [D loss: 0.753585] [G loss: 0.721014] time: 0:14:29.346341\n",
      "0.89470834\n",
      "[Epoch 9/50] [Batch 205/300] [D loss: 0.753704] [G loss: 0.640708] time: 0:14:29.653496\n",
      "0.9438045\n",
      "[Epoch 9/50] [Batch 206/300] [D loss: 0.753579] [G loss: 0.761346] time: 0:14:29.948329\n",
      "0.9396413\n",
      "[Epoch 9/50] [Batch 207/300] [D loss: 0.753558] [G loss: 0.694878] time: 0:14:30.261164\n",
      "0.9306895\n",
      "[Epoch 9/50] [Batch 208/300] [D loss: 0.753603] [G loss: 0.700331] time: 0:14:30.543912\n",
      "0.93523\n",
      "[Epoch 9/50] [Batch 209/300] [D loss: 0.753591] [G loss: 0.825757] time: 0:14:30.848157\n",
      "0.9205148\n",
      "[Epoch 9/50] [Batch 210/300] [D loss: 0.753686] [G loss: 0.742483] time: 0:14:31.168571\n",
      "0.9367741\n",
      "[Epoch 9/50] [Batch 211/300] [D loss: 0.753674] [G loss: 0.639861] time: 0:14:31.491748\n",
      "0.94432265\n",
      "[Epoch 9/50] [Batch 212/300] [D loss: 0.753624] [G loss: 0.725813] time: 0:14:31.796491\n",
      "0.8910853\n",
      "[Epoch 9/50] [Batch 213/300] [D loss: 0.753594] [G loss: 0.722210] time: 0:14:32.105220\n",
      "0.9400417\n",
      "[Epoch 9/50] [Batch 214/300] [D loss: 0.753664] [G loss: 0.621470] time: 0:14:32.404603\n",
      "0.87516004\n",
      "[Epoch 9/50] [Batch 215/300] [D loss: 0.753602] [G loss: 0.746497] time: 0:14:32.696935\n",
      "0.97388226\n",
      "[Epoch 9/50] [Batch 216/300] [D loss: 0.753598] [G loss: 0.702835] time: 0:14:32.999995\n",
      "0.92693704\n",
      "[Epoch 9/50] [Batch 217/300] [D loss: 0.753613] [G loss: 0.775247] time: 0:14:33.302842\n",
      "0.9320011\n",
      "[Epoch 9/50] [Batch 218/300] [D loss: 0.753606] [G loss: 0.757368] time: 0:14:33.612728\n",
      "0.91563517\n",
      "[Epoch 9/50] [Batch 219/300] [D loss: 0.753579] [G loss: 0.718737] time: 0:14:33.915822\n",
      "0.9182691\n",
      "[Epoch 9/50] [Batch 220/300] [D loss: 0.753566] [G loss: 0.652430] time: 0:14:34.208989\n",
      "0.9552466\n",
      "[Epoch 9/50] [Batch 221/300] [D loss: 0.753611] [G loss: 0.616802] time: 0:14:34.508106\n",
      "0.9378533\n",
      "[Epoch 9/50] [Batch 222/300] [D loss: 0.753594] [G loss: 0.803458] time: 0:14:34.814505\n",
      "0.9238992\n",
      "[Epoch 9/50] [Batch 223/300] [D loss: 0.753650] [G loss: 0.624698] time: 0:14:35.139620\n",
      "0.92831016\n",
      "[Epoch 9/50] [Batch 224/300] [D loss: 0.753561] [G loss: 0.755697] time: 0:14:35.445336\n",
      "0.93509984\n",
      "[Epoch 9/50] [Batch 225/300] [D loss: 0.753578] [G loss: 0.828495] time: 0:14:35.731869\n",
      "0.92824715\n",
      "[Epoch 9/50] [Batch 226/300] [D loss: 0.753576] [G loss: 0.689636] time: 0:14:36.036571\n",
      "0.922683\n",
      "[Epoch 9/50] [Batch 227/300] [D loss: 0.753598] [G loss: 0.704586] time: 0:14:36.344139\n",
      "0.9189493\n",
      "[Epoch 9/50] [Batch 228/300] [D loss: 0.753614] [G loss: 0.700501] time: 0:14:36.653322\n",
      "0.9165576\n",
      "[Epoch 9/50] [Batch 229/300] [D loss: 0.753589] [G loss: 0.651973] time: 0:14:36.955071\n",
      "0.914066\n",
      "[Epoch 9/50] [Batch 230/300] [D loss: 0.753534] [G loss: 0.707082] time: 0:14:37.264064\n",
      "0.88000417\n",
      "[Epoch 9/50] [Batch 231/300] [D loss: 0.753571] [G loss: 0.703416] time: 0:14:37.567932\n",
      "0.89128685\n",
      "[Epoch 9/50] [Batch 232/300] [D loss: 0.753628] [G loss: 0.657755] time: 0:14:37.880407\n",
      "0.9417735\n",
      "[Epoch 9/50] [Batch 233/300] [D loss: 0.753671] [G loss: 0.698306] time: 0:14:38.184891\n",
      "0.8951281\n",
      "[Epoch 9/50] [Batch 234/300] [D loss: 0.753547] [G loss: 0.748063] time: 0:14:38.482084\n",
      "0.9395849\n",
      "[Epoch 9/50] [Batch 235/300] [D loss: 0.753601] [G loss: 0.762998] time: 0:14:38.795164\n",
      "0.9107218\n",
      "[Epoch 9/50] [Batch 236/300] [D loss: 0.753572] [G loss: 0.786369] time: 0:14:39.101445\n",
      "0.95071554\n",
      "[Epoch 9/50] [Batch 237/300] [D loss: 0.753562] [G loss: 0.630042] time: 0:14:39.405841\n",
      "0.94041246\n",
      "[Epoch 9/50] [Batch 238/300] [D loss: 0.753616] [G loss: 0.694160] time: 0:14:39.724291\n",
      "0.9103597\n",
      "[Epoch 9/50] [Batch 239/300] [D loss: 0.753517] [G loss: 0.658991] time: 0:14:40.155898\n",
      "0.92976695\n",
      "[Epoch 9/50] [Batch 240/300] [D loss: 0.753598] [G loss: 0.662497] time: 0:14:40.464778\n",
      "0.95048994\n",
      "[Epoch 9/50] [Batch 241/300] [D loss: 0.753600] [G loss: 0.658754] time: 0:14:40.767855\n",
      "0.8987531\n",
      "[Epoch 9/50] [Batch 242/300] [D loss: 0.753574] [G loss: 0.802233] time: 0:14:41.063619\n",
      "0.90246034\n",
      "[Epoch 9/50] [Batch 243/300] [D loss: 0.753590] [G loss: 0.694317] time: 0:14:41.333792\n",
      "0.9291444\n",
      "[Epoch 9/50] [Batch 244/300] [D loss: 0.753560] [G loss: 0.661861] time: 0:14:41.638188\n",
      "0.9593908\n",
      "[Epoch 9/50] [Batch 245/300] [D loss: 0.753594] [G loss: 0.706306] time: 0:14:41.933870\n",
      "0.92256874\n",
      "[Epoch 9/50] [Batch 246/300] [D loss: 0.753515] [G loss: 0.692278] time: 0:14:42.217214\n",
      "0.9285054\n",
      "[Epoch 9/50] [Batch 247/300] [D loss: 0.753637] [G loss: 0.711855] time: 0:14:42.493975\n",
      "0.9225631\n",
      "[Epoch 9/50] [Batch 248/300] [D loss: 0.753581] [G loss: 0.667974] time: 0:14:42.803393\n",
      "0.89504427\n",
      "[Epoch 9/50] [Batch 249/300] [D loss: 0.753605] [G loss: 0.698433] time: 0:14:43.096082\n",
      "0.92232627\n",
      "[Epoch 9/50] [Batch 250/300] [D loss: 0.753577] [G loss: 0.708731] time: 0:14:43.385066\n",
      "0.87233657\n",
      "[Epoch 9/50] [Batch 251/300] [D loss: 0.753516] [G loss: 0.712976] time: 0:14:43.684266\n",
      "0.8607049\n",
      "[Epoch 9/50] [Batch 252/300] [D loss: 0.753590] [G loss: 0.823733] time: 0:14:43.989950\n",
      "0.8932326\n",
      "[Epoch 9/50] [Batch 253/300] [D loss: 0.753590] [G loss: 0.690073] time: 0:14:44.284159\n",
      "0.9083869\n",
      "[Epoch 9/50] [Batch 254/300] [D loss: 0.753554] [G loss: 0.754643] time: 0:14:44.570131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241233\n",
      "[Epoch 9/50] [Batch 255/300] [D loss: 0.753541] [G loss: 0.642471] time: 0:14:44.887989\n",
      "0.9794486\n",
      "[Epoch 9/50] [Batch 256/300] [D loss: 0.753626] [G loss: 0.740085] time: 0:14:45.194945\n",
      "0.88029665\n",
      "[Epoch 9/50] [Batch 257/300] [D loss: 0.753596] [G loss: 0.781255] time: 0:14:45.482053\n",
      "0.9432974\n",
      "[Epoch 9/50] [Batch 258/300] [D loss: 0.753629] [G loss: 0.772253] time: 0:14:45.766573\n",
      "0.90275794\n",
      "[Epoch 9/50] [Batch 259/300] [D loss: 0.753567] [G loss: 0.661460] time: 0:14:46.071442\n",
      "0.94098115\n",
      "[Epoch 9/50] [Batch 260/300] [D loss: 0.753560] [G loss: 0.676432] time: 0:14:46.368363\n",
      "0.9165285\n",
      "[Epoch 9/50] [Batch 261/300] [D loss: 0.753645] [G loss: 0.605413] time: 0:14:46.670901\n",
      "0.9190393\n",
      "[Epoch 9/50] [Batch 262/300] [D loss: 0.753513] [G loss: 0.742507] time: 0:14:46.947938\n",
      "0.8844208\n",
      "[Epoch 9/50] [Batch 263/300] [D loss: 0.753535] [G loss: 0.637387] time: 0:14:47.255404\n",
      "0.93372077\n",
      "[Epoch 9/50] [Batch 264/300] [D loss: 0.753588] [G loss: 0.693316] time: 0:14:47.580176\n",
      "0.9194301\n",
      "[Epoch 9/50] [Batch 265/300] [D loss: 0.753538] [G loss: 0.679458] time: 0:14:47.882739\n",
      "0.8972881\n",
      "[Epoch 9/50] [Batch 266/300] [D loss: 0.753549] [G loss: 0.711891] time: 0:14:48.157490\n",
      "0.8727329\n",
      "[Epoch 9/50] [Batch 267/300] [D loss: 0.753596] [G loss: 0.695938] time: 0:14:48.450626\n",
      "0.9464386\n",
      "[Epoch 9/50] [Batch 268/300] [D loss: 0.753537] [G loss: 0.721718] time: 0:14:48.750376\n",
      "0.9828057\n",
      "[Epoch 9/50] [Batch 269/300] [D loss: 0.753587] [G loss: 0.717331] time: 0:14:49.035911\n",
      "0.93953615\n",
      "[Epoch 9/50] [Batch 270/300] [D loss: 0.753547] [G loss: 0.707517] time: 0:14:49.328559\n",
      "0.9411498\n",
      "[Epoch 9/50] [Batch 271/300] [D loss: 0.753604] [G loss: 0.789841] time: 0:14:49.631614\n",
      "0.91853666\n",
      "[Epoch 9/50] [Batch 272/300] [D loss: 0.753589] [G loss: 0.619664] time: 0:14:49.927535\n",
      "0.9012148\n",
      "[Epoch 9/50] [Batch 273/300] [D loss: 0.753548] [G loss: 0.688682] time: 0:14:50.241839\n",
      "0.9511726\n",
      "[Epoch 9/50] [Batch 274/300] [D loss: 0.753519] [G loss: 0.715449] time: 0:14:50.549181\n",
      "0.8792127\n",
      "[Epoch 9/50] [Batch 275/300] [D loss: 0.753529] [G loss: 0.713495] time: 0:14:50.853769\n",
      "0.9165464\n",
      "[Epoch 9/50] [Batch 276/300] [D loss: 0.753491] [G loss: 0.753698] time: 0:14:51.151666\n",
      "0.95019823\n",
      "[Epoch 9/50] [Batch 277/300] [D loss: 0.753543] [G loss: 0.699361] time: 0:14:51.437312\n",
      "0.90713876\n",
      "[Epoch 9/50] [Batch 278/300] [D loss: 0.753521] [G loss: 0.679928] time: 0:14:51.732641\n",
      "0.9424722\n",
      "[Epoch 9/50] [Batch 279/300] [D loss: 0.753553] [G loss: 0.781916] time: 0:14:52.046672\n",
      "0.8753416\n",
      "[Epoch 9/50] [Batch 280/300] [D loss: 0.753549] [G loss: 0.653470] time: 0:14:52.355212\n",
      "0.9538973\n",
      "[Epoch 9/50] [Batch 281/300] [D loss: 0.753495] [G loss: 0.743117] time: 0:14:52.673126\n",
      "0.9363175\n",
      "[Epoch 9/50] [Batch 282/300] [D loss: 0.753528] [G loss: 0.637984] time: 0:14:52.998155\n",
      "0.9679904\n",
      "[Epoch 9/50] [Batch 283/300] [D loss: 0.753542] [G loss: 0.690770] time: 0:14:53.293462\n",
      "0.88376904\n",
      "[Epoch 9/50] [Batch 284/300] [D loss: 0.753570] [G loss: 0.699416] time: 0:14:53.597158\n",
      "0.8995319\n",
      "[Epoch 9/50] [Batch 285/300] [D loss: 0.753573] [G loss: 0.671673] time: 0:14:53.900419\n",
      "0.9412737\n",
      "[Epoch 9/50] [Batch 286/300] [D loss: 0.753575] [G loss: 0.704624] time: 0:14:54.197438\n",
      "0.9431929\n",
      "[Epoch 9/50] [Batch 287/300] [D loss: 0.753540] [G loss: 0.655378] time: 0:14:54.500452\n",
      "0.95529246\n",
      "[Epoch 9/50] [Batch 288/300] [D loss: 0.753502] [G loss: 0.669770] time: 0:14:54.792087\n",
      "0.93246174\n",
      "[Epoch 9/50] [Batch 289/300] [D loss: 0.753617] [G loss: 0.692462] time: 0:14:55.079505\n",
      "0.93919104\n",
      "[Epoch 9/50] [Batch 290/300] [D loss: 0.753589] [G loss: 0.704411] time: 0:14:55.370451\n",
      "0.88827854\n",
      "[Epoch 9/50] [Batch 291/300] [D loss: 0.753510] [G loss: 0.742496] time: 0:14:55.636912\n",
      "0.9482899\n",
      "[Epoch 9/50] [Batch 292/300] [D loss: 0.753550] [G loss: 0.666958] time: 0:14:55.935944\n",
      "0.9159853\n",
      "[Epoch 9/50] [Batch 293/300] [D loss: 0.753509] [G loss: 0.844745] time: 0:14:56.238868\n",
      "0.9494991\n",
      "[Epoch 9/50] [Batch 294/300] [D loss: 0.753554] [G loss: 0.777795] time: 0:14:56.539807\n",
      "0.9239437\n",
      "[Epoch 9/50] [Batch 295/300] [D loss: 0.753600] [G loss: 0.729445] time: 0:14:56.838487\n",
      "0.95234704\n",
      "[Epoch 9/50] [Batch 296/300] [D loss: 0.753519] [G loss: 0.670569] time: 0:14:57.131420\n",
      "0.95656854\n",
      "[Epoch 9/50] [Batch 297/300] [D loss: 0.753557] [G loss: 0.738605] time: 0:14:57.418457\n",
      "0.9442151\n",
      "[Epoch 9/50] [Batch 298/300] [D loss: 0.753520] [G loss: 0.643177] time: 0:14:57.726158\n",
      "0.89802164\n",
      "[Epoch 9/50] [Batch 299/300] [D loss: 0.753550] [G loss: 0.640493] time: 0:14:58.014061\n",
      "0.8614288\n",
      "[Epoch 10/50] [Batch 0/300] [D loss: 0.753536] [G loss: 0.748021] time: 0:14:58.318026\n",
      "0.88306475\n",
      "[Epoch 10/50] [Batch 1/300] [D loss: 0.753509] [G loss: 0.621589] time: 0:14:58.591918\n",
      "0.933898\n",
      "[Epoch 10/50] [Batch 2/300] [D loss: 0.753546] [G loss: 0.653996] time: 0:14:58.885093\n",
      "0.9367098\n",
      "[Epoch 10/50] [Batch 3/300] [D loss: 0.753483] [G loss: 0.722196] time: 0:14:59.183016\n",
      "0.9253578\n",
      "[Epoch 10/50] [Batch 4/300] [D loss: 0.753574] [G loss: 0.710955] time: 0:14:59.494688\n",
      "0.9416607\n",
      "[Epoch 10/50] [Batch 5/300] [D loss: 0.753510] [G loss: 0.772393] time: 0:14:59.763334\n",
      "0.9283461\n",
      "[Epoch 10/50] [Batch 6/300] [D loss: 0.753578] [G loss: 0.782102] time: 0:15:00.071727\n",
      "0.9137452\n",
      "[Epoch 10/50] [Batch 7/300] [D loss: 0.753537] [G loss: 0.707894] time: 0:15:00.366251\n",
      "0.93490714\n",
      "[Epoch 10/50] [Batch 8/300] [D loss: 0.753537] [G loss: 0.712533] time: 0:15:00.634223\n",
      "0.9144102\n",
      "[Epoch 10/50] [Batch 10/300] [D loss: 0.753575] [G loss: 0.730214] time: 0:15:00.926159\n",
      "0.8830455\n",
      "[Epoch 10/50] [Batch 11/300] [D loss: 0.753563] [G loss: 0.602248] time: 0:15:01.217820\n",
      "0.93988967\n",
      "[Epoch 10/50] [Batch 12/300] [D loss: 0.753491] [G loss: 0.651295] time: 0:15:01.501224\n",
      "0.93180555\n",
      "[Epoch 10/50] [Batch 13/300] [D loss: 0.753617] [G loss: 0.682737] time: 0:15:01.790264\n",
      "0.96496695\n",
      "[Epoch 10/50] [Batch 14/300] [D loss: 0.753561] [G loss: 0.722932] time: 0:15:02.107559\n",
      "0.9391384\n",
      "[Epoch 10/50] [Batch 15/300] [D loss: 0.753519] [G loss: 0.670025] time: 0:15:02.403422\n",
      "0.97804075\n",
      "[Epoch 10/50] [Batch 16/300] [D loss: 0.753535] [G loss: 0.658442] time: 0:15:02.709979\n",
      "0.88501054\n",
      "[Epoch 10/50] [Batch 17/300] [D loss: 0.753536] [G loss: 0.814394] time: 0:15:03.000428\n",
      "0.9096698\n",
      "[Epoch 10/50] [Batch 18/300] [D loss: 0.753513] [G loss: 0.632609] time: 0:15:03.316080\n",
      "0.9129362\n",
      "[Epoch 10/50] [Batch 19/300] [D loss: 0.753509] [G loss: 0.756013] time: 0:15:03.606023\n",
      "0.8795092\n",
      "[Epoch 10/50] [Batch 20/300] [D loss: 0.753554] [G loss: 0.698564] time: 0:15:03.915075\n",
      "0.8851293\n",
      "[Epoch 10/50] [Batch 21/300] [D loss: 0.753511] [G loss: 0.666035] time: 0:15:04.207662\n",
      "0.92110825\n",
      "[Epoch 10/50] [Batch 22/300] [D loss: 0.753557] [G loss: 0.816901] time: 0:15:04.507983\n",
      "0.90972906\n",
      "[Epoch 10/50] [Batch 23/300] [D loss: 0.753541] [G loss: 0.598083] time: 0:15:04.812963\n",
      "0.95927095\n",
      "[Epoch 10/50] [Batch 24/300] [D loss: 0.753551] [G loss: 0.728953] time: 0:15:05.125178\n",
      "0.949615\n",
      "[Epoch 10/50] [Batch 25/300] [D loss: 0.753524] [G loss: 0.733858] time: 0:15:05.437916\n",
      "0.90665966\n",
      "[Epoch 10/50] [Batch 26/300] [D loss: 0.753517] [G loss: 0.719963] time: 0:15:05.741480\n",
      "0.97877765\n",
      "[Epoch 10/50] [Batch 27/300] [D loss: 0.753575] [G loss: 0.720796] time: 0:15:06.033794\n",
      "0.92868334\n",
      "[Epoch 10/50] [Batch 28/300] [D loss: 0.753487] [G loss: 0.758767] time: 0:15:06.336950\n",
      "0.88753515\n",
      "[Epoch 10/50] [Batch 29/300] [D loss: 0.753520] [G loss: 0.658279] time: 0:15:06.645399\n",
      "0.88582915\n",
      "[Epoch 10/50] [Batch 30/300] [D loss: 0.753449] [G loss: 0.666816] time: 0:15:06.952128\n",
      "0.9143228\n",
      "[Epoch 10/50] [Batch 31/300] [D loss: 0.753487] [G loss: 0.719165] time: 0:15:07.274587\n",
      "0.89540094\n",
      "[Epoch 10/50] [Batch 32/300] [D loss: 0.753516] [G loss: 0.678702] time: 0:15:07.578051\n",
      "0.9101009\n",
      "[Epoch 10/50] [Batch 33/300] [D loss: 0.753469] [G loss: 0.690014] time: 0:15:07.881484\n",
      "0.9001677\n",
      "[Epoch 10/50] [Batch 34/300] [D loss: 0.753517] [G loss: 0.671492] time: 0:15:08.185311\n",
      "0.90060544\n",
      "[Epoch 10/50] [Batch 35/300] [D loss: 0.753519] [G loss: 0.684187] time: 0:15:08.494861\n",
      "0.8807052\n",
      "[Epoch 10/50] [Batch 36/300] [D loss: 0.753516] [G loss: 0.685030] time: 0:15:08.816358\n",
      "0.90604967\n",
      "[Epoch 10/50] [Batch 37/300] [D loss: 0.753479] [G loss: 0.784069] time: 0:15:09.124592\n",
      "0.9414599\n",
      "[Epoch 10/50] [Batch 38/300] [D loss: 0.753540] [G loss: 0.672970] time: 0:15:09.421271\n",
      "0.87627596\n",
      "[Epoch 10/50] [Batch 39/300] [D loss: 0.753487] [G loss: 0.783292] time: 0:15:09.718769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95167106\n",
      "[Epoch 10/50] [Batch 40/300] [D loss: 0.753543] [G loss: 0.650407] time: 0:15:10.005665\n",
      "0.92539376\n",
      "[Epoch 10/50] [Batch 41/300] [D loss: 0.753507] [G loss: 0.636798] time: 0:15:10.308833\n",
      "0.89947456\n",
      "[Epoch 10/50] [Batch 42/300] [D loss: 0.753479] [G loss: 0.638854] time: 0:15:10.609965\n",
      "0.9435095\n",
      "[Epoch 10/50] [Batch 43/300] [D loss: 0.753533] [G loss: 0.645459] time: 0:15:10.923279\n",
      "0.9478794\n",
      "[Epoch 10/50] [Batch 44/300] [D loss: 0.753539] [G loss: 0.654976] time: 0:15:11.207668\n",
      "0.8838685\n",
      "[Epoch 10/50] [Batch 45/300] [D loss: 0.753505] [G loss: 0.770710] time: 0:15:11.499064\n",
      "0.9531224\n",
      "[Epoch 10/50] [Batch 46/300] [D loss: 0.753554] [G loss: 0.634907] time: 0:15:11.799843\n",
      "0.9234273\n",
      "[Epoch 10/50] [Batch 47/300] [D loss: 0.753544] [G loss: 0.629225] time: 0:15:12.095820\n",
      "0.91218966\n",
      "[Epoch 10/50] [Batch 48/300] [D loss: 0.753488] [G loss: 0.728305] time: 0:15:12.390550\n",
      "0.94156307\n",
      "[Epoch 10/50] [Batch 49/300] [D loss: 0.753492] [G loss: 0.639555] time: 0:15:12.691026\n",
      "0.90762705\n",
      "[Epoch 10/50] [Batch 50/300] [D loss: 0.753511] [G loss: 0.674996] time: 0:15:12.983329\n",
      "0.9005651\n",
      "[Epoch 10/50] [Batch 51/300] [D loss: 0.753528] [G loss: 0.795420] time: 0:15:13.295319\n",
      "0.89313906\n",
      "[Epoch 10/50] [Batch 52/300] [D loss: 0.753555] [G loss: 0.661376] time: 0:15:13.576976\n",
      "0.93631196\n",
      "[Epoch 10/50] [Batch 53/300] [D loss: 0.753572] [G loss: 0.612507] time: 0:15:13.887971\n",
      "0.88940907\n",
      "[Epoch 10/50] [Batch 54/300] [D loss: 0.753448] [G loss: 0.787596] time: 0:15:14.198021\n",
      "0.9514691\n",
      "[Epoch 10/50] [Batch 55/300] [D loss: 0.753520] [G loss: 0.700526] time: 0:15:14.508155\n",
      "0.976876\n",
      "[Epoch 10/50] [Batch 56/300] [D loss: 0.753454] [G loss: 0.617566] time: 0:15:14.791691\n",
      "0.90795845\n",
      "[Epoch 10/50] [Batch 57/300] [D loss: 0.753506] [G loss: 0.811017] time: 0:15:15.083714\n",
      "0.977169\n",
      "[Epoch 10/50] [Batch 58/300] [D loss: 0.753492] [G loss: 0.620942] time: 0:15:15.385824\n",
      "0.8720905\n",
      "[Epoch 10/50] [Batch 59/300] [D loss: 0.753491] [G loss: 0.765672] time: 0:15:15.677151\n",
      "0.91593164\n",
      "[Epoch 10/50] [Batch 60/300] [D loss: 0.753476] [G loss: 0.715197] time: 0:15:15.972736\n",
      "0.9493143\n",
      "[Epoch 10/50] [Batch 61/300] [D loss: 0.753533] [G loss: 0.617013] time: 0:15:16.291562\n",
      "0.9197095\n",
      "[Epoch 10/50] [Batch 62/300] [D loss: 0.753475] [G loss: 0.795705] time: 0:15:16.587709\n",
      "0.9275082\n",
      "[Epoch 10/50] [Batch 63/300] [D loss: 0.753496] [G loss: 0.640010] time: 0:15:16.884385\n",
      "0.93355036\n",
      "[Epoch 10/50] [Batch 64/300] [D loss: 0.753554] [G loss: 0.694537] time: 0:15:17.193811\n",
      "0.89005166\n",
      "[Epoch 10/50] [Batch 65/300] [D loss: 0.753480] [G loss: 0.616024] time: 0:15:17.488409\n",
      "0.94388646\n",
      "[Epoch 10/50] [Batch 66/300] [D loss: 0.753514] [G loss: 0.608634] time: 0:15:17.781686\n",
      "0.9413344\n",
      "[Epoch 10/50] [Batch 67/300] [D loss: 0.753510] [G loss: 0.724959] time: 0:15:18.063494\n",
      "0.91612387\n",
      "[Epoch 10/50] [Batch 68/300] [D loss: 0.753517] [G loss: 0.646567] time: 0:15:18.369136\n",
      "0.93351847\n",
      "[Epoch 10/50] [Batch 69/300] [D loss: 0.753553] [G loss: 0.632655] time: 0:15:18.685166\n",
      "0.9226164\n",
      "[Epoch 10/50] [Batch 70/300] [D loss: 0.753469] [G loss: 0.644656] time: 0:15:18.975457\n",
      "0.92777497\n",
      "[Epoch 10/50] [Batch 71/300] [D loss: 0.753484] [G loss: 0.678765] time: 0:15:19.263214\n",
      "0.9044988\n",
      "[Epoch 10/50] [Batch 72/300] [D loss: 0.753482] [G loss: 0.755229] time: 0:15:19.569323\n",
      "0.88850945\n",
      "[Epoch 10/50] [Batch 73/300] [D loss: 0.753503] [G loss: 0.681328] time: 0:15:19.863461\n",
      "0.85036856\n",
      "[Epoch 10/50] [Batch 74/300] [D loss: 0.753524] [G loss: 0.732014] time: 0:15:20.168386\n",
      "0.93361443\n",
      "[Epoch 10/50] [Batch 75/300] [D loss: 0.753460] [G loss: 0.611018] time: 0:15:20.447053\n",
      "0.94590276\n",
      "[Epoch 10/50] [Batch 76/300] [D loss: 0.753509] [G loss: 0.712792] time: 0:15:20.740241\n",
      "0.88122195\n",
      "[Epoch 10/50] [Batch 77/300] [D loss: 0.753459] [G loss: 0.711271] time: 0:15:21.040426\n",
      "0.9249956\n",
      "[Epoch 10/50] [Batch 78/300] [D loss: 0.753540] [G loss: 0.638174] time: 0:15:21.349072\n",
      "0.9585538\n",
      "[Epoch 10/50] [Batch 79/300] [D loss: 0.753528] [G loss: 0.688394] time: 0:15:21.677158\n",
      "0.9230702\n",
      "[Epoch 10/50] [Batch 80/300] [D loss: 0.753442] [G loss: 0.706084] time: 0:15:21.979897\n",
      "0.8692973\n",
      "[Epoch 10/50] [Batch 81/300] [D loss: 0.753562] [G loss: 0.631699] time: 0:15:22.277267\n",
      "0.9101748\n",
      "[Epoch 10/50] [Batch 82/300] [D loss: 0.753504] [G loss: 0.712219] time: 0:15:22.577066\n",
      "0.8258936\n",
      "[Epoch 10/50] [Batch 83/300] [D loss: 0.753453] [G loss: 0.692557] time: 0:15:22.890623\n",
      "0.93950456\n",
      "[Epoch 10/50] [Batch 84/300] [D loss: 0.753450] [G loss: 0.635798] time: 0:15:23.193531\n",
      "0.91607946\n",
      "[Epoch 10/50] [Batch 85/300] [D loss: 0.753468] [G loss: 0.697141] time: 0:15:23.491082\n",
      "0.8949866\n",
      "[Epoch 10/50] [Batch 86/300] [D loss: 0.753505] [G loss: 0.632703] time: 0:15:23.780358\n",
      "0.90880066\n",
      "[Epoch 10/50] [Batch 87/300] [D loss: 0.753497] [G loss: 0.677479] time: 0:15:24.081218\n",
      "0.9256277\n",
      "[Epoch 10/50] [Batch 88/300] [D loss: 0.753601] [G loss: 0.703594] time: 0:15:24.369395\n",
      "0.8906827\n",
      "[Epoch 10/50] [Batch 89/300] [D loss: 0.753489] [G loss: 0.693159] time: 0:15:24.669885\n",
      "0.91265345\n",
      "[Epoch 10/50] [Batch 90/300] [D loss: 0.753491] [G loss: 0.715764] time: 0:15:24.960174\n",
      "0.9276748\n",
      "[Epoch 10/50] [Batch 91/300] [D loss: 0.753484] [G loss: 0.726764] time: 0:15:25.257325\n",
      "0.91450197\n",
      "[Epoch 10/50] [Batch 92/300] [D loss: 0.753497] [G loss: 0.756418] time: 0:15:25.550529\n",
      "0.8795379\n",
      "[Epoch 10/50] [Batch 93/300] [D loss: 0.753444] [G loss: 0.693885] time: 0:15:25.848949\n",
      "0.9508591\n",
      "[Epoch 10/50] [Batch 94/300] [D loss: 0.753492] [G loss: 0.676143] time: 0:15:26.150418\n",
      "0.94628\n",
      "[Epoch 10/50] [Batch 95/300] [D loss: 0.753468] [G loss: 0.657042] time: 0:15:26.445105\n",
      "0.9389922\n",
      "[Epoch 10/50] [Batch 96/300] [D loss: 0.753477] [G loss: 0.662713] time: 0:15:26.762186\n",
      "0.9310654\n",
      "[Epoch 10/50] [Batch 97/300] [D loss: 0.753520] [G loss: 0.682002] time: 0:15:27.061346\n",
      "0.9281562\n",
      "[Epoch 10/50] [Batch 98/300] [D loss: 0.753530] [G loss: 0.775330] time: 0:15:27.345940\n",
      "0.9428728\n",
      "[Epoch 10/50] [Batch 99/300] [D loss: 0.753494] [G loss: 0.664381] time: 0:15:27.647451\n",
      "0.9015165\n",
      "[Epoch 10/50] [Batch 100/300] [D loss: 0.753518] [G loss: 0.683878] time: 0:15:27.949116\n",
      "0.93852973\n",
      "[Epoch 10/50] [Batch 101/300] [D loss: 0.753485] [G loss: 0.660523] time: 0:15:28.244954\n",
      "0.9309485\n",
      "[Epoch 10/50] [Batch 102/300] [D loss: 0.753435] [G loss: 0.647109] time: 0:15:28.567238\n",
      "0.9816585\n",
      "[Epoch 10/50] [Batch 103/300] [D loss: 0.753457] [G loss: 0.706455] time: 0:15:28.868492\n",
      "0.9289269\n",
      "[Epoch 10/50] [Batch 104/300] [D loss: 0.753483] [G loss: 0.686760] time: 0:15:29.172225\n",
      "0.89604026\n",
      "[Epoch 10/50] [Batch 105/300] [D loss: 0.753485] [G loss: 0.632524] time: 0:15:29.468691\n",
      "0.9311263\n",
      "[Epoch 10/50] [Batch 106/300] [D loss: 0.753548] [G loss: 0.681655] time: 0:15:29.764983\n",
      "0.8939449\n",
      "[Epoch 10/50] [Batch 107/300] [D loss: 0.753484] [G loss: 0.726754] time: 0:15:30.079614\n",
      "0.9712209\n",
      "[Epoch 10/50] [Batch 108/300] [D loss: 0.753460] [G loss: 0.714295] time: 0:15:30.375705\n",
      "0.93568295\n",
      "[Epoch 10/50] [Batch 109/300] [D loss: 0.753574] [G loss: 0.707894] time: 0:15:30.681198\n",
      "0.8725346\n",
      "[Epoch 10/50] [Batch 110/300] [D loss: 0.753460] [G loss: 0.684979] time: 0:15:30.974066\n",
      "0.8963058\n",
      "[Epoch 10/50] [Batch 111/300] [D loss: 0.753448] [G loss: 0.750986] time: 0:15:31.260674\n",
      "0.9195893\n",
      "[Epoch 10/50] [Batch 112/300] [D loss: 0.753449] [G loss: 0.632639] time: 0:15:31.557248\n",
      "0.91027397\n",
      "[Epoch 10/50] [Batch 113/300] [D loss: 0.753437] [G loss: 0.722055] time: 0:15:31.851298\n",
      "0.946073\n",
      "[Epoch 10/50] [Batch 114/300] [D loss: 0.753482] [G loss: 0.661401] time: 0:15:32.167162\n",
      "0.88895434\n",
      "[Epoch 10/50] [Batch 115/300] [D loss: 0.753471] [G loss: 0.679088] time: 0:15:32.481482\n",
      "0.9518323\n",
      "[Epoch 10/50] [Batch 116/300] [D loss: 0.753437] [G loss: 0.726882] time: 0:15:32.780965\n",
      "0.90535283\n",
      "[Epoch 10/50] [Batch 117/300] [D loss: 0.753489] [G loss: 0.692114] time: 0:15:33.074662\n",
      "0.8840335\n",
      "[Epoch 10/50] [Batch 118/300] [D loss: 0.753549] [G loss: 0.627640] time: 0:15:33.367824\n",
      "0.8492257\n",
      "[Epoch 10/50] [Batch 119/300] [D loss: 0.753409] [G loss: 0.677680] time: 0:15:33.691619\n",
      "0.92703646\n",
      "[Epoch 10/50] [Batch 120/300] [D loss: 0.753479] [G loss: 0.612731] time: 0:15:33.979336\n",
      "0.9168449\n",
      "[Epoch 10/50] [Batch 121/300] [D loss: 0.753448] [G loss: 0.711815] time: 0:15:34.271037\n",
      "0.9080922\n",
      "[Epoch 10/50] [Batch 122/300] [D loss: 0.753491] [G loss: 0.668595] time: 0:15:34.594727\n",
      "0.92354846\n",
      "[Epoch 10/50] [Batch 123/300] [D loss: 0.753523] [G loss: 0.614567] time: 0:15:34.899959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92029935\n",
      "[Epoch 10/50] [Batch 124/300] [D loss: 0.753498] [G loss: 0.613765] time: 0:15:35.184714\n",
      "0.9123133\n",
      "[Epoch 10/50] [Batch 125/300] [D loss: 0.753494] [G loss: 0.653773] time: 0:15:35.481223\n",
      "0.87857246\n",
      "[Epoch 10/50] [Batch 126/300] [D loss: 0.753415] [G loss: 0.678319] time: 0:15:35.773285\n",
      "0.8534828\n",
      "[Epoch 10/50] [Batch 127/300] [D loss: 0.753523] [G loss: 0.686964] time: 0:15:36.065151\n",
      "0.900616\n",
      "[Epoch 10/50] [Batch 128/300] [D loss: 0.753488] [G loss: 0.695756] time: 0:15:36.391453\n",
      "0.94911337\n",
      "[Epoch 10/50] [Batch 129/300] [D loss: 0.753449] [G loss: 0.654351] time: 0:15:36.698135\n",
      "0.9205864\n",
      "[Epoch 10/50] [Batch 130/300] [D loss: 0.753464] [G loss: 0.715810] time: 0:15:37.019008\n",
      "0.94278026\n",
      "[Epoch 10/50] [Batch 131/300] [D loss: 0.753459] [G loss: 0.687424] time: 0:15:37.329529\n",
      "0.93460065\n",
      "[Epoch 10/50] [Batch 132/300] [D loss: 0.753383] [G loss: 0.634839] time: 0:15:37.630578\n",
      "0.9490439\n",
      "[Epoch 10/50] [Batch 133/300] [D loss: 0.753518] [G loss: 0.666557] time: 0:15:37.910858\n",
      "0.90451074\n",
      "[Epoch 10/50] [Batch 134/300] [D loss: 0.753538] [G loss: 0.663136] time: 0:15:38.206962\n",
      "0.8992184\n",
      "[Epoch 10/50] [Batch 135/300] [D loss: 0.753440] [G loss: 0.631875] time: 0:15:38.516760\n",
      "0.9751399\n",
      "[Epoch 10/50] [Batch 136/300] [D loss: 0.753484] [G loss: 0.623829] time: 0:15:38.828534\n",
      "0.9005154\n",
      "[Epoch 10/50] [Batch 137/300] [D loss: 0.753419] [G loss: 0.676055] time: 0:15:39.113220\n",
      "0.960648\n",
      "[Epoch 10/50] [Batch 138/300] [D loss: 0.753470] [G loss: 0.626707] time: 0:15:39.412588\n",
      "0.94307965\n",
      "[Epoch 10/50] [Batch 139/300] [D loss: 0.753447] [G loss: 0.700858] time: 0:15:39.715141\n",
      "0.9185632\n",
      "[Epoch 10/50] [Batch 140/300] [D loss: 0.753474] [G loss: 0.630873] time: 0:15:40.010823\n",
      "0.91030693\n",
      "[Epoch 10/50] [Batch 141/300] [D loss: 0.753462] [G loss: 0.684873] time: 0:15:40.295443\n",
      "0.8799903\n",
      "[Epoch 10/50] [Batch 142/300] [D loss: 0.753450] [G loss: 0.706383] time: 0:15:40.582684\n",
      "0.9241454\n",
      "[Epoch 10/50] [Batch 143/300] [D loss: 0.753475] [G loss: 0.625598] time: 0:15:40.872165\n",
      "0.9000799\n",
      "[Epoch 10/50] [Batch 144/300] [D loss: 0.753456] [G loss: 0.670082] time: 0:15:41.179717\n",
      "0.9447231\n",
      "[Epoch 10/50] [Batch 145/300] [D loss: 0.753476] [G loss: 0.643152] time: 0:15:41.482129\n",
      "0.90701157\n",
      "[Epoch 10/50] [Batch 146/300] [D loss: 0.753457] [G loss: 0.659470] time: 0:15:41.783187\n",
      "0.9604605\n",
      "[Epoch 10/50] [Batch 147/300] [D loss: 0.753491] [G loss: 0.724887] time: 0:15:42.052298\n",
      "0.8459664\n",
      "[Epoch 10/50] [Batch 148/300] [D loss: 0.753508] [G loss: 0.755900] time: 0:15:42.334724\n",
      "0.90727335\n",
      "[Epoch 10/50] [Batch 149/300] [D loss: 0.753430] [G loss: 0.671645] time: 0:15:42.655280\n",
      "0.88448334\n",
      "[Epoch 10/50] [Batch 150/300] [D loss: 0.753464] [G loss: 0.638434] time: 0:15:42.962955\n",
      "0.9203283\n",
      "[Epoch 10/50] [Batch 151/300] [D loss: 0.753499] [G loss: 0.704317] time: 0:15:43.277073\n",
      "0.9082975\n",
      "[Epoch 10/50] [Batch 152/300] [D loss: 0.753380] [G loss: 0.566395] time: 0:15:43.585415\n",
      "0.93054867\n",
      "[Epoch 10/50] [Batch 153/300] [D loss: 0.753437] [G loss: 0.706749] time: 0:15:43.878720\n",
      "0.9235509\n",
      "[Epoch 10/50] [Batch 154/300] [D loss: 0.753372] [G loss: 0.699727] time: 0:15:44.178675\n",
      "0.9279863\n",
      "[Epoch 10/50] [Batch 155/300] [D loss: 0.753511] [G loss: 0.647702] time: 0:15:44.445635\n",
      "0.9434023\n",
      "[Epoch 10/50] [Batch 156/300] [D loss: 0.753513] [G loss: 0.730343] time: 0:15:44.735198\n",
      "0.9308939\n",
      "[Epoch 10/50] [Batch 157/300] [D loss: 0.753420] [G loss: 0.703335] time: 0:15:45.041972\n",
      "0.91831845\n",
      "[Epoch 10/50] [Batch 158/300] [D loss: 0.753427] [G loss: 0.678779] time: 0:15:45.348432\n",
      "0.9217947\n",
      "[Epoch 10/50] [Batch 159/300] [D loss: 0.753423] [G loss: 0.713521] time: 0:15:45.655618\n",
      "0.89585686\n",
      "[Epoch 10/50] [Batch 160/300] [D loss: 0.753461] [G loss: 0.751341] time: 0:15:45.936099\n",
      "0.9537398\n",
      "[Epoch 10/50] [Batch 161/300] [D loss: 0.753506] [G loss: 0.719608] time: 0:15:46.235496\n",
      "0.93949085\n",
      "[Epoch 10/50] [Batch 162/300] [D loss: 0.753435] [G loss: 0.739193] time: 0:15:46.504796\n",
      "0.92084926\n",
      "[Epoch 10/50] [Batch 163/300] [D loss: 0.753505] [G loss: 0.597565] time: 0:15:46.794546\n",
      "0.9019652\n",
      "[Epoch 10/50] [Batch 164/300] [D loss: 0.753449] [G loss: 0.593335] time: 0:15:47.097353\n",
      "0.9094505\n",
      "[Epoch 10/50] [Batch 165/300] [D loss: 0.753478] [G loss: 0.725075] time: 0:15:47.401090\n",
      "0.91184574\n",
      "[Epoch 10/50] [Batch 166/300] [D loss: 0.753448] [G loss: 0.688726] time: 0:15:47.695540\n",
      "0.89287853\n",
      "[Epoch 10/50] [Batch 167/300] [D loss: 0.753495] [G loss: 0.675910] time: 0:15:47.988143\n",
      "0.9348337\n",
      "[Epoch 10/50] [Batch 168/300] [D loss: 0.753437] [G loss: 0.694222] time: 0:15:48.271046\n",
      "0.916493\n",
      "[Epoch 10/50] [Batch 169/300] [D loss: 0.753457] [G loss: 0.725275] time: 0:15:48.567658\n",
      "0.9304361\n",
      "[Epoch 10/50] [Batch 170/300] [D loss: 0.753446] [G loss: 0.764498] time: 0:15:48.872007\n",
      "0.94025564\n",
      "[Epoch 10/50] [Batch 171/300] [D loss: 0.753490] [G loss: 0.703494] time: 0:15:49.175018\n",
      "0.9567798\n",
      "[Epoch 10/50] [Batch 172/300] [D loss: 0.753382] [G loss: 0.585357] time: 0:15:49.477127\n",
      "0.91096586\n",
      "[Epoch 10/50] [Batch 173/300] [D loss: 0.753404] [G loss: 0.689148] time: 0:15:49.789276\n",
      "0.9470443\n",
      "[Epoch 10/50] [Batch 174/300] [D loss: 0.753419] [G loss: 0.678034] time: 0:15:50.097796\n",
      "0.90006566\n",
      "[Epoch 10/50] [Batch 175/300] [D loss: 0.753490] [G loss: 0.643779] time: 0:15:50.370722\n",
      "0.88632566\n",
      "[Epoch 10/50] [Batch 176/300] [D loss: 0.753436] [G loss: 0.654857] time: 0:15:50.663269\n",
      "0.90307623\n",
      "[Epoch 10/50] [Batch 177/300] [D loss: 0.753442] [G loss: 0.660459] time: 0:15:50.947380\n",
      "0.92964894\n",
      "[Epoch 10/50] [Batch 178/300] [D loss: 0.753412] [G loss: 0.736887] time: 0:15:51.234056\n",
      "0.9320217\n",
      "[Epoch 10/50] [Batch 179/300] [D loss: 0.753473] [G loss: 0.654245] time: 0:15:51.545249\n",
      "0.9536066\n",
      "[Epoch 10/50] [Batch 180/300] [D loss: 0.753415] [G loss: 0.674754] time: 0:15:51.844058\n",
      "0.89096695\n",
      "[Epoch 10/50] [Batch 181/300] [D loss: 0.753432] [G loss: 0.633075] time: 0:15:52.136439\n",
      "0.9183662\n",
      "[Epoch 10/50] [Batch 182/300] [D loss: 0.753474] [G loss: 0.607853] time: 0:15:52.426911\n",
      "0.9489724\n",
      "[Epoch 10/50] [Batch 183/300] [D loss: 0.753403] [G loss: 0.739519] time: 0:15:52.724561\n",
      "0.9181619\n",
      "[Epoch 10/50] [Batch 184/300] [D loss: 0.753423] [G loss: 0.663951] time: 0:15:52.992611\n",
      "0.8840351\n",
      "[Epoch 10/50] [Batch 185/300] [D loss: 0.753456] [G loss: 0.643976] time: 0:15:53.279187\n",
      "0.91623163\n",
      "[Epoch 10/50] [Batch 186/300] [D loss: 0.753410] [G loss: 0.735012] time: 0:15:53.571174\n",
      "0.9257841\n",
      "[Epoch 10/50] [Batch 187/300] [D loss: 0.753464] [G loss: 0.773032] time: 0:15:53.875801\n",
      "0.88437486\n",
      "[Epoch 10/50] [Batch 188/300] [D loss: 0.753431] [G loss: 0.671328] time: 0:15:54.177966\n",
      "0.9049447\n",
      "[Epoch 10/50] [Batch 189/300] [D loss: 0.753429] [G loss: 0.699167] time: 0:15:54.475619\n",
      "0.89336085\n",
      "[Epoch 10/50] [Batch 190/300] [D loss: 0.753437] [G loss: 0.654730] time: 0:15:54.776647\n",
      "0.89793706\n",
      "[Epoch 10/50] [Batch 191/300] [D loss: 0.753417] [G loss: 0.753453] time: 0:15:55.084225\n",
      "0.9340525\n",
      "[Epoch 10/50] [Batch 192/300] [D loss: 0.753409] [G loss: 0.687405] time: 0:15:55.370643\n",
      "0.974196\n",
      "[Epoch 10/50] [Batch 193/300] [D loss: 0.753384] [G loss: 0.621861] time: 0:15:55.665243\n",
      "0.871517\n",
      "[Epoch 10/50] [Batch 194/300] [D loss: 0.753474] [G loss: 0.648064] time: 0:15:55.969457\n",
      "0.9309106\n",
      "[Epoch 10/50] [Batch 195/300] [D loss: 0.753475] [G loss: 0.638233] time: 0:15:56.284428\n",
      "0.8916505\n",
      "[Epoch 10/50] [Batch 196/300] [D loss: 0.753414] [G loss: 0.686649] time: 0:15:56.579624\n",
      "0.8803549\n",
      "[Epoch 10/50] [Batch 197/300] [D loss: 0.753370] [G loss: 0.660983] time: 0:15:56.873312\n",
      "0.8926975\n",
      "[Epoch 10/50] [Batch 198/300] [D loss: 0.753485] [G loss: 0.655656] time: 0:15:57.171002\n",
      "0.9414151\n",
      "[Epoch 10/50] [Batch 199/300] [D loss: 0.753409] [G loss: 0.618998] time: 0:15:57.472312\n",
      "0.91436386\n",
      "[Epoch 10/50] [Batch 200/300] [D loss: 0.753424] [G loss: 0.799921] time: 0:15:57.770015\n",
      "0.916202\n",
      "[Epoch 10/50] [Batch 201/300] [D loss: 0.753414] [G loss: 0.688508] time: 0:15:58.073105\n",
      "0.9565423\n",
      "[Epoch 10/50] [Batch 202/300] [D loss: 0.753428] [G loss: 0.690407] time: 0:15:58.367911\n",
      "0.9389806\n",
      "[Epoch 10/50] [Batch 203/300] [D loss: 0.753400] [G loss: 0.690940] time: 0:15:58.683904\n",
      "0.9286258\n",
      "[Epoch 10/50] [Batch 204/300] [D loss: 0.753420] [G loss: 0.664349] time: 0:15:58.959028\n",
      "0.93970233\n",
      "[Epoch 10/50] [Batch 205/300] [D loss: 0.753401] [G loss: 0.627438] time: 0:15:59.254643\n",
      "0.9198521\n",
      "[Epoch 10/50] [Batch 206/300] [D loss: 0.753446] [G loss: 0.612167] time: 0:15:59.575178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9174591\n",
      "[Epoch 10/50] [Batch 207/300] [D loss: 0.753403] [G loss: 0.665694] time: 0:15:59.870125\n",
      "0.9106707\n",
      "[Epoch 10/50] [Batch 208/300] [D loss: 0.753433] [G loss: 0.730027] time: 0:16:00.168346\n",
      "0.97170043\n",
      "[Epoch 10/50] [Batch 209/300] [D loss: 0.753467] [G loss: 0.765786] time: 0:16:00.463752\n",
      "0.8811057\n",
      "[Epoch 10/50] [Batch 210/300] [D loss: 0.753385] [G loss: 0.681571] time: 0:16:00.766044\n",
      "0.9433262\n",
      "[Epoch 10/50] [Batch 211/300] [D loss: 0.753428] [G loss: 0.642115] time: 0:16:01.067913\n",
      "0.9415879\n",
      "[Epoch 10/50] [Batch 212/300] [D loss: 0.753403] [G loss: 0.615532] time: 0:16:01.369871\n",
      "0.8786834\n",
      "[Epoch 10/50] [Batch 213/300] [D loss: 0.753414] [G loss: 0.706002] time: 0:16:01.662231\n",
      "0.90220565\n",
      "[Epoch 10/50] [Batch 214/300] [D loss: 0.753396] [G loss: 0.729491] time: 0:16:01.968691\n",
      "0.9422276\n",
      "[Epoch 10/50] [Batch 215/300] [D loss: 0.753433] [G loss: 0.612375] time: 0:16:02.261867\n",
      "0.9410865\n",
      "[Epoch 10/50] [Batch 216/300] [D loss: 0.753414] [G loss: 0.607281] time: 0:16:02.554001\n",
      "0.97428113\n",
      "[Epoch 10/50] [Batch 217/300] [D loss: 0.753423] [G loss: 0.668643] time: 0:16:02.852554\n",
      "0.94879127\n",
      "[Epoch 10/50] [Batch 218/300] [D loss: 0.753434] [G loss: 0.617706] time: 0:16:03.135681\n",
      "0.89355403\n",
      "[Epoch 10/50] [Batch 219/300] [D loss: 0.753396] [G loss: 0.767176] time: 0:16:03.448280\n",
      "0.87814856\n",
      "[Epoch 10/50] [Batch 220/300] [D loss: 0.753399] [G loss: 0.776859] time: 0:16:03.736651\n",
      "0.89608544\n",
      "[Epoch 10/50] [Batch 221/300] [D loss: 0.753439] [G loss: 0.665579] time: 0:16:04.039181\n",
      "0.9708627\n",
      "[Epoch 10/50] [Batch 222/300] [D loss: 0.753409] [G loss: 0.620917] time: 0:16:04.322334\n",
      "0.9133291\n",
      "[Epoch 10/50] [Batch 223/300] [D loss: 0.753398] [G loss: 0.627982] time: 0:16:04.629525\n",
      "0.88963056\n",
      "[Epoch 10/50] [Batch 224/300] [D loss: 0.753425] [G loss: 0.655475] time: 0:16:04.922314\n",
      "0.8902866\n",
      "[Epoch 10/50] [Batch 225/300] [D loss: 0.753456] [G loss: 0.664494] time: 0:16:05.233500\n",
      "0.94856477\n",
      "[Epoch 10/50] [Batch 226/300] [D loss: 0.753433] [G loss: 0.737620] time: 0:16:05.531325\n",
      "0.93736404\n",
      "[Epoch 10/50] [Batch 227/300] [D loss: 0.753490] [G loss: 0.624906] time: 0:16:05.812506\n",
      "0.95416766\n",
      "[Epoch 10/50] [Batch 228/300] [D loss: 0.753399] [G loss: 0.655855] time: 0:16:06.106539\n",
      "0.94549817\n",
      "[Epoch 10/50] [Batch 229/300] [D loss: 0.753455] [G loss: 0.638828] time: 0:16:06.376561\n",
      "0.92373466\n",
      "[Epoch 10/50] [Batch 230/300] [D loss: 0.753474] [G loss: 0.647028] time: 0:16:06.673065\n",
      "0.9763922\n",
      "[Epoch 10/50] [Batch 231/300] [D loss: 0.753475] [G loss: 0.632637] time: 0:16:06.978241\n",
      "0.87581426\n",
      "[Epoch 10/50] [Batch 232/300] [D loss: 0.753376] [G loss: 0.621858] time: 0:16:07.253800\n",
      "0.8904123\n",
      "[Epoch 10/50] [Batch 233/300] [D loss: 0.753397] [G loss: 0.643628] time: 0:16:07.547282\n",
      "0.95214814\n",
      "[Epoch 10/50] [Batch 234/300] [D loss: 0.753416] [G loss: 0.588724] time: 0:16:07.814015\n",
      "0.9555685\n",
      "[Epoch 10/50] [Batch 235/300] [D loss: 0.753432] [G loss: 0.655385] time: 0:16:08.103393\n",
      "0.97951704\n",
      "[Epoch 10/50] [Batch 236/300] [D loss: 0.753396] [G loss: 0.627256] time: 0:16:08.405565\n",
      "0.9123723\n",
      "[Epoch 10/50] [Batch 237/300] [D loss: 0.753439] [G loss: 0.679781] time: 0:16:08.682772\n",
      "0.88042235\n",
      "[Epoch 10/50] [Batch 238/300] [D loss: 0.753377] [G loss: 0.619439] time: 0:16:08.974931\n",
      "0.9271057\n",
      "[Epoch 10/50] [Batch 239/300] [D loss: 0.753361] [G loss: 0.708382] time: 0:16:09.282595\n",
      "0.94289285\n",
      "[Epoch 10/50] [Batch 240/300] [D loss: 0.753353] [G loss: 0.689872] time: 0:16:09.558022\n",
      "0.9025585\n",
      "[Epoch 10/50] [Batch 241/300] [D loss: 0.753411] [G loss: 0.808872] time: 0:16:09.831157\n",
      "0.8830552\n",
      "[Epoch 10/50] [Batch 242/300] [D loss: 0.753410] [G loss: 0.714384] time: 0:16:10.120832\n",
      "0.916884\n",
      "[Epoch 10/50] [Batch 243/300] [D loss: 0.753398] [G loss: 0.621462] time: 0:16:10.406627\n",
      "0.9407964\n",
      "[Epoch 10/50] [Batch 244/300] [D loss: 0.753388] [G loss: 0.640118] time: 0:16:10.692621\n",
      "0.92731\n",
      "[Epoch 10/50] [Batch 245/300] [D loss: 0.753352] [G loss: 0.694577] time: 0:16:10.979775\n",
      "0.9260893\n",
      "[Epoch 10/50] [Batch 246/300] [D loss: 0.753382] [G loss: 0.702917] time: 0:16:11.256167\n",
      "0.8853523\n",
      "[Epoch 10/50] [Batch 247/300] [D loss: 0.753368] [G loss: 0.685625] time: 0:16:11.549146\n",
      "0.9002774\n",
      "[Epoch 10/50] [Batch 248/300] [D loss: 0.753394] [G loss: 0.623290] time: 0:16:11.843712\n",
      "0.9030376\n",
      "[Epoch 10/50] [Batch 249/300] [D loss: 0.753386] [G loss: 0.716808] time: 0:16:12.144452\n",
      "0.90026116\n",
      "[Epoch 10/50] [Batch 250/300] [D loss: 0.753370] [G loss: 0.638500] time: 0:16:12.425679\n",
      "0.90358084\n",
      "[Epoch 10/50] [Batch 251/300] [D loss: 0.753358] [G loss: 0.866026] time: 0:16:12.735103\n",
      "0.87547714\n",
      "[Epoch 10/50] [Batch 252/300] [D loss: 0.753434] [G loss: 0.683128] time: 0:16:13.048579\n",
      "0.9291118\n",
      "[Epoch 10/50] [Batch 253/300] [D loss: 0.753427] [G loss: 0.676605] time: 0:16:13.348545\n",
      "0.9366347\n",
      "[Epoch 10/50] [Batch 254/300] [D loss: 0.753347] [G loss: 0.663841] time: 0:16:13.639926\n",
      "0.8831694\n",
      "[Epoch 10/50] [Batch 255/300] [D loss: 0.753456] [G loss: 0.709404] time: 0:16:13.942628\n",
      "0.91009516\n",
      "[Epoch 10/50] [Batch 256/300] [D loss: 0.753367] [G loss: 0.762685] time: 0:16:14.245660\n",
      "0.9155424\n",
      "[Epoch 10/50] [Batch 257/300] [D loss: 0.753457] [G loss: 0.715248] time: 0:16:14.564890\n",
      "0.8881703\n",
      "[Epoch 10/50] [Batch 258/300] [D loss: 0.753423] [G loss: 0.748698] time: 0:16:14.851681\n",
      "0.8874288\n",
      "[Epoch 10/50] [Batch 259/300] [D loss: 0.753370] [G loss: 0.640719] time: 0:16:15.149347\n",
      "0.93011063\n",
      "[Epoch 10/50] [Batch 260/300] [D loss: 0.753394] [G loss: 0.662843] time: 0:16:15.453539\n",
      "0.9346583\n",
      "[Epoch 10/50] [Batch 261/300] [D loss: 0.753341] [G loss: 0.735479] time: 0:16:15.755934\n",
      "0.8802977\n",
      "[Epoch 10/50] [Batch 262/300] [D loss: 0.753461] [G loss: 0.593202] time: 0:16:16.044020\n",
      "0.9042085\n",
      "[Epoch 10/50] [Batch 263/300] [D loss: 0.753389] [G loss: 0.663546] time: 0:16:16.355472\n",
      "0.84552604\n",
      "[Epoch 10/50] [Batch 264/300] [D loss: 0.753405] [G loss: 0.692908] time: 0:16:16.657556\n",
      "0.9193557\n",
      "[Epoch 10/50] [Batch 265/300] [D loss: 0.753412] [G loss: 0.661041] time: 0:16:16.970946\n",
      "0.95051557\n",
      "[Epoch 10/50] [Batch 266/300] [D loss: 0.753433] [G loss: 0.760085] time: 0:16:17.278938\n",
      "0.94858557\n",
      "[Epoch 10/50] [Batch 267/300] [D loss: 0.753386] [G loss: 0.630015] time: 0:16:17.576379\n",
      "0.9380102\n",
      "[Epoch 10/50] [Batch 268/300] [D loss: 0.753387] [G loss: 0.679824] time: 0:16:17.875537\n",
      "0.8883856\n",
      "[Epoch 10/50] [Batch 269/300] [D loss: 0.753338] [G loss: 0.653596] time: 0:16:18.195512\n",
      "0.89723635\n",
      "[Epoch 10/50] [Batch 270/300] [D loss: 0.753352] [G loss: 0.604068] time: 0:16:18.493174\n",
      "0.9368682\n",
      "[Epoch 10/50] [Batch 271/300] [D loss: 0.753435] [G loss: 0.594019] time: 0:16:18.792741\n",
      "0.94503254\n",
      "[Epoch 10/50] [Batch 272/300] [D loss: 0.753357] [G loss: 0.738817] time: 0:16:19.086398\n",
      "0.91308594\n",
      "[Epoch 10/50] [Batch 273/300] [D loss: 0.753394] [G loss: 0.579461] time: 0:16:19.394193\n",
      "0.9227368\n",
      "[Epoch 10/50] [Batch 274/300] [D loss: 0.753422] [G loss: 0.643109] time: 0:16:19.671121\n",
      "0.8993876\n",
      "[Epoch 10/50] [Batch 275/300] [D loss: 0.753361] [G loss: 0.584833] time: 0:16:19.959680\n",
      "0.9370394\n",
      "[Epoch 10/50] [Batch 276/300] [D loss: 0.753366] [G loss: 0.655361] time: 0:16:20.258935\n",
      "0.89225173\n",
      "[Epoch 10/50] [Batch 277/300] [D loss: 0.753365] [G loss: 0.710997] time: 0:16:20.560166\n",
      "0.937167\n",
      "[Epoch 10/50] [Batch 278/300] [D loss: 0.753342] [G loss: 0.631070] time: 0:16:20.845756\n",
      "0.90531826\n",
      "[Epoch 10/50] [Batch 279/300] [D loss: 0.753363] [G loss: 0.705374] time: 0:16:21.137300\n",
      "0.94645256\n",
      "[Epoch 10/50] [Batch 280/300] [D loss: 0.753412] [G loss: 0.620294] time: 0:16:21.442595\n",
      "0.9253397\n",
      "[Epoch 10/50] [Batch 281/300] [D loss: 0.753435] [G loss: 0.658893] time: 0:16:21.741082\n",
      "0.91386276\n",
      "[Epoch 10/50] [Batch 282/300] [D loss: 0.753345] [G loss: 0.600401] time: 0:16:22.046697\n",
      "0.93200344\n",
      "[Epoch 10/50] [Batch 283/300] [D loss: 0.753396] [G loss: 0.626267] time: 0:16:22.348322\n",
      "0.90643483\n",
      "[Epoch 10/50] [Batch 284/300] [D loss: 0.753380] [G loss: 0.594704] time: 0:16:22.664189\n",
      "0.94292134\n",
      "[Epoch 10/50] [Batch 285/300] [D loss: 0.753408] [G loss: 0.640503] time: 0:16:22.959066\n",
      "0.8906508\n",
      "[Epoch 10/50] [Batch 286/300] [D loss: 0.753342] [G loss: 0.699886] time: 0:16:23.259032\n",
      "0.9039881\n",
      "[Epoch 10/50] [Batch 287/300] [D loss: 0.753338] [G loss: 0.655252] time: 0:16:23.540360\n",
      "0.9827519\n",
      "[Epoch 10/50] [Batch 288/300] [D loss: 0.753348] [G loss: 0.615503] time: 0:16:23.840828\n",
      "0.9475382\n",
      "[Epoch 10/50] [Batch 289/300] [D loss: 0.753455] [G loss: 0.619769] time: 0:16:24.134734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88334394\n",
      "[Epoch 10/50] [Batch 290/300] [D loss: 0.753379] [G loss: 0.744757] time: 0:16:24.431072\n",
      "0.95488995\n",
      "[Epoch 10/50] [Batch 291/300] [D loss: 0.753299] [G loss: 0.690149] time: 0:16:24.731442\n",
      "0.9115844\n",
      "[Epoch 10/50] [Batch 292/300] [D loss: 0.753417] [G loss: 0.663387] time: 0:16:25.021714\n",
      "0.921622\n",
      "[Epoch 10/50] [Batch 293/300] [D loss: 0.753383] [G loss: 0.665931] time: 0:16:25.325973\n",
      "0.89101505\n",
      "[Epoch 10/50] [Batch 294/300] [D loss: 0.753428] [G loss: 0.640002] time: 0:16:25.622458\n",
      "0.929631\n",
      "[Epoch 10/50] [Batch 295/300] [D loss: 0.753380] [G loss: 0.763472] time: 0:16:25.918721\n",
      "0.91888326\n",
      "[Epoch 10/50] [Batch 296/300] [D loss: 0.753414] [G loss: 0.711853] time: 0:16:26.211795\n",
      "0.9232108\n",
      "[Epoch 10/50] [Batch 297/300] [D loss: 0.753356] [G loss: 0.695106] time: 0:16:26.515892\n",
      "0.92878175\n",
      "[Epoch 10/50] [Batch 298/300] [D loss: 0.753341] [G loss: 0.657231] time: 0:16:26.812056\n",
      "0.9396058\n",
      "[Epoch 10/50] [Batch 299/300] [D loss: 0.753373] [G loss: 0.714630] time: 0:16:27.088954\n",
      "0.8926325\n",
      "[Epoch 11/50] [Batch 0/300] [D loss: 0.753374] [G loss: 0.658376] time: 0:16:27.387641\n",
      "0.92006373\n",
      "[Epoch 11/50] [Batch 1/300] [D loss: 0.753419] [G loss: 0.806966] time: 0:16:27.706439\n",
      "0.8868472\n",
      "[Epoch 11/50] [Batch 2/300] [D loss: 0.753348] [G loss: 0.696059] time: 0:16:28.006374\n",
      "0.87309355\n",
      "[Epoch 11/50] [Batch 3/300] [D loss: 0.753394] [G loss: 0.636900] time: 0:16:28.298251\n",
      "0.89851\n",
      "[Epoch 11/50] [Batch 4/300] [D loss: 0.753352] [G loss: 0.697295] time: 0:16:28.602745\n",
      "0.9340176\n",
      "[Epoch 11/50] [Batch 5/300] [D loss: 0.753400] [G loss: 0.763771] time: 0:16:28.900242\n",
      "0.9043997\n",
      "[Epoch 11/50] [Batch 6/300] [D loss: 0.753356] [G loss: 0.567855] time: 0:16:29.204673\n",
      "0.91345304\n",
      "[Epoch 11/50] [Batch 7/300] [D loss: 0.753306] [G loss: 0.642898] time: 0:16:29.502628\n",
      "0.9355925\n",
      "[Epoch 11/50] [Batch 8/300] [D loss: 0.753346] [G loss: 0.641225] time: 0:16:29.796929\n",
      "0.9107044\n",
      "[Epoch 11/50] [Batch 9/300] [D loss: 0.753387] [G loss: 0.652293] time: 0:16:30.097077\n",
      "0.90254635\n",
      "[Epoch 11/50] [Batch 11/300] [D loss: 0.753408] [G loss: 0.636572] time: 0:16:30.403938\n",
      "0.9104833\n",
      "[Epoch 11/50] [Batch 12/300] [D loss: 0.753389] [G loss: 0.680671] time: 0:16:30.701627\n",
      "0.9829168\n",
      "[Epoch 11/50] [Batch 13/300] [D loss: 0.753457] [G loss: 0.566743] time: 0:16:31.008564\n",
      "0.9061229\n",
      "[Epoch 11/50] [Batch 14/300] [D loss: 0.753311] [G loss: 0.656099] time: 0:16:31.303532\n",
      "0.90029174\n",
      "[Epoch 11/50] [Batch 15/300] [D loss: 0.753358] [G loss: 0.614250] time: 0:16:31.617125\n",
      "0.8454239\n",
      "[Epoch 11/50] [Batch 16/300] [D loss: 0.753350] [G loss: 0.682760] time: 0:16:31.906538\n",
      "0.91628027\n",
      "[Epoch 11/50] [Batch 17/300] [D loss: 0.753394] [G loss: 0.706878] time: 0:16:32.206737\n",
      "0.89499277\n",
      "[Epoch 11/50] [Batch 18/300] [D loss: 0.753421] [G loss: 0.586412] time: 0:16:32.508339\n",
      "0.8881125\n",
      "[Epoch 11/50] [Batch 19/300] [D loss: 0.753348] [G loss: 0.607302] time: 0:16:32.811086\n",
      "0.90209585\n",
      "[Epoch 11/50] [Batch 20/300] [D loss: 0.753382] [G loss: 0.635121] time: 0:16:33.118751\n",
      "0.905152\n",
      "[Epoch 11/50] [Batch 21/300] [D loss: 0.753344] [G loss: 0.644292] time: 0:16:33.409070\n",
      "0.92782277\n",
      "[Epoch 11/50] [Batch 22/300] [D loss: 0.753358] [G loss: 0.707735] time: 0:16:33.716718\n",
      "0.9164767\n",
      "[Epoch 11/50] [Batch 23/300] [D loss: 0.753347] [G loss: 0.726499] time: 0:16:34.011459\n",
      "0.9269343\n",
      "[Epoch 11/50] [Batch 24/300] [D loss: 0.753353] [G loss: 0.672227] time: 0:16:34.332216\n",
      "0.9085498\n",
      "[Epoch 11/50] [Batch 25/300] [D loss: 0.753384] [G loss: 0.586694] time: 0:16:34.625361\n",
      "0.9116271\n",
      "[Epoch 11/50] [Batch 26/300] [D loss: 0.753376] [G loss: 0.601386] time: 0:16:34.933541\n",
      "0.9031456\n",
      "[Epoch 11/50] [Batch 27/300] [D loss: 0.753373] [G loss: 0.636799] time: 0:16:35.218789\n",
      "0.9533715\n",
      "[Epoch 11/50] [Batch 28/300] [D loss: 0.753369] [G loss: 0.653099] time: 0:16:35.514126\n",
      "0.9124345\n",
      "[Epoch 11/50] [Batch 29/300] [D loss: 0.753315] [G loss: 0.750867] time: 0:16:35.803779\n",
      "0.9082033\n",
      "[Epoch 11/50] [Batch 30/300] [D loss: 0.753344] [G loss: 0.714563] time: 0:16:36.082039\n",
      "0.91398674\n",
      "[Epoch 11/50] [Batch 31/300] [D loss: 0.753358] [G loss: 0.665604] time: 0:16:36.390126\n",
      "0.9239383\n",
      "[Epoch 11/50] [Batch 32/300] [D loss: 0.753297] [G loss: 0.628812] time: 0:16:36.676349\n",
      "0.8852553\n",
      "[Epoch 11/50] [Batch 33/300] [D loss: 0.753366] [G loss: 0.599988] time: 0:16:36.983298\n",
      "0.9603699\n",
      "[Epoch 11/50] [Batch 34/300] [D loss: 0.753393] [G loss: 0.598906] time: 0:16:37.284890\n",
      "0.92455244\n",
      "[Epoch 11/50] [Batch 35/300] [D loss: 0.753459] [G loss: 0.598336] time: 0:16:37.579142\n",
      "0.8812156\n",
      "[Epoch 11/50] [Batch 36/300] [D loss: 0.753341] [G loss: 0.697437] time: 0:16:37.876261\n",
      "0.94910675\n",
      "[Epoch 11/50] [Batch 37/300] [D loss: 0.753402] [G loss: 0.560015] time: 0:16:38.175741\n",
      "0.9072447\n",
      "[Epoch 11/50] [Batch 38/300] [D loss: 0.753318] [G loss: 0.681171] time: 0:16:38.474118\n",
      "0.9477001\n",
      "[Epoch 11/50] [Batch 39/300] [D loss: 0.753409] [G loss: 0.604849] time: 0:16:38.749028\n",
      "0.918058\n",
      "[Epoch 11/50] [Batch 40/300] [D loss: 0.753369] [G loss: 0.635855] time: 0:16:39.049091\n",
      "0.9105204\n",
      "[Epoch 11/50] [Batch 41/300] [D loss: 0.753364] [G loss: 0.591955] time: 0:16:39.359887\n",
      "0.9369235\n",
      "[Epoch 11/50] [Batch 42/300] [D loss: 0.753434] [G loss: 0.616412] time: 0:16:39.646474\n",
      "0.91888595\n",
      "[Epoch 11/50] [Batch 43/300] [D loss: 0.753326] [G loss: 0.655413] time: 0:16:39.916102\n",
      "0.90909785\n",
      "[Epoch 11/50] [Batch 44/300] [D loss: 0.753350] [G loss: 0.662682] time: 0:16:40.211015\n",
      "0.939248\n",
      "[Epoch 11/50] [Batch 45/300] [D loss: 0.753364] [G loss: 0.636782] time: 0:16:40.512050\n",
      "0.9133912\n",
      "[Epoch 11/50] [Batch 46/300] [D loss: 0.753329] [G loss: 0.601773] time: 0:16:40.816207\n",
      "0.9033658\n",
      "[Epoch 11/50] [Batch 47/300] [D loss: 0.753335] [G loss: 0.609064] time: 0:16:41.102894\n",
      "0.93171865\n",
      "[Epoch 11/50] [Batch 48/300] [D loss: 0.753401] [G loss: 0.678953] time: 0:16:41.401357\n",
      "0.86058235\n",
      "[Epoch 11/50] [Batch 49/300] [D loss: 0.753289] [G loss: 0.592291] time: 0:16:41.687812\n",
      "0.9250036\n",
      "[Epoch 11/50] [Batch 50/300] [D loss: 0.753350] [G loss: 0.616990] time: 0:16:41.996023\n",
      "0.93454653\n",
      "[Epoch 11/50] [Batch 51/300] [D loss: 0.753371] [G loss: 0.586525] time: 0:16:42.297791\n",
      "0.9127036\n",
      "[Epoch 11/50] [Batch 52/300] [D loss: 0.753352] [G loss: 0.645518] time: 0:16:42.595887\n",
      "0.90502375\n",
      "[Epoch 11/50] [Batch 53/300] [D loss: 0.753408] [G loss: 0.600710] time: 0:16:42.883454\n",
      "0.90971136\n",
      "[Epoch 11/50] [Batch 54/300] [D loss: 0.753315] [G loss: 0.632257] time: 0:16:43.161711\n",
      "0.9307745\n",
      "[Epoch 11/50] [Batch 55/300] [D loss: 0.753332] [G loss: 0.585793] time: 0:16:43.456797\n",
      "0.9333167\n",
      "[Epoch 11/50] [Batch 56/300] [D loss: 0.753364] [G loss: 0.646276] time: 0:16:43.757044\n",
      "0.9321378\n",
      "[Epoch 11/50] [Batch 57/300] [D loss: 0.753349] [G loss: 0.756752] time: 0:16:44.082265\n",
      "0.92286533\n",
      "[Epoch 11/50] [Batch 58/300] [D loss: 0.753369] [G loss: 0.763610] time: 0:16:44.380555\n",
      "0.89370877\n",
      "[Epoch 11/50] [Batch 59/300] [D loss: 0.753345] [G loss: 0.657040] time: 0:16:44.677613\n",
      "0.93872756\n",
      "[Epoch 11/50] [Batch 60/300] [D loss: 0.753332] [G loss: 0.717424] time: 0:16:44.995250\n",
      "0.9149304\n",
      "[Epoch 11/50] [Batch 61/300] [D loss: 0.753318] [G loss: 0.645043] time: 0:16:45.288448\n",
      "0.8864476\n",
      "[Epoch 11/50] [Batch 62/300] [D loss: 0.753330] [G loss: 0.626165] time: 0:16:45.590564\n",
      "0.8993244\n",
      "[Epoch 11/50] [Batch 63/300] [D loss: 0.753309] [G loss: 0.628003] time: 0:16:45.883842\n",
      "0.9201679\n",
      "[Epoch 11/50] [Batch 64/300] [D loss: 0.753333] [G loss: 0.740856] time: 0:16:46.199064\n",
      "0.9142204\n",
      "[Epoch 11/50] [Batch 65/300] [D loss: 0.753343] [G loss: 0.583000] time: 0:16:46.498931\n",
      "0.89080316\n",
      "[Epoch 11/50] [Batch 66/300] [D loss: 0.753350] [G loss: 0.648817] time: 0:16:46.798689\n",
      "0.91318065\n",
      "[Epoch 11/50] [Batch 67/300] [D loss: 0.753324] [G loss: 0.736047] time: 0:16:47.107849\n",
      "0.9165695\n",
      "[Epoch 11/50] [Batch 68/300] [D loss: 0.753311] [G loss: 0.672023] time: 0:16:47.406015\n",
      "0.9458079\n",
      "[Epoch 11/50] [Batch 69/300] [D loss: 0.753322] [G loss: 0.619964] time: 0:16:47.700535\n",
      "0.9753205\n",
      "[Epoch 11/50] [Batch 70/300] [D loss: 0.753355] [G loss: 0.620155] time: 0:16:48.020512\n",
      "0.9074219\n",
      "[Epoch 11/50] [Batch 71/300] [D loss: 0.753282] [G loss: 0.774477] time: 0:16:48.308898\n",
      "0.9177971\n",
      "[Epoch 11/50] [Batch 72/300] [D loss: 0.753360] [G loss: 0.592383] time: 0:16:48.612817\n",
      "0.94786483\n",
      "[Epoch 11/50] [Batch 73/300] [D loss: 0.753331] [G loss: 0.683826] time: 0:16:48.904232\n",
      "0.95817715\n",
      "[Epoch 11/50] [Batch 74/300] [D loss: 0.753348] [G loss: 0.618354] time: 0:16:49.201591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92206717\n",
      "[Epoch 11/50] [Batch 75/300] [D loss: 0.753373] [G loss: 0.666934] time: 0:16:49.511474\n",
      "0.89580816\n",
      "[Epoch 11/50] [Batch 76/300] [D loss: 0.753336] [G loss: 0.641485] time: 0:16:49.813690\n",
      "0.8999853\n",
      "[Epoch 11/50] [Batch 77/300] [D loss: 0.753299] [G loss: 0.624560] time: 0:16:50.121384\n",
      "0.9373562\n",
      "[Epoch 11/50] [Batch 78/300] [D loss: 0.753340] [G loss: 0.634500] time: 0:16:50.430220\n",
      "0.94786423\n",
      "[Epoch 11/50] [Batch 79/300] [D loss: 0.753331] [G loss: 0.628250] time: 0:16:50.732080\n",
      "0.8410578\n",
      "[Epoch 11/50] [Batch 80/300] [D loss: 0.753359] [G loss: 0.614629] time: 0:16:51.030878\n",
      "0.93578917\n",
      "[Epoch 11/50] [Batch 81/300] [D loss: 0.753375] [G loss: 0.644662] time: 0:16:51.328792\n",
      "0.91968244\n",
      "[Epoch 11/50] [Batch 82/300] [D loss: 0.753283] [G loss: 0.718086] time: 0:16:51.631594\n",
      "0.9163633\n",
      "[Epoch 11/50] [Batch 83/300] [D loss: 0.753360] [G loss: 0.669158] time: 0:16:51.932327\n",
      "0.9088283\n",
      "[Epoch 11/50] [Batch 84/300] [D loss: 0.753358] [G loss: 0.640611] time: 0:16:52.227815\n",
      "0.94038874\n",
      "[Epoch 11/50] [Batch 85/300] [D loss: 0.753352] [G loss: 0.640827] time: 0:16:52.536856\n",
      "0.90418667\n",
      "[Epoch 11/50] [Batch 86/300] [D loss: 0.753333] [G loss: 0.653474] time: 0:16:52.829652\n",
      "0.8993066\n",
      "[Epoch 11/50] [Batch 87/300] [D loss: 0.753297] [G loss: 0.690254] time: 0:16:53.134888\n",
      "0.9098527\n",
      "[Epoch 11/50] [Batch 88/300] [D loss: 0.753333] [G loss: 0.707358] time: 0:16:53.424168\n",
      "0.91479516\n",
      "[Epoch 11/50] [Batch 89/300] [D loss: 0.753333] [G loss: 0.688636] time: 0:16:53.728810\n",
      "0.8525142\n",
      "[Epoch 11/50] [Batch 90/300] [D loss: 0.753313] [G loss: 0.666196] time: 0:16:54.043714\n",
      "0.8966267\n",
      "[Epoch 11/50] [Batch 91/300] [D loss: 0.753380] [G loss: 0.681779] time: 0:16:54.341322\n",
      "0.88677937\n",
      "[Epoch 11/50] [Batch 92/300] [D loss: 0.753356] [G loss: 0.611377] time: 0:16:54.651100\n",
      "0.9344995\n",
      "[Epoch 11/50] [Batch 93/300] [D loss: 0.753318] [G loss: 0.625904] time: 0:16:54.950451\n",
      "0.95676446\n",
      "[Epoch 11/50] [Batch 94/300] [D loss: 0.753347] [G loss: 0.654219] time: 0:16:55.244002\n",
      "0.9279828\n",
      "[Epoch 11/50] [Batch 95/300] [D loss: 0.753323] [G loss: 0.700197] time: 0:16:55.547325\n",
      "0.92276734\n",
      "[Epoch 11/50] [Batch 96/300] [D loss: 0.753376] [G loss: 0.634051] time: 0:16:55.844127\n",
      "0.8943839\n",
      "[Epoch 11/50] [Batch 97/300] [D loss: 0.753346] [G loss: 0.694607] time: 0:16:56.123440\n",
      "0.8956234\n",
      "[Epoch 11/50] [Batch 98/300] [D loss: 0.753389] [G loss: 0.621051] time: 0:16:56.418637\n",
      "0.9182539\n",
      "[Epoch 11/50] [Batch 99/300] [D loss: 0.753306] [G loss: 0.713610] time: 0:16:56.718709\n",
      "0.918529\n",
      "[Epoch 11/50] [Batch 100/300] [D loss: 0.753274] [G loss: 0.706822] time: 0:16:57.025592\n",
      "0.9251025\n",
      "[Epoch 11/50] [Batch 101/300] [D loss: 0.753355] [G loss: 0.658342] time: 0:16:57.321116\n",
      "0.9616728\n",
      "[Epoch 11/50] [Batch 102/300] [D loss: 0.753328] [G loss: 0.643696] time: 0:16:57.635065\n",
      "0.88942283\n",
      "[Epoch 11/50] [Batch 103/300] [D loss: 0.753334] [G loss: 0.611588] time: 0:16:57.919913\n",
      "0.9120002\n",
      "[Epoch 11/50] [Batch 104/300] [D loss: 0.753337] [G loss: 0.615817] time: 0:16:58.224755\n",
      "0.8774996\n",
      "[Epoch 11/50] [Batch 105/300] [D loss: 0.753272] [G loss: 0.675163] time: 0:16:58.520946\n",
      "0.87389284\n",
      "[Epoch 11/50] [Batch 106/300] [D loss: 0.753343] [G loss: 0.624079] time: 0:16:58.840029\n",
      "0.9211702\n",
      "[Epoch 11/50] [Batch 107/300] [D loss: 0.753337] [G loss: 0.691423] time: 0:16:59.148959\n",
      "0.9107595\n",
      "[Epoch 11/50] [Batch 108/300] [D loss: 0.753337] [G loss: 0.658838] time: 0:16:59.449755\n",
      "0.9196568\n",
      "[Epoch 11/50] [Batch 109/300] [D loss: 0.753299] [G loss: 0.614595] time: 0:16:59.746017\n",
      "0.9299798\n",
      "[Epoch 11/50] [Batch 110/300] [D loss: 0.753316] [G loss: 0.717151] time: 0:17:00.040810\n",
      "0.90635234\n",
      "[Epoch 11/50] [Batch 111/300] [D loss: 0.753331] [G loss: 0.636802] time: 0:17:00.347507\n",
      "0.96465796\n",
      "[Epoch 11/50] [Batch 112/300] [D loss: 0.753283] [G loss: 0.695657] time: 0:17:00.644224\n",
      "0.9453704\n",
      "[Epoch 11/50] [Batch 113/300] [D loss: 0.753307] [G loss: 0.680711] time: 0:17:00.943951\n",
      "0.90515524\n",
      "[Epoch 11/50] [Batch 114/300] [D loss: 0.753285] [G loss: 0.668115] time: 0:17:01.240903\n",
      "0.9554649\n",
      "[Epoch 11/50] [Batch 115/300] [D loss: 0.753365] [G loss: 0.672923] time: 0:17:01.546559\n",
      "0.9266136\n",
      "[Epoch 11/50] [Batch 116/300] [D loss: 0.753262] [G loss: 0.653659] time: 0:17:01.840618\n",
      "0.94160247\n",
      "[Epoch 11/50] [Batch 117/300] [D loss: 0.753279] [G loss: 0.633873] time: 0:17:02.144510\n",
      "0.853784\n",
      "[Epoch 11/50] [Batch 118/300] [D loss: 0.753312] [G loss: 0.715981] time: 0:17:02.431803\n",
      "0.9476306\n",
      "[Epoch 11/50] [Batch 119/300] [D loss: 0.753282] [G loss: 0.720986] time: 0:17:02.742181\n",
      "0.8827695\n",
      "[Epoch 11/50] [Batch 120/300] [D loss: 0.753327] [G loss: 0.635254] time: 0:17:03.048890\n",
      "0.92200947\n",
      "[Epoch 11/50] [Batch 121/300] [D loss: 0.753282] [G loss: 0.646463] time: 0:17:03.363591\n",
      "0.96622753\n",
      "[Epoch 11/50] [Batch 122/300] [D loss: 0.753294] [G loss: 0.656124] time: 0:17:03.668053\n",
      "0.9293458\n",
      "[Epoch 11/50] [Batch 123/300] [D loss: 0.753293] [G loss: 0.657360] time: 0:17:03.966490\n",
      "0.8939691\n",
      "[Epoch 11/50] [Batch 124/300] [D loss: 0.753269] [G loss: 0.641439] time: 0:17:04.252662\n",
      "0.900572\n",
      "[Epoch 11/50] [Batch 125/300] [D loss: 0.753281] [G loss: 0.616154] time: 0:17:04.581043\n",
      "0.90475935\n",
      "[Epoch 11/50] [Batch 126/300] [D loss: 0.753352] [G loss: 0.618421] time: 0:17:04.879261\n",
      "0.939472\n",
      "[Epoch 11/50] [Batch 127/300] [D loss: 0.753331] [G loss: 0.639794] time: 0:17:05.160194\n",
      "0.97586966\n",
      "[Epoch 11/50] [Batch 128/300] [D loss: 0.753351] [G loss: 0.587619] time: 0:17:05.446952\n",
      "0.9162693\n",
      "[Epoch 11/50] [Batch 129/300] [D loss: 0.753307] [G loss: 0.715666] time: 0:17:05.732265\n",
      "0.8394525\n",
      "[Epoch 11/50] [Batch 130/300] [D loss: 0.753342] [G loss: 0.682588] time: 0:17:06.031095\n",
      "0.93042326\n",
      "[Epoch 11/50] [Batch 131/300] [D loss: 0.753345] [G loss: 0.640805] time: 0:17:06.332690\n",
      "0.95071864\n",
      "[Epoch 11/50] [Batch 132/300] [D loss: 0.753287] [G loss: 0.647675] time: 0:17:06.631927\n",
      "0.88992715\n",
      "[Epoch 11/50] [Batch 133/300] [D loss: 0.753288] [G loss: 0.613578] time: 0:17:06.926814\n",
      "0.9219133\n",
      "[Epoch 11/50] [Batch 134/300] [D loss: 0.753348] [G loss: 0.617960] time: 0:17:07.221795\n",
      "0.92621154\n",
      "[Epoch 11/50] [Batch 135/300] [D loss: 0.753312] [G loss: 0.605095] time: 0:17:07.513946\n",
      "0.8991001\n",
      "[Epoch 11/50] [Batch 136/300] [D loss: 0.753358] [G loss: 0.574655] time: 0:17:07.799291\n",
      "0.9336429\n",
      "[Epoch 11/50] [Batch 137/300] [D loss: 0.753292] [G loss: 0.719902] time: 0:17:08.100106\n",
      "0.89747316\n",
      "[Epoch 11/50] [Batch 138/300] [D loss: 0.753300] [G loss: 0.621942] time: 0:17:08.396856\n",
      "0.90352315\n",
      "[Epoch 11/50] [Batch 139/300] [D loss: 0.753345] [G loss: 0.643244] time: 0:17:08.696080\n",
      "0.9055578\n",
      "[Epoch 11/50] [Batch 140/300] [D loss: 0.753216] [G loss: 0.704933] time: 0:17:08.984307\n",
      "0.9253716\n",
      "[Epoch 11/50] [Batch 141/300] [D loss: 0.753291] [G loss: 0.662481] time: 0:17:09.289393\n",
      "0.9091099\n",
      "[Epoch 11/50] [Batch 142/300] [D loss: 0.753300] [G loss: 0.613141] time: 0:17:09.579939\n",
      "0.9083745\n",
      "[Epoch 11/50] [Batch 143/300] [D loss: 0.753308] [G loss: 0.657926] time: 0:17:09.865320\n",
      "0.9160637\n",
      "[Epoch 11/50] [Batch 144/300] [D loss: 0.753267] [G loss: 0.592276] time: 0:17:10.167541\n",
      "0.9211455\n",
      "[Epoch 11/50] [Batch 145/300] [D loss: 0.753302] [G loss: 0.683294] time: 0:17:10.482957\n",
      "0.9537266\n",
      "[Epoch 11/50] [Batch 146/300] [D loss: 0.753315] [G loss: 0.699385] time: 0:17:10.776649\n",
      "0.8798472\n",
      "[Epoch 11/50] [Batch 147/300] [D loss: 0.753312] [G loss: 0.645169] time: 0:17:11.081386\n",
      "0.97569674\n",
      "[Epoch 11/50] [Batch 148/300] [D loss: 0.753274] [G loss: 0.676329] time: 0:17:11.371011\n",
      "0.8908681\n",
      "[Epoch 11/50] [Batch 149/300] [D loss: 0.753271] [G loss: 0.662318] time: 0:17:11.678604\n",
      "0.94528157\n",
      "[Epoch 11/50] [Batch 150/300] [D loss: 0.753363] [G loss: 0.652041] time: 0:17:11.993908\n",
      "0.94012374\n",
      "[Epoch 11/50] [Batch 151/300] [D loss: 0.753268] [G loss: 0.751989] time: 0:17:12.278494\n",
      "0.9005692\n",
      "[Epoch 11/50] [Batch 152/300] [D loss: 0.753270] [G loss: 0.667968] time: 0:17:12.560641\n",
      "0.9600356\n",
      "[Epoch 11/50] [Batch 153/300] [D loss: 0.753240] [G loss: 0.637857] time: 0:17:12.871555\n",
      "0.92690325\n",
      "[Epoch 11/50] [Batch 154/300] [D loss: 0.753329] [G loss: 0.642470] time: 0:17:13.157498\n",
      "0.934432\n",
      "[Epoch 11/50] [Batch 155/300] [D loss: 0.753305] [G loss: 0.668578] time: 0:17:13.446436\n",
      "0.95409465\n",
      "[Epoch 11/50] [Batch 156/300] [D loss: 0.753286] [G loss: 0.808279] time: 0:17:13.754824\n",
      "0.9118177\n",
      "[Epoch 11/50] [Batch 157/300] [D loss: 0.753311] [G loss: 0.646198] time: 0:17:14.057388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95302963\n",
      "[Epoch 11/50] [Batch 158/300] [D loss: 0.753262] [G loss: 0.666750] time: 0:17:14.370413\n",
      "0.94611716\n",
      "[Epoch 11/50] [Batch 159/300] [D loss: 0.753321] [G loss: 0.666828] time: 0:17:14.657999\n",
      "0.91166\n",
      "[Epoch 11/50] [Batch 160/300] [D loss: 0.753292] [G loss: 0.645350] time: 0:17:14.955071\n",
      "0.9143622\n",
      "[Epoch 11/50] [Batch 161/300] [D loss: 0.753284] [G loss: 0.624498] time: 0:17:15.247699\n",
      "0.9231503\n",
      "[Epoch 11/50] [Batch 162/300] [D loss: 0.753303] [G loss: 0.594844] time: 0:17:15.553331\n",
      "0.90958476\n",
      "[Epoch 11/50] [Batch 163/300] [D loss: 0.753301] [G loss: 0.642187] time: 0:17:15.845788\n",
      "0.8823433\n",
      "[Epoch 11/50] [Batch 164/300] [D loss: 0.753282] [G loss: 0.696911] time: 0:17:16.139727\n",
      "0.8956299\n",
      "[Epoch 11/50] [Batch 165/300] [D loss: 0.753256] [G loss: 0.682289] time: 0:17:16.448291\n",
      "0.8676155\n",
      "[Epoch 11/50] [Batch 166/300] [D loss: 0.753319] [G loss: 0.672214] time: 0:17:16.746847\n",
      "0.91594297\n",
      "[Epoch 11/50] [Batch 167/300] [D loss: 0.753280] [G loss: 0.632383] time: 0:17:17.054807\n",
      "0.9161332\n",
      "[Epoch 11/50] [Batch 168/300] [D loss: 0.753288] [G loss: 0.719526] time: 0:17:17.354305\n",
      "0.9032218\n",
      "[Epoch 11/50] [Batch 169/300] [D loss: 0.753302] [G loss: 0.660787] time: 0:17:17.653005\n",
      "0.929974\n",
      "[Epoch 11/50] [Batch 170/300] [D loss: 0.753244] [G loss: 0.646891] time: 0:17:17.948208\n",
      "0.9148903\n",
      "[Epoch 11/50] [Batch 171/300] [D loss: 0.753235] [G loss: 0.661132] time: 0:17:18.240434\n",
      "0.91984826\n",
      "[Epoch 11/50] [Batch 172/300] [D loss: 0.753317] [G loss: 0.605151] time: 0:17:18.541162\n",
      "0.92191464\n",
      "[Epoch 11/50] [Batch 173/300] [D loss: 0.753282] [G loss: 0.576454] time: 0:17:18.857573\n",
      "0.9583395\n",
      "[Epoch 11/50] [Batch 174/300] [D loss: 0.753269] [G loss: 0.607501] time: 0:17:19.172843\n",
      "0.9579962\n",
      "[Epoch 11/50] [Batch 175/300] [D loss: 0.753304] [G loss: 0.628122] time: 0:17:19.481087\n",
      "0.91617537\n",
      "[Epoch 11/50] [Batch 176/300] [D loss: 0.753379] [G loss: 0.613765] time: 0:17:19.776984\n",
      "0.90353227\n",
      "[Epoch 11/50] [Batch 177/300] [D loss: 0.753330] [G loss: 0.647246] time: 0:17:20.069112\n",
      "0.94000465\n",
      "[Epoch 11/50] [Batch 178/300] [D loss: 0.753291] [G loss: 0.652750] time: 0:17:20.345346\n",
      "0.9127502\n",
      "[Epoch 11/50] [Batch 179/300] [D loss: 0.753300] [G loss: 0.607456] time: 0:17:20.645146\n",
      "0.9378696\n",
      "[Epoch 11/50] [Batch 180/300] [D loss: 0.753303] [G loss: 0.662379] time: 0:17:20.933444\n",
      "0.9273091\n",
      "[Epoch 11/50] [Batch 181/300] [D loss: 0.753240] [G loss: 0.669426] time: 0:17:21.210181\n",
      "0.9383948\n",
      "[Epoch 11/50] [Batch 182/300] [D loss: 0.753298] [G loss: 0.612906] time: 0:17:21.483169\n",
      "0.9388814\n",
      "[Epoch 11/50] [Batch 183/300] [D loss: 0.753286] [G loss: 0.669006] time: 0:17:21.776535\n",
      "0.90737873\n",
      "[Epoch 11/50] [Batch 184/300] [D loss: 0.753289] [G loss: 0.651034] time: 0:17:22.078579\n",
      "0.90852404\n",
      "[Epoch 11/50] [Batch 185/300] [D loss: 0.753272] [G loss: 0.630233] time: 0:17:22.386904\n",
      "0.8853903\n",
      "[Epoch 11/50] [Batch 186/300] [D loss: 0.753239] [G loss: 0.823780] time: 0:17:22.671300\n",
      "0.8848374\n",
      "[Epoch 11/50] [Batch 187/300] [D loss: 0.753295] [G loss: 0.707444] time: 0:17:22.973059\n",
      "0.9049828\n",
      "[Epoch 11/50] [Batch 188/300] [D loss: 0.753271] [G loss: 0.654914] time: 0:17:23.270034\n",
      "0.91726273\n",
      "[Epoch 11/50] [Batch 189/300] [D loss: 0.753291] [G loss: 0.624936] time: 0:17:23.568117\n",
      "0.9160878\n",
      "[Epoch 11/50] [Batch 190/300] [D loss: 0.753270] [G loss: 0.661034] time: 0:17:23.848918\n",
      "0.9370908\n",
      "[Epoch 11/50] [Batch 191/300] [D loss: 0.753320] [G loss: 0.653958] time: 0:17:24.159716\n",
      "0.91076183\n",
      "[Epoch 11/50] [Batch 192/300] [D loss: 0.753295] [G loss: 0.651437] time: 0:17:24.470527\n",
      "0.9830025\n",
      "[Epoch 11/50] [Batch 193/300] [D loss: 0.753298] [G loss: 0.632217] time: 0:17:24.758629\n",
      "0.9551999\n",
      "[Epoch 11/50] [Batch 194/300] [D loss: 0.753253] [G loss: 0.655696] time: 0:17:25.042036\n",
      "0.88085717\n",
      "[Epoch 11/50] [Batch 195/300] [D loss: 0.753264] [G loss: 0.632727] time: 0:17:25.334030\n",
      "0.9467006\n",
      "[Epoch 11/50] [Batch 196/300] [D loss: 0.753313] [G loss: 0.634356] time: 0:17:25.639371\n",
      "0.90421486\n",
      "[Epoch 11/50] [Batch 197/300] [D loss: 0.753278] [G loss: 0.633039] time: 0:17:25.930883\n",
      "0.90269566\n",
      "[Epoch 11/50] [Batch 198/300] [D loss: 0.753276] [G loss: 0.619618] time: 0:17:26.240510\n",
      "0.9603761\n",
      "[Epoch 11/50] [Batch 199/300] [D loss: 0.753258] [G loss: 0.613964] time: 0:17:26.541989\n",
      "0.880179\n",
      "[Epoch 11/50] [Batch 200/300] [D loss: 0.753271] [G loss: 0.678968] time: 0:17:26.841467\n",
      "0.9836294\n",
      "[Epoch 11/50] [Batch 201/300] [D loss: 0.753326] [G loss: 0.691748] time: 0:17:27.145366\n",
      "0.87962514\n",
      "[Epoch 11/50] [Batch 202/300] [D loss: 0.753286] [G loss: 0.648547] time: 0:17:27.439725\n",
      "0.9278577\n",
      "[Epoch 11/50] [Batch 203/300] [D loss: 0.753346] [G loss: 0.648510] time: 0:17:27.735739\n",
      "0.94603515\n",
      "[Epoch 11/50] [Batch 204/300] [D loss: 0.753305] [G loss: 0.683699] time: 0:17:28.032952\n",
      "0.8924949\n",
      "[Epoch 11/50] [Batch 205/300] [D loss: 0.753309] [G loss: 0.694705] time: 0:17:28.339724\n",
      "0.9167041\n",
      "[Epoch 11/50] [Batch 206/300] [D loss: 0.753323] [G loss: 0.663649] time: 0:17:28.652158\n",
      "0.892251\n",
      "[Epoch 11/50] [Batch 207/300] [D loss: 0.753259] [G loss: 0.594467] time: 0:17:28.953297\n",
      "0.92023975\n",
      "[Epoch 11/50] [Batch 208/300] [D loss: 0.753298] [G loss: 0.635942] time: 0:17:29.254064\n",
      "0.89593536\n",
      "[Epoch 11/50] [Batch 209/300] [D loss: 0.753295] [G loss: 0.591037] time: 0:17:29.560995\n",
      "0.93800956\n",
      "[Epoch 11/50] [Batch 210/300] [D loss: 0.753284] [G loss: 0.739086] time: 0:17:29.854493\n",
      "0.925565\n",
      "[Epoch 11/50] [Batch 211/300] [D loss: 0.753261] [G loss: 0.634385] time: 0:17:30.159723\n",
      "0.9253228\n",
      "[Epoch 11/50] [Batch 212/300] [D loss: 0.753265] [G loss: 0.651087] time: 0:17:30.463783\n",
      "0.9185364\n",
      "[Epoch 11/50] [Batch 213/300] [D loss: 0.753293] [G loss: 0.612025] time: 0:17:30.754362\n",
      "0.9374587\n",
      "[Epoch 11/50] [Batch 214/300] [D loss: 0.753271] [G loss: 0.632054] time: 0:17:31.073567\n",
      "0.925932\n",
      "[Epoch 11/50] [Batch 215/300] [D loss: 0.753297] [G loss: 0.740848] time: 0:17:31.380211\n",
      "0.9470072\n",
      "[Epoch 11/50] [Batch 216/300] [D loss: 0.753281] [G loss: 0.700036] time: 0:17:31.685524\n",
      "0.92582756\n",
      "[Epoch 11/50] [Batch 217/300] [D loss: 0.753235] [G loss: 0.664855] time: 0:17:31.992349\n",
      "0.8925648\n",
      "[Epoch 11/50] [Batch 218/300] [D loss: 0.753297] [G loss: 0.662780] time: 0:17:32.273724\n",
      "0.91575235\n",
      "[Epoch 11/50] [Batch 219/300] [D loss: 0.753274] [G loss: 0.571442] time: 0:17:32.577484\n",
      "0.91365314\n",
      "[Epoch 11/50] [Batch 220/300] [D loss: 0.753254] [G loss: 0.699960] time: 0:17:32.874444\n",
      "0.93157214\n",
      "[Epoch 11/50] [Batch 221/300] [D loss: 0.753250] [G loss: 0.668289] time: 0:17:33.166683\n",
      "0.95356154\n",
      "[Epoch 11/50] [Batch 222/300] [D loss: 0.753254] [G loss: 0.642205] time: 0:17:33.465970\n",
      "0.936655\n",
      "[Epoch 11/50] [Batch 223/300] [D loss: 0.753282] [G loss: 0.608091] time: 0:17:33.754365\n",
      "0.901053\n",
      "[Epoch 11/50] [Batch 224/300] [D loss: 0.753264] [G loss: 0.691055] time: 0:17:34.054536\n",
      "0.8721946\n",
      "[Epoch 11/50] [Batch 225/300] [D loss: 0.753257] [G loss: 0.583349] time: 0:17:34.340798\n",
      "0.9190212\n",
      "[Epoch 11/50] [Batch 226/300] [D loss: 0.753300] [G loss: 0.565882] time: 0:17:34.624081\n",
      "0.9126036\n",
      "[Epoch 11/50] [Batch 227/300] [D loss: 0.753284] [G loss: 0.607490] time: 0:17:34.910304\n",
      "0.90961266\n",
      "[Epoch 11/50] [Batch 228/300] [D loss: 0.753291] [G loss: 0.729310] time: 0:17:35.218741\n",
      "0.898083\n",
      "[Epoch 11/50] [Batch 229/300] [D loss: 0.753321] [G loss: 0.578121] time: 0:17:35.503811\n",
      "0.89890665\n",
      "[Epoch 11/50] [Batch 230/300] [D loss: 0.753261] [G loss: 0.646391] time: 0:17:35.814747\n",
      "0.92401737\n",
      "[Epoch 11/50] [Batch 231/300] [D loss: 0.753290] [G loss: 0.653541] time: 0:17:36.110119\n",
      "0.96185964\n",
      "[Epoch 11/50] [Batch 232/300] [D loss: 0.753273] [G loss: 0.610435] time: 0:17:36.401819\n",
      "0.9570246\n",
      "[Epoch 11/50] [Batch 233/300] [D loss: 0.753224] [G loss: 0.669310] time: 0:17:36.714596\n",
      "0.9448121\n",
      "[Epoch 11/50] [Batch 234/300] [D loss: 0.753274] [G loss: 0.616241] time: 0:17:37.005057\n",
      "0.9558656\n",
      "[Epoch 11/50] [Batch 235/300] [D loss: 0.753239] [G loss: 0.677853] time: 0:17:37.287009\n",
      "0.94866633\n",
      "[Epoch 11/50] [Batch 236/300] [D loss: 0.753231] [G loss: 0.613023] time: 0:17:37.564309\n",
      "0.92103654\n",
      "[Epoch 11/50] [Batch 237/300] [D loss: 0.753273] [G loss: 0.655576] time: 0:17:37.860288\n",
      "0.9210558\n",
      "[Epoch 11/50] [Batch 238/300] [D loss: 0.753265] [G loss: 0.585445] time: 0:17:38.151378\n",
      "0.90826815\n",
      "[Epoch 11/50] [Batch 239/300] [D loss: 0.753266] [G loss: 0.656056] time: 0:17:38.446512\n",
      "0.9062081\n",
      "[Epoch 11/50] [Batch 240/300] [D loss: 0.753242] [G loss: 0.626342] time: 0:17:38.752818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491042\n",
      "[Epoch 11/50] [Batch 241/300] [D loss: 0.753199] [G loss: 0.679489] time: 0:17:39.032136\n",
      "0.9469042\n",
      "[Epoch 11/50] [Batch 242/300] [D loss: 0.753211] [G loss: 0.766247] time: 0:17:39.335230\n",
      "0.9417665\n",
      "[Epoch 11/50] [Batch 243/300] [D loss: 0.753277] [G loss: 0.603639] time: 0:17:39.644097\n",
      "0.954556\n",
      "[Epoch 11/50] [Batch 244/300] [D loss: 0.753294] [G loss: 0.619328] time: 0:17:39.928885\n",
      "0.932375\n",
      "[Epoch 11/50] [Batch 245/300] [D loss: 0.753265] [G loss: 0.615287] time: 0:17:40.231589\n",
      "0.92420167\n",
      "[Epoch 11/50] [Batch 246/300] [D loss: 0.753294] [G loss: 0.599618] time: 0:17:40.537739\n",
      "0.9046016\n",
      "[Epoch 11/50] [Batch 247/300] [D loss: 0.753276] [G loss: 0.629723] time: 0:17:40.852624\n",
      "0.9204665\n",
      "[Epoch 11/50] [Batch 248/300] [D loss: 0.753297] [G loss: 0.574607] time: 0:17:41.125595\n",
      "0.9297896\n",
      "[Epoch 11/50] [Batch 249/300] [D loss: 0.753301] [G loss: 0.636344] time: 0:17:41.427997\n",
      "0.91034675\n",
      "[Epoch 11/50] [Batch 250/300] [D loss: 0.753211] [G loss: 0.729409] time: 0:17:41.725708\n",
      "0.93731254\n",
      "[Epoch 11/50] [Batch 251/300] [D loss: 0.753302] [G loss: 0.661526] time: 0:17:42.018272\n",
      "0.90066695\n",
      "[Epoch 11/50] [Batch 252/300] [D loss: 0.753246] [G loss: 0.642310] time: 0:17:42.308219\n",
      "0.9114317\n",
      "[Epoch 11/50] [Batch 253/300] [D loss: 0.753304] [G loss: 0.672597] time: 0:17:42.623713\n",
      "0.9121912\n",
      "[Epoch 11/50] [Batch 254/300] [D loss: 0.753215] [G loss: 0.662291] time: 0:17:42.907929\n",
      "0.9133466\n",
      "[Epoch 11/50] [Batch 255/300] [D loss: 0.753196] [G loss: 0.646602] time: 0:17:43.216774\n",
      "0.8706046\n",
      "[Epoch 11/50] [Batch 256/300] [D loss: 0.753266] [G loss: 0.662438] time: 0:17:43.526731\n",
      "0.8737626\n",
      "[Epoch 11/50] [Batch 257/300] [D loss: 0.753304] [G loss: 0.591566] time: 0:17:43.827055\n",
      "0.9481097\n",
      "[Epoch 11/50] [Batch 258/300] [D loss: 0.753265] [G loss: 0.627579] time: 0:17:44.127599\n",
      "0.90199596\n",
      "[Epoch 11/50] [Batch 259/300] [D loss: 0.753263] [G loss: 0.665206] time: 0:17:44.415431\n",
      "0.9176359\n",
      "[Epoch 11/50] [Batch 260/300] [D loss: 0.753264] [G loss: 0.619108] time: 0:17:44.714771\n",
      "0.8906832\n",
      "[Epoch 11/50] [Batch 261/300] [D loss: 0.753253] [G loss: 0.620178] time: 0:17:45.017311\n",
      "0.9187712\n",
      "[Epoch 11/50] [Batch 262/300] [D loss: 0.753268] [G loss: 0.585550] time: 0:17:45.316919\n",
      "0.8907234\n",
      "[Epoch 11/50] [Batch 263/300] [D loss: 0.753279] [G loss: 0.623573] time: 0:17:45.606147\n",
      "0.9255952\n",
      "[Epoch 11/50] [Batch 264/300] [D loss: 0.753239] [G loss: 0.768317] time: 0:17:45.907762\n",
      "0.9392622\n",
      "[Epoch 11/50] [Batch 265/300] [D loss: 0.753242] [G loss: 0.626908] time: 0:17:46.210794\n",
      "0.9237506\n",
      "[Epoch 11/50] [Batch 266/300] [D loss: 0.753274] [G loss: 0.626061] time: 0:17:46.528621\n",
      "0.913189\n",
      "[Epoch 11/50] [Batch 267/300] [D loss: 0.753211] [G loss: 0.676331] time: 0:17:46.820549\n",
      "0.8814948\n",
      "[Epoch 11/50] [Batch 268/300] [D loss: 0.753217] [G loss: 0.669550] time: 0:17:47.120162\n",
      "0.9558396\n",
      "[Epoch 11/50] [Batch 269/300] [D loss: 0.753204] [G loss: 0.695313] time: 0:17:47.424313\n",
      "0.93006164\n",
      "[Epoch 11/50] [Batch 270/300] [D loss: 0.753284] [G loss: 0.733377] time: 0:17:47.729478\n",
      "0.95391923\n",
      "[Epoch 11/50] [Batch 271/300] [D loss: 0.753320] [G loss: 0.681779] time: 0:17:48.034240\n",
      "0.91188806\n",
      "[Epoch 11/50] [Batch 272/300] [D loss: 0.753222] [G loss: 0.690706] time: 0:17:48.340964\n",
      "0.9363656\n",
      "[Epoch 11/50] [Batch 273/300] [D loss: 0.753269] [G loss: 0.606980] time: 0:17:48.661165\n",
      "0.9168401\n",
      "[Epoch 11/50] [Batch 274/300] [D loss: 0.753221] [G loss: 0.617014] time: 0:17:48.971959\n",
      "0.9009652\n",
      "[Epoch 11/50] [Batch 275/300] [D loss: 0.753256] [G loss: 0.645642] time: 0:17:49.269841\n",
      "0.9033297\n",
      "[Epoch 11/50] [Batch 276/300] [D loss: 0.753239] [G loss: 0.630243] time: 0:17:49.566172\n",
      "0.9291243\n",
      "[Epoch 11/50] [Batch 277/300] [D loss: 0.753291] [G loss: 0.652877] time: 0:17:49.853137\n",
      "0.90664005\n",
      "[Epoch 11/50] [Batch 278/300] [D loss: 0.753246] [G loss: 0.588135] time: 0:17:50.162692\n",
      "0.9180467\n",
      "[Epoch 11/50] [Batch 279/300] [D loss: 0.753234] [G loss: 0.570691] time: 0:17:50.477598\n",
      "0.94276935\n",
      "[Epoch 11/50] [Batch 280/300] [D loss: 0.753270] [G loss: 0.621351] time: 0:17:50.779169\n",
      "0.9353754\n",
      "[Epoch 11/50] [Batch 281/300] [D loss: 0.753210] [G loss: 0.682676] time: 0:17:51.080177\n",
      "0.9081138\n",
      "[Epoch 11/50] [Batch 282/300] [D loss: 0.753209] [G loss: 0.673705] time: 0:17:51.376601\n",
      "0.88588095\n",
      "[Epoch 11/50] [Batch 283/300] [D loss: 0.753238] [G loss: 0.613804] time: 0:17:51.674455\n",
      "0.94448334\n",
      "[Epoch 11/50] [Batch 284/300] [D loss: 0.753280] [G loss: 0.605572] time: 0:17:51.957612\n",
      "0.9160397\n",
      "[Epoch 11/50] [Batch 285/300] [D loss: 0.753230] [G loss: 0.651843] time: 0:17:52.255314\n",
      "0.9368832\n",
      "[Epoch 11/50] [Batch 286/300] [D loss: 0.753320] [G loss: 0.615881] time: 0:17:52.553714\n",
      "0.96105504\n",
      "[Epoch 11/50] [Batch 287/300] [D loss: 0.753259] [G loss: 0.701741] time: 0:17:52.841333\n",
      "0.91188526\n",
      "[Epoch 11/50] [Batch 288/300] [D loss: 0.753233] [G loss: 0.729907] time: 0:17:53.131248\n",
      "0.92728096\n",
      "[Epoch 11/50] [Batch 289/300] [D loss: 0.753230] [G loss: 0.661771] time: 0:17:53.433819\n",
      "0.8662626\n",
      "[Epoch 11/50] [Batch 290/300] [D loss: 0.753233] [G loss: 0.654508] time: 0:17:53.732903\n",
      "0.9203394\n",
      "[Epoch 11/50] [Batch 291/300] [D loss: 0.753284] [G loss: 0.614489] time: 0:17:54.061843\n",
      "0.942252\n",
      "[Epoch 11/50] [Batch 292/300] [D loss: 0.753229] [G loss: 0.737466] time: 0:17:54.359956\n",
      "0.9109695\n",
      "[Epoch 11/50] [Batch 293/300] [D loss: 0.753258] [G loss: 0.600625] time: 0:17:54.656986\n",
      "0.88238615\n",
      "[Epoch 11/50] [Batch 294/300] [D loss: 0.753207] [G loss: 0.665246] time: 0:17:54.945985\n",
      "0.8821042\n",
      "[Epoch 11/50] [Batch 295/300] [D loss: 0.753206] [G loss: 0.602791] time: 0:17:55.255087\n",
      "0.88979965\n",
      "[Epoch 11/50] [Batch 296/300] [D loss: 0.753205] [G loss: 0.638083] time: 0:17:55.556472\n",
      "0.9166441\n",
      "[Epoch 11/50] [Batch 297/300] [D loss: 0.753230] [G loss: 0.613026] time: 0:17:55.855200\n",
      "0.90371925\n",
      "[Epoch 11/50] [Batch 298/300] [D loss: 0.753164] [G loss: 0.701420] time: 0:17:56.153516\n",
      "0.91858095\n",
      "[Epoch 11/50] [Batch 299/300] [D loss: 0.753216] [G loss: 0.674044] time: 0:17:56.447086\n",
      "0.95528346\n",
      "[Epoch 12/50] [Batch 0/300] [D loss: 0.753218] [G loss: 0.631101] time: 0:17:56.761323\n",
      "0.9174404\n",
      "[Epoch 12/50] [Batch 1/300] [D loss: 0.753218] [G loss: 0.603463] time: 0:17:57.057478\n",
      "0.90345067\n",
      "[Epoch 12/50] [Batch 2/300] [D loss: 0.753205] [G loss: 0.577696] time: 0:17:57.367938\n",
      "0.9165757\n",
      "[Epoch 12/50] [Batch 3/300] [D loss: 0.753247] [G loss: 0.657237] time: 0:17:57.680335\n",
      "0.9080619\n",
      "[Epoch 12/50] [Batch 4/300] [D loss: 0.753193] [G loss: 0.594109] time: 0:17:57.980715\n",
      "0.87193173\n",
      "[Epoch 12/50] [Batch 5/300] [D loss: 0.753224] [G loss: 0.595961] time: 0:17:58.273716\n",
      "0.8892948\n",
      "[Epoch 12/50] [Batch 6/300] [D loss: 0.753224] [G loss: 0.637892] time: 0:17:58.571075\n",
      "0.9067345\n",
      "[Epoch 12/50] [Batch 7/300] [D loss: 0.753188] [G loss: 0.589185] time: 0:17:58.853355\n",
      "0.96309453\n",
      "[Epoch 12/50] [Batch 8/300] [D loss: 0.753248] [G loss: 0.652572] time: 0:17:59.147768\n",
      "0.9339302\n",
      "[Epoch 12/50] [Batch 9/300] [D loss: 0.753228] [G loss: 0.667682] time: 0:17:59.412926\n",
      "0.9678897\n",
      "[Epoch 12/50] [Batch 10/300] [D loss: 0.753218] [G loss: 0.655828] time: 0:17:59.712818\n",
      "0.9124637\n",
      "[Epoch 12/50] [Batch 12/300] [D loss: 0.753271] [G loss: 0.648411] time: 0:18:00.007841\n",
      "0.95536804\n",
      "[Epoch 12/50] [Batch 13/300] [D loss: 0.753217] [G loss: 0.613627] time: 0:18:00.316462\n",
      "0.925329\n",
      "[Epoch 12/50] [Batch 14/300] [D loss: 0.753188] [G loss: 0.617574] time: 0:18:00.601447\n",
      "0.9070925\n",
      "[Epoch 12/50] [Batch 15/300] [D loss: 0.753264] [G loss: 0.571729] time: 0:18:00.898135\n",
      "0.9166028\n",
      "[Epoch 12/50] [Batch 16/300] [D loss: 0.753199] [G loss: 0.588517] time: 0:18:01.191541\n",
      "0.9395762\n",
      "[Epoch 12/50] [Batch 17/300] [D loss: 0.753187] [G loss: 0.677582] time: 0:18:01.482410\n",
      "0.95409656\n",
      "[Epoch 12/50] [Batch 18/300] [D loss: 0.753231] [G loss: 0.674848] time: 0:18:01.767063\n",
      "0.89870244\n",
      "[Epoch 12/50] [Batch 19/300] [D loss: 0.753217] [G loss: 0.631536] time: 0:18:02.068279\n",
      "0.90765\n",
      "[Epoch 12/50] [Batch 20/300] [D loss: 0.753237] [G loss: 0.636934] time: 0:18:02.354352\n",
      "0.92302984\n",
      "[Epoch 12/50] [Batch 21/300] [D loss: 0.753213] [G loss: 0.677314] time: 0:18:02.655316\n",
      "0.9532047\n",
      "[Epoch 12/50] [Batch 22/300] [D loss: 0.753215] [G loss: 0.695178] time: 0:18:02.957798\n",
      "0.91579825\n",
      "[Epoch 12/50] [Batch 23/300] [D loss: 0.753237] [G loss: 0.613007] time: 0:18:03.260335\n",
      "0.8913512\n",
      "[Epoch 12/50] [Batch 24/300] [D loss: 0.753218] [G loss: 0.661067] time: 0:18:03.561382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253978\n",
      "[Epoch 12/50] [Batch 25/300] [D loss: 0.753231] [G loss: 0.624479] time: 0:18:03.868092\n",
      "0.95182633\n",
      "[Epoch 12/50] [Batch 26/300] [D loss: 0.753224] [G loss: 0.664305] time: 0:18:04.171952\n",
      "0.84662265\n",
      "[Epoch 12/50] [Batch 27/300] [D loss: 0.753226] [G loss: 0.664391] time: 0:18:04.468103\n",
      "0.8848786\n",
      "[Epoch 12/50] [Batch 28/300] [D loss: 0.753218] [G loss: 0.616618] time: 0:18:04.767938\n",
      "0.918205\n",
      "[Epoch 12/50] [Batch 29/300] [D loss: 0.753240] [G loss: 0.596335] time: 0:18:05.052212\n",
      "0.8842187\n",
      "[Epoch 12/50] [Batch 30/300] [D loss: 0.753206] [G loss: 0.652534] time: 0:18:05.338728\n",
      "0.9145526\n",
      "[Epoch 12/50] [Batch 31/300] [D loss: 0.753230] [G loss: 0.604111] time: 0:18:05.654871\n",
      "0.9366555\n",
      "[Epoch 12/50] [Batch 32/300] [D loss: 0.753263] [G loss: 0.601035] time: 0:18:05.956871\n",
      "0.8939581\n",
      "[Epoch 12/50] [Batch 33/300] [D loss: 0.753198] [G loss: 0.630229] time: 0:18:06.247009\n",
      "0.8842287\n",
      "[Epoch 12/50] [Batch 34/300] [D loss: 0.753193] [G loss: 0.729675] time: 0:18:06.548148\n",
      "0.940504\n",
      "[Epoch 12/50] [Batch 35/300] [D loss: 0.753207] [G loss: 0.618858] time: 0:18:06.852718\n",
      "0.89053077\n",
      "[Epoch 12/50] [Batch 36/300] [D loss: 0.753256] [G loss: 0.639736] time: 0:18:07.157100\n",
      "0.91416025\n",
      "[Epoch 12/50] [Batch 37/300] [D loss: 0.753243] [G loss: 0.668811] time: 0:18:07.453839\n",
      "0.8879238\n",
      "[Epoch 12/50] [Batch 38/300] [D loss: 0.753247] [G loss: 0.698962] time: 0:18:07.762173\n",
      "0.89622575\n",
      "[Epoch 12/50] [Batch 39/300] [D loss: 0.753168] [G loss: 0.570363] time: 0:18:08.060105\n",
      "0.93279606\n",
      "[Epoch 12/50] [Batch 40/300] [D loss: 0.753181] [G loss: 0.607345] time: 0:18:08.357436\n",
      "0.864655\n",
      "[Epoch 12/50] [Batch 41/300] [D loss: 0.753185] [G loss: 0.608113] time: 0:18:08.637674\n",
      "0.91233844\n",
      "[Epoch 12/50] [Batch 42/300] [D loss: 0.753241] [G loss: 0.622624] time: 0:18:08.944914\n",
      "0.92751884\n",
      "[Epoch 12/50] [Batch 43/300] [D loss: 0.753210] [G loss: 0.616123] time: 0:18:09.251721\n",
      "0.94802827\n",
      "[Epoch 12/50] [Batch 44/300] [D loss: 0.753216] [G loss: 0.678939] time: 0:18:09.541286\n",
      "0.87808245\n",
      "[Epoch 12/50] [Batch 45/300] [D loss: 0.753218] [G loss: 0.608407] time: 0:18:09.852038\n",
      "0.94250613\n",
      "[Epoch 12/50] [Batch 46/300] [D loss: 0.753197] [G loss: 0.670128] time: 0:18:10.151459\n",
      "0.8837045\n",
      "[Epoch 12/50] [Batch 47/300] [D loss: 0.753228] [G loss: 0.666940] time: 0:18:10.452029\n",
      "0.93309\n",
      "[Epoch 12/50] [Batch 48/300] [D loss: 0.753182] [G loss: 0.572771] time: 0:18:10.751349\n",
      "0.94172674\n",
      "[Epoch 12/50] [Batch 49/300] [D loss: 0.753233] [G loss: 0.687909] time: 0:18:11.052037\n",
      "0.9351657\n",
      "[Epoch 12/50] [Batch 50/300] [D loss: 0.753275] [G loss: 0.541710] time: 0:18:11.346617\n",
      "0.9819011\n",
      "[Epoch 12/50] [Batch 51/300] [D loss: 0.753243] [G loss: 0.689299] time: 0:18:11.656255\n",
      "0.9027448\n",
      "[Epoch 12/50] [Batch 52/300] [D loss: 0.753213] [G loss: 0.663062] time: 0:18:11.949045\n",
      "0.9116588\n",
      "[Epoch 12/50] [Batch 53/300] [D loss: 0.753226] [G loss: 0.550234] time: 0:18:12.229074\n",
      "0.9261226\n",
      "[Epoch 12/50] [Batch 54/300] [D loss: 0.753237] [G loss: 0.688647] time: 0:18:12.512499\n",
      "0.90111476\n",
      "[Epoch 12/50] [Batch 55/300] [D loss: 0.753244] [G loss: 0.617763] time: 0:18:12.799701\n",
      "0.90468925\n",
      "[Epoch 12/50] [Batch 56/300] [D loss: 0.753204] [G loss: 0.705720] time: 0:18:13.072502\n",
      "0.9529349\n",
      "[Epoch 12/50] [Batch 57/300] [D loss: 0.753184] [G loss: 0.621598] time: 0:18:13.365820\n",
      "0.92570776\n",
      "[Epoch 12/50] [Batch 58/300] [D loss: 0.753209] [G loss: 0.582219] time: 0:18:13.672453\n",
      "0.9658672\n",
      "[Epoch 12/50] [Batch 59/300] [D loss: 0.753185] [G loss: 0.601561] time: 0:18:13.991922\n",
      "0.9402528\n",
      "[Epoch 12/50] [Batch 60/300] [D loss: 0.753147] [G loss: 0.649693] time: 0:18:14.272392\n",
      "0.8677618\n",
      "[Epoch 12/50] [Batch 61/300] [D loss: 0.753228] [G loss: 0.670642] time: 0:18:14.558164\n",
      "0.95145756\n",
      "[Epoch 12/50] [Batch 62/300] [D loss: 0.753264] [G loss: 0.641293] time: 0:18:14.853994\n",
      "0.94890195\n",
      "[Epoch 12/50] [Batch 63/300] [D loss: 0.753192] [G loss: 0.605888] time: 0:18:15.166971\n",
      "0.8984287\n",
      "[Epoch 12/50] [Batch 64/300] [D loss: 0.753156] [G loss: 0.681307] time: 0:18:15.465307\n",
      "0.88689613\n",
      "[Epoch 12/50] [Batch 65/300] [D loss: 0.753166] [G loss: 0.680837] time: 0:18:15.763221\n",
      "0.92706984\n",
      "[Epoch 12/50] [Batch 66/300] [D loss: 0.753171] [G loss: 0.717279] time: 0:18:16.052179\n",
      "0.8528227\n",
      "[Epoch 12/50] [Batch 67/300] [D loss: 0.753208] [G loss: 0.670391] time: 0:18:16.355513\n",
      "0.9694819\n",
      "[Epoch 12/50] [Batch 68/300] [D loss: 0.753229] [G loss: 0.691306] time: 0:18:16.665898\n",
      "0.9151513\n",
      "[Epoch 12/50] [Batch 69/300] [D loss: 0.753217] [G loss: 0.626155] time: 0:18:16.955560\n",
      "0.8861499\n",
      "[Epoch 12/50] [Batch 70/300] [D loss: 0.753223] [G loss: 0.656724] time: 0:18:17.248390\n",
      "0.92441934\n",
      "[Epoch 12/50] [Batch 71/300] [D loss: 0.753258] [G loss: 0.626190] time: 0:18:17.542501\n",
      "0.896097\n",
      "[Epoch 12/50] [Batch 72/300] [D loss: 0.753166] [G loss: 0.650751] time: 0:18:17.840803\n",
      "0.96386933\n",
      "[Epoch 12/50] [Batch 73/300] [D loss: 0.753192] [G loss: 0.612055] time: 0:18:18.140983\n",
      "0.9146698\n",
      "[Epoch 12/50] [Batch 74/300] [D loss: 0.753222] [G loss: 0.631393] time: 0:18:18.447762\n",
      "0.9624713\n",
      "[Epoch 12/50] [Batch 75/300] [D loss: 0.753171] [G loss: 0.637871] time: 0:18:18.746735\n",
      "0.9035699\n",
      "[Epoch 12/50] [Batch 76/300] [D loss: 0.753183] [G loss: 0.583865] time: 0:18:19.035001\n",
      "0.93855864\n",
      "[Epoch 12/50] [Batch 77/300] [D loss: 0.753220] [G loss: 0.553617] time: 0:18:19.342318\n",
      "0.8641674\n",
      "[Epoch 12/50] [Batch 78/300] [D loss: 0.753176] [G loss: 0.607331] time: 0:18:19.645558\n",
      "0.90864307\n",
      "[Epoch 12/50] [Batch 79/300] [D loss: 0.753173] [G loss: 0.662954] time: 0:18:19.934974\n",
      "0.9163242\n",
      "[Epoch 12/50] [Batch 80/300] [D loss: 0.753225] [G loss: 0.614646] time: 0:18:20.216794\n",
      "0.8623453\n",
      "[Epoch 12/50] [Batch 81/300] [D loss: 0.753181] [G loss: 0.577724] time: 0:18:20.509440\n",
      "0.93882936\n",
      "[Epoch 12/50] [Batch 82/300] [D loss: 0.753194] [G loss: 0.586663] time: 0:18:20.808054\n",
      "0.9335484\n",
      "[Epoch 12/50] [Batch 83/300] [D loss: 0.753214] [G loss: 0.557499] time: 0:18:21.099671\n",
      "0.9189174\n",
      "[Epoch 12/50] [Batch 84/300] [D loss: 0.753223] [G loss: 0.668876] time: 0:18:21.400817\n",
      "0.93530875\n",
      "[Epoch 12/50] [Batch 85/300] [D loss: 0.753180] [G loss: 0.643309] time: 0:18:21.686857\n",
      "0.9445786\n",
      "[Epoch 12/50] [Batch 86/300] [D loss: 0.753173] [G loss: 0.576354] time: 0:18:21.979630\n",
      "0.96277577\n",
      "[Epoch 12/50] [Batch 87/300] [D loss: 0.753170] [G loss: 0.622160] time: 0:18:22.276334\n",
      "0.90472317\n",
      "[Epoch 12/50] [Batch 88/300] [D loss: 0.753187] [G loss: 0.604805] time: 0:18:22.575476\n",
      "0.8665621\n",
      "[Epoch 12/50] [Batch 89/300] [D loss: 0.753245] [G loss: 0.638793] time: 0:18:22.874426\n",
      "0.8954065\n",
      "[Epoch 12/50] [Batch 90/300] [D loss: 0.753178] [G loss: 0.637393] time: 0:18:23.180890\n",
      "0.89215404\n",
      "[Epoch 12/50] [Batch 91/300] [D loss: 0.753168] [G loss: 0.561333] time: 0:18:23.444128\n",
      "0.914164\n",
      "[Epoch 12/50] [Batch 92/300] [D loss: 0.753201] [G loss: 0.599124] time: 0:18:23.717191\n",
      "0.93428355\n",
      "[Epoch 12/50] [Batch 93/300] [D loss: 0.753176] [G loss: 0.633339] time: 0:18:24.013704\n",
      "0.9003985\n",
      "[Epoch 12/50] [Batch 94/300] [D loss: 0.753219] [G loss: 0.631632] time: 0:18:24.323098\n",
      "0.9435032\n",
      "[Epoch 12/50] [Batch 95/300] [D loss: 0.753158] [G loss: 0.634060] time: 0:18:24.635339\n",
      "0.91251975\n",
      "[Epoch 12/50] [Batch 96/300] [D loss: 0.753153] [G loss: 0.651875] time: 0:18:24.930485\n",
      "0.9198899\n",
      "[Epoch 12/50] [Batch 97/300] [D loss: 0.753178] [G loss: 0.616728] time: 0:18:25.233837\n",
      "0.93163615\n",
      "[Epoch 12/50] [Batch 98/300] [D loss: 0.753195] [G loss: 0.580922] time: 0:18:25.534559\n",
      "0.91301805\n",
      "[Epoch 12/50] [Batch 99/300] [D loss: 0.753162] [G loss: 0.659619] time: 0:18:25.841404\n",
      "0.9022834\n",
      "[Epoch 12/50] [Batch 100/300] [D loss: 0.753191] [G loss: 0.677556] time: 0:18:26.114038\n",
      "0.90870255\n",
      "[Epoch 12/50] [Batch 101/300] [D loss: 0.753183] [G loss: 0.632619] time: 0:18:26.418407\n",
      "0.93065256\n",
      "[Epoch 12/50] [Batch 102/300] [D loss: 0.753207] [G loss: 0.684954] time: 0:18:26.723629\n",
      "0.9190057\n",
      "[Epoch 12/50] [Batch 103/300] [D loss: 0.753185] [G loss: 0.617208] time: 0:18:27.019630\n",
      "0.9135961\n",
      "[Epoch 12/50] [Batch 104/300] [D loss: 0.753164] [G loss: 0.636964] time: 0:18:27.315538\n",
      "0.9348611\n",
      "[Epoch 12/50] [Batch 105/300] [D loss: 0.753217] [G loss: 0.641403] time: 0:18:27.608914\n",
      "0.8771005\n",
      "[Epoch 12/50] [Batch 106/300] [D loss: 0.753179] [G loss: 0.657074] time: 0:18:27.882407\n",
      "0.95316076\n",
      "[Epoch 12/50] [Batch 107/300] [D loss: 0.753205] [G loss: 0.607503] time: 0:18:28.182247\n",
      "0.93048596\n",
      "[Epoch 12/50] [Batch 108/300] [D loss: 0.753231] [G loss: 0.564410] time: 0:18:28.478346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9705116\n",
      "[Epoch 12/50] [Batch 109/300] [D loss: 0.753218] [G loss: 0.580975] time: 0:18:28.775465\n",
      "0.9193437\n",
      "[Epoch 12/50] [Batch 110/300] [D loss: 0.753204] [G loss: 0.652698] time: 0:18:29.070155\n",
      "0.98250645\n",
      "[Epoch 12/50] [Batch 111/300] [D loss: 0.753199] [G loss: 0.615423] time: 0:18:29.374196\n",
      "0.93617153\n",
      "[Epoch 12/50] [Batch 112/300] [D loss: 0.753195] [G loss: 0.650974] time: 0:18:29.671006\n",
      "0.9606318\n",
      "[Epoch 12/50] [Batch 113/300] [D loss: 0.753185] [G loss: 0.574181] time: 0:18:29.978456\n",
      "0.91676164\n",
      "[Epoch 12/50] [Batch 114/300] [D loss: 0.753216] [G loss: 0.601222] time: 0:18:30.289648\n",
      "0.93705684\n",
      "[Epoch 12/50] [Batch 115/300] [D loss: 0.753167] [G loss: 0.667508] time: 0:18:30.590423\n",
      "0.9428533\n",
      "[Epoch 12/50] [Batch 116/300] [D loss: 0.753181] [G loss: 0.605213] time: 0:18:30.889859\n",
      "0.9503751\n",
      "[Epoch 12/50] [Batch 117/300] [D loss: 0.753258] [G loss: 0.604144] time: 0:18:31.193604\n",
      "0.9098733\n",
      "[Epoch 12/50] [Batch 118/300] [D loss: 0.753204] [G loss: 0.599292] time: 0:18:31.479256\n",
      "0.9344794\n",
      "[Epoch 12/50] [Batch 119/300] [D loss: 0.753149] [G loss: 0.589439] time: 0:18:31.781889\n",
      "0.9448018\n",
      "[Epoch 12/50] [Batch 120/300] [D loss: 0.753186] [G loss: 0.628303] time: 0:18:32.076968\n",
      "0.8952872\n",
      "[Epoch 12/50] [Batch 121/300] [D loss: 0.753215] [G loss: 0.652609] time: 0:18:32.406136\n",
      "0.9531739\n",
      "[Epoch 12/50] [Batch 122/300] [D loss: 0.753158] [G loss: 0.648455] time: 0:18:32.692127\n",
      "0.96016043\n",
      "[Epoch 12/50] [Batch 123/300] [D loss: 0.753179] [G loss: 0.632619] time: 0:18:32.995673\n",
      "0.88787645\n",
      "[Epoch 12/50] [Batch 124/300] [D loss: 0.753196] [G loss: 0.567121] time: 0:18:33.292996\n",
      "0.94789547\n",
      "[Epoch 12/50] [Batch 125/300] [D loss: 0.753214] [G loss: 0.600852] time: 0:18:33.587703\n",
      "0.952787\n",
      "[Epoch 12/50] [Batch 126/300] [D loss: 0.753157] [G loss: 0.639562] time: 0:18:33.885598\n",
      "0.87537366\n",
      "[Epoch 12/50] [Batch 127/300] [D loss: 0.753180] [G loss: 0.633501] time: 0:18:34.166614\n",
      "0.93200564\n",
      "[Epoch 12/50] [Batch 128/300] [D loss: 0.753165] [G loss: 0.729625] time: 0:18:34.443348\n",
      "0.9055888\n",
      "[Epoch 12/50] [Batch 129/300] [D loss: 0.753110] [G loss: 0.671351] time: 0:18:34.726509\n",
      "0.90508676\n",
      "[Epoch 12/50] [Batch 130/300] [D loss: 0.753136] [G loss: 0.619887] time: 0:18:35.032673\n",
      "0.8967797\n",
      "[Epoch 12/50] [Batch 131/300] [D loss: 0.753178] [G loss: 0.624907] time: 0:18:35.334599\n",
      "0.96882915\n",
      "[Epoch 12/50] [Batch 132/300] [D loss: 0.753179] [G loss: 0.591040] time: 0:18:35.635943\n",
      "0.9139471\n",
      "[Epoch 12/50] [Batch 133/300] [D loss: 0.753147] [G loss: 0.605391] time: 0:18:35.916126\n",
      "0.94674754\n",
      "[Epoch 12/50] [Batch 134/300] [D loss: 0.753175] [G loss: 0.598418] time: 0:18:36.219600\n",
      "0.9531653\n",
      "[Epoch 12/50] [Batch 135/300] [D loss: 0.753165] [G loss: 0.571313] time: 0:18:36.505923\n",
      "0.91194767\n",
      "[Epoch 12/50] [Batch 136/300] [D loss: 0.753201] [G loss: 0.679686] time: 0:18:36.789672\n",
      "0.9220831\n",
      "[Epoch 12/50] [Batch 137/300] [D loss: 0.753218] [G loss: 0.573924] time: 0:18:37.076040\n",
      "0.9181628\n",
      "[Epoch 12/50] [Batch 138/300] [D loss: 0.753184] [G loss: 0.640628] time: 0:18:37.381149\n",
      "0.9307805\n",
      "[Epoch 12/50] [Batch 139/300] [D loss: 0.753171] [G loss: 0.687047] time: 0:18:37.684594\n",
      "0.91646737\n",
      "[Epoch 12/50] [Batch 140/300] [D loss: 0.753119] [G loss: 0.583771] time: 0:18:37.986156\n",
      "0.8722058\n",
      "[Epoch 12/50] [Batch 141/300] [D loss: 0.753154] [G loss: 0.616825] time: 0:18:38.278320\n",
      "0.91655177\n",
      "[Epoch 12/50] [Batch 142/300] [D loss: 0.753203] [G loss: 0.617918] time: 0:18:38.563758\n",
      "0.89672107\n",
      "[Epoch 12/50] [Batch 143/300] [D loss: 0.753188] [G loss: 0.668103] time: 0:18:38.864438\n",
      "0.91364795\n",
      "[Epoch 12/50] [Batch 144/300] [D loss: 0.753164] [G loss: 0.648839] time: 0:18:39.161731\n",
      "0.92016524\n",
      "[Epoch 12/50] [Batch 145/300] [D loss: 0.753170] [G loss: 0.637860] time: 0:18:39.456549\n",
      "0.9307644\n",
      "[Epoch 12/50] [Batch 146/300] [D loss: 0.753204] [G loss: 0.647148] time: 0:18:39.770415\n",
      "0.9420984\n",
      "[Epoch 12/50] [Batch 147/300] [D loss: 0.753180] [G loss: 0.640392] time: 0:18:40.072389\n",
      "0.9531617\n",
      "[Epoch 12/50] [Batch 148/300] [D loss: 0.753160] [G loss: 0.587337] time: 0:18:40.374549\n",
      "0.8975437\n",
      "[Epoch 12/50] [Batch 149/300] [D loss: 0.753139] [G loss: 0.606487] time: 0:18:40.678511\n",
      "0.91728026\n",
      "[Epoch 12/50] [Batch 150/300] [D loss: 0.753178] [G loss: 0.600435] time: 0:18:40.962555\n",
      "0.9348605\n",
      "[Epoch 12/50] [Batch 151/300] [D loss: 0.753168] [G loss: 0.610315] time: 0:18:41.263748\n",
      "0.90789753\n",
      "[Epoch 12/50] [Batch 152/300] [D loss: 0.753150] [G loss: 0.660699] time: 0:18:41.564581\n",
      "0.9003561\n",
      "[Epoch 12/50] [Batch 153/300] [D loss: 0.753139] [G loss: 0.640316] time: 0:18:41.855542\n",
      "0.9149603\n",
      "[Epoch 12/50] [Batch 154/300] [D loss: 0.753156] [G loss: 0.635929] time: 0:18:42.137550\n",
      "0.91516644\n",
      "[Epoch 12/50] [Batch 155/300] [D loss: 0.753169] [G loss: 0.632254] time: 0:18:42.439641\n",
      "0.9541916\n",
      "[Epoch 12/50] [Batch 156/300] [D loss: 0.753190] [G loss: 0.643405] time: 0:18:42.756850\n",
      "0.95159864\n",
      "[Epoch 12/50] [Batch 157/300] [D loss: 0.753096] [G loss: 0.706195] time: 0:18:43.058527\n",
      "0.9060506\n",
      "[Epoch 12/50] [Batch 158/300] [D loss: 0.753179] [G loss: 0.650393] time: 0:18:43.354462\n",
      "0.97722673\n",
      "[Epoch 12/50] [Batch 159/300] [D loss: 0.753222] [G loss: 0.626966] time: 0:18:43.644363\n",
      "0.94192606\n",
      "[Epoch 12/50] [Batch 160/300] [D loss: 0.753182] [G loss: 0.699412] time: 0:18:43.945051\n",
      "0.9304361\n",
      "[Epoch 12/50] [Batch 161/300] [D loss: 0.753150] [G loss: 0.633639] time: 0:18:44.242447\n",
      "0.97315186\n",
      "[Epoch 12/50] [Batch 162/300] [D loss: 0.753159] [G loss: 0.687959] time: 0:18:44.539058\n",
      "0.9505768\n",
      "[Epoch 12/50] [Batch 163/300] [D loss: 0.753174] [G loss: 0.637890] time: 0:18:44.855694\n",
      "0.9392774\n",
      "[Epoch 12/50] [Batch 164/300] [D loss: 0.753226] [G loss: 0.624497] time: 0:18:45.142581\n",
      "0.95804137\n",
      "[Epoch 12/50] [Batch 165/300] [D loss: 0.753151] [G loss: 0.636474] time: 0:18:45.428005\n",
      "0.88241625\n",
      "[Epoch 12/50] [Batch 166/300] [D loss: 0.753207] [G loss: 0.631055] time: 0:18:45.736943\n",
      "0.9486985\n",
      "[Epoch 12/50] [Batch 167/300] [D loss: 0.753157] [G loss: 0.605223] time: 0:18:46.040024\n",
      "0.9140582\n",
      "[Epoch 12/50] [Batch 168/300] [D loss: 0.753148] [G loss: 0.681676] time: 0:18:46.337074\n",
      "0.9307973\n",
      "[Epoch 12/50] [Batch 169/300] [D loss: 0.753202] [G loss: 0.675078] time: 0:18:46.634917\n",
      "0.9109781\n",
      "[Epoch 12/50] [Batch 170/300] [D loss: 0.753123] [G loss: 0.726174] time: 0:18:46.917653\n",
      "0.94101834\n",
      "[Epoch 12/50] [Batch 171/300] [D loss: 0.753180] [G loss: 0.623248] time: 0:18:47.203235\n",
      "0.9137942\n",
      "[Epoch 12/50] [Batch 172/300] [D loss: 0.753170] [G loss: 0.706508] time: 0:18:47.499379\n",
      "0.88993216\n",
      "[Epoch 12/50] [Batch 173/300] [D loss: 0.753213] [G loss: 0.616306] time: 0:18:47.793956\n",
      "0.8844057\n",
      "[Epoch 12/50] [Batch 174/300] [D loss: 0.753136] [G loss: 0.654118] time: 0:18:48.092108\n",
      "0.87603694\n",
      "[Epoch 12/50] [Batch 175/300] [D loss: 0.753113] [G loss: 0.651863] time: 0:18:48.390049\n",
      "0.9304604\n",
      "[Epoch 12/50] [Batch 176/300] [D loss: 0.753209] [G loss: 0.617752] time: 0:18:48.691058\n",
      "0.91138405\n",
      "[Epoch 12/50] [Batch 177/300] [D loss: 0.753157] [G loss: 0.676312] time: 0:18:48.985745\n",
      "0.95478636\n",
      "[Epoch 12/50] [Batch 178/300] [D loss: 0.753176] [G loss: 0.746896] time: 0:18:49.280007\n",
      "0.9115277\n",
      "[Epoch 12/50] [Batch 179/300] [D loss: 0.753154] [G loss: 0.747246] time: 0:18:49.585086\n",
      "0.8876726\n",
      "[Epoch 12/50] [Batch 180/300] [D loss: 0.753140] [G loss: 0.611359] time: 0:18:49.890013\n",
      "0.9362795\n",
      "[Epoch 12/50] [Batch 181/300] [D loss: 0.753133] [G loss: 0.641343] time: 0:18:50.205293\n",
      "0.87867576\n",
      "[Epoch 12/50] [Batch 182/300] [D loss: 0.753164] [G loss: 0.666426] time: 0:18:50.516739\n",
      "0.9823856\n",
      "[Epoch 12/50] [Batch 183/300] [D loss: 0.753157] [G loss: 0.623820] time: 0:18:50.819666\n",
      "0.87556344\n",
      "[Epoch 12/50] [Batch 184/300] [D loss: 0.753208] [G loss: 0.613495] time: 0:18:51.109093\n",
      "0.9326275\n",
      "[Epoch 12/50] [Batch 185/300] [D loss: 0.753136] [G loss: 0.599524] time: 0:18:51.405227\n",
      "0.93523926\n",
      "[Epoch 12/50] [Batch 186/300] [D loss: 0.753177] [G loss: 0.641694] time: 0:18:51.722862\n",
      "0.93197125\n",
      "[Epoch 12/50] [Batch 187/300] [D loss: 0.753146] [G loss: 0.571297] time: 0:18:52.035838\n",
      "0.9454661\n",
      "[Epoch 12/50] [Batch 188/300] [D loss: 0.753207] [G loss: 0.625063] time: 0:18:52.310548\n",
      "0.9169542\n",
      "[Epoch 12/50] [Batch 189/300] [D loss: 0.753213] [G loss: 0.575246] time: 0:18:52.599678\n",
      "0.9069218\n",
      "[Epoch 12/50] [Batch 190/300] [D loss: 0.753143] [G loss: 0.573583] time: 0:18:52.902180\n",
      "0.981414\n",
      "[Epoch 12/50] [Batch 191/300] [D loss: 0.753121] [G loss: 0.597447] time: 0:18:53.191209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177842\n",
      "[Epoch 12/50] [Batch 192/300] [D loss: 0.753187] [G loss: 0.613052] time: 0:18:53.478553\n",
      "0.9267064\n",
      "[Epoch 12/50] [Batch 193/300] [D loss: 0.753192] [G loss: 0.579799] time: 0:18:53.790277\n",
      "0.9407452\n",
      "[Epoch 12/50] [Batch 194/300] [D loss: 0.753117] [G loss: 0.625905] time: 0:18:54.086095\n",
      "0.8954192\n",
      "[Epoch 12/50] [Batch 195/300] [D loss: 0.753145] [G loss: 0.592243] time: 0:18:54.374767\n",
      "0.92623705\n",
      "[Epoch 12/50] [Batch 196/300] [D loss: 0.753182] [G loss: 0.622404] time: 0:18:54.675168\n",
      "0.93002176\n",
      "[Epoch 12/50] [Batch 197/300] [D loss: 0.753166] [G loss: 0.550019] time: 0:18:54.982689\n",
      "0.91827106\n",
      "[Epoch 12/50] [Batch 198/300] [D loss: 0.753130] [G loss: 0.629143] time: 0:18:55.270547\n",
      "0.9309376\n",
      "[Epoch 12/50] [Batch 199/300] [D loss: 0.753146] [G loss: 0.659664] time: 0:18:55.564230\n",
      "0.88442844\n",
      "[Epoch 12/50] [Batch 200/300] [D loss: 0.753145] [G loss: 0.650541] time: 0:18:55.861801\n",
      "0.8732791\n",
      "[Epoch 12/50] [Batch 201/300] [D loss: 0.753153] [G loss: 0.598811] time: 0:18:56.172388\n",
      "0.89002174\n",
      "[Epoch 12/50] [Batch 202/300] [D loss: 0.753131] [G loss: 0.612722] time: 0:18:56.482173\n",
      "0.90178245\n",
      "[Epoch 12/50] [Batch 203/300] [D loss: 0.753165] [G loss: 0.597620] time: 0:18:56.779111\n",
      "0.93843937\n",
      "[Epoch 12/50] [Batch 204/300] [D loss: 0.753125] [G loss: 0.596783] time: 0:18:57.088402\n",
      "0.867918\n",
      "[Epoch 12/50] [Batch 205/300] [D loss: 0.753160] [G loss: 0.691887] time: 0:18:57.381058\n",
      "0.98149675\n",
      "[Epoch 12/50] [Batch 206/300] [D loss: 0.753228] [G loss: 0.652301] time: 0:18:57.690778\n",
      "0.9062252\n",
      "[Epoch 12/50] [Batch 207/300] [D loss: 0.753139] [G loss: 0.602008] time: 0:18:57.966736\n",
      "0.9376316\n",
      "[Epoch 12/50] [Batch 208/300] [D loss: 0.753185] [G loss: 0.697915] time: 0:18:58.256425\n",
      "0.9156833\n",
      "[Epoch 12/50] [Batch 209/300] [D loss: 0.753151] [G loss: 0.626508] time: 0:18:58.533972\n",
      "0.9531366\n",
      "[Epoch 12/50] [Batch 210/300] [D loss: 0.753109] [G loss: 0.620610] time: 0:18:58.831002\n",
      "0.9303465\n",
      "[Epoch 12/50] [Batch 211/300] [D loss: 0.753177] [G loss: 0.618219] time: 0:18:59.121946\n",
      "0.9480491\n",
      "[Epoch 12/50] [Batch 212/300] [D loss: 0.753120] [G loss: 0.587781] time: 0:18:59.502131\n",
      "0.97407776\n",
      "[Epoch 12/50] [Batch 213/300] [D loss: 0.753167] [G loss: 0.585758] time: 0:18:59.785709\n",
      "0.9275546\n",
      "[Epoch 12/50] [Batch 214/300] [D loss: 0.753138] [G loss: 0.656557] time: 0:19:00.088894\n",
      "0.9263882\n",
      "[Epoch 12/50] [Batch 215/300] [D loss: 0.753120] [G loss: 0.584993] time: 0:19:00.403336\n",
      "0.97227424\n",
      "[Epoch 12/50] [Batch 216/300] [D loss: 0.753137] [G loss: 0.609284] time: 0:19:00.696386\n",
      "0.91036814\n",
      "[Epoch 12/50] [Batch 217/300] [D loss: 0.753210] [G loss: 0.653532] time: 0:19:01.001869\n",
      "0.923137\n",
      "[Epoch 12/50] [Batch 218/300] [D loss: 0.753187] [G loss: 0.593843] time: 0:19:01.313357\n",
      "0.9523813\n",
      "[Epoch 12/50] [Batch 219/300] [D loss: 0.753140] [G loss: 0.629887] time: 0:19:01.624118\n",
      "0.96464443\n",
      "[Epoch 12/50] [Batch 220/300] [D loss: 0.753184] [G loss: 0.585892] time: 0:19:01.930617\n",
      "0.9456985\n",
      "[Epoch 12/50] [Batch 221/300] [D loss: 0.753119] [G loss: 0.625820] time: 0:19:02.246798\n",
      "0.98313785\n",
      "[Epoch 12/50] [Batch 222/300] [D loss: 0.753147] [G loss: 0.609268] time: 0:19:02.551424\n",
      "0.93789595\n",
      "[Epoch 12/50] [Batch 223/300] [D loss: 0.753181] [G loss: 0.623096] time: 0:19:02.868150\n",
      "0.93696356\n",
      "[Epoch 12/50] [Batch 224/300] [D loss: 0.753168] [G loss: 0.604332] time: 0:19:03.169934\n",
      "0.9144633\n",
      "[Epoch 12/50] [Batch 225/300] [D loss: 0.753138] [G loss: 0.662375] time: 0:19:03.450833\n",
      "0.89936656\n",
      "[Epoch 12/50] [Batch 226/300] [D loss: 0.753136] [G loss: 0.576267] time: 0:19:03.763711\n",
      "0.9054913\n",
      "[Epoch 12/50] [Batch 227/300] [D loss: 0.753164] [G loss: 0.597388] time: 0:19:04.082490\n",
      "0.91334313\n",
      "[Epoch 12/50] [Batch 228/300] [D loss: 0.753156] [G loss: 0.581475] time: 0:19:04.389917\n",
      "0.9572387\n",
      "[Epoch 12/50] [Batch 229/300] [D loss: 0.753173] [G loss: 0.627689] time: 0:19:04.685849\n",
      "0.9278577\n",
      "[Epoch 12/50] [Batch 230/300] [D loss: 0.753118] [G loss: 0.612637] time: 0:19:04.978607\n",
      "0.87022233\n",
      "[Epoch 12/50] [Batch 231/300] [D loss: 0.753149] [G loss: 0.596936] time: 0:19:05.277562\n",
      "0.9511811\n",
      "[Epoch 12/50] [Batch 232/300] [D loss: 0.753152] [G loss: 0.651143] time: 0:19:05.613566\n",
      "0.92552876\n",
      "[Epoch 12/50] [Batch 233/300] [D loss: 0.753154] [G loss: 0.570173] time: 0:19:05.920014\n",
      "0.9089859\n",
      "[Epoch 12/50] [Batch 234/300] [D loss: 0.753110] [G loss: 0.701565] time: 0:19:06.223356\n",
      "0.90995294\n",
      "[Epoch 12/50] [Batch 235/300] [D loss: 0.753143] [G loss: 0.619687] time: 0:19:06.504668\n",
      "0.9169013\n",
      "[Epoch 12/50] [Batch 236/300] [D loss: 0.753181] [G loss: 0.623296] time: 0:19:06.795454\n",
      "0.9146339\n",
      "[Epoch 12/50] [Batch 237/300] [D loss: 0.753106] [G loss: 0.582588] time: 0:19:07.089185\n",
      "0.9140458\n",
      "[Epoch 12/50] [Batch 238/300] [D loss: 0.753193] [G loss: 0.604809] time: 0:19:07.389028\n",
      "0.8872094\n",
      "[Epoch 12/50] [Batch 239/300] [D loss: 0.753130] [G loss: 0.548487] time: 0:19:07.701492\n",
      "0.9546652\n",
      "[Epoch 12/50] [Batch 240/300] [D loss: 0.753115] [G loss: 0.604042] time: 0:19:08.015265\n",
      "0.9288843\n",
      "[Epoch 12/50] [Batch 241/300] [D loss: 0.753137] [G loss: 0.627171] time: 0:19:08.316378\n",
      "0.90050656\n",
      "[Epoch 12/50] [Batch 242/300] [D loss: 0.753169] [G loss: 0.622276] time: 0:19:08.610873\n",
      "0.92190677\n",
      "[Epoch 12/50] [Batch 243/300] [D loss: 0.753138] [G loss: 0.564893] time: 0:19:08.910292\n",
      "0.9599983\n",
      "[Epoch 12/50] [Batch 244/300] [D loss: 0.753147] [G loss: 0.601234] time: 0:19:09.202707\n",
      "0.9171478\n",
      "[Epoch 12/50] [Batch 245/300] [D loss: 0.753106] [G loss: 0.645041] time: 0:19:09.500990\n",
      "0.88275766\n",
      "[Epoch 12/50] [Batch 246/300] [D loss: 0.753152] [G loss: 0.601901] time: 0:19:09.814613\n",
      "0.93038225\n",
      "[Epoch 12/50] [Batch 247/300] [D loss: 0.753143] [G loss: 0.635479] time: 0:19:10.120555\n",
      "0.92414093\n",
      "[Epoch 12/50] [Batch 248/300] [D loss: 0.753185] [G loss: 0.620361] time: 0:19:10.426122\n",
      "0.9194353\n",
      "[Epoch 12/50] [Batch 249/300] [D loss: 0.753142] [G loss: 0.620671] time: 0:19:10.716787\n",
      "0.8992123\n",
      "[Epoch 12/50] [Batch 250/300] [D loss: 0.753074] [G loss: 0.644194] time: 0:19:11.013515\n",
      "0.91643316\n",
      "[Epoch 12/50] [Batch 251/300] [D loss: 0.753178] [G loss: 0.609227] time: 0:19:11.300992\n",
      "0.90880466\n",
      "[Epoch 12/50] [Batch 252/300] [D loss: 0.753125] [G loss: 0.637524] time: 0:19:11.600254\n",
      "0.93204063\n",
      "[Epoch 12/50] [Batch 253/300] [D loss: 0.753161] [G loss: 0.653335] time: 0:19:11.889441\n",
      "0.92215323\n",
      "[Epoch 12/50] [Batch 254/300] [D loss: 0.753114] [G loss: 0.602958] time: 0:19:12.189493\n",
      "0.94784874\n",
      "[Epoch 12/50] [Batch 255/300] [D loss: 0.753134] [G loss: 0.588582] time: 0:19:12.488843\n",
      "0.90849113\n",
      "[Epoch 12/50] [Batch 256/300] [D loss: 0.753139] [G loss: 0.598094] time: 0:19:12.808102\n",
      "0.9050917\n",
      "[Epoch 12/50] [Batch 257/300] [D loss: 0.753112] [G loss: 0.659477] time: 0:19:13.116288\n",
      "0.9161635\n",
      "[Epoch 12/50] [Batch 258/300] [D loss: 0.753077] [G loss: 0.621409] time: 0:19:13.399757\n",
      "0.89138746\n",
      "[Epoch 12/50] [Batch 259/300] [D loss: 0.753102] [G loss: 0.586262] time: 0:19:13.701846\n",
      "0.9103815\n",
      "[Epoch 12/50] [Batch 260/300] [D loss: 0.753146] [G loss: 0.680803] time: 0:19:14.004030\n",
      "0.93558866\n",
      "[Epoch 12/50] [Batch 261/300] [D loss: 0.753211] [G loss: 0.615725] time: 0:19:14.327264\n",
      "0.8902114\n",
      "[Epoch 12/50] [Batch 262/300] [D loss: 0.753123] [G loss: 0.597258] time: 0:19:14.632727\n",
      "0.8770902\n",
      "[Epoch 12/50] [Batch 263/300] [D loss: 0.753115] [G loss: 0.645308] time: 0:19:14.948553\n",
      "0.91111916\n",
      "[Epoch 12/50] [Batch 264/300] [D loss: 0.753150] [G loss: 0.603002] time: 0:19:15.253827\n",
      "0.90829444\n",
      "[Epoch 12/50] [Batch 265/300] [D loss: 0.753134] [G loss: 0.633289] time: 0:19:15.552126\n",
      "0.92032963\n",
      "[Epoch 12/50] [Batch 266/300] [D loss: 0.753107] [G loss: 0.637992] time: 0:19:15.846091\n",
      "0.9202549\n",
      "[Epoch 12/50] [Batch 267/300] [D loss: 0.753105] [G loss: 0.641733] time: 0:19:16.150960\n",
      "0.89566344\n",
      "[Epoch 12/50] [Batch 268/300] [D loss: 0.753072] [G loss: 0.611833] time: 0:19:16.458076\n",
      "0.8842127\n",
      "[Epoch 12/50] [Batch 269/300] [D loss: 0.753165] [G loss: 0.575336] time: 0:19:16.760398\n",
      "0.89015895\n",
      "[Epoch 12/50] [Batch 270/300] [D loss: 0.753133] [G loss: 0.584590] time: 0:19:17.062844\n",
      "0.91338164\n",
      "[Epoch 12/50] [Batch 271/300] [D loss: 0.753182] [G loss: 0.606604] time: 0:19:17.362988\n",
      "0.9560867\n",
      "[Epoch 12/50] [Batch 272/300] [D loss: 0.753153] [G loss: 0.637931] time: 0:19:17.668276\n",
      "0.90709335\n",
      "[Epoch 12/50] [Batch 273/300] [D loss: 0.753148] [G loss: 0.638933] time: 0:19:17.981356\n",
      "0.8991647\n",
      "[Epoch 12/50] [Batch 274/300] [D loss: 0.753108] [G loss: 0.599032] time: 0:19:18.281682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8903919\n",
      "[Epoch 12/50] [Batch 275/300] [D loss: 0.753113] [G loss: 0.614065] time: 0:19:18.567268\n",
      "0.9072063\n",
      "[Epoch 12/50] [Batch 276/300] [D loss: 0.753111] [G loss: 0.686082] time: 0:19:18.849080\n",
      "0.9331327\n",
      "[Epoch 12/50] [Batch 277/300] [D loss: 0.753086] [G loss: 0.547826] time: 0:19:19.154669\n",
      "0.93004966\n",
      "[Epoch 12/50] [Batch 278/300] [D loss: 0.753130] [G loss: 0.622729] time: 0:19:19.457410\n",
      "0.9450659\n",
      "[Epoch 12/50] [Batch 279/300] [D loss: 0.753090] [G loss: 0.608247] time: 0:19:19.758980\n",
      "0.9019286\n",
      "[Epoch 12/50] [Batch 280/300] [D loss: 0.753154] [G loss: 0.598099] time: 0:19:20.058790\n",
      "0.9284639\n",
      "[Epoch 12/50] [Batch 281/300] [D loss: 0.753107] [G loss: 0.642476] time: 0:19:20.363339\n",
      "0.92353415\n",
      "[Epoch 12/50] [Batch 282/300] [D loss: 0.753107] [G loss: 0.588623] time: 0:19:20.675756\n",
      "0.94546366\n",
      "[Epoch 12/50] [Batch 283/300] [D loss: 0.753091] [G loss: 0.699772] time: 0:19:20.969778\n",
      "0.9235894\n",
      "[Epoch 12/50] [Batch 284/300] [D loss: 0.753164] [G loss: 0.601939] time: 0:19:21.260139\n",
      "0.9388094\n",
      "[Epoch 12/50] [Batch 285/300] [D loss: 0.753134] [G loss: 0.647254] time: 0:19:21.540827\n",
      "0.9511774\n",
      "[Epoch 12/50] [Batch 286/300] [D loss: 0.753109] [G loss: 0.602683] time: 0:19:21.837282\n",
      "0.8884556\n",
      "[Epoch 12/50] [Batch 287/300] [D loss: 0.753111] [G loss: 0.640679] time: 0:19:22.124242\n",
      "0.8875243\n",
      "[Epoch 12/50] [Batch 288/300] [D loss: 0.753133] [G loss: 0.555432] time: 0:19:22.429498\n",
      "0.9825592\n",
      "[Epoch 12/50] [Batch 289/300] [D loss: 0.753105] [G loss: 0.660319] time: 0:19:22.729666\n",
      "0.94840497\n",
      "[Epoch 12/50] [Batch 290/300] [D loss: 0.753092] [G loss: 0.674543] time: 0:19:23.015975\n",
      "0.9012656\n",
      "[Epoch 12/50] [Batch 291/300] [D loss: 0.753137] [G loss: 0.668024] time: 0:19:23.316800\n",
      "0.94073015\n",
      "[Epoch 12/50] [Batch 292/300] [D loss: 0.753138] [G loss: 0.674183] time: 0:19:23.634689\n",
      "0.9282851\n",
      "[Epoch 12/50] [Batch 293/300] [D loss: 0.753091] [G loss: 0.647739] time: 0:19:23.927448\n",
      "0.94766885\n",
      "[Epoch 12/50] [Batch 294/300] [D loss: 0.753148] [G loss: 0.608492] time: 0:19:24.209418\n",
      "0.94999886\n",
      "[Epoch 12/50] [Batch 295/300] [D loss: 0.753134] [G loss: 0.662112] time: 0:19:24.511457\n",
      "0.88416314\n",
      "[Epoch 12/50] [Batch 296/300] [D loss: 0.753119] [G loss: 0.590257] time: 0:19:24.815783\n",
      "0.90794754\n",
      "[Epoch 12/50] [Batch 297/300] [D loss: 0.753118] [G loss: 0.613857] time: 0:19:25.111130\n",
      "0.9351184\n",
      "[Epoch 12/50] [Batch 298/300] [D loss: 0.753147] [G loss: 0.615880] time: 0:19:25.424575\n",
      "0.9469369\n",
      "[Epoch 12/50] [Batch 299/300] [D loss: 0.753132] [G loss: 0.604217] time: 0:19:25.736679\n",
      "0.9558566\n",
      "[Epoch 13/50] [Batch 0/300] [D loss: 0.753126] [G loss: 0.611867] time: 0:19:26.026228\n",
      "0.92809075\n",
      "[Epoch 13/50] [Batch 1/300] [D loss: 0.753148] [G loss: 0.694487] time: 0:19:26.333179\n",
      "0.93876284\n",
      "[Epoch 13/50] [Batch 2/300] [D loss: 0.753101] [G loss: 0.549493] time: 0:19:26.626561\n",
      "0.8985696\n",
      "[Epoch 13/50] [Batch 3/300] [D loss: 0.753125] [G loss: 0.595889] time: 0:19:26.933806\n",
      "0.9316633\n",
      "[Epoch 13/50] [Batch 4/300] [D loss: 0.753136] [G loss: 0.607803] time: 0:19:27.256915\n",
      "0.9381067\n",
      "[Epoch 13/50] [Batch 5/300] [D loss: 0.753116] [G loss: 0.664951] time: 0:19:27.567530\n",
      "0.871131\n",
      "[Epoch 13/50] [Batch 6/300] [D loss: 0.753141] [G loss: 0.602089] time: 0:19:27.869890\n",
      "0.9071214\n",
      "[Epoch 13/50] [Batch 7/300] [D loss: 0.753121] [G loss: 0.633454] time: 0:19:28.171807\n",
      "0.88296014\n",
      "[Epoch 13/50] [Batch 8/300] [D loss: 0.753108] [G loss: 0.591797] time: 0:19:28.474956\n",
      "0.9414551\n",
      "[Epoch 13/50] [Batch 9/300] [D loss: 0.753091] [G loss: 0.595987] time: 0:19:28.784209\n",
      "0.9101522\n",
      "[Epoch 13/50] [Batch 10/300] [D loss: 0.753145] [G loss: 0.597349] time: 0:19:29.078349\n",
      "0.93899584\n",
      "[Epoch 13/50] [Batch 11/300] [D loss: 0.753095] [G loss: 0.571787] time: 0:19:29.354226\n",
      "0.9489139\n",
      "[Epoch 13/50] [Batch 13/300] [D loss: 0.753140] [G loss: 0.602283] time: 0:19:29.667559\n",
      "0.94367415\n",
      "[Epoch 13/50] [Batch 14/300] [D loss: 0.753100] [G loss: 0.670943] time: 0:19:29.976533\n",
      "0.8985515\n",
      "[Epoch 13/50] [Batch 15/300] [D loss: 0.753113] [G loss: 0.641439] time: 0:19:30.271349\n",
      "0.85160875\n",
      "[Epoch 13/50] [Batch 16/300] [D loss: 0.753116] [G loss: 0.620763] time: 0:19:30.580370\n",
      "0.9381891\n",
      "[Epoch 13/50] [Batch 17/300] [D loss: 0.753074] [G loss: 0.597361] time: 0:19:30.888386\n",
      "0.8870967\n",
      "[Epoch 13/50] [Batch 18/300] [D loss: 0.753115] [G loss: 0.646045] time: 0:19:31.184090\n",
      "0.9144357\n",
      "[Epoch 13/50] [Batch 19/300] [D loss: 0.753189] [G loss: 0.638025] time: 0:19:31.491140\n",
      "0.8887868\n",
      "[Epoch 13/50] [Batch 20/300] [D loss: 0.753104] [G loss: 0.564584] time: 0:19:31.797398\n",
      "0.9303134\n",
      "[Epoch 13/50] [Batch 21/300] [D loss: 0.753183] [G loss: 0.568098] time: 0:19:32.096943\n",
      "0.9127597\n",
      "[Epoch 13/50] [Batch 22/300] [D loss: 0.753159] [G loss: 0.643740] time: 0:19:32.397647\n",
      "0.9289426\n",
      "[Epoch 13/50] [Batch 23/300] [D loss: 0.753081] [G loss: 0.606438] time: 0:19:32.696830\n",
      "0.88205194\n",
      "[Epoch 13/50] [Batch 24/300] [D loss: 0.753140] [G loss: 0.618853] time: 0:19:32.983583\n",
      "0.97075105\n",
      "[Epoch 13/50] [Batch 25/300] [D loss: 0.753126] [G loss: 0.675836] time: 0:19:33.281132\n",
      "0.9269633\n",
      "[Epoch 13/50] [Batch 26/300] [D loss: 0.753078] [G loss: 0.633568] time: 0:19:33.584633\n",
      "0.9467848\n",
      "[Epoch 13/50] [Batch 27/300] [D loss: 0.753106] [G loss: 0.637290] time: 0:19:33.892346\n",
      "0.9308056\n",
      "[Epoch 13/50] [Batch 28/300] [D loss: 0.753142] [G loss: 0.551963] time: 0:19:34.179200\n",
      "0.93682957\n",
      "[Epoch 13/50] [Batch 29/300] [D loss: 0.753153] [G loss: 0.627775] time: 0:19:34.458583\n",
      "0.9343574\n",
      "[Epoch 13/50] [Batch 30/300] [D loss: 0.753146] [G loss: 0.624941] time: 0:19:34.754370\n",
      "0.91357565\n",
      "[Epoch 13/50] [Batch 31/300] [D loss: 0.753126] [G loss: 0.564147] time: 0:19:35.051834\n",
      "0.8838043\n",
      "[Epoch 13/50] [Batch 32/300] [D loss: 0.753176] [G loss: 0.559783] time: 0:19:35.354131\n",
      "0.96847016\n",
      "[Epoch 13/50] [Batch 33/300] [D loss: 0.753119] [G loss: 0.590086] time: 0:19:35.667121\n",
      "0.9249592\n",
      "[Epoch 13/50] [Batch 34/300] [D loss: 0.753118] [G loss: 0.549230] time: 0:19:35.970079\n",
      "0.91206187\n",
      "[Epoch 13/50] [Batch 35/300] [D loss: 0.753091] [G loss: 0.583208] time: 0:19:36.257982\n",
      "0.88973856\n",
      "[Epoch 13/50] [Batch 36/300] [D loss: 0.753121] [G loss: 0.619073] time: 0:19:36.551196\n",
      "0.9177184\n",
      "[Epoch 13/50] [Batch 37/300] [D loss: 0.753113] [G loss: 0.574080] time: 0:19:36.839466\n",
      "0.91193575\n",
      "[Epoch 13/50] [Batch 38/300] [D loss: 0.753174] [G loss: 0.594105] time: 0:19:37.128371\n",
      "0.90714073\n",
      "[Epoch 13/50] [Batch 39/300] [D loss: 0.753160] [G loss: 0.596308] time: 0:19:37.427095\n",
      "0.89937973\n",
      "[Epoch 13/50] [Batch 40/300] [D loss: 0.753153] [G loss: 0.596395] time: 0:19:37.732010\n",
      "0.91564506\n",
      "[Epoch 13/50] [Batch 41/300] [D loss: 0.753072] [G loss: 0.576781] time: 0:19:38.042981\n",
      "0.92978793\n",
      "[Epoch 13/50] [Batch 42/300] [D loss: 0.753068] [G loss: 0.666095] time: 0:19:38.352978\n",
      "0.9114459\n",
      "[Epoch 13/50] [Batch 43/300] [D loss: 0.753087] [G loss: 0.577133] time: 0:19:38.649633\n",
      "0.93694335\n",
      "[Epoch 13/50] [Batch 44/300] [D loss: 0.753056] [G loss: 0.636639] time: 0:19:38.962811\n",
      "0.87946516\n",
      "[Epoch 13/50] [Batch 45/300] [D loss: 0.753165] [G loss: 0.618716] time: 0:19:39.257385\n",
      "0.945031\n",
      "[Epoch 13/50] [Batch 46/300] [D loss: 0.753131] [G loss: 0.568061] time: 0:19:39.546998\n",
      "0.8789695\n",
      "[Epoch 13/50] [Batch 47/300] [D loss: 0.753082] [G loss: 0.632054] time: 0:19:39.845487\n",
      "0.9427125\n",
      "[Epoch 13/50] [Batch 48/300] [D loss: 0.753083] [G loss: 0.592958] time: 0:19:40.140083\n",
      "0.9305499\n",
      "[Epoch 13/50] [Batch 49/300] [D loss: 0.753147] [G loss: 0.575927] time: 0:19:40.438535\n",
      "0.9084366\n",
      "[Epoch 13/50] [Batch 50/300] [D loss: 0.753118] [G loss: 0.555147] time: 0:19:40.729609\n",
      "0.91207534\n",
      "[Epoch 13/50] [Batch 51/300] [D loss: 0.753136] [G loss: 0.531740] time: 0:19:41.026561\n",
      "0.9062455\n",
      "[Epoch 13/50] [Batch 52/300] [D loss: 0.753092] [G loss: 0.548946] time: 0:19:41.328402\n",
      "0.88864714\n",
      "[Epoch 13/50] [Batch 53/300] [D loss: 0.753098] [G loss: 0.576084] time: 0:19:41.618323\n",
      "0.93569237\n",
      "[Epoch 13/50] [Batch 54/300] [D loss: 0.753080] [G loss: 0.566046] time: 0:19:41.918240\n",
      "0.89901567\n",
      "[Epoch 13/50] [Batch 55/300] [D loss: 0.753117] [G loss: 0.605456] time: 0:19:42.232014\n",
      "0.94500226\n",
      "[Epoch 13/50] [Batch 56/300] [D loss: 0.753147] [G loss: 0.569641] time: 0:19:42.534593\n",
      "0.92377967\n",
      "[Epoch 13/50] [Batch 57/300] [D loss: 0.753040] [G loss: 0.593054] time: 0:19:42.836233\n",
      "0.93444484\n",
      "[Epoch 13/50] [Batch 58/300] [D loss: 0.753104] [G loss: 0.624534] time: 0:19:43.144380\n",
      "0.9297471\n",
      "[Epoch 13/50] [Batch 59/300] [D loss: 0.753093] [G loss: 0.548603] time: 0:19:43.448644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9343532\n",
      "[Epoch 13/50] [Batch 60/300] [D loss: 0.753119] [G loss: 0.670772] time: 0:19:43.754143\n",
      "0.9356194\n",
      "[Epoch 13/50] [Batch 61/300] [D loss: 0.753137] [G loss: 0.588679] time: 0:19:44.076899\n",
      "0.9155555\n",
      "[Epoch 13/50] [Batch 62/300] [D loss: 0.753158] [G loss: 0.551183] time: 0:19:44.374262\n",
      "0.8866396\n",
      "[Epoch 13/50] [Batch 63/300] [D loss: 0.753090] [G loss: 0.536070] time: 0:19:44.675785\n",
      "0.9083057\n",
      "[Epoch 13/50] [Batch 64/300] [D loss: 0.753108] [G loss: 0.534465] time: 0:19:44.980924\n",
      "0.94586515\n",
      "[Epoch 13/50] [Batch 65/300] [D loss: 0.753074] [G loss: 0.636104] time: 0:19:45.286605\n",
      "0.9030443\n",
      "[Epoch 13/50] [Batch 66/300] [D loss: 0.753086] [G loss: 0.663342] time: 0:19:45.580531\n",
      "0.9104255\n",
      "[Epoch 13/50] [Batch 67/300] [D loss: 0.753083] [G loss: 0.684252] time: 0:19:45.879236\n",
      "0.91797477\n",
      "[Epoch 13/50] [Batch 68/300] [D loss: 0.753057] [G loss: 0.617694] time: 0:19:46.183833\n",
      "0.89164335\n",
      "[Epoch 13/50] [Batch 69/300] [D loss: 0.753109] [G loss: 0.627177] time: 0:19:46.479559\n",
      "0.9559407\n",
      "[Epoch 13/50] [Batch 70/300] [D loss: 0.753075] [G loss: 0.686978] time: 0:19:46.772663\n",
      "0.92703724\n",
      "[Epoch 13/50] [Batch 71/300] [D loss: 0.753118] [G loss: 0.613320] time: 0:19:47.068358\n",
      "0.9240044\n",
      "[Epoch 13/50] [Batch 72/300] [D loss: 0.753115] [G loss: 0.637816] time: 0:19:47.371559\n",
      "0.93444204\n",
      "[Epoch 13/50] [Batch 73/300] [D loss: 0.753081] [G loss: 0.590931] time: 0:19:47.668256\n",
      "0.9366627\n",
      "[Epoch 13/50] [Batch 74/300] [D loss: 0.753072] [G loss: 0.594827] time: 0:19:47.964037\n",
      "0.9038629\n",
      "[Epoch 13/50] [Batch 75/300] [D loss: 0.753080] [G loss: 0.625214] time: 0:19:48.263140\n",
      "0.881455\n",
      "[Epoch 13/50] [Batch 76/300] [D loss: 0.753121] [G loss: 0.589124] time: 0:19:48.565334\n",
      "0.95867664\n",
      "[Epoch 13/50] [Batch 77/300] [D loss: 0.753082] [G loss: 0.593583] time: 0:19:48.868979\n",
      "0.94184464\n",
      "[Epoch 13/50] [Batch 78/300] [D loss: 0.753106] [G loss: 0.597564] time: 0:19:49.167775\n",
      "0.8992923\n",
      "[Epoch 13/50] [Batch 79/300] [D loss: 0.753087] [G loss: 0.629146] time: 0:19:49.453557\n",
      "0.9150565\n",
      "[Epoch 13/50] [Batch 80/300] [D loss: 0.753077] [G loss: 0.571892] time: 0:19:49.760081\n",
      "0.86840296\n",
      "[Epoch 13/50] [Batch 81/300] [D loss: 0.753103] [G loss: 0.738606] time: 0:19:50.067228\n",
      "0.9529868\n",
      "[Epoch 13/50] [Batch 82/300] [D loss: 0.753075] [G loss: 0.624718] time: 0:19:50.363046\n",
      "0.9455597\n",
      "[Epoch 13/50] [Batch 83/300] [D loss: 0.753083] [G loss: 0.624382] time: 0:19:50.670743\n",
      "0.9010498\n",
      "[Epoch 13/50] [Batch 84/300] [D loss: 0.753072] [G loss: 0.604034] time: 0:19:50.972398\n",
      "0.9027427\n",
      "[Epoch 13/50] [Batch 85/300] [D loss: 0.753074] [G loss: 0.551887] time: 0:19:51.280143\n",
      "0.9534885\n",
      "[Epoch 13/50] [Batch 86/300] [D loss: 0.753099] [G loss: 0.633766] time: 0:19:51.569297\n",
      "0.93706846\n",
      "[Epoch 13/50] [Batch 87/300] [D loss: 0.753080] [G loss: 0.600997] time: 0:19:51.876252\n",
      "0.93003696\n",
      "[Epoch 13/50] [Batch 88/300] [D loss: 0.753074] [G loss: 0.595807] time: 0:19:52.165898\n",
      "0.91615146\n",
      "[Epoch 13/50] [Batch 89/300] [D loss: 0.753050] [G loss: 0.571636] time: 0:19:52.466564\n",
      "0.9299209\n",
      "[Epoch 13/50] [Batch 90/300] [D loss: 0.753043] [G loss: 0.640671] time: 0:19:52.746559\n",
      "0.94139737\n",
      "[Epoch 13/50] [Batch 91/300] [D loss: 0.753095] [G loss: 0.603082] time: 0:19:53.042704\n",
      "0.9376196\n",
      "[Epoch 13/50] [Batch 92/300] [D loss: 0.753060] [G loss: 0.659860] time: 0:19:53.340142\n",
      "0.94732314\n",
      "[Epoch 13/50] [Batch 93/300] [D loss: 0.753082] [G loss: 0.600788] time: 0:19:53.641107\n",
      "0.91460234\n",
      "[Epoch 13/50] [Batch 94/300] [D loss: 0.753061] [G loss: 0.593009] time: 0:19:53.935630\n",
      "0.9350748\n",
      "[Epoch 13/50] [Batch 95/300] [D loss: 0.753059] [G loss: 0.601463] time: 0:19:54.226733\n",
      "0.9432562\n",
      "[Epoch 13/50] [Batch 96/300] [D loss: 0.753109] [G loss: 0.577428] time: 0:19:54.525852\n",
      "0.9365015\n",
      "[Epoch 13/50] [Batch 97/300] [D loss: 0.753071] [G loss: 0.614398] time: 0:19:54.835770\n",
      "0.913436\n",
      "[Epoch 13/50] [Batch 98/300] [D loss: 0.753059] [G loss: 0.706989] time: 0:19:55.137154\n",
      "0.914598\n",
      "[Epoch 13/50] [Batch 99/300] [D loss: 0.753094] [G loss: 0.556019] time: 0:19:55.443440\n",
      "0.9079852\n",
      "[Epoch 13/50] [Batch 100/300] [D loss: 0.753112] [G loss: 0.558986] time: 0:19:55.742812\n",
      "0.9247101\n",
      "[Epoch 13/50] [Batch 101/300] [D loss: 0.753125] [G loss: 0.581596] time: 0:19:56.039507\n",
      "0.9164174\n",
      "[Epoch 13/50] [Batch 102/300] [D loss: 0.753052] [G loss: 0.570785] time: 0:19:56.339271\n",
      "0.9327867\n",
      "[Epoch 13/50] [Batch 103/300] [D loss: 0.753074] [G loss: 0.552184] time: 0:19:56.624086\n",
      "0.9338259\n",
      "[Epoch 13/50] [Batch 104/300] [D loss: 0.753043] [G loss: 0.611761] time: 0:19:56.921859\n",
      "0.9387954\n",
      "[Epoch 13/50] [Batch 105/300] [D loss: 0.753088] [G loss: 0.651482] time: 0:19:57.212624\n",
      "0.95702046\n",
      "[Epoch 13/50] [Batch 106/300] [D loss: 0.753071] [G loss: 0.563170] time: 0:19:57.496952\n",
      "0.91795635\n",
      "[Epoch 13/50] [Batch 107/300] [D loss: 0.753054] [G loss: 0.673439] time: 0:19:57.798774\n",
      "0.88469934\n",
      "[Epoch 13/50] [Batch 108/300] [D loss: 0.753034] [G loss: 0.631887] time: 0:19:58.093135\n",
      "0.90896624\n",
      "[Epoch 13/50] [Batch 109/300] [D loss: 0.753089] [G loss: 0.673732] time: 0:19:58.370907\n",
      "0.9072694\n",
      "[Epoch 13/50] [Batch 110/300] [D loss: 0.753130] [G loss: 0.578297] time: 0:19:58.670799\n",
      "0.9329982\n",
      "[Epoch 13/50] [Batch 111/300] [D loss: 0.753090] [G loss: 0.632123] time: 0:19:58.952923\n",
      "0.9205682\n",
      "[Epoch 13/50] [Batch 112/300] [D loss: 0.753076] [G loss: 0.575286] time: 0:19:59.235191\n",
      "0.91210395\n",
      "[Epoch 13/50] [Batch 113/300] [D loss: 0.753056] [G loss: 0.571558] time: 0:19:59.550997\n",
      "0.905523\n",
      "[Epoch 13/50] [Batch 114/300] [D loss: 0.753056] [G loss: 0.581020] time: 0:19:59.866192\n",
      "0.93437\n",
      "[Epoch 13/50] [Batch 115/300] [D loss: 0.753066] [G loss: 0.585878] time: 0:20:00.162859\n",
      "0.9330733\n",
      "[Epoch 13/50] [Batch 116/300] [D loss: 0.753057] [G loss: 0.629108] time: 0:20:00.456258\n",
      "0.9425923\n",
      "[Epoch 13/50] [Batch 117/300] [D loss: 0.753105] [G loss: 0.598003] time: 0:20:00.746147\n",
      "0.9264458\n",
      "[Epoch 13/50] [Batch 118/300] [D loss: 0.753107] [G loss: 0.680926] time: 0:20:01.063698\n",
      "0.92880446\n",
      "[Epoch 13/50] [Batch 119/300] [D loss: 0.753071] [G loss: 0.596107] time: 0:20:01.352481\n",
      "0.885591\n",
      "[Epoch 13/50] [Batch 120/300] [D loss: 0.753117] [G loss: 0.567172] time: 0:20:01.656315\n",
      "0.9237425\n",
      "[Epoch 13/50] [Batch 121/300] [D loss: 0.753103] [G loss: 0.581656] time: 0:20:01.968329\n",
      "0.9012962\n",
      "[Epoch 13/50] [Batch 122/300] [D loss: 0.753050] [G loss: 0.620350] time: 0:20:02.259203\n",
      "0.9363008\n",
      "[Epoch 13/50] [Batch 123/300] [D loss: 0.753131] [G loss: 0.623847] time: 0:20:02.564274\n",
      "0.93686086\n",
      "[Epoch 13/50] [Batch 124/300] [D loss: 0.753098] [G loss: 0.592799] time: 0:20:02.864333\n",
      "0.9032111\n",
      "[Epoch 13/50] [Batch 125/300] [D loss: 0.753072] [G loss: 0.591450] time: 0:20:03.159756\n",
      "0.9084838\n",
      "[Epoch 13/50] [Batch 126/300] [D loss: 0.753082] [G loss: 0.593651] time: 0:20:03.464344\n",
      "0.955152\n",
      "[Epoch 13/50] [Batch 127/300] [D loss: 0.753053] [G loss: 0.621457] time: 0:20:03.778735\n",
      "0.9620002\n",
      "[Epoch 13/50] [Batch 128/300] [D loss: 0.753053] [G loss: 0.562822] time: 0:20:04.099483\n",
      "0.9355174\n",
      "[Epoch 13/50] [Batch 129/300] [D loss: 0.753123] [G loss: 0.597369] time: 0:20:04.399019\n",
      "0.9147517\n",
      "[Epoch 13/50] [Batch 130/300] [D loss: 0.753038] [G loss: 0.671348] time: 0:20:04.712215\n",
      "0.911244\n",
      "[Epoch 13/50] [Batch 131/300] [D loss: 0.753079] [G loss: 0.581448] time: 0:20:05.022120\n",
      "0.90389675\n",
      "[Epoch 13/50] [Batch 132/300] [D loss: 0.753072] [G loss: 0.637850] time: 0:20:05.313814\n",
      "0.93485945\n",
      "[Epoch 13/50] [Batch 133/300] [D loss: 0.753082] [G loss: 0.646474] time: 0:20:05.618951\n",
      "0.90337753\n",
      "[Epoch 13/50] [Batch 134/300] [D loss: 0.753045] [G loss: 0.590001] time: 0:20:05.917412\n",
      "0.9540973\n",
      "[Epoch 13/50] [Batch 135/300] [D loss: 0.753098] [G loss: 0.677536] time: 0:20:06.222937\n",
      "0.9117041\n",
      "[Epoch 13/50] [Batch 136/300] [D loss: 0.753037] [G loss: 0.590256] time: 0:20:06.535749\n",
      "0.9400565\n",
      "[Epoch 13/50] [Batch 137/300] [D loss: 0.753113] [G loss: 0.620204] time: 0:20:06.814145\n",
      "0.9597771\n",
      "[Epoch 13/50] [Batch 138/300] [D loss: 0.753107] [G loss: 0.587072] time: 0:20:07.122755\n",
      "0.9092769\n",
      "[Epoch 13/50] [Batch 139/300] [D loss: 0.753056] [G loss: 0.625770] time: 0:20:07.419831\n",
      "0.8844885\n",
      "[Epoch 13/50] [Batch 140/300] [D loss: 0.753068] [G loss: 0.656587] time: 0:20:07.737391\n",
      "0.9495211\n",
      "[Epoch 13/50] [Batch 141/300] [D loss: 0.753076] [G loss: 0.646845] time: 0:20:08.056114\n",
      "0.97237366\n",
      "[Epoch 13/50] [Batch 142/300] [D loss: 0.753069] [G loss: 0.592746] time: 0:20:08.388146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90255874\n",
      "[Epoch 13/50] [Batch 143/300] [D loss: 0.753067] [G loss: 0.591748] time: 0:20:08.695859\n",
      "0.89624715\n",
      "[Epoch 13/50] [Batch 144/300] [D loss: 0.753053] [G loss: 0.627210] time: 0:20:09.008804\n",
      "0.88434094\n",
      "[Epoch 13/50] [Batch 145/300] [D loss: 0.753075] [G loss: 0.594258] time: 0:20:09.307784\n",
      "0.941853\n",
      "[Epoch 13/50] [Batch 146/300] [D loss: 0.753068] [G loss: 0.555468] time: 0:20:09.571798\n",
      "0.87390953\n",
      "[Epoch 13/50] [Batch 147/300] [D loss: 0.753051] [G loss: 0.566664] time: 0:20:09.843488\n",
      "0.91058284\n",
      "[Epoch 13/50] [Batch 148/300] [D loss: 0.753085] [G loss: 0.615557] time: 0:20:10.166817\n",
      "0.9170497\n",
      "[Epoch 13/50] [Batch 149/300] [D loss: 0.753050] [G loss: 0.682351] time: 0:20:10.451923\n",
      "0.90591264\n",
      "[Epoch 13/50] [Batch 150/300] [D loss: 0.753064] [G loss: 0.601672] time: 0:20:10.749996\n",
      "0.92112756\n",
      "[Epoch 13/50] [Batch 151/300] [D loss: 0.753075] [G loss: 0.591051] time: 0:20:11.057011\n",
      "0.87589455\n",
      "[Epoch 13/50] [Batch 152/300] [D loss: 0.753058] [G loss: 0.583258] time: 0:20:11.329108\n",
      "0.9161671\n",
      "[Epoch 13/50] [Batch 153/300] [D loss: 0.753061] [G loss: 0.606001] time: 0:20:11.638004\n",
      "0.92724556\n",
      "[Epoch 13/50] [Batch 154/300] [D loss: 0.753102] [G loss: 0.565190] time: 0:20:11.937086\n",
      "0.9271442\n",
      "[Epoch 13/50] [Batch 155/300] [D loss: 0.753095] [G loss: 0.630523] time: 0:20:12.240843\n",
      "0.8915433\n",
      "[Epoch 13/50] [Batch 156/300] [D loss: 0.753086] [G loss: 0.599347] time: 0:20:12.549592\n",
      "0.89906603\n",
      "[Epoch 13/50] [Batch 157/300] [D loss: 0.753051] [G loss: 0.595119] time: 0:20:12.858724\n",
      "0.9319803\n",
      "[Epoch 13/50] [Batch 158/300] [D loss: 0.753028] [G loss: 0.589746] time: 0:20:13.161984\n",
      "0.9465367\n",
      "[Epoch 13/50] [Batch 159/300] [D loss: 0.753094] [G loss: 0.598500] time: 0:20:13.433078\n",
      "0.9091731\n",
      "[Epoch 13/50] [Batch 160/300] [D loss: 0.753070] [G loss: 0.619425] time: 0:20:13.731950\n",
      "0.92946213\n",
      "[Epoch 13/50] [Batch 161/300] [D loss: 0.753051] [G loss: 0.646020] time: 0:20:14.034322\n",
      "0.9830738\n",
      "[Epoch 13/50] [Batch 162/300] [D loss: 0.753126] [G loss: 0.596356] time: 0:20:14.336026\n",
      "0.9330607\n",
      "[Epoch 13/50] [Batch 163/300] [D loss: 0.753023] [G loss: 0.625815] time: 0:20:14.649187\n",
      "0.94413877\n",
      "[Epoch 13/50] [Batch 164/300] [D loss: 0.753038] [G loss: 0.620934] time: 0:20:14.939287\n",
      "0.95109016\n",
      "[Epoch 13/50] [Batch 165/300] [D loss: 0.753027] [G loss: 0.612424] time: 0:20:15.244595\n",
      "0.93981725\n",
      "[Epoch 13/50] [Batch 166/300] [D loss: 0.752998] [G loss: 0.641292] time: 0:20:15.561526\n",
      "0.8508601\n",
      "[Epoch 13/50] [Batch 167/300] [D loss: 0.753053] [G loss: 0.646348] time: 0:20:15.854213\n",
      "0.9461209\n",
      "[Epoch 13/50] [Batch 168/300] [D loss: 0.753063] [G loss: 0.560192] time: 0:20:16.174425\n",
      "0.92486024\n",
      "[Epoch 13/50] [Batch 169/300] [D loss: 0.753058] [G loss: 0.609319] time: 0:20:16.475388\n",
      "0.93398625\n",
      "[Epoch 13/50] [Batch 170/300] [D loss: 0.753052] [G loss: 0.587600] time: 0:20:16.795812\n",
      "0.9108332\n",
      "[Epoch 13/50] [Batch 171/300] [D loss: 0.753108] [G loss: 0.615870] time: 0:20:17.088052\n",
      "0.92030066\n",
      "[Epoch 13/50] [Batch 172/300] [D loss: 0.753099] [G loss: 0.612466] time: 0:20:17.411606\n",
      "0.9314131\n",
      "[Epoch 13/50] [Batch 173/300] [D loss: 0.753082] [G loss: 0.584042] time: 0:20:17.690753\n",
      "0.9354296\n",
      "[Epoch 13/50] [Batch 174/300] [D loss: 0.753080] [G loss: 0.552445] time: 0:20:17.978410\n",
      "0.89284056\n",
      "[Epoch 13/50] [Batch 175/300] [D loss: 0.753037] [G loss: 0.647672] time: 0:20:18.278270\n",
      "0.9372569\n",
      "[Epoch 13/50] [Batch 176/300] [D loss: 0.753077] [G loss: 0.568124] time: 0:20:18.568517\n",
      "0.92361784\n",
      "[Epoch 13/50] [Batch 177/300] [D loss: 0.753039] [G loss: 0.623943] time: 0:20:18.879732\n",
      "0.88245803\n",
      "[Epoch 13/50] [Batch 178/300] [D loss: 0.753029] [G loss: 0.655880] time: 0:20:19.182734\n",
      "0.9076216\n",
      "[Epoch 13/50] [Batch 179/300] [D loss: 0.753078] [G loss: 0.596049] time: 0:20:19.460631\n",
      "0.953517\n",
      "[Epoch 13/50] [Batch 180/300] [D loss: 0.753036] [G loss: 0.608803] time: 0:20:19.767018\n",
      "0.93952507\n",
      "[Epoch 13/50] [Batch 181/300] [D loss: 0.753062] [G loss: 0.598824] time: 0:20:20.058654\n",
      "0.9120608\n",
      "[Epoch 13/50] [Batch 182/300] [D loss: 0.753018] [G loss: 0.619294] time: 0:20:20.364656\n",
      "0.92953944\n",
      "[Epoch 13/50] [Batch 183/300] [D loss: 0.753090] [G loss: 0.679673] time: 0:20:20.660828\n",
      "0.91457707\n",
      "[Epoch 13/50] [Batch 184/300] [D loss: 0.753057] [G loss: 0.621408] time: 0:20:20.952713\n",
      "0.8525159\n",
      "[Epoch 13/50] [Batch 185/300] [D loss: 0.753042] [G loss: 0.585537] time: 0:20:21.249814\n",
      "0.92256045\n",
      "[Epoch 13/50] [Batch 186/300] [D loss: 0.753032] [G loss: 0.635980] time: 0:20:21.552172\n",
      "0.93174154\n",
      "[Epoch 13/50] [Batch 187/300] [D loss: 0.753051] [G loss: 0.614812] time: 0:20:21.865571\n",
      "0.8820636\n",
      "[Epoch 13/50] [Batch 188/300] [D loss: 0.753100] [G loss: 0.583783] time: 0:20:22.171415\n",
      "0.9088242\n",
      "[Epoch 13/50] [Batch 189/300] [D loss: 0.753066] [G loss: 0.603433] time: 0:20:22.470999\n",
      "0.8922315\n",
      "[Epoch 13/50] [Batch 190/300] [D loss: 0.753036] [G loss: 0.610432] time: 0:20:22.782837\n",
      "0.87148976\n",
      "[Epoch 13/50] [Batch 191/300] [D loss: 0.753019] [G loss: 0.627213] time: 0:20:23.088282\n",
      "0.9117162\n",
      "[Epoch 13/50] [Batch 192/300] [D loss: 0.753089] [G loss: 0.567574] time: 0:20:23.395215\n",
      "0.89324814\n",
      "[Epoch 13/50] [Batch 193/300] [D loss: 0.753045] [G loss: 0.651280] time: 0:20:23.687934\n",
      "0.9171105\n",
      "[Epoch 13/50] [Batch 194/300] [D loss: 0.753069] [G loss: 0.611178] time: 0:20:24.007370\n",
      "0.8811023\n",
      "[Epoch 13/50] [Batch 195/300] [D loss: 0.753065] [G loss: 0.632921] time: 0:20:24.297644\n",
      "0.95840484\n",
      "[Epoch 13/50] [Batch 196/300] [D loss: 0.753012] [G loss: 0.641936] time: 0:20:24.590179\n",
      "0.9139741\n",
      "[Epoch 13/50] [Batch 197/300] [D loss: 0.753034] [G loss: 0.618891] time: 0:20:24.876135\n",
      "0.8499486\n",
      "[Epoch 13/50] [Batch 198/300] [D loss: 0.753052] [G loss: 0.688397] time: 0:20:25.175985\n",
      "0.9262786\n",
      "[Epoch 13/50] [Batch 199/300] [D loss: 0.753041] [G loss: 0.557376] time: 0:20:25.484372\n",
      "0.98278785\n",
      "[Epoch 13/50] [Batch 200/300] [D loss: 0.753055] [G loss: 0.603734] time: 0:20:25.769079\n",
      "0.8976248\n",
      "[Epoch 13/50] [Batch 201/300] [D loss: 0.753075] [G loss: 0.579776] time: 0:20:26.078826\n",
      "0.9232084\n",
      "[Epoch 13/50] [Batch 202/300] [D loss: 0.753036] [G loss: 0.595498] time: 0:20:26.385665\n",
      "0.97783995\n",
      "[Epoch 13/50] [Batch 203/300] [D loss: 0.753036] [G loss: 0.664281] time: 0:20:26.679972\n",
      "0.896025\n",
      "[Epoch 13/50] [Batch 204/300] [D loss: 0.753071] [G loss: 0.674517] time: 0:20:26.975522\n",
      "0.92967606\n",
      "[Epoch 13/50] [Batch 205/300] [D loss: 0.753101] [G loss: 0.600801] time: 0:20:27.272440\n",
      "0.94615275\n",
      "[Epoch 13/50] [Batch 206/300] [D loss: 0.753031] [G loss: 0.633870] time: 0:20:27.578931\n",
      "0.9046863\n",
      "[Epoch 13/50] [Batch 207/300] [D loss: 0.752999] [G loss: 0.592531] time: 0:20:27.884537\n",
      "0.88726115\n",
      "[Epoch 13/50] [Batch 208/300] [D loss: 0.753073] [G loss: 0.660241] time: 0:20:28.185086\n",
      "0.9024997\n",
      "[Epoch 13/50] [Batch 209/300] [D loss: 0.753067] [G loss: 0.628557] time: 0:20:28.481148\n",
      "0.96001464\n",
      "[Epoch 13/50] [Batch 210/300] [D loss: 0.753075] [G loss: 0.590092] time: 0:20:28.791086\n",
      "0.9588752\n",
      "[Epoch 13/50] [Batch 211/300] [D loss: 0.753054] [G loss: 0.664411] time: 0:20:29.075211\n",
      "0.9088567\n",
      "[Epoch 13/50] [Batch 212/300] [D loss: 0.753026] [G loss: 0.596328] time: 0:20:29.380702\n",
      "0.9216542\n",
      "[Epoch 13/50] [Batch 213/300] [D loss: 0.753062] [G loss: 0.621111] time: 0:20:29.682593\n",
      "0.9305759\n",
      "[Epoch 13/50] [Batch 214/300] [D loss: 0.753046] [G loss: 0.563603] time: 0:20:29.988717\n",
      "0.98032904\n",
      "[Epoch 13/50] [Batch 215/300] [D loss: 0.753030] [G loss: 0.581772] time: 0:20:30.274293\n",
      "0.9330732\n",
      "[Epoch 13/50] [Batch 216/300] [D loss: 0.753034] [G loss: 0.544342] time: 0:20:30.578749\n",
      "0.92684394\n",
      "[Epoch 13/50] [Batch 217/300] [D loss: 0.753029] [G loss: 0.595621] time: 0:20:30.875681\n",
      "0.95410186\n",
      "[Epoch 13/50] [Batch 218/300] [D loss: 0.753040] [G loss: 0.593937] time: 0:20:31.173458\n",
      "0.88980347\n",
      "[Epoch 13/50] [Batch 219/300] [D loss: 0.753009] [G loss: 0.570250] time: 0:20:31.477026\n",
      "0.94376\n",
      "[Epoch 13/50] [Batch 220/300] [D loss: 0.753096] [G loss: 0.655787] time: 0:20:31.780958\n",
      "0.9422648\n",
      "[Epoch 13/50] [Batch 221/300] [D loss: 0.753022] [G loss: 0.602390] time: 0:20:32.089105\n",
      "0.9065089\n",
      "[Epoch 13/50] [Batch 222/300] [D loss: 0.753036] [G loss: 0.701467] time: 0:20:32.388746\n",
      "0.8915108\n",
      "[Epoch 13/50] [Batch 223/300] [D loss: 0.753101] [G loss: 0.606441] time: 0:20:32.666300\n",
      "0.92018676\n",
      "[Epoch 13/50] [Batch 224/300] [D loss: 0.753005] [G loss: 0.716743] time: 0:20:32.970270\n",
      "0.8882665\n",
      "[Epoch 13/50] [Batch 225/300] [D loss: 0.753058] [G loss: 0.615003] time: 0:20:33.268311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399522\n",
      "[Epoch 13/50] [Batch 226/300] [D loss: 0.753044] [G loss: 0.618728] time: 0:20:33.566562\n",
      "0.9158043\n",
      "[Epoch 13/50] [Batch 227/300] [D loss: 0.753007] [G loss: 0.565334] time: 0:20:33.880590\n",
      "0.8672669\n",
      "[Epoch 13/50] [Batch 228/300] [D loss: 0.753040] [G loss: 0.572121] time: 0:20:34.188254\n",
      "0.94740313\n",
      "[Epoch 13/50] [Batch 229/300] [D loss: 0.753036] [G loss: 0.577137] time: 0:20:34.487472\n",
      "0.91645145\n",
      "[Epoch 13/50] [Batch 230/300] [D loss: 0.753075] [G loss: 0.605057] time: 0:20:34.785946\n",
      "0.9460837\n",
      "[Epoch 13/50] [Batch 231/300] [D loss: 0.753013] [G loss: 0.657411] time: 0:20:35.082073\n",
      "0.93986034\n",
      "[Epoch 13/50] [Batch 232/300] [D loss: 0.753092] [G loss: 0.671090] time: 0:20:35.381173\n",
      "0.92541987\n",
      "[Epoch 13/50] [Batch 233/300] [D loss: 0.753011] [G loss: 0.608040] time: 0:20:35.670337\n",
      "0.9250288\n",
      "[Epoch 13/50] [Batch 234/300] [D loss: 0.753037] [G loss: 0.659932] time: 0:20:35.967965\n",
      "0.9241261\n",
      "[Epoch 13/50] [Batch 235/300] [D loss: 0.753039] [G loss: 0.574560] time: 0:20:36.268885\n",
      "0.9281607\n",
      "[Epoch 13/50] [Batch 236/300] [D loss: 0.753020] [G loss: 0.630576] time: 0:20:36.566349\n",
      "0.9235653\n",
      "[Epoch 13/50] [Batch 237/300] [D loss: 0.753053] [G loss: 0.615509] time: 0:20:36.877461\n",
      "0.9304371\n",
      "[Epoch 13/50] [Batch 238/300] [D loss: 0.753010] [G loss: 0.545753] time: 0:20:37.178473\n",
      "0.9523098\n",
      "[Epoch 13/50] [Batch 239/300] [D loss: 0.753012] [G loss: 0.605526] time: 0:20:37.475497\n",
      "0.9595852\n",
      "[Epoch 13/50] [Batch 240/300] [D loss: 0.753024] [G loss: 0.589897] time: 0:20:37.769693\n",
      "0.9276485\n",
      "[Epoch 13/50] [Batch 241/300] [D loss: 0.753048] [G loss: 0.659969] time: 0:20:38.064685\n",
      "0.93125147\n",
      "[Epoch 13/50] [Batch 242/300] [D loss: 0.753018] [G loss: 0.626202] time: 0:20:38.369317\n",
      "0.8943406\n",
      "[Epoch 13/50] [Batch 243/300] [D loss: 0.753035] [G loss: 0.549499] time: 0:20:38.686201\n",
      "0.9350622\n",
      "[Epoch 13/50] [Batch 244/300] [D loss: 0.753046] [G loss: 0.618341] time: 0:20:38.979093\n",
      "0.88531923\n",
      "[Epoch 13/50] [Batch 245/300] [D loss: 0.753019] [G loss: 0.657413] time: 0:20:39.280390\n",
      "0.8964407\n",
      "[Epoch 13/50] [Batch 246/300] [D loss: 0.753024] [G loss: 0.656277] time: 0:20:39.585617\n",
      "0.9446475\n",
      "[Epoch 13/50] [Batch 247/300] [D loss: 0.753020] [G loss: 0.634782] time: 0:20:39.884136\n",
      "0.9462587\n",
      "[Epoch 13/50] [Batch 248/300] [D loss: 0.753019] [G loss: 0.544863] time: 0:20:40.189119\n",
      "0.9207311\n",
      "[Epoch 13/50] [Batch 249/300] [D loss: 0.753004] [G loss: 0.633995] time: 0:20:40.492998\n",
      "0.94669145\n",
      "[Epoch 13/50] [Batch 250/300] [D loss: 0.753033] [G loss: 0.566534] time: 0:20:40.791334\n",
      "0.86692005\n",
      "[Epoch 13/50] [Batch 251/300] [D loss: 0.753024] [G loss: 0.679870] time: 0:20:41.069655\n",
      "0.93761873\n",
      "[Epoch 13/50] [Batch 252/300] [D loss: 0.753062] [G loss: 0.556510] time: 0:20:41.362234\n",
      "0.941204\n",
      "[Epoch 13/50] [Batch 253/300] [D loss: 0.753012] [G loss: 0.597030] time: 0:20:41.665388\n",
      "0.9145902\n",
      "[Epoch 13/50] [Batch 254/300] [D loss: 0.753076] [G loss: 0.623421] time: 0:20:41.956272\n",
      "0.8863725\n",
      "[Epoch 13/50] [Batch 255/300] [D loss: 0.753005] [G loss: 0.644498] time: 0:20:42.269970\n",
      "0.8916494\n",
      "[Epoch 13/50] [Batch 256/300] [D loss: 0.753018] [G loss: 0.672007] time: 0:20:42.580801\n",
      "0.8894126\n",
      "[Epoch 13/50] [Batch 257/300] [D loss: 0.753014] [G loss: 0.627890] time: 0:20:42.878964\n",
      "0.92750925\n",
      "[Epoch 13/50] [Batch 258/300] [D loss: 0.753028] [G loss: 0.574277] time: 0:20:43.186459\n",
      "0.87208694\n",
      "[Epoch 13/50] [Batch 259/300] [D loss: 0.753039] [G loss: 0.606213] time: 0:20:43.487302\n",
      "0.9304692\n",
      "[Epoch 13/50] [Batch 260/300] [D loss: 0.753069] [G loss: 0.578535] time: 0:20:43.792710\n",
      "0.92809033\n",
      "[Epoch 13/50] [Batch 261/300] [D loss: 0.753062] [G loss: 0.573277] time: 0:20:44.085052\n",
      "0.9342745\n",
      "[Epoch 13/50] [Batch 262/300] [D loss: 0.753045] [G loss: 0.607275] time: 0:20:44.390968\n",
      "0.8823943\n",
      "[Epoch 13/50] [Batch 263/300] [D loss: 0.753026] [G loss: 0.630813] time: 0:20:44.811549\n",
      "0.8819125\n",
      "[Epoch 13/50] [Batch 264/300] [D loss: 0.753000] [G loss: 0.545660] time: 0:20:45.098766\n",
      "0.946585\n",
      "[Epoch 13/50] [Batch 265/300] [D loss: 0.752986] [G loss: 0.622023] time: 0:20:45.404736\n",
      "0.8995556\n",
      "[Epoch 13/50] [Batch 266/300] [D loss: 0.753048] [G loss: 0.592321] time: 0:20:45.713985\n",
      "0.9249837\n",
      "[Epoch 13/50] [Batch 267/300] [D loss: 0.753045] [G loss: 0.653268] time: 0:20:46.003951\n",
      "0.91272074\n",
      "[Epoch 13/50] [Batch 268/300] [D loss: 0.753036] [G loss: 0.544971] time: 0:20:46.293832\n",
      "0.9146027\n",
      "[Epoch 13/50] [Batch 269/300] [D loss: 0.753042] [G loss: 0.613105] time: 0:20:46.595307\n",
      "0.93143624\n",
      "[Epoch 13/50] [Batch 270/300] [D loss: 0.753049] [G loss: 0.557712] time: 0:20:46.892816\n",
      "0.87520456\n",
      "[Epoch 13/50] [Batch 271/300] [D loss: 0.752993] [G loss: 0.663110] time: 0:20:47.194766\n",
      "0.9119682\n",
      "[Epoch 13/50] [Batch 272/300] [D loss: 0.753022] [G loss: 0.570192] time: 0:20:47.494775\n",
      "0.940615\n",
      "[Epoch 13/50] [Batch 273/300] [D loss: 0.752983] [G loss: 0.547482] time: 0:20:47.813216\n",
      "0.9562463\n",
      "[Epoch 13/50] [Batch 274/300] [D loss: 0.752996] [G loss: 0.595997] time: 0:20:48.105681\n",
      "0.9672782\n",
      "[Epoch 13/50] [Batch 275/300] [D loss: 0.752991] [G loss: 0.590718] time: 0:20:48.388361\n",
      "0.8977032\n",
      "[Epoch 13/50] [Batch 276/300] [D loss: 0.753029] [G loss: 0.620962] time: 0:20:48.687757\n",
      "0.92418814\n",
      "[Epoch 13/50] [Batch 277/300] [D loss: 0.753020] [G loss: 0.629059] time: 0:20:48.985907\n",
      "0.90269727\n",
      "[Epoch 13/50] [Batch 278/300] [D loss: 0.753030] [G loss: 0.587525] time: 0:20:49.269248\n",
      "0.88979775\n",
      "[Epoch 13/50] [Batch 279/300] [D loss: 0.752993] [G loss: 0.562681] time: 0:20:49.561736\n",
      "0.8925004\n",
      "[Epoch 13/50] [Batch 280/300] [D loss: 0.753003] [G loss: 0.608985] time: 0:20:49.862672\n",
      "0.9233761\n",
      "[Epoch 13/50] [Batch 281/300] [D loss: 0.753042] [G loss: 0.553273] time: 0:20:50.145825\n",
      "0.8942093\n",
      "[Epoch 13/50] [Batch 282/300] [D loss: 0.753012] [G loss: 0.598874] time: 0:20:50.450122\n",
      "0.8722035\n",
      "[Epoch 13/50] [Batch 283/300] [D loss: 0.753043] [G loss: 0.556984] time: 0:20:50.760432\n",
      "0.9309487\n",
      "[Epoch 13/50] [Batch 284/300] [D loss: 0.753061] [G loss: 0.597691] time: 0:20:51.056061\n",
      "0.93602866\n",
      "[Epoch 13/50] [Batch 285/300] [D loss: 0.753032] [G loss: 0.601016] time: 0:20:51.341237\n",
      "0.8800488\n",
      "[Epoch 13/50] [Batch 286/300] [D loss: 0.753052] [G loss: 0.583929] time: 0:20:51.637177\n",
      "0.9139927\n",
      "[Epoch 13/50] [Batch 287/300] [D loss: 0.753023] [G loss: 0.583290] time: 0:20:51.956431\n",
      "0.91238385\n",
      "[Epoch 13/50] [Batch 288/300] [D loss: 0.753026] [G loss: 0.577419] time: 0:20:52.280946\n",
      "0.943584\n",
      "[Epoch 13/50] [Batch 289/300] [D loss: 0.753045] [G loss: 0.553901] time: 0:20:52.576497\n",
      "0.92590815\n",
      "[Epoch 13/50] [Batch 290/300] [D loss: 0.753044] [G loss: 0.651055] time: 0:20:52.867925\n",
      "0.8841097\n",
      "[Epoch 13/50] [Batch 291/300] [D loss: 0.753028] [G loss: 0.576393] time: 0:20:53.156648\n",
      "0.90898323\n",
      "[Epoch 13/50] [Batch 292/300] [D loss: 0.752979] [G loss: 0.591829] time: 0:20:53.462039\n",
      "0.9658935\n",
      "[Epoch 13/50] [Batch 293/300] [D loss: 0.753026] [G loss: 0.623668] time: 0:20:53.782547\n",
      "0.88545984\n",
      "[Epoch 13/50] [Batch 294/300] [D loss: 0.752990] [G loss: 0.631879] time: 0:20:54.095289\n",
      "0.9349881\n",
      "[Epoch 13/50] [Batch 295/300] [D loss: 0.753029] [G loss: 0.596787] time: 0:20:54.398548\n",
      "0.90558654\n",
      "[Epoch 13/50] [Batch 296/300] [D loss: 0.753044] [G loss: 0.600174] time: 0:20:54.688846\n",
      "0.89583236\n",
      "[Epoch 13/50] [Batch 297/300] [D loss: 0.753008] [G loss: 0.545655] time: 0:20:54.994158\n",
      "0.94422466\n",
      "[Epoch 13/50] [Batch 298/300] [D loss: 0.753004] [G loss: 0.573977] time: 0:20:55.298257\n",
      "0.9390416\n",
      "[Epoch 13/50] [Batch 299/300] [D loss: 0.752995] [G loss: 0.657023] time: 0:20:55.609589\n",
      "0.9410339\n",
      "[Epoch 14/50] [Batch 0/300] [D loss: 0.752971] [G loss: 0.621911] time: 0:20:55.888724\n",
      "0.87574863\n",
      "[Epoch 14/50] [Batch 1/300] [D loss: 0.753034] [G loss: 0.586267] time: 0:20:56.166739\n",
      "0.8943046\n",
      "[Epoch 14/50] [Batch 2/300] [D loss: 0.753034] [G loss: 0.589524] time: 0:20:56.466747\n",
      "0.8990881\n",
      "[Epoch 14/50] [Batch 3/300] [D loss: 0.752987] [G loss: 0.611626] time: 0:20:56.765555\n",
      "0.90913177\n",
      "[Epoch 14/50] [Batch 4/300] [D loss: 0.753000] [G loss: 0.590495] time: 0:20:57.042805\n",
      "0.9154313\n",
      "[Epoch 14/50] [Batch 5/300] [D loss: 0.753018] [G loss: 0.568945] time: 0:20:57.334351\n",
      "0.88439846\n",
      "[Epoch 14/50] [Batch 6/300] [D loss: 0.753073] [G loss: 0.566374] time: 0:20:57.642110\n",
      "0.88771296\n",
      "[Epoch 14/50] [Batch 7/300] [D loss: 0.753017] [G loss: 0.607176] time: 0:20:57.936708\n",
      "0.9056143\n",
      "[Epoch 14/50] [Batch 8/300] [D loss: 0.753017] [G loss: 0.584568] time: 0:20:58.232093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9316332\n",
      "[Epoch 14/50] [Batch 9/300] [D loss: 0.753035] [G loss: 0.556984] time: 0:20:58.539276\n",
      "0.9066806\n",
      "[Epoch 14/50] [Batch 10/300] [D loss: 0.752992] [G loss: 0.556148] time: 0:20:58.862718\n",
      "0.9458272\n",
      "[Epoch 14/50] [Batch 11/300] [D loss: 0.752992] [G loss: 0.554274] time: 0:20:59.161803\n",
      "0.88267565\n",
      "[Epoch 14/50] [Batch 12/300] [D loss: 0.752948] [G loss: 0.592603] time: 0:20:59.447895\n",
      "0.94830495\n",
      "[Epoch 14/50] [Batch 14/300] [D loss: 0.752991] [G loss: 0.593270] time: 0:20:59.759491\n",
      "0.91852665\n",
      "[Epoch 14/50] [Batch 15/300] [D loss: 0.753014] [G loss: 0.656527] time: 0:21:00.064121\n",
      "0.8769848\n",
      "[Epoch 14/50] [Batch 16/300] [D loss: 0.753003] [G loss: 0.608117] time: 0:21:00.355745\n",
      "0.8958053\n",
      "[Epoch 14/50] [Batch 17/300] [D loss: 0.752978] [G loss: 0.671121] time: 0:21:00.657234\n",
      "0.8997705\n",
      "[Epoch 14/50] [Batch 18/300] [D loss: 0.753041] [G loss: 0.645693] time: 0:21:00.974224\n",
      "0.91527885\n",
      "[Epoch 14/50] [Batch 19/300] [D loss: 0.753029] [G loss: 0.660500] time: 0:21:01.260935\n",
      "0.9256828\n",
      "[Epoch 14/50] [Batch 20/300] [D loss: 0.753028] [G loss: 0.575574] time: 0:21:01.563633\n",
      "0.9119385\n",
      "[Epoch 14/50] [Batch 21/300] [D loss: 0.753001] [G loss: 0.616978] time: 0:21:01.849067\n",
      "0.9463137\n",
      "[Epoch 14/50] [Batch 22/300] [D loss: 0.752998] [G loss: 0.556410] time: 0:21:02.138473\n",
      "0.912257\n",
      "[Epoch 14/50] [Batch 23/300] [D loss: 0.752999] [G loss: 0.555254] time: 0:21:02.438331\n",
      "0.9105455\n",
      "[Epoch 14/50] [Batch 24/300] [D loss: 0.753061] [G loss: 0.570933] time: 0:21:02.738854\n",
      "0.89564824\n",
      "[Epoch 14/50] [Batch 25/300] [D loss: 0.752987] [G loss: 0.586334] time: 0:21:03.044165\n",
      "0.9225433\n",
      "[Epoch 14/50] [Batch 26/300] [D loss: 0.752990] [G loss: 0.632704] time: 0:21:03.348145\n",
      "0.9245539\n",
      "[Epoch 14/50] [Batch 27/300] [D loss: 0.752995] [G loss: 0.609211] time: 0:21:03.652119\n",
      "0.96019727\n",
      "[Epoch 14/50] [Batch 28/300] [D loss: 0.753006] [G loss: 0.582373] time: 0:21:03.952558\n",
      "0.9130988\n",
      "[Epoch 14/50] [Batch 29/300] [D loss: 0.753016] [G loss: 0.602051] time: 0:21:04.254049\n",
      "0.8961447\n",
      "[Epoch 14/50] [Batch 30/300] [D loss: 0.753009] [G loss: 0.595199] time: 0:21:04.548343\n",
      "0.90646774\n",
      "[Epoch 14/50] [Batch 31/300] [D loss: 0.752976] [G loss: 0.616675] time: 0:21:04.854646\n",
      "0.91789645\n",
      "[Epoch 14/50] [Batch 32/300] [D loss: 0.753053] [G loss: 0.565555] time: 0:21:05.147107\n",
      "0.8859152\n",
      "[Epoch 14/50] [Batch 33/300] [D loss: 0.753035] [G loss: 0.589217] time: 0:21:05.439098\n",
      "0.9603788\n",
      "[Epoch 14/50] [Batch 34/300] [D loss: 0.753032] [G loss: 0.560007] time: 0:21:05.746645\n",
      "0.9420983\n",
      "[Epoch 14/50] [Batch 35/300] [D loss: 0.752995] [G loss: 0.578288] time: 0:21:06.040333\n",
      "0.896873\n",
      "[Epoch 14/50] [Batch 36/300] [D loss: 0.753034] [G loss: 0.581848] time: 0:21:06.340430\n",
      "0.9762464\n",
      "[Epoch 14/50] [Batch 37/300] [D loss: 0.753041] [G loss: 0.602896] time: 0:21:06.645450\n",
      "0.903389\n",
      "[Epoch 14/50] [Batch 38/300] [D loss: 0.752996] [G loss: 0.563720] time: 0:21:06.937255\n",
      "0.91381\n",
      "[Epoch 14/50] [Batch 39/300] [D loss: 0.752976] [G loss: 0.572064] time: 0:21:07.260840\n",
      "0.90519077\n",
      "[Epoch 14/50] [Batch 40/300] [D loss: 0.752984] [G loss: 0.604723] time: 0:21:07.558630\n",
      "0.9385564\n",
      "[Epoch 14/50] [Batch 41/300] [D loss: 0.753003] [G loss: 0.551964] time: 0:21:07.864816\n",
      "0.8920906\n",
      "[Epoch 14/50] [Batch 42/300] [D loss: 0.752983] [G loss: 0.576698] time: 0:21:08.158672\n",
      "0.95134705\n",
      "[Epoch 14/50] [Batch 43/300] [D loss: 0.752960] [G loss: 0.559214] time: 0:21:08.459539\n",
      "0.8994877\n",
      "[Epoch 14/50] [Batch 44/300] [D loss: 0.753009] [G loss: 0.593521] time: 0:21:08.740978\n",
      "0.92113304\n",
      "[Epoch 14/50] [Batch 45/300] [D loss: 0.752993] [G loss: 0.601830] time: 0:21:09.032545\n",
      "0.9341195\n",
      "[Epoch 14/50] [Batch 46/300] [D loss: 0.752984] [G loss: 0.585482] time: 0:21:09.333882\n",
      "0.9240268\n",
      "[Epoch 14/50] [Batch 47/300] [D loss: 0.753014] [G loss: 0.625815] time: 0:21:09.625020\n",
      "0.9251857\n",
      "[Epoch 14/50] [Batch 48/300] [D loss: 0.753005] [G loss: 0.627889] time: 0:21:09.916130\n",
      "0.9740274\n",
      "[Epoch 14/50] [Batch 49/300] [D loss: 0.752997] [G loss: 0.549923] time: 0:21:10.224614\n",
      "0.92485\n",
      "[Epoch 14/50] [Batch 50/300] [D loss: 0.752984] [G loss: 0.605487] time: 0:21:10.522599\n",
      "0.9358964\n",
      "[Epoch 14/50] [Batch 51/300] [D loss: 0.753033] [G loss: 0.541032] time: 0:21:10.824526\n",
      "0.93090326\n",
      "[Epoch 14/50] [Batch 52/300] [D loss: 0.752988] [G loss: 0.628326] time: 0:21:11.128441\n",
      "0.95128345\n",
      "[Epoch 14/50] [Batch 53/300] [D loss: 0.752994] [G loss: 0.579833] time: 0:21:11.417462\n",
      "0.9264316\n",
      "[Epoch 14/50] [Batch 54/300] [D loss: 0.753005] [G loss: 0.597318] time: 0:21:11.726506\n",
      "0.92919874\n",
      "[Epoch 14/50] [Batch 55/300] [D loss: 0.753029] [G loss: 0.548235] time: 0:21:12.028936\n",
      "0.9225121\n",
      "[Epoch 14/50] [Batch 56/300] [D loss: 0.753005] [G loss: 0.610595] time: 0:21:12.330118\n",
      "0.8786877\n",
      "[Epoch 14/50] [Batch 57/300] [D loss: 0.752971] [G loss: 0.607443] time: 0:21:12.635994\n",
      "0.9481732\n",
      "[Epoch 14/50] [Batch 58/300] [D loss: 0.753004] [G loss: 0.583771] time: 0:21:12.920012\n",
      "0.92517036\n",
      "[Epoch 14/50] [Batch 59/300] [D loss: 0.753005] [G loss: 0.591711] time: 0:21:13.238128\n",
      "0.9331765\n",
      "[Epoch 14/50] [Batch 60/300] [D loss: 0.752957] [G loss: 0.628842] time: 0:21:13.531080\n",
      "0.9205785\n",
      "[Epoch 14/50] [Batch 61/300] [D loss: 0.753004] [G loss: 0.575634] time: 0:21:13.836095\n",
      "0.93352693\n",
      "[Epoch 14/50] [Batch 62/300] [D loss: 0.752974] [G loss: 0.564565] time: 0:21:14.162140\n",
      "0.9475601\n",
      "[Epoch 14/50] [Batch 63/300] [D loss: 0.753007] [G loss: 0.611646] time: 0:21:14.449824\n",
      "0.9288697\n",
      "[Epoch 14/50] [Batch 64/300] [D loss: 0.752997] [G loss: 0.543666] time: 0:21:14.754667\n",
      "0.9488282\n",
      "[Epoch 14/50] [Batch 65/300] [D loss: 0.753037] [G loss: 0.525436] time: 0:21:15.055661\n",
      "0.90611094\n",
      "[Epoch 14/50] [Batch 66/300] [D loss: 0.752965] [G loss: 0.588587] time: 0:21:15.354267\n",
      "0.956736\n",
      "[Epoch 14/50] [Batch 67/300] [D loss: 0.752965] [G loss: 0.597812] time: 0:21:15.654493\n",
      "0.921242\n",
      "[Epoch 14/50] [Batch 68/300] [D loss: 0.753054] [G loss: 0.574256] time: 0:21:15.952443\n",
      "0.90274566\n",
      "[Epoch 14/50] [Batch 69/300] [D loss: 0.753005] [G loss: 0.596086] time: 0:21:16.271629\n",
      "0.92471904\n",
      "[Epoch 14/50] [Batch 70/300] [D loss: 0.753026] [G loss: 0.601036] time: 0:21:16.543689\n",
      "0.93851703\n",
      "[Epoch 14/50] [Batch 71/300] [D loss: 0.752983] [G loss: 0.571863] time: 0:21:16.860664\n",
      "0.9234298\n",
      "[Epoch 14/50] [Batch 72/300] [D loss: 0.752982] [G loss: 0.616487] time: 0:21:17.164573\n",
      "0.93724227\n",
      "[Epoch 14/50] [Batch 73/300] [D loss: 0.753004] [G loss: 0.580051] time: 0:21:17.463595\n",
      "0.8965222\n",
      "[Epoch 14/50] [Batch 74/300] [D loss: 0.752987] [G loss: 0.594128] time: 0:21:17.774121\n",
      "0.92651635\n",
      "[Epoch 14/50] [Batch 75/300] [D loss: 0.752971] [G loss: 0.594314] time: 0:21:18.073595\n",
      "0.902576\n",
      "[Epoch 14/50] [Batch 76/300] [D loss: 0.752970] [G loss: 0.571125] time: 0:21:18.364076\n",
      "0.94260365\n",
      "[Epoch 14/50] [Batch 77/300] [D loss: 0.753004] [G loss: 0.582640] time: 0:21:18.659242\n",
      "0.93631935\n",
      "[Epoch 14/50] [Batch 78/300] [D loss: 0.752999] [G loss: 0.613275] time: 0:21:18.950593\n",
      "0.9120645\n",
      "[Epoch 14/50] [Batch 79/300] [D loss: 0.752981] [G loss: 0.653571] time: 0:21:19.256206\n",
      "0.94007754\n",
      "[Epoch 14/50] [Batch 80/300] [D loss: 0.753017] [G loss: 0.611092] time: 0:21:19.544272\n",
      "0.9161189\n",
      "[Epoch 14/50] [Batch 81/300] [D loss: 0.753030] [G loss: 0.573368] time: 0:21:19.843038\n",
      "0.92770576\n",
      "[Epoch 14/50] [Batch 82/300] [D loss: 0.752995] [G loss: 0.631336] time: 0:21:20.147703\n",
      "0.9318948\n",
      "[Epoch 14/50] [Batch 83/300] [D loss: 0.752996] [G loss: 0.606819] time: 0:21:20.453056\n",
      "0.925381\n",
      "[Epoch 14/50] [Batch 84/300] [D loss: 0.753015] [G loss: 0.578813] time: 0:21:20.760211\n",
      "0.9396369\n",
      "[Epoch 14/50] [Batch 85/300] [D loss: 0.752986] [G loss: 0.648340] time: 0:21:21.057520\n",
      "0.9085889\n",
      "[Epoch 14/50] [Batch 86/300] [D loss: 0.752992] [G loss: 0.611002] time: 0:21:21.344094\n",
      "0.9236441\n",
      "[Epoch 14/50] [Batch 87/300] [D loss: 0.752976] [G loss: 0.661380] time: 0:21:21.642690\n",
      "0.95944434\n",
      "[Epoch 14/50] [Batch 88/300] [D loss: 0.753015] [G loss: 0.529202] time: 0:21:21.934513\n",
      "0.8871196\n",
      "[Epoch 14/50] [Batch 89/300] [D loss: 0.752986] [G loss: 0.578996] time: 0:21:22.232282\n",
      "0.92955095\n",
      "[Epoch 14/50] [Batch 90/300] [D loss: 0.753023] [G loss: 0.599423] time: 0:21:22.517798\n",
      "0.9137257\n",
      "[Epoch 14/50] [Batch 91/300] [D loss: 0.753012] [G loss: 0.645206] time: 0:21:22.829600\n",
      "0.9353101\n",
      "[Epoch 14/50] [Batch 92/300] [D loss: 0.752954] [G loss: 0.627838] time: 0:21:23.138921\n",
      "0.9410215\n",
      "[Epoch 14/50] [Batch 93/300] [D loss: 0.752992] [G loss: 0.624913] time: 0:21:23.431984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89950615\n",
      "[Epoch 14/50] [Batch 94/300] [D loss: 0.752998] [G loss: 0.573091] time: 0:21:23.734002\n",
      "0.93484086\n",
      "[Epoch 14/50] [Batch 95/300] [D loss: 0.752984] [G loss: 0.605854] time: 0:21:24.032197\n",
      "0.9282627\n",
      "[Epoch 14/50] [Batch 96/300] [D loss: 0.753009] [G loss: 0.590103] time: 0:21:24.335245\n",
      "0.9474371\n",
      "[Epoch 14/50] [Batch 97/300] [D loss: 0.752982] [G loss: 0.616322] time: 0:21:24.633268\n",
      "0.9231313\n",
      "[Epoch 14/50] [Batch 98/300] [D loss: 0.752991] [G loss: 0.605446] time: 0:21:24.935567\n",
      "0.9332924\n",
      "[Epoch 14/50] [Batch 99/300] [D loss: 0.752971] [G loss: 0.554008] time: 0:21:25.255812\n",
      "0.9332518\n",
      "[Epoch 14/50] [Batch 100/300] [D loss: 0.753016] [G loss: 0.645351] time: 0:21:25.547748\n",
      "0.91789556\n",
      "[Epoch 14/50] [Batch 101/300] [D loss: 0.752969] [G loss: 0.582246] time: 0:21:25.850151\n",
      "0.88211775\n",
      "[Epoch 14/50] [Batch 102/300] [D loss: 0.752993] [G loss: 0.621504] time: 0:21:26.143678\n",
      "0.89027214\n",
      "[Epoch 14/50] [Batch 103/300] [D loss: 0.752964] [G loss: 0.591688] time: 0:21:26.444907\n",
      "0.8874082\n",
      "[Epoch 14/50] [Batch 104/300] [D loss: 0.753038] [G loss: 0.585111] time: 0:21:26.751926\n",
      "0.9043355\n",
      "[Epoch 14/50] [Batch 105/300] [D loss: 0.752973] [G loss: 0.581204] time: 0:21:27.051360\n",
      "0.8871906\n",
      "[Epoch 14/50] [Batch 106/300] [D loss: 0.752967] [G loss: 0.620967] time: 0:21:27.364710\n",
      "0.892374\n",
      "[Epoch 14/50] [Batch 107/300] [D loss: 0.752993] [G loss: 0.591110] time: 0:21:27.683345\n",
      "0.91182184\n",
      "[Epoch 14/50] [Batch 108/300] [D loss: 0.752990] [G loss: 0.610127] time: 0:21:27.988155\n",
      "0.88842076\n",
      "[Epoch 14/50] [Batch 109/300] [D loss: 0.752994] [G loss: 0.603525] time: 0:21:28.289483\n",
      "0.9243374\n",
      "[Epoch 14/50] [Batch 110/300] [D loss: 0.752987] [G loss: 0.592114] time: 0:21:28.595202\n",
      "0.91228896\n",
      "[Epoch 14/50] [Batch 111/300] [D loss: 0.752973] [G loss: 0.612751] time: 0:21:28.894631\n",
      "0.9569955\n",
      "[Epoch 14/50] [Batch 112/300] [D loss: 0.752991] [G loss: 0.634099] time: 0:21:29.170270\n",
      "0.90149385\n",
      "[Epoch 14/50] [Batch 113/300] [D loss: 0.752993] [G loss: 0.613174] time: 0:21:29.470699\n",
      "0.87956125\n",
      "[Epoch 14/50] [Batch 114/300] [D loss: 0.753025] [G loss: 0.606154] time: 0:21:29.785506\n",
      "0.9053111\n",
      "[Epoch 14/50] [Batch 115/300] [D loss: 0.752985] [G loss: 0.569863] time: 0:21:30.087128\n",
      "0.922466\n",
      "[Epoch 14/50] [Batch 116/300] [D loss: 0.753015] [G loss: 0.596376] time: 0:21:30.397397\n",
      "0.9234678\n",
      "[Epoch 14/50] [Batch 117/300] [D loss: 0.752997] [G loss: 0.584914] time: 0:21:30.694719\n",
      "0.9069105\n",
      "[Epoch 14/50] [Batch 118/300] [D loss: 0.752957] [G loss: 0.542206] time: 0:21:30.976601\n",
      "0.9381785\n",
      "[Epoch 14/50] [Batch 119/300] [D loss: 0.752985] [G loss: 0.566086] time: 0:21:31.270455\n",
      "0.9213984\n",
      "[Epoch 14/50] [Batch 120/300] [D loss: 0.753010] [G loss: 0.528258] time: 0:21:31.571939\n",
      "0.9159873\n",
      "[Epoch 14/50] [Batch 121/300] [D loss: 0.752980] [G loss: 0.593125] time: 0:21:31.885457\n",
      "0.93391734\n",
      "[Epoch 14/50] [Batch 122/300] [D loss: 0.752993] [G loss: 0.550380] time: 0:21:32.182289\n",
      "0.92347986\n",
      "[Epoch 14/50] [Batch 123/300] [D loss: 0.752934] [G loss: 0.619435] time: 0:21:32.473449\n",
      "0.91669875\n",
      "[Epoch 14/50] [Batch 124/300] [D loss: 0.753034] [G loss: 0.574449] time: 0:21:32.788005\n",
      "0.9139444\n",
      "[Epoch 14/50] [Batch 125/300] [D loss: 0.753017] [G loss: 0.599550] time: 0:21:33.100470\n",
      "0.92134434\n",
      "[Epoch 14/50] [Batch 126/300] [D loss: 0.752998] [G loss: 0.546131] time: 0:21:33.400825\n",
      "0.886399\n",
      "[Epoch 14/50] [Batch 127/300] [D loss: 0.752980] [G loss: 0.610825] time: 0:21:33.705767\n",
      "0.916985\n",
      "[Epoch 14/50] [Batch 128/300] [D loss: 0.753002] [G loss: 0.602099] time: 0:21:33.990927\n",
      "0.9422162\n",
      "[Epoch 14/50] [Batch 129/300] [D loss: 0.752980] [G loss: 0.608856] time: 0:21:34.302117\n",
      "0.907794\n",
      "[Epoch 14/50] [Batch 130/300] [D loss: 0.752973] [G loss: 0.652484] time: 0:21:34.586374\n",
      "0.87037724\n",
      "[Epoch 14/50] [Batch 131/300] [D loss: 0.753023] [G loss: 0.590220] time: 0:21:34.871623\n",
      "0.972066\n",
      "[Epoch 14/50] [Batch 132/300] [D loss: 0.752960] [G loss: 0.603969] time: 0:21:35.165512\n",
      "0.9420168\n",
      "[Epoch 14/50] [Batch 133/300] [D loss: 0.752978] [G loss: 0.588279] time: 0:21:35.464512\n",
      "0.91541654\n",
      "[Epoch 14/50] [Batch 134/300] [D loss: 0.752972] [G loss: 0.601002] time: 0:21:35.776059\n",
      "0.9452928\n",
      "[Epoch 14/50] [Batch 135/300] [D loss: 0.753003] [G loss: 0.576912] time: 0:21:36.079026\n",
      "0.92922956\n",
      "[Epoch 14/50] [Batch 136/300] [D loss: 0.752951] [G loss: 0.574992] time: 0:21:36.393779\n",
      "0.9490331\n",
      "[Epoch 14/50] [Batch 137/300] [D loss: 0.752962] [G loss: 0.544726] time: 0:21:36.693587\n",
      "0.91680807\n",
      "[Epoch 14/50] [Batch 138/300] [D loss: 0.752991] [G loss: 0.595139] time: 0:21:36.989100\n",
      "0.8969953\n",
      "[Epoch 14/50] [Batch 139/300] [D loss: 0.753004] [G loss: 0.575281] time: 0:21:37.298628\n",
      "0.909364\n",
      "[Epoch 14/50] [Batch 140/300] [D loss: 0.752977] [G loss: 0.581836] time: 0:21:37.614974\n",
      "0.94513994\n",
      "[Epoch 14/50] [Batch 141/300] [D loss: 0.752984] [G loss: 0.567198] time: 0:21:37.918820\n",
      "0.91359305\n",
      "[Epoch 14/50] [Batch 142/300] [D loss: 0.752988] [G loss: 0.596480] time: 0:21:38.243941\n",
      "0.93025446\n",
      "[Epoch 14/50] [Batch 143/300] [D loss: 0.753012] [G loss: 0.584721] time: 0:21:38.526738\n",
      "0.95581514\n",
      "[Epoch 14/50] [Batch 144/300] [D loss: 0.752960] [G loss: 0.553727] time: 0:21:38.828247\n",
      "0.9071564\n",
      "[Epoch 14/50] [Batch 145/300] [D loss: 0.752998] [G loss: 0.628717] time: 0:21:39.122371\n",
      "0.9380212\n",
      "[Epoch 14/50] [Batch 146/300] [D loss: 0.753018] [G loss: 0.575059] time: 0:21:39.415546\n",
      "0.93465644\n",
      "[Epoch 14/50] [Batch 147/300] [D loss: 0.753008] [G loss: 0.542307] time: 0:21:39.710036\n",
      "0.9103767\n",
      "[Epoch 14/50] [Batch 148/300] [D loss: 0.753031] [G loss: 0.593518] time: 0:21:40.008945\n",
      "0.9550288\n",
      "[Epoch 14/50] [Batch 149/300] [D loss: 0.752971] [G loss: 0.646873] time: 0:21:40.322292\n",
      "0.85324496\n",
      "[Epoch 14/50] [Batch 150/300] [D loss: 0.753009] [G loss: 0.587374] time: 0:21:40.623721\n",
      "0.9167218\n",
      "[Epoch 14/50] [Batch 151/300] [D loss: 0.752978] [G loss: 0.601731] time: 0:21:40.932801\n",
      "0.9335432\n",
      "[Epoch 14/50] [Batch 152/300] [D loss: 0.752937] [G loss: 0.576385] time: 0:21:41.227672\n",
      "0.9017778\n",
      "[Epoch 14/50] [Batch 153/300] [D loss: 0.752944] [G loss: 0.602520] time: 0:21:41.527443\n",
      "0.9362631\n",
      "[Epoch 14/50] [Batch 154/300] [D loss: 0.752982] [G loss: 0.566046] time: 0:21:41.820323\n",
      "0.92818326\n",
      "[Epoch 14/50] [Batch 155/300] [D loss: 0.752986] [G loss: 0.558672] time: 0:21:42.130480\n",
      "0.8640423\n",
      "[Epoch 14/50] [Batch 156/300] [D loss: 0.752960] [G loss: 0.619674] time: 0:21:42.419101\n",
      "0.9055643\n",
      "[Epoch 14/50] [Batch 157/300] [D loss: 0.752921] [G loss: 0.565249] time: 0:21:42.716817\n",
      "0.9292767\n",
      "[Epoch 14/50] [Batch 158/300] [D loss: 0.753005] [G loss: 0.580072] time: 0:21:43.009586\n",
      "0.8877327\n",
      "[Epoch 14/50] [Batch 159/300] [D loss: 0.752931] [G loss: 0.550162] time: 0:21:43.299422\n",
      "0.9072428\n",
      "[Epoch 14/50] [Batch 160/300] [D loss: 0.752949] [G loss: 0.607912] time: 0:21:43.588342\n",
      "0.9211015\n",
      "[Epoch 14/50] [Batch 161/300] [D loss: 0.752982] [G loss: 0.641881] time: 0:21:43.900893\n",
      "0.92169875\n",
      "[Epoch 14/50] [Batch 162/300] [D loss: 0.752945] [G loss: 0.563303] time: 0:21:44.185323\n",
      "0.8946469\n",
      "[Epoch 14/50] [Batch 163/300] [D loss: 0.752946] [G loss: 0.649385] time: 0:21:44.469463\n",
      "0.88378054\n",
      "[Epoch 14/50] [Batch 164/300] [D loss: 0.752970] [G loss: 0.586336] time: 0:21:44.781632\n",
      "0.94376034\n",
      "[Epoch 14/50] [Batch 165/300] [D loss: 0.752974] [G loss: 0.594529] time: 0:21:45.079665\n",
      "0.94196624\n",
      "[Epoch 14/50] [Batch 166/300] [D loss: 0.752948] [G loss: 0.599751] time: 0:21:45.377347\n",
      "0.8689428\n",
      "[Epoch 14/50] [Batch 167/300] [D loss: 0.752962] [G loss: 0.581100] time: 0:21:45.678860\n",
      "0.88070107\n",
      "[Epoch 14/50] [Batch 168/300] [D loss: 0.752960] [G loss: 0.548293] time: 0:21:45.968325\n",
      "0.8957851\n",
      "[Epoch 14/50] [Batch 169/300] [D loss: 0.752971] [G loss: 0.528644] time: 0:21:46.270595\n",
      "0.8901281\n",
      "[Epoch 14/50] [Batch 170/300] [D loss: 0.752983] [G loss: 0.535920] time: 0:21:46.564176\n",
      "0.95989925\n",
      "[Epoch 14/50] [Batch 171/300] [D loss: 0.752936] [G loss: 0.562289] time: 0:21:46.860361\n",
      "0.92854524\n",
      "[Epoch 14/50] [Batch 172/300] [D loss: 0.752964] [G loss: 0.586104] time: 0:21:47.166771\n",
      "0.9830346\n",
      "[Epoch 14/50] [Batch 173/300] [D loss: 0.753047] [G loss: 0.560489] time: 0:21:47.467675\n",
      "0.9023945\n",
      "[Epoch 14/50] [Batch 174/300] [D loss: 0.753003] [G loss: 0.590811] time: 0:21:47.778002\n",
      "0.9226246\n",
      "[Epoch 14/50] [Batch 175/300] [D loss: 0.752945] [G loss: 0.677750] time: 0:21:48.074021\n",
      "0.92576176\n",
      "[Epoch 14/50] [Batch 176/300] [D loss: 0.753005] [G loss: 0.579877] time: 0:21:48.376221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194464\n",
      "[Epoch 14/50] [Batch 177/300] [D loss: 0.752969] [G loss: 0.604409] time: 0:21:48.673349\n",
      "0.9181962\n",
      "[Epoch 14/50] [Batch 178/300] [D loss: 0.752952] [G loss: 0.637514] time: 0:21:48.961417\n",
      "0.9065836\n",
      "[Epoch 14/50] [Batch 179/300] [D loss: 0.752952] [G loss: 0.640187] time: 0:21:49.278101\n",
      "0.9186389\n",
      "[Epoch 14/50] [Batch 180/300] [D loss: 0.752934] [G loss: 0.594988] time: 0:21:49.577006\n",
      "0.96456546\n",
      "[Epoch 14/50] [Batch 181/300] [D loss: 0.752998] [G loss: 0.590297] time: 0:21:49.870342\n",
      "0.9400328\n",
      "[Epoch 14/50] [Batch 182/300] [D loss: 0.752986] [G loss: 0.652170] time: 0:21:50.158050\n",
      "0.92058295\n",
      "[Epoch 14/50] [Batch 183/300] [D loss: 0.752981] [G loss: 0.588281] time: 0:21:50.450414\n",
      "0.9560199\n",
      "[Epoch 14/50] [Batch 184/300] [D loss: 0.752972] [G loss: 0.612393] time: 0:21:50.742686\n",
      "0.88063234\n",
      "[Epoch 14/50] [Batch 185/300] [D loss: 0.752957] [G loss: 0.582902] time: 0:21:51.026310\n",
      "0.957464\n",
      "[Epoch 14/50] [Batch 186/300] [D loss: 0.752939] [G loss: 0.601394] time: 0:21:51.316145\n",
      "0.92462426\n",
      "[Epoch 14/50] [Batch 187/300] [D loss: 0.752995] [G loss: 0.571061] time: 0:21:51.607106\n",
      "0.96027595\n",
      "[Epoch 14/50] [Batch 188/300] [D loss: 0.752969] [G loss: 0.590879] time: 0:21:51.887558\n",
      "0.9707826\n",
      "[Epoch 14/50] [Batch 189/300] [D loss: 0.753001] [G loss: 0.608712] time: 0:21:52.205692\n",
      "0.9166449\n",
      "[Epoch 14/50] [Batch 190/300] [D loss: 0.752971] [G loss: 0.589372] time: 0:21:52.489361\n",
      "0.92773676\n",
      "[Epoch 14/50] [Batch 191/300] [D loss: 0.752934] [G loss: 0.553263] time: 0:21:52.786731\n",
      "0.94653463\n",
      "[Epoch 14/50] [Batch 192/300] [D loss: 0.752959] [G loss: 0.587557] time: 0:21:53.085861\n",
      "0.8969634\n",
      "[Epoch 14/50] [Batch 193/300] [D loss: 0.752986] [G loss: 0.635520] time: 0:21:53.381418\n",
      "0.8681665\n",
      "[Epoch 14/50] [Batch 194/300] [D loss: 0.752936] [G loss: 0.619072] time: 0:21:53.699853\n",
      "0.8822853\n",
      "[Epoch 14/50] [Batch 195/300] [D loss: 0.752938] [G loss: 0.590323] time: 0:21:53.977795\n",
      "0.9166053\n",
      "[Epoch 14/50] [Batch 196/300] [D loss: 0.752990] [G loss: 0.582214] time: 0:21:54.274759\n",
      "0.93438023\n",
      "[Epoch 14/50] [Batch 197/300] [D loss: 0.752984] [G loss: 0.559963] time: 0:21:54.561868\n",
      "0.92157453\n",
      "[Epoch 14/50] [Batch 198/300] [D loss: 0.752925] [G loss: 0.582261] time: 0:21:54.857310\n",
      "0.96746635\n",
      "[Epoch 14/50] [Batch 199/300] [D loss: 0.752939] [G loss: 0.569555] time: 0:21:55.142035\n",
      "0.9455669\n",
      "[Epoch 14/50] [Batch 200/300] [D loss: 0.752947] [G loss: 0.630896] time: 0:21:55.410022\n",
      "0.89875203\n",
      "[Epoch 14/50] [Batch 201/300] [D loss: 0.752975] [G loss: 0.639704] time: 0:21:55.713567\n",
      "0.9799819\n",
      "[Epoch 14/50] [Batch 202/300] [D loss: 0.752947] [G loss: 0.559427] time: 0:21:56.004579\n",
      "0.9094024\n",
      "[Epoch 14/50] [Batch 203/300] [D loss: 0.752951] [G loss: 0.629976] time: 0:21:56.294594\n",
      "0.93726605\n",
      "[Epoch 14/50] [Batch 204/300] [D loss: 0.752935] [G loss: 0.601350] time: 0:21:56.601249\n",
      "0.8518369\n",
      "[Epoch 14/50] [Batch 205/300] [D loss: 0.752911] [G loss: 0.577686] time: 0:21:56.903565\n",
      "0.92039126\n",
      "[Epoch 14/50] [Batch 206/300] [D loss: 0.752965] [G loss: 0.590876] time: 0:21:57.206280\n",
      "0.93274254\n",
      "[Epoch 14/50] [Batch 207/300] [D loss: 0.752912] [G loss: 0.665513] time: 0:21:57.491845\n",
      "0.87102604\n",
      "[Epoch 14/50] [Batch 208/300] [D loss: 0.752986] [G loss: 0.614524] time: 0:21:57.785949\n",
      "0.9456784\n",
      "[Epoch 14/50] [Batch 209/300] [D loss: 0.752980] [G loss: 0.583313] time: 0:21:58.105581\n",
      "0.891501\n",
      "[Epoch 14/50] [Batch 210/300] [D loss: 0.752913] [G loss: 0.552748] time: 0:21:58.391806\n",
      "0.9433513\n",
      "[Epoch 14/50] [Batch 211/300] [D loss: 0.753005] [G loss: 0.545623] time: 0:21:58.701980\n",
      "0.92485636\n",
      "[Epoch 14/50] [Batch 212/300] [D loss: 0.752962] [G loss: 0.602407] time: 0:21:59.001592\n",
      "0.9464858\n",
      "[Epoch 14/50] [Batch 213/300] [D loss: 0.752944] [G loss: 0.577833] time: 0:21:59.303632\n",
      "0.9612958\n",
      "[Epoch 14/50] [Batch 214/300] [D loss: 0.752954] [G loss: 0.576288] time: 0:21:59.609626\n",
      "0.9004852\n",
      "[Epoch 14/50] [Batch 215/300] [D loss: 0.752942] [G loss: 0.627749] time: 0:21:59.917118\n",
      "0.9054877\n",
      "[Epoch 14/50] [Batch 216/300] [D loss: 0.752964] [G loss: 0.584294] time: 0:22:00.215998\n",
      "0.92911464\n",
      "[Epoch 14/50] [Batch 217/300] [D loss: 0.752929] [G loss: 0.601925] time: 0:22:00.511027\n",
      "0.87335116\n",
      "[Epoch 14/50] [Batch 218/300] [D loss: 0.752948] [G loss: 0.567454] time: 0:22:00.814033\n",
      "0.9404888\n",
      "[Epoch 14/50] [Batch 219/300] [D loss: 0.753007] [G loss: 0.565569] time: 0:22:01.115926\n",
      "0.91468334\n",
      "[Epoch 14/50] [Batch 220/300] [D loss: 0.752962] [G loss: 0.612725] time: 0:22:01.434110\n",
      "0.9554217\n",
      "[Epoch 14/50] [Batch 221/300] [D loss: 0.752932] [G loss: 0.584350] time: 0:22:01.748681\n",
      "0.9307607\n",
      "[Epoch 14/50] [Batch 222/300] [D loss: 0.752922] [G loss: 0.656208] time: 0:22:02.047887\n",
      "0.9182415\n",
      "[Epoch 14/50] [Batch 223/300] [D loss: 0.752946] [G loss: 0.556408] time: 0:22:02.353043\n",
      "0.9557683\n",
      "[Epoch 14/50] [Batch 224/300] [D loss: 0.752999] [G loss: 0.603140] time: 0:22:02.659707\n",
      "0.91980404\n",
      "[Epoch 14/50] [Batch 225/300] [D loss: 0.752943] [G loss: 0.581610] time: 0:22:02.960358\n",
      "0.9310568\n",
      "[Epoch 14/50] [Batch 226/300] [D loss: 0.752955] [G loss: 0.567083] time: 0:22:03.275965\n",
      "0.89827555\n",
      "[Epoch 14/50] [Batch 227/300] [D loss: 0.752952] [G loss: 0.551974] time: 0:22:03.582355\n",
      "0.929508\n",
      "[Epoch 14/50] [Batch 228/300] [D loss: 0.752937] [G loss: 0.552667] time: 0:22:03.889859\n",
      "0.9356008\n",
      "[Epoch 14/50] [Batch 229/300] [D loss: 0.752952] [G loss: 0.616889] time: 0:22:04.199963\n",
      "0.9471641\n",
      "[Epoch 14/50] [Batch 230/300] [D loss: 0.752961] [G loss: 0.602793] time: 0:22:04.487450\n",
      "0.88678867\n",
      "[Epoch 14/50] [Batch 231/300] [D loss: 0.752950] [G loss: 0.564496] time: 0:22:04.786590\n",
      "0.9325244\n",
      "[Epoch 14/50] [Batch 232/300] [D loss: 0.752944] [G loss: 0.613139] time: 0:22:05.086146\n",
      "0.9268665\n",
      "[Epoch 14/50] [Batch 233/300] [D loss: 0.752956] [G loss: 0.578205] time: 0:22:05.402785\n",
      "0.9095718\n",
      "[Epoch 14/50] [Batch 234/300] [D loss: 0.752968] [G loss: 0.614927] time: 0:22:05.687741\n",
      "0.9385231\n",
      "[Epoch 14/50] [Batch 235/300] [D loss: 0.752953] [G loss: 0.594090] time: 0:22:05.990082\n",
      "0.8869893\n",
      "[Epoch 14/50] [Batch 236/300] [D loss: 0.752964] [G loss: 0.579770] time: 0:22:06.260946\n",
      "0.9123242\n",
      "[Epoch 14/50] [Batch 237/300] [D loss: 0.752977] [G loss: 0.551099] time: 0:22:06.520179\n",
      "0.9086916\n",
      "[Epoch 14/50] [Batch 238/300] [D loss: 0.752935] [G loss: 0.535404] time: 0:22:06.815008\n",
      "0.8944087\n",
      "[Epoch 14/50] [Batch 239/300] [D loss: 0.752916] [G loss: 0.592289] time: 0:22:07.123933\n",
      "0.9209395\n",
      "[Epoch 14/50] [Batch 240/300] [D loss: 0.752937] [G loss: 0.673974] time: 0:22:07.418386\n",
      "0.9100938\n",
      "[Epoch 14/50] [Batch 241/300] [D loss: 0.753007] [G loss: 0.611876] time: 0:22:07.729609\n",
      "0.9303364\n",
      "[Epoch 14/50] [Batch 242/300] [D loss: 0.752947] [G loss: 0.604160] time: 0:22:08.017508\n",
      "0.90358526\n",
      "[Epoch 14/50] [Batch 243/300] [D loss: 0.753001] [G loss: 0.661161] time: 0:22:08.327125\n",
      "0.9263644\n",
      "[Epoch 14/50] [Batch 244/300] [D loss: 0.752969] [G loss: 0.558590] time: 0:22:08.643929\n",
      "0.90372795\n",
      "[Epoch 14/50] [Batch 245/300] [D loss: 0.752880] [G loss: 0.559202] time: 0:22:08.929349\n",
      "0.9054416\n",
      "[Epoch 14/50] [Batch 246/300] [D loss: 0.752969] [G loss: 0.567921] time: 0:22:09.235585\n",
      "0.94630617\n",
      "[Epoch 14/50] [Batch 247/300] [D loss: 0.752970] [G loss: 0.606577] time: 0:22:09.534170\n",
      "0.9201997\n",
      "[Epoch 14/50] [Batch 248/300] [D loss: 0.752946] [G loss: 0.606188] time: 0:22:09.820980\n",
      "0.8786404\n",
      "[Epoch 14/50] [Batch 249/300] [D loss: 0.752957] [G loss: 0.600812] time: 0:22:10.109701\n",
      "0.95116186\n",
      "[Epoch 14/50] [Batch 250/300] [D loss: 0.752944] [G loss: 0.589165] time: 0:22:10.395462\n",
      "0.9351017\n",
      "[Epoch 14/50] [Batch 251/300] [D loss: 0.752927] [G loss: 0.594678] time: 0:22:10.695117\n",
      "0.8989617\n",
      "[Epoch 14/50] [Batch 252/300] [D loss: 0.752959] [G loss: 0.618241] time: 0:22:10.988313\n",
      "0.8814327\n",
      "[Epoch 14/50] [Batch 253/300] [D loss: 0.752927] [G loss: 0.557470] time: 0:22:11.281050\n",
      "0.92539406\n",
      "[Epoch 14/50] [Batch 254/300] [D loss: 0.752908] [G loss: 0.648168] time: 0:22:11.584566\n",
      "0.9344347\n",
      "[Epoch 14/50] [Batch 255/300] [D loss: 0.752926] [G loss: 0.582295] time: 0:22:11.877404\n",
      "0.94142896\n",
      "[Epoch 14/50] [Batch 256/300] [D loss: 0.752928] [G loss: 0.604259] time: 0:22:12.168764\n",
      "0.8818228\n",
      "[Epoch 14/50] [Batch 257/300] [D loss: 0.752934] [G loss: 0.633133] time: 0:22:12.471562\n",
      "0.912292\n",
      "[Epoch 14/50] [Batch 258/300] [D loss: 0.752958] [G loss: 0.574037] time: 0:22:12.770370\n",
      "0.85980487\n",
      "[Epoch 14/50] [Batch 259/300] [D loss: 0.752951] [G loss: 0.574555] time: 0:22:13.075361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8929472\n",
      "[Epoch 14/50] [Batch 260/300] [D loss: 0.752957] [G loss: 0.682286] time: 0:22:13.353965\n",
      "0.9317591\n",
      "[Epoch 14/50] [Batch 261/300] [D loss: 0.752964] [G loss: 0.581527] time: 0:22:13.654912\n",
      "0.9085576\n",
      "[Epoch 14/50] [Batch 262/300] [D loss: 0.752958] [G loss: 0.544782] time: 0:22:13.963074\n",
      "0.95397145\n",
      "[Epoch 14/50] [Batch 263/300] [D loss: 0.752927] [G loss: 0.540918] time: 0:22:14.245192\n",
      "0.88662654\n",
      "[Epoch 14/50] [Batch 264/300] [D loss: 0.752941] [G loss: 0.598464] time: 0:22:14.537429\n",
      "0.9271733\n",
      "[Epoch 14/50] [Batch 265/300] [D loss: 0.752933] [G loss: 0.578625] time: 0:22:14.833838\n",
      "0.9454372\n",
      "[Epoch 14/50] [Batch 266/300] [D loss: 0.752930] [G loss: 0.564805] time: 0:22:15.124153\n",
      "0.90932846\n",
      "[Epoch 14/50] [Batch 267/300] [D loss: 0.752929] [G loss: 0.569318] time: 0:22:15.421318\n",
      "0.89050716\n",
      "[Epoch 14/50] [Batch 268/300] [D loss: 0.752957] [G loss: 0.625811] time: 0:22:15.749378\n",
      "0.90112907\n",
      "[Epoch 14/50] [Batch 269/300] [D loss: 0.752955] [G loss: 0.561426] time: 0:22:16.027988\n",
      "0.9339586\n",
      "[Epoch 14/50] [Batch 270/300] [D loss: 0.752942] [G loss: 0.614093] time: 0:22:16.326632\n",
      "0.9369505\n",
      "[Epoch 14/50] [Batch 271/300] [D loss: 0.752946] [G loss: 0.577978] time: 0:22:16.632441\n",
      "0.94738585\n",
      "[Epoch 14/50] [Batch 272/300] [D loss: 0.752990] [G loss: 0.559753] time: 0:22:16.926758\n",
      "0.9532048\n",
      "[Epoch 14/50] [Batch 273/300] [D loss: 0.752940] [G loss: 0.563959] time: 0:22:17.230528\n",
      "0.93735975\n",
      "[Epoch 14/50] [Batch 274/300] [D loss: 0.752894] [G loss: 0.585286] time: 0:22:17.536164\n",
      "0.93413407\n",
      "[Epoch 14/50] [Batch 275/300] [D loss: 0.752954] [G loss: 0.590904] time: 0:22:17.830194\n",
      "0.9075281\n",
      "[Epoch 14/50] [Batch 276/300] [D loss: 0.752962] [G loss: 0.541838] time: 0:22:18.146468\n",
      "0.9119234\n",
      "[Epoch 14/50] [Batch 277/300] [D loss: 0.752935] [G loss: 0.560325] time: 0:22:18.442926\n",
      "0.9170091\n",
      "[Epoch 14/50] [Batch 278/300] [D loss: 0.752938] [G loss: 0.604839] time: 0:22:18.745805\n",
      "0.9152513\n",
      "[Epoch 14/50] [Batch 279/300] [D loss: 0.752977] [G loss: 0.594347] time: 0:22:19.024744\n",
      "0.8910329\n",
      "[Epoch 14/50] [Batch 280/300] [D loss: 0.752954] [G loss: 0.560511] time: 0:22:19.332545\n",
      "0.9307293\n",
      "[Epoch 14/50] [Batch 281/300] [D loss: 0.752967] [G loss: 0.571990] time: 0:22:19.638800\n",
      "0.9428129\n",
      "[Epoch 14/50] [Batch 282/300] [D loss: 0.752963] [G loss: 0.620296] time: 0:22:19.942441\n",
      "0.9314435\n",
      "[Epoch 14/50] [Batch 283/300] [D loss: 0.752931] [G loss: 0.615114] time: 0:22:20.234674\n",
      "0.94258887\n",
      "[Epoch 14/50] [Batch 284/300] [D loss: 0.752907] [G loss: 0.667915] time: 0:22:20.529086\n",
      "0.9105549\n",
      "[Epoch 14/50] [Batch 285/300] [D loss: 0.752928] [G loss: 0.649005] time: 0:22:20.831385\n",
      "0.93921477\n",
      "[Epoch 14/50] [Batch 286/300] [D loss: 0.752976] [G loss: 0.584427] time: 0:22:21.129688\n",
      "0.927819\n",
      "[Epoch 14/50] [Batch 287/300] [D loss: 0.752896] [G loss: 0.586574] time: 0:22:21.428653\n",
      "0.89330655\n",
      "[Epoch 14/50] [Batch 288/300] [D loss: 0.752962] [G loss: 0.581481] time: 0:22:21.706502\n",
      "0.93198794\n",
      "[Epoch 14/50] [Batch 289/300] [D loss: 0.752906] [G loss: 0.575536] time: 0:22:22.017574\n",
      "0.9523533\n",
      "[Epoch 14/50] [Batch 290/300] [D loss: 0.752952] [G loss: 0.587107] time: 0:22:22.319926\n",
      "0.9388663\n",
      "[Epoch 14/50] [Batch 291/300] [D loss: 0.752911] [G loss: 0.528219] time: 0:22:22.631591\n",
      "0.89071697\n",
      "[Epoch 14/50] [Batch 292/300] [D loss: 0.752916] [G loss: 0.550743] time: 0:22:22.917262\n",
      "0.89471275\n",
      "[Epoch 14/50] [Batch 293/300] [D loss: 0.752982] [G loss: 0.532479] time: 0:22:23.200492\n",
      "0.898393\n",
      "[Epoch 14/50] [Batch 294/300] [D loss: 0.752941] [G loss: 0.593466] time: 0:22:23.509794\n",
      "0.9203958\n",
      "[Epoch 14/50] [Batch 295/300] [D loss: 0.752932] [G loss: 0.538070] time: 0:22:23.811568\n",
      "0.9065564\n",
      "[Epoch 14/50] [Batch 296/300] [D loss: 0.752932] [G loss: 0.536255] time: 0:22:24.127845\n",
      "0.93070453\n",
      "[Epoch 14/50] [Batch 297/300] [D loss: 0.752963] [G loss: 0.601679] time: 0:22:24.429587\n",
      "0.8939077\n",
      "[Epoch 14/50] [Batch 298/300] [D loss: 0.752941] [G loss: 0.586891] time: 0:22:24.737036\n",
      "0.88931435\n",
      "[Epoch 14/50] [Batch 299/300] [D loss: 0.752965] [G loss: 0.589110] time: 0:22:25.058420\n",
      "0.8528113\n",
      "[Epoch 15/50] [Batch 0/300] [D loss: 0.752929] [G loss: 0.572374] time: 0:22:25.363530\n",
      "0.94647807\n",
      "[Epoch 15/50] [Batch 1/300] [D loss: 0.752909] [G loss: 0.546106] time: 0:22:25.663006\n",
      "0.90943\n",
      "[Epoch 15/50] [Batch 2/300] [D loss: 0.752912] [G loss: 0.581823] time: 0:22:25.957516\n",
      "0.9290126\n",
      "[Epoch 15/50] [Batch 3/300] [D loss: 0.752944] [G loss: 0.576372] time: 0:22:26.255371\n",
      "0.925932\n",
      "[Epoch 15/50] [Batch 4/300] [D loss: 0.752928] [G loss: 0.570630] time: 0:22:26.562574\n",
      "0.8931028\n",
      "[Epoch 15/50] [Batch 5/300] [D loss: 0.752958] [G loss: 0.539650] time: 0:22:26.867589\n",
      "0.9307084\n",
      "[Epoch 15/50] [Batch 6/300] [D loss: 0.752907] [G loss: 0.606173] time: 0:22:27.175747\n",
      "0.90870076\n",
      "[Epoch 15/50] [Batch 7/300] [D loss: 0.752883] [G loss: 0.636047] time: 0:22:27.476141\n",
      "0.90848595\n",
      "[Epoch 15/50] [Batch 8/300] [D loss: 0.752964] [G loss: 0.588142] time: 0:22:27.769821\n",
      "0.9033713\n",
      "[Epoch 15/50] [Batch 9/300] [D loss: 0.752919] [G loss: 0.590757] time: 0:22:28.073890\n",
      "0.9377579\n",
      "[Epoch 15/50] [Batch 10/300] [D loss: 0.752941] [G loss: 0.568085] time: 0:22:28.380005\n",
      "0.89662385\n",
      "[Epoch 15/50] [Batch 11/300] [D loss: 0.752985] [G loss: 0.568748] time: 0:22:28.675968\n",
      "0.91441303\n",
      "[Epoch 15/50] [Batch 12/300] [D loss: 0.752924] [G loss: 0.567250] time: 0:22:28.974315\n",
      "0.9255373\n",
      "[Epoch 15/50] [Batch 13/300] [D loss: 0.752943] [G loss: 0.609266] time: 0:22:29.265824\n",
      "0.9080832\n",
      "[Epoch 15/50] [Batch 15/300] [D loss: 0.752940] [G loss: 0.569131] time: 0:22:29.569460\n",
      "0.92511725\n",
      "[Epoch 15/50] [Batch 16/300] [D loss: 0.752911] [G loss: 0.559484] time: 0:22:29.871740\n",
      "0.92830276\n",
      "[Epoch 15/50] [Batch 17/300] [D loss: 0.752939] [G loss: 0.571117] time: 0:22:30.191241\n",
      "0.9414618\n",
      "[Epoch 15/50] [Batch 18/300] [D loss: 0.752878] [G loss: 0.623900] time: 0:22:30.483848\n",
      "0.96727663\n",
      "[Epoch 15/50] [Batch 19/300] [D loss: 0.752876] [G loss: 0.539467] time: 0:22:30.780704\n",
      "0.9089833\n",
      "[Epoch 15/50] [Batch 20/300] [D loss: 0.752895] [G loss: 0.594175] time: 0:22:31.210259\n",
      "0.93914366\n",
      "[Epoch 15/50] [Batch 21/300] [D loss: 0.752928] [G loss: 0.572303] time: 0:22:31.485722\n",
      "0.90543365\n",
      "[Epoch 15/50] [Batch 22/300] [D loss: 0.752977] [G loss: 0.556064] time: 0:22:31.776373\n",
      "0.8863859\n",
      "[Epoch 15/50] [Batch 23/300] [D loss: 0.752934] [G loss: 0.556500] time: 0:22:32.070946\n",
      "0.9270641\n",
      "[Epoch 15/50] [Batch 24/300] [D loss: 0.752894] [G loss: 0.596199] time: 0:22:32.363132\n",
      "0.91320086\n",
      "[Epoch 15/50] [Batch 25/300] [D loss: 0.752960] [G loss: 0.566889] time: 0:22:32.663426\n",
      "0.96095484\n",
      "[Epoch 15/50] [Batch 26/300] [D loss: 0.752925] [G loss: 0.554520] time: 0:22:32.962189\n",
      "0.89909315\n",
      "[Epoch 15/50] [Batch 27/300] [D loss: 0.752910] [G loss: 0.605641] time: 0:22:33.254821\n",
      "0.931464\n",
      "[Epoch 15/50] [Batch 28/300] [D loss: 0.752942] [G loss: 0.637071] time: 0:22:33.547804\n",
      "0.9037015\n",
      "[Epoch 15/50] [Batch 29/300] [D loss: 0.752918] [G loss: 0.547659] time: 0:22:33.836539\n",
      "0.9110282\n",
      "[Epoch 15/50] [Batch 30/300] [D loss: 0.752907] [G loss: 0.621971] time: 0:22:34.146974\n",
      "0.86922294\n",
      "[Epoch 15/50] [Batch 31/300] [D loss: 0.752926] [G loss: 0.574228] time: 0:22:34.446851\n",
      "0.9184337\n",
      "[Epoch 15/50] [Batch 32/300] [D loss: 0.752948] [G loss: 0.541678] time: 0:22:34.768318\n",
      "0.9096408\n",
      "[Epoch 15/50] [Batch 33/300] [D loss: 0.752952] [G loss: 0.557758] time: 0:22:35.052060\n",
      "0.9325125\n",
      "[Epoch 15/50] [Batch 34/300] [D loss: 0.752972] [G loss: 0.620122] time: 0:22:35.377672\n",
      "0.9471248\n",
      "[Epoch 15/50] [Batch 35/300] [D loss: 0.752945] [G loss: 0.601056] time: 0:22:35.686119\n",
      "0.91194946\n",
      "[Epoch 15/50] [Batch 36/300] [D loss: 0.752876] [G loss: 0.657740] time: 0:22:35.979507\n",
      "0.8743908\n",
      "[Epoch 15/50] [Batch 37/300] [D loss: 0.752911] [G loss: 0.612105] time: 0:22:36.284607\n",
      "0.92531806\n",
      "[Epoch 15/50] [Batch 38/300] [D loss: 0.752969] [G loss: 0.546564] time: 0:22:36.585648\n",
      "0.9130599\n",
      "[Epoch 15/50] [Batch 39/300] [D loss: 0.752935] [G loss: 0.569955] time: 0:22:36.894526\n",
      "0.9292392\n",
      "[Epoch 15/50] [Batch 40/300] [D loss: 0.752939] [G loss: 0.599357] time: 0:22:37.196612\n",
      "0.8840664\n",
      "[Epoch 15/50] [Batch 41/300] [D loss: 0.752937] [G loss: 0.557757] time: 0:22:37.497490\n",
      "0.9089668\n",
      "[Epoch 15/50] [Batch 42/300] [D loss: 0.752928] [G loss: 0.558870] time: 0:22:37.803582\n",
      "0.905191\n",
      "[Epoch 15/50] [Batch 43/300] [D loss: 0.752906] [G loss: 0.564295] time: 0:22:38.104502\n",
      "0.9056394\n",
      "[Epoch 15/50] [Batch 44/300] [D loss: 0.752925] [G loss: 0.560810] time: 0:22:38.402949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9064209\n",
      "[Epoch 15/50] [Batch 45/300] [D loss: 0.752953] [G loss: 0.544654] time: 0:22:38.690197\n",
      "0.93433\n",
      "[Epoch 15/50] [Batch 46/300] [D loss: 0.752971] [G loss: 0.582142] time: 0:22:39.002571\n",
      "0.86341363\n",
      "[Epoch 15/50] [Batch 47/300] [D loss: 0.752915] [G loss: 0.601471] time: 0:22:39.308163\n",
      "0.9057022\n",
      "[Epoch 15/50] [Batch 48/300] [D loss: 0.752946] [G loss: 0.536609] time: 0:22:39.612185\n",
      "0.9336336\n",
      "[Epoch 15/50] [Batch 49/300] [D loss: 0.752941] [G loss: 0.605284] time: 0:22:39.915987\n",
      "0.90594345\n",
      "[Epoch 15/50] [Batch 50/300] [D loss: 0.752880] [G loss: 0.571382] time: 0:22:40.228559\n",
      "0.903873\n",
      "[Epoch 15/50] [Batch 51/300] [D loss: 0.752900] [G loss: 0.531983] time: 0:22:40.543953\n",
      "0.9146635\n",
      "[Epoch 15/50] [Batch 52/300] [D loss: 0.752913] [G loss: 0.538793] time: 0:22:40.853220\n",
      "0.9533437\n",
      "[Epoch 15/50] [Batch 53/300] [D loss: 0.752939] [G loss: 0.543454] time: 0:22:41.154439\n",
      "0.89146596\n",
      "[Epoch 15/50] [Batch 54/300] [D loss: 0.752904] [G loss: 0.603731] time: 0:22:41.448488\n",
      "0.97110367\n",
      "[Epoch 15/50] [Batch 55/300] [D loss: 0.752915] [G loss: 0.544448] time: 0:22:41.761199\n",
      "0.9144521\n",
      "[Epoch 15/50] [Batch 56/300] [D loss: 0.752948] [G loss: 0.541887] time: 0:22:42.076676\n",
      "0.93319243\n",
      "[Epoch 15/50] [Batch 57/300] [D loss: 0.752926] [G loss: 0.585744] time: 0:22:42.375497\n",
      "0.88191754\n",
      "[Epoch 15/50] [Batch 58/300] [D loss: 0.752942] [G loss: 0.579059] time: 0:22:42.659759\n",
      "0.8911421\n",
      "[Epoch 15/50] [Batch 59/300] [D loss: 0.752913] [G loss: 0.574975] time: 0:22:42.937109\n",
      "0.89135116\n",
      "[Epoch 15/50] [Batch 60/300] [D loss: 0.752937] [G loss: 0.554261] time: 0:22:43.241611\n",
      "0.9200983\n",
      "[Epoch 15/50] [Batch 61/300] [D loss: 0.752895] [G loss: 0.572321] time: 0:22:43.529667\n",
      "0.91310835\n",
      "[Epoch 15/50] [Batch 62/300] [D loss: 0.752917] [G loss: 0.554058] time: 0:22:43.818459\n",
      "0.903615\n",
      "[Epoch 15/50] [Batch 63/300] [D loss: 0.752898] [G loss: 0.567076] time: 0:22:44.115495\n",
      "0.8865946\n",
      "[Epoch 15/50] [Batch 64/300] [D loss: 0.752968] [G loss: 0.610341] time: 0:22:44.424477\n",
      "0.95222\n",
      "[Epoch 15/50] [Batch 65/300] [D loss: 0.752933] [G loss: 0.578693] time: 0:22:44.720892\n",
      "0.9322247\n",
      "[Epoch 15/50] [Batch 66/300] [D loss: 0.752922] [G loss: 0.592517] time: 0:22:45.027968\n",
      "0.9161103\n",
      "[Epoch 15/50] [Batch 67/300] [D loss: 0.752910] [G loss: 0.532606] time: 0:22:45.320479\n",
      "0.90867996\n",
      "[Epoch 15/50] [Batch 68/300] [D loss: 0.752936] [G loss: 0.574298] time: 0:22:45.617203\n",
      "0.8905212\n",
      "[Epoch 15/50] [Batch 69/300] [D loss: 0.752908] [G loss: 0.598257] time: 0:22:45.943571\n",
      "0.90683454\n",
      "[Epoch 15/50] [Batch 70/300] [D loss: 0.752909] [G loss: 0.529047] time: 0:22:46.248480\n",
      "0.90919656\n",
      "[Epoch 15/50] [Batch 71/300] [D loss: 0.752920] [G loss: 0.546798] time: 0:22:46.546588\n",
      "0.94501084\n",
      "[Epoch 15/50] [Batch 72/300] [D loss: 0.752904] [G loss: 0.515005] time: 0:22:46.843538\n",
      "0.9047913\n",
      "[Epoch 15/50] [Batch 73/300] [D loss: 0.752930] [G loss: 0.630282] time: 0:22:47.141987\n",
      "0.9054683\n",
      "[Epoch 15/50] [Batch 74/300] [D loss: 0.752897] [G loss: 0.632279] time: 0:22:47.448062\n",
      "0.89883924\n",
      "[Epoch 15/50] [Batch 75/300] [D loss: 0.752912] [G loss: 0.587894] time: 0:22:47.747794\n",
      "0.89990634\n",
      "[Epoch 15/50] [Batch 76/300] [D loss: 0.752970] [G loss: 0.583646] time: 0:22:48.043109\n",
      "0.97546434\n",
      "[Epoch 15/50] [Batch 77/300] [D loss: 0.752916] [G loss: 0.590917] time: 0:22:48.350221\n",
      "0.9693732\n",
      "[Epoch 15/50] [Batch 78/300] [D loss: 0.752920] [G loss: 0.606830] time: 0:22:48.647291\n",
      "0.9444709\n",
      "[Epoch 15/50] [Batch 79/300] [D loss: 0.752911] [G loss: 0.567340] time: 0:22:48.946823\n",
      "0.905075\n",
      "[Epoch 15/50] [Batch 80/300] [D loss: 0.752923] [G loss: 0.608150] time: 0:22:49.255747\n",
      "0.9424235\n",
      "[Epoch 15/50] [Batch 81/300] [D loss: 0.752962] [G loss: 0.570207] time: 0:22:49.550775\n",
      "0.95497924\n",
      "[Epoch 15/50] [Batch 82/300] [D loss: 0.752907] [G loss: 0.545596] time: 0:22:49.860493\n",
      "0.93724656\n",
      "[Epoch 15/50] [Batch 83/300] [D loss: 0.752994] [G loss: 0.574060] time: 0:22:50.165547\n",
      "0.93779045\n",
      "[Epoch 15/50] [Batch 84/300] [D loss: 0.752880] [G loss: 0.572415] time: 0:22:50.474008\n",
      "0.91549706\n",
      "[Epoch 15/50] [Batch 85/300] [D loss: 0.752919] [G loss: 0.545317] time: 0:22:50.794556\n",
      "0.9160717\n",
      "[Epoch 15/50] [Batch 86/300] [D loss: 0.752911] [G loss: 0.547889] time: 0:22:51.106461\n",
      "0.9501233\n",
      "[Epoch 15/50] [Batch 87/300] [D loss: 0.752912] [G loss: 0.578094] time: 0:22:51.417560\n",
      "0.9431875\n",
      "[Epoch 15/50] [Batch 88/300] [D loss: 0.752914] [G loss: 0.583722] time: 0:22:51.711190\n",
      "0.8861251\n",
      "[Epoch 15/50] [Batch 89/300] [D loss: 0.752895] [G loss: 0.625087] time: 0:22:52.024961\n",
      "0.92174816\n",
      "[Epoch 15/50] [Batch 90/300] [D loss: 0.752898] [G loss: 0.618806] time: 0:22:52.327099\n",
      "0.9469181\n",
      "[Epoch 15/50] [Batch 91/300] [D loss: 0.752877] [G loss: 0.607386] time: 0:22:52.635872\n",
      "0.9149721\n",
      "[Epoch 15/50] [Batch 92/300] [D loss: 0.752904] [G loss: 0.595052] time: 0:22:52.928757\n",
      "0.8960336\n",
      "[Epoch 15/50] [Batch 93/300] [D loss: 0.752940] [G loss: 0.530873] time: 0:22:53.220441\n",
      "0.9603319\n",
      "[Epoch 15/50] [Batch 94/300] [D loss: 0.752914] [G loss: 0.574854] time: 0:22:53.525556\n",
      "0.9162357\n",
      "[Epoch 15/50] [Batch 95/300] [D loss: 0.752879] [G loss: 0.599258] time: 0:22:53.834868\n",
      "0.93320733\n",
      "[Epoch 15/50] [Batch 96/300] [D loss: 0.752899] [G loss: 0.543912] time: 0:22:54.130886\n",
      "0.88499266\n",
      "[Epoch 15/50] [Batch 97/300] [D loss: 0.752927] [G loss: 0.560750] time: 0:22:54.429795\n",
      "0.9478578\n",
      "[Epoch 15/50] [Batch 98/300] [D loss: 0.752899] [G loss: 0.564605] time: 0:22:54.759047\n",
      "0.8739237\n",
      "[Epoch 15/50] [Batch 99/300] [D loss: 0.752934] [G loss: 0.585319] time: 0:22:55.075427\n",
      "0.93562514\n",
      "[Epoch 15/50] [Batch 100/300] [D loss: 0.752896] [G loss: 0.552254] time: 0:22:55.378895\n",
      "0.9420249\n",
      "[Epoch 15/50] [Batch 101/300] [D loss: 0.752950] [G loss: 0.562761] time: 0:22:55.691918\n",
      "0.97100925\n",
      "[Epoch 15/50] [Batch 102/300] [D loss: 0.752914] [G loss: 0.555094] time: 0:22:55.981310\n",
      "0.9816449\n",
      "[Epoch 15/50] [Batch 103/300] [D loss: 0.752935] [G loss: 0.543395] time: 0:22:56.281451\n",
      "0.9116762\n",
      "[Epoch 15/50] [Batch 104/300] [D loss: 0.752871] [G loss: 0.572385] time: 0:22:56.592147\n",
      "0.92903775\n",
      "[Epoch 15/50] [Batch 105/300] [D loss: 0.752897] [G loss: 0.607249] time: 0:22:56.898490\n",
      "0.92554593\n",
      "[Epoch 15/50] [Batch 106/300] [D loss: 0.752890] [G loss: 0.578511] time: 0:22:57.203531\n",
      "0.908674\n",
      "[Epoch 15/50] [Batch 107/300] [D loss: 0.752895] [G loss: 0.592102] time: 0:22:57.486267\n",
      "0.90868473\n",
      "[Epoch 15/50] [Batch 108/300] [D loss: 0.752895] [G loss: 0.594462] time: 0:22:57.795798\n",
      "0.93918854\n",
      "[Epoch 15/50] [Batch 109/300] [D loss: 0.752869] [G loss: 0.687106] time: 0:22:58.080887\n",
      "0.94226617\n",
      "[Epoch 15/50] [Batch 110/300] [D loss: 0.752914] [G loss: 0.559104] time: 0:22:58.396933\n",
      "0.8855538\n",
      "[Epoch 15/50] [Batch 111/300] [D loss: 0.752927] [G loss: 0.579569] time: 0:22:58.686214\n",
      "0.93930435\n",
      "[Epoch 15/50] [Batch 112/300] [D loss: 0.752889] [G loss: 0.627072] time: 0:22:58.978168\n",
      "0.8957022\n",
      "[Epoch 15/50] [Batch 113/300] [D loss: 0.752929] [G loss: 0.564732] time: 0:22:59.275246\n",
      "0.93149376\n",
      "[Epoch 15/50] [Batch 114/300] [D loss: 0.752918] [G loss: 0.544919] time: 0:22:59.576016\n",
      "0.8876968\n",
      "[Epoch 15/50] [Batch 115/300] [D loss: 0.752924] [G loss: 0.568291] time: 0:22:59.897141\n",
      "0.9444325\n",
      "[Epoch 15/50] [Batch 116/300] [D loss: 0.752914] [G loss: 0.590208] time: 0:23:00.217736\n",
      "0.88799816\n",
      "[Epoch 15/50] [Batch 117/300] [D loss: 0.752932] [G loss: 0.564484] time: 0:23:00.510570\n",
      "0.8818088\n",
      "[Epoch 15/50] [Batch 118/300] [D loss: 0.752890] [G loss: 0.544521] time: 0:23:00.812804\n",
      "0.876502\n",
      "[Epoch 15/50] [Batch 119/300] [D loss: 0.752883] [G loss: 0.589512] time: 0:23:01.103354\n",
      "0.9491946\n",
      "[Epoch 15/50] [Batch 120/300] [D loss: 0.752876] [G loss: 0.601461] time: 0:23:01.403706\n",
      "0.93915874\n",
      "[Epoch 15/50] [Batch 121/300] [D loss: 0.752913] [G loss: 0.530899] time: 0:23:01.699219\n",
      "0.9761041\n",
      "[Epoch 15/50] [Batch 122/300] [D loss: 0.752925] [G loss: 0.552874] time: 0:23:02.015662\n",
      "0.9363006\n",
      "[Epoch 15/50] [Batch 123/300] [D loss: 0.752902] [G loss: 0.570064] time: 0:23:02.308652\n",
      "0.9541843\n",
      "[Epoch 15/50] [Batch 124/300] [D loss: 0.752899] [G loss: 0.544581] time: 0:23:02.620559\n",
      "0.92975646\n",
      "[Epoch 15/50] [Batch 125/300] [D loss: 0.752920] [G loss: 0.535754] time: 0:23:02.906363\n",
      "0.9036184\n",
      "[Epoch 15/50] [Batch 126/300] [D loss: 0.752882] [G loss: 0.588910] time: 0:23:03.203978\n",
      "0.939126\n",
      "[Epoch 15/50] [Batch 127/300] [D loss: 0.752904] [G loss: 0.625623] time: 0:23:03.496106\n",
      "0.9383697\n",
      "[Epoch 15/50] [Batch 128/300] [D loss: 0.752890] [G loss: 0.548289] time: 0:23:03.811760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8663326\n",
      "[Epoch 15/50] [Batch 129/300] [D loss: 0.752913] [G loss: 0.641437] time: 0:23:04.117170\n",
      "0.88378763\n",
      "[Epoch 15/50] [Batch 130/300] [D loss: 0.752922] [G loss: 0.589445] time: 0:23:04.414561\n",
      "0.91403675\n",
      "[Epoch 15/50] [Batch 131/300] [D loss: 0.752942] [G loss: 0.559963] time: 0:23:04.718410\n",
      "0.93883204\n",
      "[Epoch 15/50] [Batch 132/300] [D loss: 0.752906] [G loss: 0.616347] time: 0:23:05.028513\n",
      "0.9139851\n",
      "[Epoch 15/50] [Batch 133/300] [D loss: 0.752894] [G loss: 0.567909] time: 0:23:05.343857\n",
      "0.91068935\n",
      "[Epoch 15/50] [Batch 134/300] [D loss: 0.752937] [G loss: 0.589929] time: 0:23:05.636038\n",
      "0.94712204\n",
      "[Epoch 15/50] [Batch 135/300] [D loss: 0.752933] [G loss: 0.581062] time: 0:23:05.950337\n",
      "0.9454406\n",
      "[Epoch 15/50] [Batch 136/300] [D loss: 0.752913] [G loss: 0.565821] time: 0:23:06.262683\n",
      "0.88370377\n",
      "[Epoch 15/50] [Batch 137/300] [D loss: 0.752936] [G loss: 0.585976] time: 0:23:06.553092\n",
      "0.83450365\n",
      "[Epoch 15/50] [Batch 138/300] [D loss: 0.752891] [G loss: 0.604458] time: 0:23:06.845481\n",
      "0.952997\n",
      "[Epoch 15/50] [Batch 139/300] [D loss: 0.752945] [G loss: 0.541290] time: 0:23:07.148550\n",
      "0.9336714\n",
      "[Epoch 15/50] [Batch 140/300] [D loss: 0.752912] [G loss: 0.572882] time: 0:23:07.469538\n",
      "0.9139714\n",
      "[Epoch 15/50] [Batch 141/300] [D loss: 0.752903] [G loss: 0.650490] time: 0:23:07.766545\n",
      "0.90481466\n",
      "[Epoch 15/50] [Batch 142/300] [D loss: 0.752868] [G loss: 0.516354] time: 0:23:08.073745\n",
      "0.9054513\n",
      "[Epoch 15/50] [Batch 143/300] [D loss: 0.752887] [G loss: 0.621037] time: 0:23:08.375307\n",
      "0.90430886\n",
      "[Epoch 15/50] [Batch 144/300] [D loss: 0.752893] [G loss: 0.611833] time: 0:23:08.660802\n",
      "0.86265105\n",
      "[Epoch 15/50] [Batch 145/300] [D loss: 0.752911] [G loss: 0.579660] time: 0:23:08.971144\n",
      "0.90800506\n",
      "[Epoch 15/50] [Batch 146/300] [D loss: 0.752890] [G loss: 0.582074] time: 0:23:09.265658\n",
      "0.92894226\n",
      "[Epoch 15/50] [Batch 147/300] [D loss: 0.752921] [G loss: 0.582270] time: 0:23:09.538607\n",
      "0.93307\n",
      "[Epoch 15/50] [Batch 148/300] [D loss: 0.752920] [G loss: 0.551824] time: 0:23:09.830666\n",
      "0.9057503\n",
      "[Epoch 15/50] [Batch 149/300] [D loss: 0.752918] [G loss: 0.522776] time: 0:23:10.142574\n",
      "0.96039915\n",
      "[Epoch 15/50] [Batch 150/300] [D loss: 0.752896] [G loss: 0.619887] time: 0:23:10.436050\n",
      "0.9215841\n",
      "[Epoch 15/50] [Batch 151/300] [D loss: 0.752874] [G loss: 0.620667] time: 0:23:10.725579\n",
      "0.8931102\n",
      "[Epoch 15/50] [Batch 152/300] [D loss: 0.752883] [G loss: 0.553183] time: 0:23:11.039683\n",
      "0.96045995\n",
      "[Epoch 15/50] [Batch 153/300] [D loss: 0.752886] [G loss: 0.558504] time: 0:23:11.319860\n",
      "0.90685064\n",
      "[Epoch 15/50] [Batch 154/300] [D loss: 0.752897] [G loss: 0.618638] time: 0:23:11.636626\n",
      "0.88722914\n",
      "[Epoch 15/50] [Batch 155/300] [D loss: 0.752900] [G loss: 0.578244] time: 0:23:11.960748\n",
      "0.9391195\n",
      "[Epoch 15/50] [Batch 156/300] [D loss: 0.752873] [G loss: 0.585215] time: 0:23:12.261726\n",
      "0.88571\n",
      "[Epoch 15/50] [Batch 157/300] [D loss: 0.752874] [G loss: 0.568931] time: 0:23:12.575087\n",
      "0.91576624\n",
      "[Epoch 15/50] [Batch 158/300] [D loss: 0.752907] [G loss: 0.549331] time: 0:23:12.884658\n",
      "0.8928842\n",
      "[Epoch 15/50] [Batch 159/300] [D loss: 0.752903] [G loss: 0.564253] time: 0:23:13.179654\n",
      "0.9507397\n",
      "[Epoch 15/50] [Batch 160/300] [D loss: 0.752899] [G loss: 0.547699] time: 0:23:13.492303\n",
      "0.8867801\n",
      "[Epoch 15/50] [Batch 161/300] [D loss: 0.752898] [G loss: 0.634465] time: 0:23:13.805492\n",
      "0.89098746\n",
      "[Epoch 15/50] [Batch 162/300] [D loss: 0.752887] [G loss: 0.591244] time: 0:23:14.117861\n",
      "0.91053456\n",
      "[Epoch 15/50] [Batch 163/300] [D loss: 0.752870] [G loss: 0.544117] time: 0:23:14.412706\n",
      "0.9393015\n",
      "[Epoch 15/50] [Batch 164/300] [D loss: 0.752892] [G loss: 0.550380] time: 0:23:14.720980\n",
      "0.92091507\n",
      "[Epoch 15/50] [Batch 165/300] [D loss: 0.752885] [G loss: 0.560653] time: 0:23:15.010064\n",
      "0.9114742\n",
      "[Epoch 15/50] [Batch 166/300] [D loss: 0.752884] [G loss: 0.625518] time: 0:23:15.318114\n",
      "0.89030844\n",
      "[Epoch 15/50] [Batch 167/300] [D loss: 0.752910] [G loss: 0.556553] time: 0:23:15.623442\n",
      "0.9380639\n",
      "[Epoch 15/50] [Batch 168/300] [D loss: 0.752909] [G loss: 0.602913] time: 0:23:15.907013\n",
      "0.95291144\n",
      "[Epoch 15/50] [Batch 169/300] [D loss: 0.752891] [G loss: 0.577916] time: 0:23:16.214109\n",
      "0.89195424\n",
      "[Epoch 15/50] [Batch 170/300] [D loss: 0.752875] [G loss: 0.655236] time: 0:23:16.518310\n",
      "0.9532655\n",
      "[Epoch 15/50] [Batch 171/300] [D loss: 0.752907] [G loss: 0.515110] time: 0:23:16.813344\n",
      "0.9107127\n",
      "[Epoch 15/50] [Batch 172/300] [D loss: 0.752864] [G loss: 0.600776] time: 0:23:17.110496\n",
      "0.9197142\n",
      "[Epoch 15/50] [Batch 173/300] [D loss: 0.752905] [G loss: 0.560813] time: 0:23:17.407364\n",
      "0.9333093\n",
      "[Epoch 15/50] [Batch 174/300] [D loss: 0.752881] [G loss: 0.591827] time: 0:23:17.718369\n",
      "0.9713683\n",
      "[Epoch 15/50] [Batch 175/300] [D loss: 0.752880] [G loss: 0.602329] time: 0:23:18.007251\n",
      "0.95035124\n",
      "[Epoch 15/50] [Batch 176/300] [D loss: 0.752866] [G loss: 0.573131] time: 0:23:18.309812\n",
      "0.9407232\n",
      "[Epoch 15/50] [Batch 177/300] [D loss: 0.752933] [G loss: 0.549245] time: 0:23:18.614649\n",
      "0.9451236\n",
      "[Epoch 15/50] [Batch 178/300] [D loss: 0.752902] [G loss: 0.535265] time: 0:23:18.916348\n",
      "0.8923518\n",
      "[Epoch 15/50] [Batch 179/300] [D loss: 0.752882] [G loss: 0.577953] time: 0:23:19.206725\n",
      "0.940465\n",
      "[Epoch 15/50] [Batch 180/300] [D loss: 0.752877] [G loss: 0.557610] time: 0:23:19.518846\n",
      "0.8839876\n",
      "[Epoch 15/50] [Batch 181/300] [D loss: 0.752892] [G loss: 0.596712] time: 0:23:19.819849\n",
      "0.93948644\n",
      "[Epoch 15/50] [Batch 182/300] [D loss: 0.752863] [G loss: 0.676057] time: 0:23:20.135595\n",
      "0.9308112\n",
      "[Epoch 15/50] [Batch 183/300] [D loss: 0.752950] [G loss: 0.561920] time: 0:23:20.436448\n",
      "0.88862205\n",
      "[Epoch 15/50] [Batch 184/300] [D loss: 0.752895] [G loss: 0.569790] time: 0:23:20.718701\n",
      "0.97171384\n",
      "[Epoch 15/50] [Batch 185/300] [D loss: 0.752880] [G loss: 0.598562] time: 0:23:21.024443\n",
      "0.9426326\n",
      "[Epoch 15/50] [Batch 186/300] [D loss: 0.752902] [G loss: 0.568804] time: 0:23:21.322943\n",
      "0.88000065\n",
      "[Epoch 15/50] [Batch 187/300] [D loss: 0.752878] [G loss: 0.564514] time: 0:23:21.635176\n",
      "0.9044051\n",
      "[Epoch 15/50] [Batch 188/300] [D loss: 0.752888] [G loss: 0.577286] time: 0:23:21.952948\n",
      "0.9677537\n",
      "[Epoch 15/50] [Batch 189/300] [D loss: 0.752866] [G loss: 0.605694] time: 0:23:22.243606\n",
      "0.9193883\n",
      "[Epoch 15/50] [Batch 190/300] [D loss: 0.752859] [G loss: 0.623139] time: 0:23:22.516921\n",
      "0.9167826\n",
      "[Epoch 15/50] [Batch 191/300] [D loss: 0.752888] [G loss: 0.543126] time: 0:23:22.823055\n",
      "0.90254784\n",
      "[Epoch 15/50] [Batch 192/300] [D loss: 0.752943] [G loss: 0.570925] time: 0:23:23.110471\n",
      "0.90842336\n",
      "[Epoch 15/50] [Batch 193/300] [D loss: 0.752896] [G loss: 0.560995] time: 0:23:23.391960\n",
      "0.932671\n",
      "[Epoch 15/50] [Batch 194/300] [D loss: 0.752887] [G loss: 0.533821] time: 0:23:23.678672\n",
      "0.93552023\n",
      "[Epoch 15/50] [Batch 195/300] [D loss: 0.752904] [G loss: 0.569158] time: 0:23:23.951338\n",
      "0.95714873\n",
      "[Epoch 15/50] [Batch 196/300] [D loss: 0.752866] [G loss: 0.643425] time: 0:23:24.252641\n",
      "0.91171956\n",
      "[Epoch 15/50] [Batch 197/300] [D loss: 0.752928] [G loss: 0.590200] time: 0:23:24.548488\n",
      "0.9402664\n",
      "[Epoch 15/50] [Batch 198/300] [D loss: 0.752921] [G loss: 0.597387] time: 0:23:24.833637\n",
      "0.91692233\n",
      "[Epoch 15/50] [Batch 199/300] [D loss: 0.752901] [G loss: 0.529717] time: 0:23:25.139034\n",
      "0.9422793\n",
      "[Epoch 15/50] [Batch 200/300] [D loss: 0.752863] [G loss: 0.555936] time: 0:23:25.444800\n",
      "0.9190581\n",
      "[Epoch 15/50] [Batch 201/300] [D loss: 0.752875] [G loss: 0.606708] time: 0:23:25.760216\n",
      "0.9328664\n",
      "[Epoch 15/50] [Batch 202/300] [D loss: 0.752873] [G loss: 0.595200] time: 0:23:26.056269\n",
      "0.9252317\n",
      "[Epoch 15/50] [Batch 203/300] [D loss: 0.752913] [G loss: 0.514077] time: 0:23:26.359285\n",
      "0.9291598\n",
      "[Epoch 15/50] [Batch 204/300] [D loss: 0.752883] [G loss: 0.660399] time: 0:23:26.645392\n",
      "0.91677564\n",
      "[Epoch 15/50] [Batch 205/300] [D loss: 0.752898] [G loss: 0.574897] time: 0:23:26.947629\n",
      "0.93224055\n",
      "[Epoch 15/50] [Batch 206/300] [D loss: 0.752890] [G loss: 0.546424] time: 0:23:27.256100\n",
      "0.9479077\n",
      "[Epoch 15/50] [Batch 207/300] [D loss: 0.752864] [G loss: 0.551078] time: 0:23:27.554754\n",
      "0.9690266\n",
      "[Epoch 15/50] [Batch 208/300] [D loss: 0.752923] [G loss: 0.557840] time: 0:23:27.858179\n",
      "0.93083334\n",
      "[Epoch 15/50] [Batch 209/300] [D loss: 0.752886] [G loss: 0.612962] time: 0:23:28.149765\n",
      "0.9306709\n",
      "[Epoch 15/50] [Batch 210/300] [D loss: 0.752893] [G loss: 0.538509] time: 0:23:28.465082\n",
      "0.880946\n",
      "[Epoch 15/50] [Batch 211/300] [D loss: 0.752880] [G loss: 0.550933] time: 0:23:28.772929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956185\n",
      "[Epoch 15/50] [Batch 212/300] [D loss: 0.752876] [G loss: 0.613195] time: 0:23:29.075574\n",
      "0.8838363\n",
      "[Epoch 15/50] [Batch 213/300] [D loss: 0.752896] [G loss: 0.535618] time: 0:23:29.386823\n",
      "0.8906608\n",
      "[Epoch 15/50] [Batch 214/300] [D loss: 0.752881] [G loss: 0.626767] time: 0:23:29.689638\n",
      "0.8943939\n",
      "[Epoch 15/50] [Batch 215/300] [D loss: 0.752887] [G loss: 0.560913] time: 0:23:29.985187\n",
      "0.90402097\n",
      "[Epoch 15/50] [Batch 216/300] [D loss: 0.752854] [G loss: 0.546853] time: 0:23:30.262033\n",
      "0.90447\n",
      "[Epoch 15/50] [Batch 217/300] [D loss: 0.752893] [G loss: 0.592630] time: 0:23:30.552217\n",
      "0.89214736\n",
      "[Epoch 15/50] [Batch 218/300] [D loss: 0.752876] [G loss: 0.580031] time: 0:23:30.855168\n",
      "0.8899526\n",
      "[Epoch 15/50] [Batch 219/300] [D loss: 0.752885] [G loss: 0.549310] time: 0:23:31.136753\n",
      "0.9228352\n",
      "[Epoch 15/50] [Batch 220/300] [D loss: 0.752871] [G loss: 0.612157] time: 0:23:31.425837\n",
      "0.9062267\n",
      "[Epoch 15/50] [Batch 221/300] [D loss: 0.752905] [G loss: 0.550446] time: 0:23:31.725451\n",
      "0.91800594\n",
      "[Epoch 15/50] [Batch 222/300] [D loss: 0.752895] [G loss: 0.587774] time: 0:23:32.025662\n",
      "0.91014314\n",
      "[Epoch 15/50] [Batch 223/300] [D loss: 0.752886] [G loss: 0.647173] time: 0:23:32.336021\n",
      "0.9553234\n",
      "[Epoch 15/50] [Batch 224/300] [D loss: 0.752862] [G loss: 0.588534] time: 0:23:32.636222\n",
      "0.9382529\n",
      "[Epoch 15/50] [Batch 225/300] [D loss: 0.752896] [G loss: 0.673882] time: 0:23:32.947582\n",
      "0.95250297\n",
      "[Epoch 15/50] [Batch 226/300] [D loss: 0.752848] [G loss: 0.600034] time: 0:23:33.234135\n",
      "0.90602154\n",
      "[Epoch 15/50] [Batch 227/300] [D loss: 0.752874] [G loss: 0.594999] time: 0:23:33.524526\n",
      "0.9466362\n",
      "[Epoch 15/50] [Batch 228/300] [D loss: 0.752886] [G loss: 0.567065] time: 0:23:33.811934\n",
      "0.91388106\n",
      "[Epoch 15/50] [Batch 229/300] [D loss: 0.752869] [G loss: 0.538755] time: 0:23:34.124853\n",
      "0.8995724\n",
      "[Epoch 15/50] [Batch 230/300] [D loss: 0.752874] [G loss: 0.631950] time: 0:23:34.430132\n",
      "0.9082503\n",
      "[Epoch 15/50] [Batch 231/300] [D loss: 0.752867] [G loss: 0.547975] time: 0:23:34.731870\n",
      "0.9166798\n",
      "[Epoch 15/50] [Batch 232/300] [D loss: 0.752880] [G loss: 0.561302] time: 0:23:35.040787\n",
      "0.9444151\n",
      "[Epoch 15/50] [Batch 233/300] [D loss: 0.752885] [G loss: 0.610121] time: 0:23:35.345734\n",
      "0.93899775\n",
      "[Epoch 15/50] [Batch 234/300] [D loss: 0.752879] [G loss: 0.598696] time: 0:23:35.630045\n",
      "0.95375663\n",
      "[Epoch 15/50] [Batch 235/300] [D loss: 0.752895] [G loss: 0.525037] time: 0:23:35.932976\n",
      "0.9295699\n",
      "[Epoch 15/50] [Batch 236/300] [D loss: 0.752852] [G loss: 0.588032] time: 0:23:36.225815\n",
      "0.90749294\n",
      "[Epoch 15/50] [Batch 237/300] [D loss: 0.752851] [G loss: 0.551914] time: 0:23:36.518613\n",
      "0.9315638\n",
      "[Epoch 15/50] [Batch 238/300] [D loss: 0.752903] [G loss: 0.529336] time: 0:23:36.812502\n",
      "0.9552526\n",
      "[Epoch 15/50] [Batch 239/300] [D loss: 0.752859] [G loss: 0.568751] time: 0:23:37.133663\n",
      "0.9060003\n",
      "[Epoch 15/50] [Batch 240/300] [D loss: 0.752854] [G loss: 0.621066] time: 0:23:37.440076\n",
      "0.98266894\n",
      "[Epoch 15/50] [Batch 241/300] [D loss: 0.752890] [G loss: 0.545826] time: 0:23:37.733468\n",
      "0.96187514\n",
      "[Epoch 15/50] [Batch 242/300] [D loss: 0.752889] [G loss: 0.558232] time: 0:23:38.048484\n",
      "0.90959686\n",
      "[Epoch 15/50] [Batch 243/300] [D loss: 0.752827] [G loss: 0.562930] time: 0:23:38.348285\n",
      "0.904731\n",
      "[Epoch 15/50] [Batch 244/300] [D loss: 0.752930] [G loss: 0.540778] time: 0:23:38.655392\n",
      "0.9208491\n",
      "[Epoch 15/50] [Batch 245/300] [D loss: 0.752904] [G loss: 0.567889] time: 0:23:38.962606\n",
      "0.88923866\n",
      "[Epoch 15/50] [Batch 246/300] [D loss: 0.752882] [G loss: 0.540959] time: 0:23:39.272728\n",
      "0.9240765\n",
      "[Epoch 15/50] [Batch 247/300] [D loss: 0.752881] [G loss: 0.554069] time: 0:23:39.571368\n",
      "0.9322114\n",
      "[Epoch 15/50] [Batch 248/300] [D loss: 0.752893] [G loss: 0.548943] time: 0:23:39.870922\n",
      "0.8814426\n",
      "[Epoch 15/50] [Batch 249/300] [D loss: 0.752874] [G loss: 0.526216] time: 0:23:40.177619\n",
      "0.9030606\n",
      "[Epoch 15/50] [Batch 250/300] [D loss: 0.752902] [G loss: 0.561963] time: 0:23:40.487701\n",
      "0.9107377\n",
      "[Epoch 15/50] [Batch 251/300] [D loss: 0.752893] [G loss: 0.564740] time: 0:23:40.795215\n",
      "0.9223425\n",
      "[Epoch 15/50] [Batch 252/300] [D loss: 0.752867] [G loss: 0.548120] time: 0:23:41.104296\n",
      "0.9161032\n",
      "[Epoch 15/50] [Batch 253/300] [D loss: 0.752907] [G loss: 0.553380] time: 0:23:41.411341\n",
      "0.91634727\n",
      "[Epoch 15/50] [Batch 254/300] [D loss: 0.752846] [G loss: 0.559460] time: 0:23:41.714226\n",
      "0.8585301\n",
      "[Epoch 15/50] [Batch 255/300] [D loss: 0.752881] [G loss: 0.586936] time: 0:23:42.032198\n",
      "0.8961304\n",
      "[Epoch 15/50] [Batch 256/300] [D loss: 0.752868] [G loss: 0.579560] time: 0:23:42.327609\n",
      "0.89593416\n",
      "[Epoch 15/50] [Batch 257/300] [D loss: 0.752836] [G loss: 0.572430] time: 0:23:42.643231\n",
      "0.91667277\n",
      "[Epoch 15/50] [Batch 258/300] [D loss: 0.752905] [G loss: 0.540924] time: 0:23:42.945488\n",
      "0.8910081\n",
      "[Epoch 15/50] [Batch 259/300] [D loss: 0.752859] [G loss: 0.604530] time: 0:23:43.239148\n",
      "0.903522\n",
      "[Epoch 15/50] [Batch 260/300] [D loss: 0.752862] [G loss: 0.529127] time: 0:23:43.551335\n",
      "0.96007967\n",
      "[Epoch 15/50] [Batch 261/300] [D loss: 0.752856] [G loss: 0.545267] time: 0:23:43.848375\n",
      "0.94364953\n",
      "[Epoch 15/50] [Batch 262/300] [D loss: 0.752831] [G loss: 0.594664] time: 0:23:44.140759\n",
      "0.9194942\n",
      "[Epoch 15/50] [Batch 263/300] [D loss: 0.752884] [G loss: 0.564929] time: 0:23:44.461550\n",
      "0.90472937\n",
      "[Epoch 15/50] [Batch 264/300] [D loss: 0.752843] [G loss: 0.663598] time: 0:23:44.776486\n",
      "0.9435659\n",
      "[Epoch 15/50] [Batch 265/300] [D loss: 0.752849] [G loss: 0.624892] time: 0:23:45.091333\n",
      "0.9527342\n",
      "[Epoch 15/50] [Batch 266/300] [D loss: 0.752907] [G loss: 0.550747] time: 0:23:45.373943\n",
      "0.9024952\n",
      "[Epoch 15/50] [Batch 267/300] [D loss: 0.752885] [G loss: 0.577638] time: 0:23:45.665097\n",
      "0.8798614\n",
      "[Epoch 15/50] [Batch 268/300] [D loss: 0.752923] [G loss: 0.580654] time: 0:23:45.955008\n",
      "0.9025235\n",
      "[Epoch 15/50] [Batch 269/300] [D loss: 0.752884] [G loss: 0.543168] time: 0:23:46.271429\n",
      "0.9465149\n",
      "[Epoch 15/50] [Batch 270/300] [D loss: 0.752896] [G loss: 0.535333] time: 0:23:46.578873\n",
      "0.94745225\n",
      "[Epoch 15/50] [Batch 271/300] [D loss: 0.752883] [G loss: 0.592423] time: 0:23:46.893357\n",
      "0.9457124\n",
      "[Epoch 15/50] [Batch 272/300] [D loss: 0.752898] [G loss: 0.593064] time: 0:23:47.180894\n",
      "0.9396587\n",
      "[Epoch 15/50] [Batch 273/300] [D loss: 0.752856] [G loss: 0.561506] time: 0:23:47.464051\n",
      "0.9343236\n",
      "[Epoch 15/50] [Batch 274/300] [D loss: 0.752888] [G loss: 0.557295] time: 0:23:47.768877\n",
      "0.9467435\n",
      "[Epoch 15/50] [Batch 275/300] [D loss: 0.752863] [G loss: 0.598673] time: 0:23:48.081505\n",
      "0.90909725\n",
      "[Epoch 15/50] [Batch 276/300] [D loss: 0.752876] [G loss: 0.518184] time: 0:23:48.385412\n",
      "0.8846821\n",
      "[Epoch 15/50] [Batch 277/300] [D loss: 0.752859] [G loss: 0.582806] time: 0:23:48.693387\n",
      "0.9078283\n",
      "[Epoch 15/50] [Batch 278/300] [D loss: 0.752829] [G loss: 0.570518] time: 0:23:48.985255\n",
      "0.91259986\n",
      "[Epoch 15/50] [Batch 279/300] [D loss: 0.752805] [G loss: 0.574400] time: 0:23:49.288286\n",
      "0.97041816\n",
      "[Epoch 15/50] [Batch 280/300] [D loss: 0.752948] [G loss: 0.547805] time: 0:23:49.595142\n",
      "0.9215956\n",
      "[Epoch 15/50] [Batch 281/300] [D loss: 0.752822] [G loss: 0.567640] time: 0:23:49.896985\n",
      "0.91791534\n",
      "[Epoch 15/50] [Batch 282/300] [D loss: 0.752862] [G loss: 0.566881] time: 0:23:50.205166\n",
      "0.9132076\n",
      "[Epoch 15/50] [Batch 283/300] [D loss: 0.752892] [G loss: 0.584631] time: 0:23:50.503563\n",
      "0.9132151\n",
      "[Epoch 15/50] [Batch 284/300] [D loss: 0.752842] [G loss: 0.557875] time: 0:23:50.805928\n",
      "0.9137488\n",
      "[Epoch 15/50] [Batch 285/300] [D loss: 0.752889] [G loss: 0.599359] time: 0:23:51.110869\n",
      "0.9363652\n",
      "[Epoch 15/50] [Batch 286/300] [D loss: 0.752893] [G loss: 0.547539] time: 0:23:51.420802\n",
      "0.95169145\n",
      "[Epoch 15/50] [Batch 287/300] [D loss: 0.752868] [G loss: 0.536392] time: 0:23:51.723421\n",
      "0.9427483\n",
      "[Epoch 15/50] [Batch 288/300] [D loss: 0.752845] [G loss: 0.538182] time: 0:23:52.018989\n",
      "0.90353614\n",
      "[Epoch 15/50] [Batch 289/300] [D loss: 0.752895] [G loss: 0.561532] time: 0:23:52.326116\n",
      "0.911761\n",
      "[Epoch 15/50] [Batch 290/300] [D loss: 0.752860] [G loss: 0.663529] time: 0:23:52.637272\n",
      "0.95821595\n",
      "[Epoch 15/50] [Batch 291/300] [D loss: 0.752921] [G loss: 0.561744] time: 0:23:52.932369\n",
      "0.94812727\n",
      "[Epoch 15/50] [Batch 292/300] [D loss: 0.752853] [G loss: 0.642718] time: 0:23:53.243253\n",
      "0.9575636\n",
      "[Epoch 15/50] [Batch 293/300] [D loss: 0.752849] [G loss: 0.574917] time: 0:23:53.568616\n",
      "0.94146276\n",
      "[Epoch 15/50] [Batch 294/300] [D loss: 0.752829] [G loss: 0.614905] time: 0:23:53.877258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9740357\n",
      "[Epoch 15/50] [Batch 295/300] [D loss: 0.752867] [G loss: 0.626866] time: 0:23:54.193486\n",
      "0.8872018\n",
      "[Epoch 15/50] [Batch 296/300] [D loss: 0.752873] [G loss: 0.545484] time: 0:23:54.495574\n",
      "0.9042633\n",
      "[Epoch 15/50] [Batch 297/300] [D loss: 0.752882] [G loss: 0.557117] time: 0:23:54.806442\n",
      "0.92297316\n",
      "[Epoch 15/50] [Batch 298/300] [D loss: 0.752928] [G loss: 0.514362] time: 0:23:55.104983\n",
      "0.88883096\n",
      "[Epoch 15/50] [Batch 299/300] [D loss: 0.752863] [G loss: 0.540451] time: 0:23:55.421874\n",
      "0.88398004\n",
      "[Epoch 16/50] [Batch 0/300] [D loss: 0.752861] [G loss: 0.525048] time: 0:23:55.740808\n",
      "0.9072249\n",
      "[Epoch 16/50] [Batch 1/300] [D loss: 0.752873] [G loss: 0.540093] time: 0:23:56.054120\n",
      "0.9454734\n",
      "[Epoch 16/50] [Batch 2/300] [D loss: 0.752844] [G loss: 0.552791] time: 0:23:56.373801\n",
      "0.8840261\n",
      "[Epoch 16/50] [Batch 3/300] [D loss: 0.752920] [G loss: 0.682231] time: 0:23:56.672304\n",
      "0.90372753\n",
      "[Epoch 16/50] [Batch 4/300] [D loss: 0.752871] [G loss: 0.603930] time: 0:23:56.972023\n",
      "0.9244499\n",
      "[Epoch 16/50] [Batch 5/300] [D loss: 0.752839] [G loss: 0.592304] time: 0:23:57.272733\n",
      "0.9057608\n",
      "[Epoch 16/50] [Batch 6/300] [D loss: 0.752862] [G loss: 0.541851] time: 0:23:57.582367\n",
      "0.8924703\n",
      "[Epoch 16/50] [Batch 7/300] [D loss: 0.752881] [G loss: 0.546681] time: 0:23:57.894498\n",
      "0.98213273\n",
      "[Epoch 16/50] [Batch 8/300] [D loss: 0.752867] [G loss: 0.607976] time: 0:23:58.205261\n",
      "0.95500684\n",
      "[Epoch 16/50] [Batch 9/300] [D loss: 0.752827] [G loss: 0.572626] time: 0:23:58.534287\n",
      "0.9169547\n",
      "[Epoch 16/50] [Batch 10/300] [D loss: 0.752827] [G loss: 0.570282] time: 0:23:58.824692\n",
      "0.944664\n",
      "[Epoch 16/50] [Batch 11/300] [D loss: 0.752889] [G loss: 0.617809] time: 0:23:59.104550\n",
      "0.8882239\n",
      "[Epoch 16/50] [Batch 12/300] [D loss: 0.752841] [G loss: 0.532473] time: 0:23:59.388335\n",
      "0.88105273\n",
      "[Epoch 16/50] [Batch 13/300] [D loss: 0.752862] [G loss: 0.614177] time: 0:23:59.694832\n",
      "0.9007111\n",
      "[Epoch 16/50] [Batch 14/300] [D loss: 0.752894] [G loss: 0.534280] time: 0:23:59.987832\n",
      "0.8996894\n",
      "[Epoch 16/50] [Batch 16/300] [D loss: 0.752859] [G loss: 0.587194] time: 0:24:00.304978\n",
      "0.93472266\n",
      "[Epoch 16/50] [Batch 17/300] [D loss: 0.752854] [G loss: 0.518702] time: 0:24:00.630172\n",
      "0.8879393\n",
      "[Epoch 16/50] [Batch 18/300] [D loss: 0.752831] [G loss: 0.571366] time: 0:24:00.919094\n",
      "0.9844057\n",
      "[Epoch 16/50] [Batch 19/300] [D loss: 0.752937] [G loss: 0.547369] time: 0:24:01.225363\n",
      "0.9396162\n",
      "[Epoch 16/50] [Batch 20/300] [D loss: 0.752853] [G loss: 0.554992] time: 0:24:01.537751\n",
      "0.9154635\n",
      "[Epoch 16/50] [Batch 21/300] [D loss: 0.752831] [G loss: 0.578021] time: 0:24:01.843538\n",
      "0.87381333\n",
      "[Epoch 16/50] [Batch 22/300] [D loss: 0.752873] [G loss: 0.551134] time: 0:24:02.140401\n",
      "0.926871\n",
      "[Epoch 16/50] [Batch 23/300] [D loss: 0.752884] [G loss: 0.571146] time: 0:24:02.451046\n",
      "0.9311686\n",
      "[Epoch 16/50] [Batch 24/300] [D loss: 0.752854] [G loss: 0.557155] time: 0:24:02.741949\n",
      "0.9375233\n",
      "[Epoch 16/50] [Batch 25/300] [D loss: 0.752875] [G loss: 0.592161] time: 0:24:03.042656\n",
      "0.9123362\n",
      "[Epoch 16/50] [Batch 26/300] [D loss: 0.752882] [G loss: 0.641472] time: 0:24:03.341472\n",
      "0.9088604\n",
      "[Epoch 16/50] [Batch 27/300] [D loss: 0.752859] [G loss: 0.573881] time: 0:24:03.643094\n",
      "0.9211831\n",
      "[Epoch 16/50] [Batch 28/300] [D loss: 0.752833] [G loss: 0.555709] time: 0:24:03.945783\n",
      "0.8815256\n",
      "[Epoch 16/50] [Batch 29/300] [D loss: 0.752879] [G loss: 0.541881] time: 0:24:04.245672\n",
      "0.95538384\n",
      "[Epoch 16/50] [Batch 30/300] [D loss: 0.752818] [G loss: 0.540267] time: 0:24:04.551027\n",
      "0.9131939\n",
      "[Epoch 16/50] [Batch 31/300] [D loss: 0.752809] [G loss: 0.555429] time: 0:24:04.839994\n",
      "0.9600281\n",
      "[Epoch 16/50] [Batch 32/300] [D loss: 0.752850] [G loss: 0.573095] time: 0:24:05.148631\n",
      "0.9045331\n",
      "[Epoch 16/50] [Batch 33/300] [D loss: 0.752854] [G loss: 0.555812] time: 0:24:05.444536\n",
      "0.9072862\n",
      "[Epoch 16/50] [Batch 34/300] [D loss: 0.752856] [G loss: 0.531772] time: 0:24:05.738221\n",
      "0.9471492\n",
      "[Epoch 16/50] [Batch 35/300] [D loss: 0.752878] [G loss: 0.583150] time: 0:24:06.035576\n",
      "0.9034004\n",
      "[Epoch 16/50] [Batch 36/300] [D loss: 0.752841] [G loss: 0.542136] time: 0:24:06.345028\n",
      "0.9008005\n",
      "[Epoch 16/50] [Batch 37/300] [D loss: 0.752825] [G loss: 0.588452] time: 0:24:06.637513\n",
      "0.94555736\n",
      "[Epoch 16/50] [Batch 38/300] [D loss: 0.752834] [G loss: 0.531630] time: 0:24:06.947488\n",
      "0.96955603\n",
      "[Epoch 16/50] [Batch 39/300] [D loss: 0.752885] [G loss: 0.532875] time: 0:24:07.248735\n",
      "0.9382665\n",
      "[Epoch 16/50] [Batch 40/300] [D loss: 0.752845] [G loss: 0.546780] time: 0:24:07.559554\n",
      "0.95951825\n",
      "[Epoch 16/50] [Batch 41/300] [D loss: 0.752824] [G loss: 0.610696] time: 0:24:07.867458\n",
      "0.93152857\n",
      "[Epoch 16/50] [Batch 42/300] [D loss: 0.752848] [G loss: 0.539737] time: 0:24:08.179992\n",
      "0.9194605\n",
      "[Epoch 16/50] [Batch 43/300] [D loss: 0.752832] [G loss: 0.554299] time: 0:24:08.485379\n",
      "0.8859146\n",
      "[Epoch 16/50] [Batch 44/300] [D loss: 0.752857] [G loss: 0.554418] time: 0:24:08.785380\n",
      "0.89179116\n",
      "[Epoch 16/50] [Batch 45/300] [D loss: 0.752831] [G loss: 0.620537] time: 0:24:09.099019\n",
      "0.9110412\n",
      "[Epoch 16/50] [Batch 46/300] [D loss: 0.752845] [G loss: 0.565119] time: 0:24:09.401098\n",
      "0.96213794\n",
      "[Epoch 16/50] [Batch 47/300] [D loss: 0.752867] [G loss: 0.563979] time: 0:24:09.695517\n",
      "0.9208023\n",
      "[Epoch 16/50] [Batch 48/300] [D loss: 0.752822] [G loss: 0.591233] time: 0:24:09.994488\n",
      "0.9334357\n",
      "[Epoch 16/50] [Batch 49/300] [D loss: 0.752839] [G loss: 0.579510] time: 0:24:10.302841\n",
      "0.91546816\n",
      "[Epoch 16/50] [Batch 50/300] [D loss: 0.752861] [G loss: 0.594081] time: 0:24:10.597542\n",
      "0.9537253\n",
      "[Epoch 16/50] [Batch 51/300] [D loss: 0.752878] [G loss: 0.543154] time: 0:24:10.899995\n",
      "0.9391358\n",
      "[Epoch 16/50] [Batch 52/300] [D loss: 0.752821] [G loss: 0.654555] time: 0:24:11.328301\n",
      "0.9402712\n",
      "[Epoch 16/50] [Batch 53/300] [D loss: 0.752830] [G loss: 0.607561] time: 0:24:11.619927\n",
      "0.88459736\n",
      "[Epoch 16/50] [Batch 54/300] [D loss: 0.752872] [G loss: 0.522804] time: 0:24:11.935525\n",
      "0.88169795\n",
      "[Epoch 16/50] [Batch 55/300] [D loss: 0.752831] [G loss: 0.578834] time: 0:24:12.248612\n",
      "0.97371966\n",
      "[Epoch 16/50] [Batch 56/300] [D loss: 0.752839] [G loss: 0.579458] time: 0:24:12.549797\n",
      "0.8995841\n",
      "[Epoch 16/50] [Batch 57/300] [D loss: 0.752869] [G loss: 0.535106] time: 0:24:12.850718\n",
      "0.92528915\n",
      "[Epoch 16/50] [Batch 58/300] [D loss: 0.752854] [G loss: 0.521951] time: 0:24:13.139734\n",
      "0.94992393\n",
      "[Epoch 16/50] [Batch 59/300] [D loss: 0.752852] [G loss: 0.572057] time: 0:24:13.444905\n",
      "0.91063946\n",
      "[Epoch 16/50] [Batch 60/300] [D loss: 0.752842] [G loss: 0.521757] time: 0:24:13.744766\n",
      "0.9446003\n",
      "[Epoch 16/50] [Batch 61/300] [D loss: 0.752841] [G loss: 0.581984] time: 0:24:14.057334\n",
      "0.9536763\n",
      "[Epoch 16/50] [Batch 62/300] [D loss: 0.752865] [G loss: 0.573352] time: 0:24:14.362462\n",
      "0.91384643\n",
      "[Epoch 16/50] [Batch 63/300] [D loss: 0.752863] [G loss: 0.552099] time: 0:24:14.687000\n",
      "0.9343414\n",
      "[Epoch 16/50] [Batch 64/300] [D loss: 0.752856] [G loss: 0.573183] time: 0:24:14.983563\n",
      "0.92152184\n",
      "[Epoch 16/50] [Batch 65/300] [D loss: 0.752835] [G loss: 0.572003] time: 0:24:15.278584\n",
      "0.9101903\n",
      "[Epoch 16/50] [Batch 66/300] [D loss: 0.752834] [G loss: 0.545464] time: 0:24:15.586015\n",
      "0.9424076\n",
      "[Epoch 16/50] [Batch 67/300] [D loss: 0.752827] [G loss: 0.568238] time: 0:24:15.872143\n",
      "0.92451745\n",
      "[Epoch 16/50] [Batch 68/300] [D loss: 0.752874] [G loss: 0.551051] time: 0:24:16.175835\n",
      "0.96021885\n",
      "[Epoch 16/50] [Batch 69/300] [D loss: 0.752833] [G loss: 0.521248] time: 0:24:16.489355\n",
      "0.96464705\n",
      "[Epoch 16/50] [Batch 70/300] [D loss: 0.752867] [G loss: 0.541825] time: 0:24:16.794696\n",
      "0.904838\n",
      "[Epoch 16/50] [Batch 71/300] [D loss: 0.752873] [G loss: 0.540146] time: 0:24:17.103551\n",
      "0.90575486\n",
      "[Epoch 16/50] [Batch 72/300] [D loss: 0.752842] [G loss: 0.536178] time: 0:24:17.411234\n",
      "0.8900783\n",
      "[Epoch 16/50] [Batch 73/300] [D loss: 0.752855] [G loss: 0.572417] time: 0:24:17.713927\n",
      "0.916877\n",
      "[Epoch 16/50] [Batch 74/300] [D loss: 0.752840] [G loss: 0.574093] time: 0:24:18.011347\n",
      "0.9353003\n",
      "[Epoch 16/50] [Batch 75/300] [D loss: 0.752817] [G loss: 0.536546] time: 0:24:18.313161\n",
      "0.927151\n",
      "[Epoch 16/50] [Batch 76/300] [D loss: 0.752825] [G loss: 0.549543] time: 0:24:18.622475\n",
      "0.88366884\n",
      "[Epoch 16/50] [Batch 77/300] [D loss: 0.752862] [G loss: 0.566500] time: 0:24:18.917763\n",
      "0.9000698\n",
      "[Epoch 16/50] [Batch 78/300] [D loss: 0.752838] [G loss: 0.571933] time: 0:24:19.206530\n",
      "0.8868894\n",
      "[Epoch 16/50] [Batch 79/300] [D loss: 0.752858] [G loss: 0.552696] time: 0:24:19.503269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9530471\n",
      "[Epoch 16/50] [Batch 80/300] [D loss: 0.752834] [G loss: 0.556633] time: 0:24:19.802607\n",
      "0.9187186\n",
      "[Epoch 16/50] [Batch 81/300] [D loss: 0.752872] [G loss: 0.551054] time: 0:24:20.100730\n",
      "0.90226287\n",
      "[Epoch 16/50] [Batch 82/300] [D loss: 0.752855] [G loss: 0.561329] time: 0:24:20.414570\n",
      "0.90156335\n",
      "[Epoch 16/50] [Batch 83/300] [D loss: 0.752850] [G loss: 0.599164] time: 0:24:20.718873\n",
      "0.91538876\n",
      "[Epoch 16/50] [Batch 84/300] [D loss: 0.752852] [G loss: 0.597825] time: 0:24:21.018874\n",
      "0.8944238\n",
      "[Epoch 16/50] [Batch 85/300] [D loss: 0.752880] [G loss: 0.560513] time: 0:24:21.309091\n",
      "0.8988616\n",
      "[Epoch 16/50] [Batch 86/300] [D loss: 0.752852] [G loss: 0.530953] time: 0:24:21.612347\n",
      "0.9250687\n",
      "[Epoch 16/50] [Batch 87/300] [D loss: 0.752817] [G loss: 0.561249] time: 0:24:21.914530\n",
      "0.8819336\n",
      "[Epoch 16/50] [Batch 88/300] [D loss: 0.752831] [G loss: 0.548033] time: 0:24:22.211735\n",
      "0.94069433\n",
      "[Epoch 16/50] [Batch 89/300] [D loss: 0.752861] [G loss: 0.554398] time: 0:24:22.514000\n",
      "0.9401353\n",
      "[Epoch 16/50] [Batch 90/300] [D loss: 0.752859] [G loss: 0.586036] time: 0:24:22.814870\n",
      "0.9110651\n",
      "[Epoch 16/50] [Batch 91/300] [D loss: 0.752845] [G loss: 0.587627] time: 0:24:23.116741\n",
      "0.9287786\n",
      "[Epoch 16/50] [Batch 92/300] [D loss: 0.752856] [G loss: 0.512500] time: 0:24:23.419845\n",
      "0.9458696\n",
      "[Epoch 16/50] [Batch 93/300] [D loss: 0.752851] [G loss: 0.585572] time: 0:24:23.730945\n",
      "0.9448573\n",
      "[Epoch 16/50] [Batch 94/300] [D loss: 0.752844] [G loss: 0.554527] time: 0:24:24.032901\n",
      "0.93316\n",
      "[Epoch 16/50] [Batch 95/300] [D loss: 0.752873] [G loss: 0.544159] time: 0:24:24.325594\n",
      "0.8984162\n",
      "[Epoch 16/50] [Batch 96/300] [D loss: 0.752854] [G loss: 0.552663] time: 0:24:24.637502\n",
      "0.93354696\n",
      "[Epoch 16/50] [Batch 97/300] [D loss: 0.752841] [G loss: 0.574450] time: 0:24:24.918809\n",
      "0.88585615\n",
      "[Epoch 16/50] [Batch 98/300] [D loss: 0.752845] [G loss: 0.553775] time: 0:24:25.220438\n",
      "0.9742666\n",
      "[Epoch 16/50] [Batch 99/300] [D loss: 0.752856] [G loss: 0.572362] time: 0:24:25.513867\n",
      "0.92793113\n",
      "[Epoch 16/50] [Batch 100/300] [D loss: 0.752857] [G loss: 0.563959] time: 0:24:25.795540\n",
      "0.93462664\n",
      "[Epoch 16/50] [Batch 101/300] [D loss: 0.752852] [G loss: 0.521594] time: 0:24:26.113832\n",
      "0.9809912\n",
      "[Epoch 16/50] [Batch 102/300] [D loss: 0.752866] [G loss: 0.585951] time: 0:24:26.419972\n",
      "0.89659625\n",
      "[Epoch 16/50] [Batch 103/300] [D loss: 0.752811] [G loss: 0.563107] time: 0:24:26.719659\n",
      "0.9343295\n",
      "[Epoch 16/50] [Batch 104/300] [D loss: 0.752892] [G loss: 0.568979] time: 0:24:27.035191\n",
      "0.8825106\n",
      "[Epoch 16/50] [Batch 105/300] [D loss: 0.752831] [G loss: 0.595328] time: 0:24:27.350534\n",
      "0.8965187\n",
      "[Epoch 16/50] [Batch 106/300] [D loss: 0.752829] [G loss: 0.542594] time: 0:24:27.661000\n",
      "0.92962295\n",
      "[Epoch 16/50] [Batch 107/300] [D loss: 0.752844] [G loss: 0.547801] time: 0:24:27.966190\n",
      "0.9319064\n",
      "[Epoch 16/50] [Batch 108/300] [D loss: 0.752824] [G loss: 0.569067] time: 0:24:28.254193\n",
      "0.94679976\n",
      "[Epoch 16/50] [Batch 109/300] [D loss: 0.752824] [G loss: 0.641942] time: 0:24:28.552109\n",
      "0.98356414\n",
      "[Epoch 16/50] [Batch 110/300] [D loss: 0.752833] [G loss: 0.553311] time: 0:24:28.865616\n",
      "0.9134095\n",
      "[Epoch 16/50] [Batch 111/300] [D loss: 0.752812] [G loss: 0.573218] time: 0:24:29.167890\n",
      "0.938682\n",
      "[Epoch 16/50] [Batch 112/300] [D loss: 0.752807] [G loss: 0.604722] time: 0:24:29.476033\n",
      "0.95188445\n",
      "[Epoch 16/50] [Batch 113/300] [D loss: 0.752885] [G loss: 0.579269] time: 0:24:29.778063\n",
      "0.93447787\n",
      "[Epoch 16/50] [Batch 114/300] [D loss: 0.752870] [G loss: 0.550915] time: 0:24:30.074907\n",
      "0.90647984\n",
      "[Epoch 16/50] [Batch 115/300] [D loss: 0.752833] [G loss: 0.566934] time: 0:24:30.368321\n",
      "0.8926911\n",
      "[Epoch 16/50] [Batch 116/300] [D loss: 0.752859] [G loss: 0.535993] time: 0:24:30.679094\n",
      "0.9302845\n",
      "[Epoch 16/50] [Batch 117/300] [D loss: 0.752830] [G loss: 0.576574] time: 0:24:30.986169\n",
      "0.9117026\n",
      "[Epoch 16/50] [Batch 118/300] [D loss: 0.752823] [G loss: 0.546074] time: 0:24:31.290182\n",
      "0.9804034\n",
      "[Epoch 16/50] [Batch 119/300] [D loss: 0.752847] [G loss: 0.579497] time: 0:24:31.595517\n",
      "0.92965955\n",
      "[Epoch 16/50] [Batch 120/300] [D loss: 0.752823] [G loss: 0.548831] time: 0:24:31.910120\n",
      "0.8862899\n",
      "[Epoch 16/50] [Batch 121/300] [D loss: 0.752863] [G loss: 0.560067] time: 0:24:32.218021\n",
      "0.93103343\n",
      "[Epoch 16/50] [Batch 122/300] [D loss: 0.752858] [G loss: 0.552675] time: 0:24:32.515499\n",
      "0.9119893\n",
      "[Epoch 16/50] [Batch 123/300] [D loss: 0.752859] [G loss: 0.609073] time: 0:24:32.824749\n",
      "0.9459037\n",
      "[Epoch 16/50] [Batch 124/300] [D loss: 0.752804] [G loss: 0.557782] time: 0:24:33.128797\n",
      "0.8970042\n",
      "[Epoch 16/50] [Batch 125/300] [D loss: 0.752826] [G loss: 0.596334] time: 0:24:33.444985\n",
      "0.9088828\n",
      "[Epoch 16/50] [Batch 126/300] [D loss: 0.752819] [G loss: 0.583749] time: 0:24:33.759604\n",
      "0.9342615\n",
      "[Epoch 16/50] [Batch 127/300] [D loss: 0.752833] [G loss: 0.542543] time: 0:24:34.070709\n",
      "0.9412071\n",
      "[Epoch 16/50] [Batch 128/300] [D loss: 0.752848] [G loss: 0.547951] time: 0:24:34.349903\n",
      "0.9066248\n",
      "[Epoch 16/50] [Batch 129/300] [D loss: 0.752857] [G loss: 0.557925] time: 0:24:34.661609\n",
      "0.9373126\n",
      "[Epoch 16/50] [Batch 130/300] [D loss: 0.752848] [G loss: 0.554591] time: 0:24:34.950167\n",
      "0.89137936\n",
      "[Epoch 16/50] [Batch 131/300] [D loss: 0.752831] [G loss: 0.581090] time: 0:24:35.258154\n",
      "0.94522613\n",
      "[Epoch 16/50] [Batch 132/300] [D loss: 0.752881] [G loss: 0.554591] time: 0:24:35.548809\n",
      "0.92383593\n",
      "[Epoch 16/50] [Batch 133/300] [D loss: 0.752849] [G loss: 0.593606] time: 0:24:35.833299\n",
      "0.94266105\n",
      "[Epoch 16/50] [Batch 134/300] [D loss: 0.752812] [G loss: 0.564208] time: 0:24:36.129382\n",
      "0.87116784\n",
      "[Epoch 16/50] [Batch 135/300] [D loss: 0.752837] [G loss: 0.556021] time: 0:24:36.428186\n",
      "0.94401056\n",
      "[Epoch 16/50] [Batch 136/300] [D loss: 0.752857] [G loss: 0.588463] time: 0:24:36.716434\n",
      "0.9139691\n",
      "[Epoch 16/50] [Batch 137/300] [D loss: 0.752830] [G loss: 0.553569] time: 0:24:37.021896\n",
      "0.93482643\n",
      "[Epoch 16/50] [Batch 138/300] [D loss: 0.752849] [G loss: 0.543730] time: 0:24:37.308385\n",
      "0.89075994\n",
      "[Epoch 16/50] [Batch 139/300] [D loss: 0.752837] [G loss: 0.571951] time: 0:24:37.601513\n",
      "0.88470745\n",
      "[Epoch 16/50] [Batch 140/300] [D loss: 0.752870] [G loss: 0.591577] time: 0:24:37.895936\n",
      "0.8958132\n",
      "[Epoch 16/50] [Batch 141/300] [D loss: 0.752819] [G loss: 0.563608] time: 0:24:38.205840\n",
      "0.8834961\n",
      "[Epoch 16/50] [Batch 142/300] [D loss: 0.752813] [G loss: 0.616116] time: 0:24:38.506222\n",
      "0.8995854\n",
      "[Epoch 16/50] [Batch 143/300] [D loss: 0.752844] [G loss: 0.531013] time: 0:24:38.813436\n",
      "0.93095607\n",
      "[Epoch 16/50] [Batch 144/300] [D loss: 0.752840] [G loss: 0.576379] time: 0:24:39.112034\n",
      "0.93974596\n",
      "[Epoch 16/50] [Batch 145/300] [D loss: 0.752836] [G loss: 0.578644] time: 0:24:39.392861\n",
      "0.9664305\n",
      "[Epoch 16/50] [Batch 146/300] [D loss: 0.752844] [G loss: 0.569475] time: 0:24:39.676966\n",
      "0.9080014\n",
      "[Epoch 16/50] [Batch 147/300] [D loss: 0.752858] [G loss: 0.558416] time: 0:24:39.987397\n",
      "0.88998204\n",
      "[Epoch 16/50] [Batch 148/300] [D loss: 0.752813] [G loss: 0.595833] time: 0:24:40.288286\n",
      "0.93082166\n",
      "[Epoch 16/50] [Batch 149/300] [D loss: 0.752819] [G loss: 0.595357] time: 0:24:40.586308\n",
      "0.9139536\n",
      "[Epoch 16/50] [Batch 150/300] [D loss: 0.752855] [G loss: 0.578877] time: 0:24:40.870079\n",
      "0.94662476\n",
      "[Epoch 16/50] [Batch 151/300] [D loss: 0.752827] [G loss: 0.577032] time: 0:24:41.166282\n",
      "0.91867214\n",
      "[Epoch 16/50] [Batch 152/300] [D loss: 0.752787] [G loss: 0.596735] time: 0:24:41.486636\n",
      "0.9196426\n",
      "[Epoch 16/50] [Batch 153/300] [D loss: 0.752862] [G loss: 0.603068] time: 0:24:41.780125\n",
      "0.94212\n",
      "[Epoch 16/50] [Batch 154/300] [D loss: 0.752861] [G loss: 0.539201] time: 0:24:42.079274\n",
      "0.9156249\n",
      "[Epoch 16/50] [Batch 155/300] [D loss: 0.752843] [G loss: 0.534143] time: 0:24:42.378225\n",
      "0.9361895\n",
      "[Epoch 16/50] [Batch 156/300] [D loss: 0.752852] [G loss: 0.570403] time: 0:24:42.689011\n",
      "0.90591604\n",
      "[Epoch 16/50] [Batch 157/300] [D loss: 0.752826] [G loss: 0.546113] time: 0:24:42.974544\n",
      "0.9833107\n",
      "[Epoch 16/50] [Batch 158/300] [D loss: 0.752843] [G loss: 0.610478] time: 0:24:43.267495\n",
      "0.91661626\n",
      "[Epoch 16/50] [Batch 159/300] [D loss: 0.752845] [G loss: 0.560568] time: 0:24:43.568493\n",
      "0.8852179\n",
      "[Epoch 16/50] [Batch 160/300] [D loss: 0.752846] [G loss: 0.545121] time: 0:24:43.867484\n",
      "0.9425517\n",
      "[Epoch 16/50] [Batch 161/300] [D loss: 0.752823] [G loss: 0.569284] time: 0:24:44.166899\n",
      "0.9398233\n",
      "[Epoch 16/50] [Batch 162/300] [D loss: 0.752831] [G loss: 0.581630] time: 0:24:44.466273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93580604\n",
      "[Epoch 16/50] [Batch 163/300] [D loss: 0.752824] [G loss: 0.556094] time: 0:24:44.764446\n",
      "0.95337963\n",
      "[Epoch 16/50] [Batch 164/300] [D loss: 0.752832] [G loss: 0.542466] time: 0:24:45.054711\n",
      "0.9267052\n",
      "[Epoch 16/50] [Batch 165/300] [D loss: 0.752835] [G loss: 0.553173] time: 0:24:45.341328\n",
      "0.9140048\n",
      "[Epoch 16/50] [Batch 166/300] [D loss: 0.752837] [G loss: 0.573123] time: 0:24:45.642592\n",
      "0.8809492\n",
      "[Epoch 16/50] [Batch 167/300] [D loss: 0.752826] [G loss: 0.562750] time: 0:24:45.941059\n",
      "0.91642165\n",
      "[Epoch 16/50] [Batch 168/300] [D loss: 0.752785] [G loss: 0.587655] time: 0:24:46.219114\n",
      "0.91800517\n",
      "[Epoch 16/50] [Batch 169/300] [D loss: 0.752855] [G loss: 0.552958] time: 0:24:46.527673\n",
      "0.9091646\n",
      "[Epoch 16/50] [Batch 170/300] [D loss: 0.752832] [G loss: 0.511875] time: 0:24:46.826808\n",
      "0.9141362\n",
      "[Epoch 16/50] [Batch 171/300] [D loss: 0.752866] [G loss: 0.547588] time: 0:24:47.130064\n",
      "0.9535792\n",
      "[Epoch 16/50] [Batch 172/300] [D loss: 0.752817] [G loss: 0.538118] time: 0:24:47.435400\n",
      "0.9106855\n",
      "[Epoch 16/50] [Batch 173/300] [D loss: 0.752854] [G loss: 0.516955] time: 0:24:47.737116\n",
      "0.93983084\n",
      "[Epoch 16/50] [Batch 174/300] [D loss: 0.752794] [G loss: 0.581380] time: 0:24:48.048134\n",
      "0.9341667\n",
      "[Epoch 16/50] [Batch 175/300] [D loss: 0.752838] [G loss: 0.542633] time: 0:24:48.361788\n",
      "0.9165049\n",
      "[Epoch 16/50] [Batch 176/300] [D loss: 0.752815] [G loss: 0.626765] time: 0:24:48.677280\n",
      "0.9707015\n",
      "[Epoch 16/50] [Batch 177/300] [D loss: 0.752835] [G loss: 0.594678] time: 0:24:48.973285\n",
      "0.9021852\n",
      "[Epoch 16/50] [Batch 178/300] [D loss: 0.752827] [G loss: 0.612328] time: 0:24:49.259945\n",
      "0.93676203\n",
      "[Epoch 16/50] [Batch 179/300] [D loss: 0.752847] [G loss: 0.522996] time: 0:24:49.580661\n",
      "0.94638234\n",
      "[Epoch 16/50] [Batch 180/300] [D loss: 0.752831] [G loss: 0.558638] time: 0:24:49.863919\n",
      "0.9233639\n",
      "[Epoch 16/50] [Batch 181/300] [D loss: 0.752830] [G loss: 0.516647] time: 0:24:50.171444\n",
      "0.888099\n",
      "[Epoch 16/50] [Batch 182/300] [D loss: 0.752835] [G loss: 0.529785] time: 0:24:50.465623\n",
      "0.9420901\n",
      "[Epoch 16/50] [Batch 183/300] [D loss: 0.752849] [G loss: 0.531417] time: 0:24:50.786586\n",
      "0.933119\n",
      "[Epoch 16/50] [Batch 184/300] [D loss: 0.752826] [G loss: 0.569080] time: 0:24:51.092900\n",
      "0.9363447\n",
      "[Epoch 16/50] [Batch 185/300] [D loss: 0.752845] [G loss: 0.517528] time: 0:24:51.372112\n",
      "0.9002163\n",
      "[Epoch 16/50] [Batch 186/300] [D loss: 0.752852] [G loss: 0.530143] time: 0:24:51.667615\n",
      "0.8977134\n",
      "[Epoch 16/50] [Batch 187/300] [D loss: 0.752817] [G loss: 0.511616] time: 0:24:51.968239\n",
      "0.877006\n",
      "[Epoch 16/50] [Batch 188/300] [D loss: 0.752813] [G loss: 0.575502] time: 0:24:52.272236\n",
      "0.9677253\n",
      "[Epoch 16/50] [Batch 189/300] [D loss: 0.752822] [G loss: 0.582935] time: 0:24:52.571894\n",
      "0.9245747\n",
      "[Epoch 16/50] [Batch 190/300] [D loss: 0.752823] [G loss: 0.542483] time: 0:24:52.861054\n",
      "0.9140448\n",
      "[Epoch 16/50] [Batch 191/300] [D loss: 0.752823] [G loss: 0.571567] time: 0:24:53.162940\n",
      "0.9441676\n",
      "[Epoch 16/50] [Batch 192/300] [D loss: 0.752816] [G loss: 0.556128] time: 0:24:53.463140\n",
      "0.9358945\n",
      "[Epoch 16/50] [Batch 193/300] [D loss: 0.752829] [G loss: 0.550350] time: 0:24:53.766186\n",
      "0.91715926\n",
      "[Epoch 16/50] [Batch 194/300] [D loss: 0.752799] [G loss: 0.557747] time: 0:24:54.066032\n",
      "0.93269724\n",
      "[Epoch 16/50] [Batch 195/300] [D loss: 0.752789] [G loss: 0.580354] time: 0:24:54.369342\n",
      "0.97712564\n",
      "[Epoch 16/50] [Batch 196/300] [D loss: 0.752848] [G loss: 0.573386] time: 0:24:54.672020\n",
      "0.9348201\n",
      "[Epoch 16/50] [Batch 197/300] [D loss: 0.752842] [G loss: 0.648533] time: 0:24:54.952900\n",
      "0.90211755\n",
      "[Epoch 16/50] [Batch 198/300] [D loss: 0.752848] [G loss: 0.543869] time: 0:24:55.244143\n",
      "0.93263817\n",
      "[Epoch 16/50] [Batch 199/300] [D loss: 0.752815] [G loss: 0.536921] time: 0:24:55.524337\n",
      "0.98298436\n",
      "[Epoch 16/50] [Batch 200/300] [D loss: 0.752810] [G loss: 0.546211] time: 0:24:55.810055\n",
      "0.9644735\n",
      "[Epoch 16/50] [Batch 201/300] [D loss: 0.752810] [G loss: 0.560796] time: 0:24:56.114553\n",
      "0.93168205\n",
      "[Epoch 16/50] [Batch 202/300] [D loss: 0.752793] [G loss: 0.572681] time: 0:24:56.409531\n",
      "0.93839765\n",
      "[Epoch 16/50] [Batch 203/300] [D loss: 0.752844] [G loss: 0.518682] time: 0:24:56.710273\n",
      "0.95910436\n",
      "[Epoch 16/50] [Batch 204/300] [D loss: 0.752792] [G loss: 0.597384] time: 0:24:57.013173\n",
      "0.91029054\n",
      "[Epoch 16/50] [Batch 205/300] [D loss: 0.752852] [G loss: 0.603359] time: 0:24:57.290563\n",
      "0.91494846\n",
      "[Epoch 16/50] [Batch 206/300] [D loss: 0.752814] [G loss: 0.557926] time: 0:24:57.593691\n",
      "0.9079607\n",
      "[Epoch 16/50] [Batch 207/300] [D loss: 0.752839] [G loss: 0.574201] time: 0:24:57.898121\n",
      "0.953464\n",
      "[Epoch 16/50] [Batch 208/300] [D loss: 0.752857] [G loss: 0.549393] time: 0:24:58.184200\n",
      "0.9107664\n",
      "[Epoch 16/50] [Batch 209/300] [D loss: 0.752830] [G loss: 0.639281] time: 0:24:58.482313\n",
      "0.9167397\n",
      "[Epoch 16/50] [Batch 210/300] [D loss: 0.752830] [G loss: 0.539697] time: 0:24:58.799629\n",
      "0.89174014\n",
      "[Epoch 16/50] [Batch 211/300] [D loss: 0.752808] [G loss: 0.577007] time: 0:24:59.103006\n",
      "0.9594899\n",
      "[Epoch 16/50] [Batch 212/300] [D loss: 0.752782] [G loss: 0.567097] time: 0:24:59.406357\n",
      "0.90837544\n",
      "[Epoch 16/50] [Batch 213/300] [D loss: 0.752815] [G loss: 0.559471] time: 0:24:59.706096\n",
      "0.884834\n",
      "[Epoch 16/50] [Batch 214/300] [D loss: 0.752799] [G loss: 0.560146] time: 0:25:00.017725\n",
      "0.87372255\n",
      "[Epoch 16/50] [Batch 215/300] [D loss: 0.752800] [G loss: 0.540496] time: 0:25:00.329900\n",
      "0.93012786\n",
      "[Epoch 16/50] [Batch 216/300] [D loss: 0.752798] [G loss: 0.529655] time: 0:25:00.647078\n",
      "0.97629833\n",
      "[Epoch 16/50] [Batch 217/300] [D loss: 0.752800] [G loss: 0.550968] time: 0:25:00.953601\n",
      "0.9090583\n",
      "[Epoch 16/50] [Batch 218/300] [D loss: 0.752826] [G loss: 0.588030] time: 0:25:01.258118\n",
      "0.9395464\n",
      "[Epoch 16/50] [Batch 219/300] [D loss: 0.752819] [G loss: 0.569503] time: 0:25:01.561492\n",
      "0.87474465\n",
      "[Epoch 16/50] [Batch 220/300] [D loss: 0.752817] [G loss: 0.602580] time: 0:25:01.866247\n",
      "0.9761822\n",
      "[Epoch 16/50] [Batch 221/300] [D loss: 0.752812] [G loss: 0.619032] time: 0:25:02.178288\n",
      "0.9080853\n",
      "[Epoch 16/50] [Batch 222/300] [D loss: 0.752818] [G loss: 0.585262] time: 0:25:02.489496\n",
      "0.9427607\n",
      "[Epoch 16/50] [Batch 223/300] [D loss: 0.752843] [G loss: 0.631737] time: 0:25:02.793390\n",
      "0.91566354\n",
      "[Epoch 16/50] [Batch 224/300] [D loss: 0.752839] [G loss: 0.567626] time: 0:25:03.088549\n",
      "0.90435654\n",
      "[Epoch 16/50] [Batch 225/300] [D loss: 0.752818] [G loss: 0.596746] time: 0:25:03.384797\n",
      "0.9180586\n",
      "[Epoch 16/50] [Batch 226/300] [D loss: 0.752833] [G loss: 0.538745] time: 0:25:03.691613\n",
      "0.96446323\n",
      "[Epoch 16/50] [Batch 227/300] [D loss: 0.752838] [G loss: 0.601330] time: 0:25:04.003141\n",
      "0.9162825\n",
      "[Epoch 16/50] [Batch 228/300] [D loss: 0.752816] [G loss: 0.618257] time: 0:25:04.292811\n",
      "0.91416436\n",
      "[Epoch 16/50] [Batch 229/300] [D loss: 0.752826] [G loss: 0.572440] time: 0:25:04.578708\n",
      "0.91569513\n",
      "[Epoch 16/50] [Batch 230/300] [D loss: 0.752843] [G loss: 0.526713] time: 0:25:04.856353\n",
      "0.9396019\n",
      "[Epoch 16/50] [Batch 231/300] [D loss: 0.752800] [G loss: 0.601832] time: 0:25:05.151852\n",
      "0.8985264\n",
      "[Epoch 16/50] [Batch 232/300] [D loss: 0.752825] [G loss: 0.547835] time: 0:25:05.442829\n",
      "0.85899454\n",
      "[Epoch 16/50] [Batch 233/300] [D loss: 0.752883] [G loss: 0.559546] time: 0:25:05.748437\n",
      "0.9142637\n",
      "[Epoch 16/50] [Batch 234/300] [D loss: 0.752836] [G loss: 0.567249] time: 0:25:06.039594\n",
      "0.9296243\n",
      "[Epoch 16/50] [Batch 235/300] [D loss: 0.752835] [G loss: 0.537603] time: 0:25:06.346138\n",
      "0.94614\n",
      "[Epoch 16/50] [Batch 236/300] [D loss: 0.752800] [G loss: 0.542079] time: 0:25:06.652750\n",
      "0.89209986\n",
      "[Epoch 16/50] [Batch 237/300] [D loss: 0.752797] [G loss: 0.574327] time: 0:25:06.954620\n",
      "0.8841736\n",
      "[Epoch 16/50] [Batch 238/300] [D loss: 0.752800] [G loss: 0.589418] time: 0:25:07.263879\n",
      "0.9235011\n",
      "[Epoch 16/50] [Batch 239/300] [D loss: 0.752805] [G loss: 0.546234] time: 0:25:07.556147\n",
      "0.91855866\n",
      "[Epoch 16/50] [Batch 240/300] [D loss: 0.752799] [G loss: 0.579531] time: 0:25:07.831254\n",
      "0.9457495\n",
      "[Epoch 16/50] [Batch 241/300] [D loss: 0.752809] [G loss: 0.597835] time: 0:25:08.137342\n",
      "0.9059875\n",
      "[Epoch 16/50] [Batch 242/300] [D loss: 0.752888] [G loss: 0.520640] time: 0:25:08.442189\n",
      "0.9385956\n",
      "[Epoch 16/50] [Batch 243/300] [D loss: 0.752786] [G loss: 0.595764] time: 0:25:08.714660\n",
      "0.8966069\n",
      "[Epoch 16/50] [Batch 244/300] [D loss: 0.752808] [G loss: 0.569835] time: 0:25:09.013229\n",
      "0.9069454\n",
      "[Epoch 16/50] [Batch 245/300] [D loss: 0.752831] [G loss: 0.564666] time: 0:25:09.306204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88515943\n",
      "[Epoch 16/50] [Batch 246/300] [D loss: 0.752809] [G loss: 0.553770] time: 0:25:09.615868\n",
      "0.9317792\n",
      "[Epoch 16/50] [Batch 247/300] [D loss: 0.752778] [G loss: 0.588626] time: 0:25:09.916197\n",
      "0.86435986\n",
      "[Epoch 16/50] [Batch 248/300] [D loss: 0.752772] [G loss: 0.645010] time: 0:25:10.212155\n",
      "0.9473121\n",
      "[Epoch 16/50] [Batch 249/300] [D loss: 0.752815] [G loss: 0.622562] time: 0:25:10.523249\n",
      "0.9375763\n",
      "[Epoch 16/50] [Batch 250/300] [D loss: 0.752788] [G loss: 0.559944] time: 0:25:10.840395\n",
      "0.87689996\n",
      "[Epoch 16/50] [Batch 251/300] [D loss: 0.752810] [G loss: 0.553708] time: 0:25:11.153068\n",
      "0.9210101\n",
      "[Epoch 16/50] [Batch 252/300] [D loss: 0.752780] [G loss: 0.561672] time: 0:25:11.465756\n",
      "0.9379432\n",
      "[Epoch 16/50] [Batch 253/300] [D loss: 0.752827] [G loss: 0.636423] time: 0:25:11.770882\n",
      "0.93312985\n",
      "[Epoch 16/50] [Batch 254/300] [D loss: 0.752848] [G loss: 0.513075] time: 0:25:12.071414\n",
      "0.9466775\n",
      "[Epoch 16/50] [Batch 255/300] [D loss: 0.752790] [G loss: 0.577142] time: 0:25:12.378267\n",
      "0.9254668\n",
      "[Epoch 16/50] [Batch 256/300] [D loss: 0.752816] [G loss: 0.578088] time: 0:25:12.677392\n",
      "0.9142619\n",
      "[Epoch 16/50] [Batch 257/300] [D loss: 0.752796] [G loss: 0.652922] time: 0:25:12.995987\n",
      "0.9450875\n",
      "[Epoch 16/50] [Batch 258/300] [D loss: 0.752809] [G loss: 0.530489] time: 0:25:13.289296\n",
      "0.8928215\n",
      "[Epoch 16/50] [Batch 259/300] [D loss: 0.752820] [G loss: 0.571398] time: 0:25:13.591037\n",
      "0.9164495\n",
      "[Epoch 16/50] [Batch 260/300] [D loss: 0.752793] [G loss: 0.551913] time: 0:25:13.892700\n",
      "0.95220596\n",
      "[Epoch 16/50] [Batch 261/300] [D loss: 0.752823] [G loss: 0.567080] time: 0:25:14.200022\n",
      "0.93563896\n",
      "[Epoch 16/50] [Batch 262/300] [D loss: 0.752779] [G loss: 0.540218] time: 0:25:14.500153\n",
      "0.937169\n",
      "[Epoch 16/50] [Batch 263/300] [D loss: 0.752811] [G loss: 0.572753] time: 0:25:14.798049\n",
      "0.9319558\n",
      "[Epoch 16/50] [Batch 264/300] [D loss: 0.752844] [G loss: 0.547133] time: 0:25:15.087074\n",
      "0.97603446\n",
      "[Epoch 16/50] [Batch 265/300] [D loss: 0.752829] [G loss: 0.553728] time: 0:25:15.390482\n",
      "0.9150543\n",
      "[Epoch 16/50] [Batch 266/300] [D loss: 0.752814] [G loss: 0.613544] time: 0:25:15.701641\n",
      "0.94370365\n",
      "[Epoch 16/50] [Batch 267/300] [D loss: 0.752838] [G loss: 0.550100] time: 0:25:15.997157\n",
      "0.8898329\n",
      "[Epoch 16/50] [Batch 268/300] [D loss: 0.752778] [G loss: 0.533561] time: 0:25:16.286798\n",
      "0.94734305\n",
      "[Epoch 16/50] [Batch 269/300] [D loss: 0.752811] [G loss: 0.539490] time: 0:25:16.567236\n",
      "0.9431533\n",
      "[Epoch 16/50] [Batch 270/300] [D loss: 0.752806] [G loss: 0.541087] time: 0:25:16.869993\n",
      "0.9264865\n",
      "[Epoch 16/50] [Batch 271/300] [D loss: 0.752801] [G loss: 0.592303] time: 0:25:17.153992\n",
      "0.9075064\n",
      "[Epoch 16/50] [Batch 272/300] [D loss: 0.752797] [G loss: 0.570078] time: 0:25:17.440470\n",
      "0.9663568\n",
      "[Epoch 16/50] [Batch 273/300] [D loss: 0.752812] [G loss: 0.543110] time: 0:25:17.729544\n",
      "0.88298607\n",
      "[Epoch 16/50] [Batch 274/300] [D loss: 0.752813] [G loss: 0.567817] time: 0:25:18.047772\n",
      "0.92851144\n",
      "[Epoch 16/50] [Batch 275/300] [D loss: 0.752797] [G loss: 0.615104] time: 0:25:18.334857\n",
      "0.90634173\n",
      "[Epoch 16/50] [Batch 276/300] [D loss: 0.752828] [G loss: 0.562794] time: 0:25:18.641250\n",
      "0.9126443\n",
      "[Epoch 16/50] [Batch 277/300] [D loss: 0.752794] [G loss: 0.591284] time: 0:25:18.936823\n",
      "0.8579163\n",
      "[Epoch 16/50] [Batch 278/300] [D loss: 0.752801] [G loss: 0.614185] time: 0:25:19.231145\n",
      "0.9010539\n",
      "[Epoch 16/50] [Batch 279/300] [D loss: 0.752818] [G loss: 0.585124] time: 0:25:19.534022\n",
      "0.8908274\n",
      "[Epoch 16/50] [Batch 280/300] [D loss: 0.752819] [G loss: 0.605907] time: 0:25:19.803825\n",
      "0.88562816\n",
      "[Epoch 16/50] [Batch 281/300] [D loss: 0.752818] [G loss: 0.563852] time: 0:25:20.100555\n",
      "0.91567105\n",
      "[Epoch 16/50] [Batch 282/300] [D loss: 0.752805] [G loss: 0.552387] time: 0:25:20.409779\n",
      "0.93992203\n",
      "[Epoch 16/50] [Batch 283/300] [D loss: 0.752804] [G loss: 0.543910] time: 0:25:20.712682\n",
      "0.8897732\n",
      "[Epoch 16/50] [Batch 284/300] [D loss: 0.752824] [G loss: 0.552172] time: 0:25:21.013976\n",
      "0.9116096\n",
      "[Epoch 16/50] [Batch 285/300] [D loss: 0.752785] [G loss: 0.618631] time: 0:25:21.300735\n",
      "0.90872145\n",
      "[Epoch 16/50] [Batch 286/300] [D loss: 0.752778] [G loss: 0.565404] time: 0:25:21.599258\n",
      "0.8953457\n",
      "[Epoch 16/50] [Batch 287/300] [D loss: 0.752796] [G loss: 0.555351] time: 0:25:21.907359\n",
      "0.933337\n",
      "[Epoch 16/50] [Batch 288/300] [D loss: 0.752778] [G loss: 0.516698] time: 0:25:22.210966\n",
      "0.91040283\n",
      "[Epoch 16/50] [Batch 289/300] [D loss: 0.752828] [G loss: 0.541041] time: 0:25:22.519144\n",
      "0.9444449\n",
      "[Epoch 16/50] [Batch 290/300] [D loss: 0.752821] [G loss: 0.553133] time: 0:25:22.816432\n",
      "0.9350028\n",
      "[Epoch 16/50] [Batch 291/300] [D loss: 0.752859] [G loss: 0.546538] time: 0:25:23.123084\n",
      "0.960015\n",
      "[Epoch 16/50] [Batch 292/300] [D loss: 0.752802] [G loss: 0.590298] time: 0:25:23.428236\n",
      "0.9410302\n",
      "[Epoch 16/50] [Batch 293/300] [D loss: 0.752802] [G loss: 0.552910] time: 0:25:23.726787\n",
      "0.9463722\n",
      "[Epoch 16/50] [Batch 294/300] [D loss: 0.752817] [G loss: 0.543576] time: 0:25:24.021732\n",
      "0.951562\n",
      "[Epoch 16/50] [Batch 295/300] [D loss: 0.752824] [G loss: 0.565142] time: 0:25:24.308471\n",
      "0.9461326\n",
      "[Epoch 16/50] [Batch 296/300] [D loss: 0.752812] [G loss: 0.514113] time: 0:25:24.609913\n",
      "0.9333823\n",
      "[Epoch 16/50] [Batch 297/300] [D loss: 0.752801] [G loss: 0.564955] time: 0:25:24.914201\n",
      "0.9086334\n",
      "[Epoch 16/50] [Batch 298/300] [D loss: 0.752796] [G loss: 0.572957] time: 0:25:25.214462\n",
      "0.9196386\n",
      "[Epoch 16/50] [Batch 299/300] [D loss: 0.752814] [G loss: 0.549003] time: 0:25:25.507010\n",
      "0.91203785\n",
      "[Epoch 17/50] [Batch 0/300] [D loss: 0.752773] [G loss: 0.551295] time: 0:25:25.807700\n",
      "0.8961937\n",
      "[Epoch 17/50] [Batch 1/300] [D loss: 0.752815] [G loss: 0.606309] time: 0:25:26.118180\n",
      "0.91735834\n",
      "[Epoch 17/50] [Batch 2/300] [D loss: 0.752828] [G loss: 0.530582] time: 0:25:26.405358\n",
      "0.9391622\n",
      "[Epoch 17/50] [Batch 3/300] [D loss: 0.752812] [G loss: 0.530454] time: 0:25:26.706865\n",
      "0.8795251\n",
      "[Epoch 17/50] [Batch 4/300] [D loss: 0.752808] [G loss: 0.576848] time: 0:25:27.005050\n",
      "0.9251755\n",
      "[Epoch 17/50] [Batch 5/300] [D loss: 0.752802] [G loss: 0.543909] time: 0:25:27.304574\n",
      "0.9227278\n",
      "[Epoch 17/50] [Batch 6/300] [D loss: 0.752815] [G loss: 0.561939] time: 0:25:27.610589\n",
      "0.9166693\n",
      "[Epoch 17/50] [Batch 7/300] [D loss: 0.752796] [G loss: 0.584141] time: 0:25:27.908566\n",
      "0.91207385\n",
      "[Epoch 17/50] [Batch 8/300] [D loss: 0.752818] [G loss: 0.616436] time: 0:25:28.226259\n",
      "0.92664474\n",
      "[Epoch 17/50] [Batch 9/300] [D loss: 0.752801] [G loss: 0.579922] time: 0:25:28.522631\n",
      "0.91781074\n",
      "[Epoch 17/50] [Batch 10/300] [D loss: 0.752784] [G loss: 0.546562] time: 0:25:28.826126\n",
      "0.9441083\n",
      "[Epoch 17/50] [Batch 11/300] [D loss: 0.752781] [G loss: 0.545396] time: 0:25:29.119132\n",
      "0.9311275\n",
      "[Epoch 17/50] [Batch 12/300] [D loss: 0.752772] [G loss: 0.572164] time: 0:25:29.416612\n",
      "0.905237\n",
      "[Epoch 17/50] [Batch 13/300] [D loss: 0.752842] [G loss: 0.540538] time: 0:25:29.725632\n",
      "0.95697445\n",
      "[Epoch 17/50] [Batch 14/300] [D loss: 0.752769] [G loss: 0.543886] time: 0:25:30.032690\n",
      "0.9534912\n",
      "[Epoch 17/50] [Batch 15/300] [D loss: 0.752787] [G loss: 0.560349] time: 0:25:30.345754\n",
      "0.9265039\n",
      "[Epoch 17/50] [Batch 17/300] [D loss: 0.752814] [G loss: 0.550066] time: 0:25:30.644651\n",
      "0.9118336\n",
      "[Epoch 17/50] [Batch 18/300] [D loss: 0.752773] [G loss: 0.588985] time: 0:25:30.950815\n",
      "0.8955764\n",
      "[Epoch 17/50] [Batch 19/300] [D loss: 0.752798] [G loss: 0.580962] time: 0:25:31.252853\n",
      "0.9098733\n",
      "[Epoch 17/50] [Batch 20/300] [D loss: 0.752805] [G loss: 0.549936] time: 0:25:31.558252\n",
      "0.90637654\n",
      "[Epoch 17/50] [Batch 21/300] [D loss: 0.752866] [G loss: 0.527037] time: 0:25:31.863471\n",
      "0.9082907\n",
      "[Epoch 17/50] [Batch 22/300] [D loss: 0.752776] [G loss: 0.526073] time: 0:25:32.157741\n",
      "0.96304035\n",
      "[Epoch 17/50] [Batch 23/300] [D loss: 0.752788] [G loss: 0.546616] time: 0:25:32.480261\n",
      "0.9096654\n",
      "[Epoch 17/50] [Batch 24/300] [D loss: 0.752762] [G loss: 0.566194] time: 0:25:32.798071\n",
      "0.91188616\n",
      "[Epoch 17/50] [Batch 25/300] [D loss: 0.752810] [G loss: 0.543116] time: 0:25:33.097140\n",
      "0.9340951\n",
      "[Epoch 17/50] [Batch 26/300] [D loss: 0.752764] [G loss: 0.578170] time: 0:25:33.417284\n",
      "0.94092625\n",
      "[Epoch 17/50] [Batch 27/300] [D loss: 0.752839] [G loss: 0.515796] time: 0:25:33.716288\n",
      "0.9118106\n",
      "[Epoch 17/50] [Batch 28/300] [D loss: 0.752793] [G loss: 0.539023] time: 0:25:34.003484\n",
      "0.91336465\n",
      "[Epoch 17/50] [Batch 29/300] [D loss: 0.752837] [G loss: 0.513587] time: 0:25:34.302353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90324783\n",
      "[Epoch 17/50] [Batch 30/300] [D loss: 0.752790] [G loss: 0.558268] time: 0:25:34.591060\n",
      "0.92716306\n",
      "[Epoch 17/50] [Batch 31/300] [D loss: 0.752809] [G loss: 0.518144] time: 0:25:34.902987\n",
      "0.94290274\n",
      "[Epoch 17/50] [Batch 32/300] [D loss: 0.752820] [G loss: 0.536074] time: 0:25:35.206560\n",
      "0.95541954\n",
      "[Epoch 17/50] [Batch 33/300] [D loss: 0.752796] [G loss: 0.592223] time: 0:25:35.519379\n",
      "0.97147924\n",
      "[Epoch 17/50] [Batch 34/300] [D loss: 0.752793] [G loss: 0.535227] time: 0:25:35.821144\n",
      "0.9166934\n",
      "[Epoch 17/50] [Batch 35/300] [D loss: 0.752785] [G loss: 0.591527] time: 0:25:36.112256\n",
      "0.88629866\n",
      "[Epoch 17/50] [Batch 36/300] [D loss: 0.752812] [G loss: 0.508488] time: 0:25:36.425135\n",
      "0.9839711\n",
      "[Epoch 17/50] [Batch 37/300] [D loss: 0.752782] [G loss: 0.549346] time: 0:25:36.740585\n",
      "0.8989845\n",
      "[Epoch 17/50] [Batch 38/300] [D loss: 0.752759] [G loss: 0.530306] time: 0:25:37.052330\n",
      "0.8828156\n",
      "[Epoch 17/50] [Batch 39/300] [D loss: 0.752817] [G loss: 0.532224] time: 0:25:37.363210\n",
      "0.9542648\n",
      "[Epoch 17/50] [Batch 40/300] [D loss: 0.752787] [G loss: 0.546938] time: 0:25:37.666390\n",
      "0.95389295\n",
      "[Epoch 17/50] [Batch 41/300] [D loss: 0.752779] [G loss: 0.568347] time: 0:25:37.972262\n",
      "0.96423656\n",
      "[Epoch 17/50] [Batch 42/300] [D loss: 0.752807] [G loss: 0.566537] time: 0:25:38.275104\n",
      "0.9358859\n",
      "[Epoch 17/50] [Batch 43/300] [D loss: 0.752755] [G loss: 0.574887] time: 0:25:38.583387\n",
      "0.91569185\n",
      "[Epoch 17/50] [Batch 44/300] [D loss: 0.752778] [G loss: 0.525156] time: 0:25:38.848132\n",
      "0.9185576\n",
      "[Epoch 17/50] [Batch 45/300] [D loss: 0.752791] [G loss: 0.531529] time: 0:25:39.159573\n",
      "0.95623773\n",
      "[Epoch 17/50] [Batch 46/300] [D loss: 0.752790] [G loss: 0.524317] time: 0:25:39.474038\n",
      "0.9144404\n",
      "[Epoch 17/50] [Batch 47/300] [D loss: 0.752789] [G loss: 0.537124] time: 0:25:39.784359\n",
      "0.94233245\n",
      "[Epoch 17/50] [Batch 48/300] [D loss: 0.752812] [G loss: 0.547254] time: 0:25:40.084129\n",
      "0.98207617\n",
      "[Epoch 17/50] [Batch 49/300] [D loss: 0.752807] [G loss: 0.514482] time: 0:25:40.384051\n",
      "0.95185214\n",
      "[Epoch 17/50] [Batch 50/300] [D loss: 0.752796] [G loss: 0.545889] time: 0:25:40.697776\n",
      "0.8853114\n",
      "[Epoch 17/50] [Batch 51/300] [D loss: 0.752806] [G loss: 0.541757] time: 0:25:41.019771\n",
      "0.9558045\n",
      "[Epoch 17/50] [Batch 52/300] [D loss: 0.752786] [G loss: 0.551634] time: 0:25:41.324050\n",
      "0.91365355\n",
      "[Epoch 17/50] [Batch 53/300] [D loss: 0.752797] [G loss: 0.510292] time: 0:25:41.623108\n",
      "0.9460589\n",
      "[Epoch 17/50] [Batch 54/300] [D loss: 0.752776] [G loss: 0.547903] time: 0:25:41.926097\n",
      "0.9214967\n",
      "[Epoch 17/50] [Batch 55/300] [D loss: 0.752799] [G loss: 0.567586] time: 0:25:42.218249\n",
      "0.9289152\n",
      "[Epoch 17/50] [Batch 56/300] [D loss: 0.752754] [G loss: 0.588173] time: 0:25:42.513406\n",
      "0.9763499\n",
      "[Epoch 17/50] [Batch 57/300] [D loss: 0.752822] [G loss: 0.537337] time: 0:25:42.847437\n",
      "0.9476309\n",
      "[Epoch 17/50] [Batch 58/300] [D loss: 0.752813] [G loss: 0.567796] time: 0:25:43.156171\n",
      "0.87865573\n",
      "[Epoch 17/50] [Batch 59/300] [D loss: 0.752802] [G loss: 0.518849] time: 0:25:43.451026\n",
      "0.8960839\n",
      "[Epoch 17/50] [Batch 60/300] [D loss: 0.752819] [G loss: 0.544167] time: 0:25:43.744782\n",
      "0.91689616\n",
      "[Epoch 17/50] [Batch 61/300] [D loss: 0.752770] [G loss: 0.572459] time: 0:25:44.046743\n",
      "0.9137165\n",
      "[Epoch 17/50] [Batch 62/300] [D loss: 0.752797] [G loss: 0.560384] time: 0:25:44.348832\n",
      "0.9343812\n",
      "[Epoch 17/50] [Batch 63/300] [D loss: 0.752799] [G loss: 0.568326] time: 0:25:44.646492\n",
      "0.9813578\n",
      "[Epoch 17/50] [Batch 64/300] [D loss: 0.752779] [G loss: 0.528733] time: 0:25:44.955050\n",
      "0.9142179\n",
      "[Epoch 17/50] [Batch 65/300] [D loss: 0.752776] [G loss: 0.593018] time: 0:25:45.235424\n",
      "0.88827085\n",
      "[Epoch 17/50] [Batch 66/300] [D loss: 0.752790] [G loss: 0.546627] time: 0:25:45.518193\n",
      "0.9475944\n",
      "[Epoch 17/50] [Batch 67/300] [D loss: 0.752781] [G loss: 0.546358] time: 0:25:45.834830\n",
      "0.9717023\n",
      "[Epoch 17/50] [Batch 68/300] [D loss: 0.752805] [G loss: 0.554664] time: 0:25:46.135584\n",
      "0.94023323\n",
      "[Epoch 17/50] [Batch 69/300] [D loss: 0.752762] [G loss: 0.557931] time: 0:25:46.429848\n",
      "0.9287782\n",
      "[Epoch 17/50] [Batch 70/300] [D loss: 0.752769] [G loss: 0.528957] time: 0:25:46.729666\n",
      "0.91371536\n",
      "[Epoch 17/50] [Batch 71/300] [D loss: 0.752760] [G loss: 0.554724] time: 0:25:47.034654\n",
      "0.9826278\n",
      "[Epoch 17/50] [Batch 72/300] [D loss: 0.752771] [G loss: 0.561356] time: 0:25:47.314653\n",
      "0.9445374\n",
      "[Epoch 17/50] [Batch 73/300] [D loss: 0.752770] [G loss: 0.547436] time: 0:25:47.617801\n",
      "0.9462125\n",
      "[Epoch 17/50] [Batch 74/300] [D loss: 0.752780] [G loss: 0.563513] time: 0:25:47.900172\n",
      "0.93462497\n",
      "[Epoch 17/50] [Batch 75/300] [D loss: 0.752787] [G loss: 0.521907] time: 0:25:48.188854\n",
      "0.9396998\n",
      "[Epoch 17/50] [Batch 76/300] [D loss: 0.752808] [G loss: 0.545655] time: 0:25:48.509088\n",
      "0.90571755\n",
      "[Epoch 17/50] [Batch 77/300] [D loss: 0.752784] [G loss: 0.562361] time: 0:25:48.775032\n",
      "0.9167349\n",
      "[Epoch 17/50] [Batch 78/300] [D loss: 0.752797] [G loss: 0.570028] time: 0:25:49.058977\n",
      "0.9747832\n",
      "[Epoch 17/50] [Batch 79/300] [D loss: 0.752746] [G loss: 0.568005] time: 0:25:49.379728\n",
      "0.9529725\n",
      "[Epoch 17/50] [Batch 80/300] [D loss: 0.752814] [G loss: 0.541479] time: 0:25:49.681055\n",
      "0.9418507\n",
      "[Epoch 17/50] [Batch 81/300] [D loss: 0.752774] [G loss: 0.536497] time: 0:25:49.990123\n",
      "0.92161673\n",
      "[Epoch 17/50] [Batch 82/300] [D loss: 0.752785] [G loss: 0.554694] time: 0:25:50.302159\n",
      "0.9704619\n",
      "[Epoch 17/50] [Batch 83/300] [D loss: 0.752797] [G loss: 0.547243] time: 0:25:50.597018\n",
      "0.9447661\n",
      "[Epoch 17/50] [Batch 84/300] [D loss: 0.752796] [G loss: 0.512945] time: 0:25:50.885727\n",
      "0.9349837\n",
      "[Epoch 17/50] [Batch 85/300] [D loss: 0.752786] [G loss: 0.511061] time: 0:25:51.169304\n",
      "0.9349696\n",
      "[Epoch 17/50] [Batch 86/300] [D loss: 0.752774] [G loss: 0.538829] time: 0:25:51.456093\n",
      "0.8956392\n",
      "[Epoch 17/50] [Batch 87/300] [D loss: 0.752789] [G loss: 0.569330] time: 0:25:51.756850\n",
      "0.93186134\n",
      "[Epoch 17/50] [Batch 88/300] [D loss: 0.752794] [G loss: 0.531489] time: 0:25:52.034648\n",
      "0.9281394\n",
      "[Epoch 17/50] [Batch 89/300] [D loss: 0.752769] [G loss: 0.522329] time: 0:25:52.324312\n",
      "0.93396956\n",
      "[Epoch 17/50] [Batch 90/300] [D loss: 0.752778] [G loss: 0.558587] time: 0:25:52.627964\n",
      "0.93644476\n",
      "[Epoch 17/50] [Batch 91/300] [D loss: 0.752763] [G loss: 0.512068] time: 0:25:52.947567\n",
      "0.9731863\n",
      "[Epoch 17/50] [Batch 92/300] [D loss: 0.752795] [G loss: 0.560639] time: 0:25:53.253772\n",
      "0.9079196\n",
      "[Epoch 17/50] [Batch 93/300] [D loss: 0.752778] [G loss: 0.546610] time: 0:25:53.561973\n",
      "0.90390414\n",
      "[Epoch 17/50] [Batch 94/300] [D loss: 0.752790] [G loss: 0.547032] time: 0:25:53.871699\n",
      "0.87575597\n",
      "[Epoch 17/50] [Batch 95/300] [D loss: 0.752794] [G loss: 0.558536] time: 0:25:54.166041\n",
      "0.9446582\n",
      "[Epoch 17/50] [Batch 96/300] [D loss: 0.752812] [G loss: 0.554154] time: 0:25:54.476994\n",
      "0.91767126\n",
      "[Epoch 17/50] [Batch 97/300] [D loss: 0.752779] [G loss: 0.593820] time: 0:25:54.806474\n",
      "0.8963421\n",
      "[Epoch 17/50] [Batch 98/300] [D loss: 0.752799] [G loss: 0.566537] time: 0:25:55.246700\n",
      "0.97102827\n",
      "[Epoch 17/50] [Batch 99/300] [D loss: 0.752747] [G loss: 0.532093] time: 0:25:55.544825\n",
      "0.9091089\n",
      "[Epoch 17/50] [Batch 100/300] [D loss: 0.752794] [G loss: 0.631956] time: 0:25:55.836641\n",
      "0.888391\n",
      "[Epoch 17/50] [Batch 101/300] [D loss: 0.752792] [G loss: 0.540663] time: 0:25:56.135980\n",
      "0.9110194\n",
      "[Epoch 17/50] [Batch 102/300] [D loss: 0.752784] [G loss: 0.585232] time: 0:25:56.435506\n",
      "0.9272788\n",
      "[Epoch 17/50] [Batch 103/300] [D loss: 0.752774] [G loss: 0.510497] time: 0:25:56.727849\n",
      "0.9331699\n",
      "[Epoch 17/50] [Batch 104/300] [D loss: 0.752785] [G loss: 0.543344] time: 0:25:57.035057\n",
      "0.9039672\n",
      "[Epoch 17/50] [Batch 105/300] [D loss: 0.752788] [G loss: 0.588392] time: 0:25:57.322373\n",
      "0.92966723\n",
      "[Epoch 17/50] [Batch 106/300] [D loss: 0.752799] [G loss: 0.555742] time: 0:25:57.608091\n",
      "0.8905384\n",
      "[Epoch 17/50] [Batch 107/300] [D loss: 0.752793] [G loss: 0.555438] time: 0:25:57.897357\n",
      "0.88140947\n",
      "[Epoch 17/50] [Batch 108/300] [D loss: 0.752758] [G loss: 0.516036] time: 0:25:58.194255\n",
      "0.92870957\n",
      "[Epoch 17/50] [Batch 109/300] [D loss: 0.752782] [G loss: 0.507919] time: 0:25:58.492171\n",
      "0.9356406\n",
      "[Epoch 17/50] [Batch 110/300] [D loss: 0.752781] [G loss: 0.593862] time: 0:25:58.786707\n",
      "0.9008935\n",
      "[Epoch 17/50] [Batch 111/300] [D loss: 0.752803] [G loss: 0.573670] time: 0:25:59.093711\n",
      "0.9471336\n",
      "[Epoch 17/50] [Batch 112/300] [D loss: 0.752796] [G loss: 0.553500] time: 0:25:59.408586\n",
      "0.9138818\n",
      "[Epoch 17/50] [Batch 113/300] [D loss: 0.752786] [G loss: 0.584920] time: 0:25:59.702536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93318623\n",
      "[Epoch 17/50] [Batch 114/300] [D loss: 0.752780] [G loss: 0.543720] time: 0:25:59.999509\n",
      "0.9081997\n",
      "[Epoch 17/50] [Batch 115/300] [D loss: 0.752801] [G loss: 0.543629] time: 0:26:00.310134\n",
      "0.9348944\n",
      "[Epoch 17/50] [Batch 116/300] [D loss: 0.752783] [G loss: 0.588276] time: 0:26:00.607820\n",
      "0.91414285\n",
      "[Epoch 17/50] [Batch 117/300] [D loss: 0.752764] [G loss: 0.545916] time: 0:26:00.914507\n",
      "0.9354574\n",
      "[Epoch 17/50] [Batch 118/300] [D loss: 0.752746] [G loss: 0.614954] time: 0:26:01.215144\n",
      "0.96101046\n",
      "[Epoch 17/50] [Batch 119/300] [D loss: 0.752790] [G loss: 0.524877] time: 0:26:01.514581\n",
      "0.93316436\n",
      "[Epoch 17/50] [Batch 120/300] [D loss: 0.752786] [G loss: 0.591967] time: 0:26:01.801737\n",
      "0.9350583\n",
      "[Epoch 17/50] [Batch 121/300] [D loss: 0.752779] [G loss: 0.550649] time: 0:26:02.101854\n",
      "0.96605486\n",
      "[Epoch 17/50] [Batch 122/300] [D loss: 0.752795] [G loss: 0.548490] time: 0:26:02.424608\n",
      "0.9047038\n",
      "[Epoch 17/50] [Batch 123/300] [D loss: 0.752816] [G loss: 0.551248] time: 0:26:02.717449\n",
      "0.97618335\n",
      "[Epoch 17/50] [Batch 124/300] [D loss: 0.752794] [G loss: 0.551593] time: 0:26:03.020185\n",
      "0.9117338\n",
      "[Epoch 17/50] [Batch 125/300] [D loss: 0.752779] [G loss: 0.516417] time: 0:26:03.305019\n",
      "0.9241812\n",
      "[Epoch 17/50] [Batch 126/300] [D loss: 0.752813] [G loss: 0.538883] time: 0:26:03.605073\n",
      "0.9495128\n",
      "[Epoch 17/50] [Batch 127/300] [D loss: 0.752753] [G loss: 0.521617] time: 0:26:03.900240\n",
      "0.94055873\n",
      "[Epoch 17/50] [Batch 128/300] [D loss: 0.752799] [G loss: 0.572418] time: 0:26:04.182094\n",
      "0.9157408\n",
      "[Epoch 17/50] [Batch 129/300] [D loss: 0.752786] [G loss: 0.536319] time: 0:26:04.473366\n",
      "0.953535\n",
      "[Epoch 17/50] [Batch 130/300] [D loss: 0.752759] [G loss: 0.577421] time: 0:26:04.768450\n",
      "0.8923292\n",
      "[Epoch 17/50] [Batch 131/300] [D loss: 0.752770] [G loss: 0.559525] time: 0:26:05.057346\n",
      "0.91728616\n",
      "[Epoch 17/50] [Batch 132/300] [D loss: 0.752744] [G loss: 0.583644] time: 0:26:05.353026\n",
      "0.8951843\n",
      "[Epoch 17/50] [Batch 133/300] [D loss: 0.752753] [G loss: 0.551132] time: 0:26:05.651618\n",
      "0.9165697\n",
      "[Epoch 17/50] [Batch 134/300] [D loss: 0.752801] [G loss: 0.564819] time: 0:26:05.956147\n",
      "0.92934734\n",
      "[Epoch 17/50] [Batch 135/300] [D loss: 0.752762] [G loss: 0.549626] time: 0:26:06.241493\n",
      "0.971276\n",
      "[Epoch 17/50] [Batch 136/300] [D loss: 0.752805] [G loss: 0.524456] time: 0:26:06.529297\n",
      "0.9241953\n",
      "[Epoch 17/50] [Batch 137/300] [D loss: 0.752793] [G loss: 0.595190] time: 0:26:06.839491\n",
      "0.8815212\n",
      "[Epoch 17/50] [Batch 138/300] [D loss: 0.752808] [G loss: 0.551788] time: 0:26:07.113607\n",
      "0.9373699\n",
      "[Epoch 17/50] [Batch 139/300] [D loss: 0.752764] [G loss: 0.528457] time: 0:26:07.427641\n",
      "0.9517618\n",
      "[Epoch 17/50] [Batch 140/300] [D loss: 0.752764] [G loss: 0.528380] time: 0:26:07.717651\n",
      "0.93909866\n",
      "[Epoch 17/50] [Batch 141/300] [D loss: 0.752739] [G loss: 0.534126] time: 0:26:08.021965\n",
      "0.8988083\n",
      "[Epoch 17/50] [Batch 142/300] [D loss: 0.752737] [G loss: 0.617480] time: 0:26:08.318973\n",
      "0.94459695\n",
      "[Epoch 17/50] [Batch 143/300] [D loss: 0.752764] [G loss: 0.539652] time: 0:26:08.616199\n",
      "0.9089093\n",
      "[Epoch 17/50] [Batch 144/300] [D loss: 0.752759] [G loss: 0.533875] time: 0:26:08.915390\n",
      "0.9460125\n",
      "[Epoch 17/50] [Batch 145/300] [D loss: 0.752786] [G loss: 0.565093] time: 0:26:09.223007\n",
      "0.90512997\n",
      "[Epoch 17/50] [Batch 146/300] [D loss: 0.752784] [G loss: 0.588388] time: 0:26:09.529369\n",
      "0.87737465\n",
      "[Epoch 17/50] [Batch 147/300] [D loss: 0.752762] [G loss: 0.591950] time: 0:26:09.829933\n",
      "0.94387656\n",
      "[Epoch 17/50] [Batch 148/300] [D loss: 0.752788] [G loss: 0.538540] time: 0:26:10.132096\n",
      "0.95644253\n",
      "[Epoch 17/50] [Batch 149/300] [D loss: 0.752796] [G loss: 0.566173] time: 0:26:10.424126\n",
      "0.8963227\n",
      "[Epoch 17/50] [Batch 150/300] [D loss: 0.752790] [G loss: 0.572499] time: 0:26:10.702986\n",
      "0.9079053\n",
      "[Epoch 17/50] [Batch 151/300] [D loss: 0.752770] [G loss: 0.534027] time: 0:26:10.997663\n",
      "0.91972774\n",
      "[Epoch 17/50] [Batch 152/300] [D loss: 0.752773] [G loss: 0.508598] time: 0:26:11.306578\n",
      "0.9754918\n",
      "[Epoch 17/50] [Batch 153/300] [D loss: 0.752776] [G loss: 0.572042] time: 0:26:11.583845\n",
      "0.93126076\n",
      "[Epoch 17/50] [Batch 154/300] [D loss: 0.752760] [G loss: 0.540714] time: 0:26:11.884896\n",
      "0.89641047\n",
      "[Epoch 17/50] [Batch 155/300] [D loss: 0.752795] [G loss: 0.541913] time: 0:26:12.198293\n",
      "0.9488023\n",
      "[Epoch 17/50] [Batch 156/300] [D loss: 0.752810] [G loss: 0.595075] time: 0:26:12.500228\n",
      "0.96952945\n",
      "[Epoch 17/50] [Batch 157/300] [D loss: 0.752800] [G loss: 0.560023] time: 0:26:12.814418\n",
      "0.9423993\n",
      "[Epoch 17/50] [Batch 158/300] [D loss: 0.752759] [G loss: 0.556528] time: 0:26:13.106691\n",
      "0.9355051\n",
      "[Epoch 17/50] [Batch 159/300] [D loss: 0.752802] [G loss: 0.513207] time: 0:26:13.428114\n",
      "0.9758565\n",
      "[Epoch 17/50] [Batch 160/300] [D loss: 0.752791] [G loss: 0.559320] time: 0:26:13.729095\n",
      "0.90643305\n",
      "[Epoch 17/50] [Batch 161/300] [D loss: 0.752765] [G loss: 0.551697] time: 0:26:14.012019\n",
      "0.9078524\n",
      "[Epoch 17/50] [Batch 162/300] [D loss: 0.752776] [G loss: 0.533223] time: 0:26:14.310043\n",
      "0.9375158\n",
      "[Epoch 17/50] [Batch 163/300] [D loss: 0.752769] [G loss: 0.514811] time: 0:26:14.597135\n",
      "0.90759563\n",
      "[Epoch 17/50] [Batch 164/300] [D loss: 0.752792] [G loss: 0.549603] time: 0:26:14.894242\n",
      "0.9713287\n",
      "[Epoch 17/50] [Batch 165/300] [D loss: 0.752788] [G loss: 0.576593] time: 0:26:15.185587\n",
      "0.9635191\n",
      "[Epoch 17/50] [Batch 166/300] [D loss: 0.752781] [G loss: 0.559363] time: 0:26:15.473456\n",
      "0.9429075\n",
      "[Epoch 17/50] [Batch 167/300] [D loss: 0.752763] [G loss: 0.509673] time: 0:26:15.790059\n",
      "0.9463224\n",
      "[Epoch 17/50] [Batch 168/300] [D loss: 0.752782] [G loss: 0.568865] time: 0:26:16.088425\n",
      "0.96468425\n",
      "[Epoch 17/50] [Batch 169/300] [D loss: 0.752791] [G loss: 0.510634] time: 0:26:16.375245\n",
      "0.9380173\n",
      "[Epoch 17/50] [Batch 170/300] [D loss: 0.752784] [G loss: 0.568781] time: 0:26:16.669651\n",
      "0.9040933\n",
      "[Epoch 17/50] [Batch 171/300] [D loss: 0.752756] [G loss: 0.561629] time: 0:26:16.956851\n",
      "0.89062405\n",
      "[Epoch 17/50] [Batch 172/300] [D loss: 0.752777] [G loss: 0.570135] time: 0:26:17.279068\n",
      "0.88734037\n",
      "[Epoch 17/50] [Batch 173/300] [D loss: 0.752751] [G loss: 0.592853] time: 0:26:17.566540\n",
      "0.9380493\n",
      "[Epoch 17/50] [Batch 174/300] [D loss: 0.752766] [G loss: 0.600865] time: 0:26:17.887944\n",
      "0.8768036\n",
      "[Epoch 17/50] [Batch 175/300] [D loss: 0.752768] [G loss: 0.552526] time: 0:26:18.187949\n",
      "0.9262793\n",
      "[Epoch 17/50] [Batch 176/300] [D loss: 0.752771] [G loss: 0.547803] time: 0:26:18.477258\n",
      "0.9204805\n",
      "[Epoch 17/50] [Batch 177/300] [D loss: 0.752751] [G loss: 0.582354] time: 0:26:18.780906\n",
      "0.9456107\n",
      "[Epoch 17/50] [Batch 178/300] [D loss: 0.752781] [G loss: 0.535455] time: 0:26:19.081771\n",
      "0.9090059\n",
      "[Epoch 17/50] [Batch 179/300] [D loss: 0.752764] [G loss: 0.597932] time: 0:26:19.365454\n",
      "0.9383796\n",
      "[Epoch 17/50] [Batch 180/300] [D loss: 0.752768] [G loss: 0.540527] time: 0:26:19.651379\n",
      "0.8986342\n",
      "[Epoch 17/50] [Batch 181/300] [D loss: 0.752751] [G loss: 0.520872] time: 0:26:19.940014\n",
      "0.91416067\n",
      "[Epoch 17/50] [Batch 182/300] [D loss: 0.752743] [G loss: 0.593440] time: 0:26:20.249679\n",
      "0.8984511\n",
      "[Epoch 17/50] [Batch 183/300] [D loss: 0.752799] [G loss: 0.522151] time: 0:26:20.521076\n",
      "0.90417475\n",
      "[Epoch 17/50] [Batch 184/300] [D loss: 0.752747] [G loss: 0.545529] time: 0:26:20.798450\n",
      "0.93677443\n",
      "[Epoch 17/50] [Batch 185/300] [D loss: 0.752777] [G loss: 0.569949] time: 0:26:21.084262\n",
      "0.9341543\n",
      "[Epoch 17/50] [Batch 186/300] [D loss: 0.752741] [G loss: 0.569076] time: 0:26:21.377090\n",
      "0.9143713\n",
      "[Epoch 17/50] [Batch 187/300] [D loss: 0.752731] [G loss: 0.562834] time: 0:26:21.675380\n",
      "0.93611664\n",
      "[Epoch 17/50] [Batch 188/300] [D loss: 0.752759] [G loss: 0.524886] time: 0:26:21.950423\n",
      "0.9595576\n",
      "[Epoch 17/50] [Batch 189/300] [D loss: 0.752768] [G loss: 0.548464] time: 0:26:22.251857\n",
      "0.884124\n",
      "[Epoch 17/50] [Batch 190/300] [D loss: 0.752760] [G loss: 0.549655] time: 0:26:22.543973\n",
      "0.93318886\n",
      "[Epoch 17/50] [Batch 191/300] [D loss: 0.752775] [G loss: 0.597524] time: 0:26:22.837202\n",
      "0.9391064\n",
      "[Epoch 17/50] [Batch 192/300] [D loss: 0.752755] [G loss: 0.572556] time: 0:26:23.158085\n",
      "0.9450097\n",
      "[Epoch 17/50] [Batch 193/300] [D loss: 0.752775] [G loss: 0.565714] time: 0:26:23.470832\n",
      "0.9412236\n",
      "[Epoch 17/50] [Batch 194/300] [D loss: 0.752788] [G loss: 0.556770] time: 0:26:23.755679\n",
      "0.9525245\n",
      "[Epoch 17/50] [Batch 195/300] [D loss: 0.752778] [G loss: 0.575935] time: 0:26:24.052613\n",
      "0.88291454\n",
      "[Epoch 17/50] [Batch 196/300] [D loss: 0.752760] [G loss: 0.550464] time: 0:26:24.343564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9063511\n",
      "[Epoch 17/50] [Batch 197/300] [D loss: 0.752755] [G loss: 0.574074] time: 0:26:24.657611\n",
      "0.9207948\n",
      "[Epoch 17/50] [Batch 198/300] [D loss: 0.752772] [G loss: 0.554005] time: 0:26:24.966707\n",
      "0.9156206\n",
      "[Epoch 17/50] [Batch 199/300] [D loss: 0.752750] [G loss: 0.600527] time: 0:26:25.246930\n",
      "0.9456782\n",
      "[Epoch 17/50] [Batch 200/300] [D loss: 0.752763] [G loss: 0.563892] time: 0:26:25.534213\n",
      "0.9320738\n",
      "[Epoch 17/50] [Batch 201/300] [D loss: 0.752778] [G loss: 0.573895] time: 0:26:25.826911\n",
      "0.8939164\n",
      "[Epoch 17/50] [Batch 202/300] [D loss: 0.752759] [G loss: 0.608559] time: 0:26:26.130989\n",
      "0.93356913\n",
      "[Epoch 17/50] [Batch 203/300] [D loss: 0.752771] [G loss: 0.534998] time: 0:26:26.429417\n",
      "0.89176863\n",
      "[Epoch 17/50] [Batch 204/300] [D loss: 0.752761] [G loss: 0.523092] time: 0:26:26.723954\n",
      "0.90968305\n",
      "[Epoch 17/50] [Batch 205/300] [D loss: 0.752775] [G loss: 0.616510] time: 0:26:27.041801\n",
      "0.908143\n",
      "[Epoch 17/50] [Batch 206/300] [D loss: 0.752746] [G loss: 0.525594] time: 0:26:27.336489\n",
      "0.9676867\n",
      "[Epoch 17/50] [Batch 207/300] [D loss: 0.752749] [G loss: 0.554862] time: 0:26:27.620460\n",
      "0.9668433\n",
      "[Epoch 17/50] [Batch 208/300] [D loss: 0.752761] [G loss: 0.558637] time: 0:26:27.924532\n",
      "0.88482046\n",
      "[Epoch 17/50] [Batch 209/300] [D loss: 0.752779] [G loss: 0.556894] time: 0:26:28.217366\n",
      "0.8755676\n",
      "[Epoch 17/50] [Batch 210/300] [D loss: 0.752788] [G loss: 0.519137] time: 0:26:28.513062\n",
      "0.89798576\n",
      "[Epoch 17/50] [Batch 211/300] [D loss: 0.752726] [G loss: 0.532233] time: 0:26:28.815094\n",
      "0.8487521\n",
      "[Epoch 17/50] [Batch 212/300] [D loss: 0.752768] [G loss: 0.571060] time: 0:26:29.108326\n",
      "0.90193367\n",
      "[Epoch 17/50] [Batch 213/300] [D loss: 0.752763] [G loss: 0.580300] time: 0:26:29.412795\n",
      "0.93748146\n",
      "[Epoch 17/50] [Batch 214/300] [D loss: 0.752733] [G loss: 0.614392] time: 0:26:29.714386\n",
      "0.94548815\n",
      "[Epoch 17/50] [Batch 215/300] [D loss: 0.752761] [G loss: 0.510384] time: 0:26:30.011684\n",
      "0.9140401\n",
      "[Epoch 17/50] [Batch 216/300] [D loss: 0.752770] [G loss: 0.541456] time: 0:26:30.284857\n",
      "0.8980364\n",
      "[Epoch 17/50] [Batch 217/300] [D loss: 0.752765] [G loss: 0.579314] time: 0:26:30.584299\n",
      "0.90482813\n",
      "[Epoch 17/50] [Batch 218/300] [D loss: 0.752771] [G loss: 0.526520] time: 0:26:30.877662\n",
      "0.90545225\n",
      "[Epoch 17/50] [Batch 219/300] [D loss: 0.752762] [G loss: 0.571427] time: 0:26:31.167425\n",
      "0.91673523\n",
      "[Epoch 17/50] [Batch 220/300] [D loss: 0.752759] [G loss: 0.635863] time: 0:26:31.474618\n",
      "0.9308334\n",
      "[Epoch 17/50] [Batch 221/300] [D loss: 0.752755] [G loss: 0.607338] time: 0:26:31.771433\n",
      "0.9082934\n",
      "[Epoch 17/50] [Batch 222/300] [D loss: 0.752777] [G loss: 0.554072] time: 0:26:32.073333\n",
      "0.9422922\n",
      "[Epoch 17/50] [Batch 223/300] [D loss: 0.752732] [G loss: 0.549957] time: 0:26:32.364896\n",
      "0.881511\n",
      "[Epoch 17/50] [Batch 224/300] [D loss: 0.752759] [G loss: 0.554396] time: 0:26:32.654903\n",
      "0.90280515\n",
      "[Epoch 17/50] [Batch 225/300] [D loss: 0.752731] [G loss: 0.577004] time: 0:26:32.964629\n",
      "0.91285634\n",
      "[Epoch 17/50] [Batch 226/300] [D loss: 0.752768] [G loss: 0.561844] time: 0:26:33.259232\n",
      "0.9458416\n",
      "[Epoch 17/50] [Batch 227/300] [D loss: 0.752779] [G loss: 0.562945] time: 0:26:33.537275\n",
      "0.89229673\n",
      "[Epoch 17/50] [Batch 228/300] [D loss: 0.752722] [G loss: 0.569203] time: 0:26:33.837281\n",
      "0.9436152\n",
      "[Epoch 17/50] [Batch 229/300] [D loss: 0.752748] [G loss: 0.583118] time: 0:26:34.138462\n",
      "0.9432159\n",
      "[Epoch 17/50] [Batch 230/300] [D loss: 0.752740] [G loss: 0.551531] time: 0:26:34.410957\n",
      "0.88248205\n",
      "[Epoch 17/50] [Batch 231/300] [D loss: 0.752773] [G loss: 0.611369] time: 0:26:34.717560\n",
      "0.9025288\n",
      "[Epoch 17/50] [Batch 232/300] [D loss: 0.752734] [G loss: 0.571361] time: 0:26:35.001490\n",
      "0.949573\n",
      "[Epoch 17/50] [Batch 233/300] [D loss: 0.752755] [G loss: 0.566988] time: 0:26:35.290346\n",
      "0.9119002\n",
      "[Epoch 17/50] [Batch 234/300] [D loss: 0.752749] [G loss: 0.531959] time: 0:26:35.581688\n",
      "0.8882401\n",
      "[Epoch 17/50] [Batch 235/300] [D loss: 0.752750] [G loss: 0.586098] time: 0:26:35.887724\n",
      "0.94298726\n",
      "[Epoch 17/50] [Batch 236/300] [D loss: 0.752747] [G loss: 0.559149] time: 0:26:36.187615\n",
      "0.94258696\n",
      "[Epoch 17/50] [Batch 237/300] [D loss: 0.752750] [G loss: 0.593752] time: 0:26:36.489118\n",
      "0.91896766\n",
      "[Epoch 17/50] [Batch 238/300] [D loss: 0.752759] [G loss: 0.556945] time: 0:26:36.770561\n",
      "0.90924615\n",
      "[Epoch 17/50] [Batch 239/300] [D loss: 0.752743] [G loss: 0.564547] time: 0:26:37.073177\n",
      "0.87481815\n",
      "[Epoch 17/50] [Batch 240/300] [D loss: 0.752779] [G loss: 0.552392] time: 0:26:37.376442\n",
      "0.8818297\n",
      "[Epoch 17/50] [Batch 241/300] [D loss: 0.752764] [G loss: 0.535890] time: 0:26:37.683285\n",
      "0.93976337\n",
      "[Epoch 17/50] [Batch 242/300] [D loss: 0.752765] [G loss: 0.586295] time: 0:26:37.978185\n",
      "0.9505889\n",
      "[Epoch 17/50] [Batch 243/300] [D loss: 0.752773] [G loss: 0.550150] time: 0:26:38.270544\n",
      "0.90246636\n",
      "[Epoch 17/50] [Batch 244/300] [D loss: 0.752713] [G loss: 0.544357] time: 0:26:38.542476\n",
      "0.9154036\n",
      "[Epoch 17/50] [Batch 245/300] [D loss: 0.752794] [G loss: 0.565028] time: 0:26:38.839746\n",
      "0.866214\n",
      "[Epoch 17/50] [Batch 246/300] [D loss: 0.752762] [G loss: 0.574273] time: 0:26:39.134549\n",
      "0.95004755\n",
      "[Epoch 17/50] [Batch 247/300] [D loss: 0.752774] [G loss: 0.562999] time: 0:26:39.434532\n",
      "0.9067721\n",
      "[Epoch 17/50] [Batch 248/300] [D loss: 0.752752] [G loss: 0.604141] time: 0:26:39.723051\n",
      "0.9165468\n",
      "[Epoch 17/50] [Batch 249/300] [D loss: 0.752745] [G loss: 0.564146] time: 0:26:40.003318\n",
      "0.9075508\n",
      "[Epoch 17/50] [Batch 250/300] [D loss: 0.752751] [G loss: 0.564982] time: 0:26:40.300674\n",
      "0.94699264\n",
      "[Epoch 17/50] [Batch 251/300] [D loss: 0.752760] [G loss: 0.579651] time: 0:26:40.585108\n",
      "0.9429286\n",
      "[Epoch 17/50] [Batch 252/300] [D loss: 0.752783] [G loss: 0.531053] time: 0:26:40.882636\n",
      "0.9118211\n",
      "[Epoch 17/50] [Batch 253/300] [D loss: 0.752746] [G loss: 0.528705] time: 0:26:41.201059\n",
      "0.8679474\n",
      "[Epoch 17/50] [Batch 254/300] [D loss: 0.752744] [G loss: 0.579947] time: 0:26:41.497607\n",
      "0.89198154\n",
      "[Epoch 17/50] [Batch 255/300] [D loss: 0.752759] [G loss: 0.526808] time: 0:26:41.805794\n",
      "0.93513745\n",
      "[Epoch 17/50] [Batch 256/300] [D loss: 0.752753] [G loss: 0.561898] time: 0:26:42.113972\n",
      "0.9263222\n",
      "[Epoch 17/50] [Batch 257/300] [D loss: 0.752782] [G loss: 0.560982] time: 0:26:42.405515\n",
      "0.91457397\n",
      "[Epoch 17/50] [Batch 258/300] [D loss: 0.752782] [G loss: 0.528317] time: 0:26:42.719555\n",
      "0.9029607\n",
      "[Epoch 17/50] [Batch 259/300] [D loss: 0.752759] [G loss: 0.529068] time: 0:26:43.025261\n",
      "0.9201174\n",
      "[Epoch 17/50] [Batch 260/300] [D loss: 0.752735] [G loss: 0.527408] time: 0:26:43.335716\n",
      "0.9355319\n",
      "[Epoch 17/50] [Batch 261/300] [D loss: 0.752763] [G loss: 0.563130] time: 0:26:43.644001\n",
      "0.9080763\n",
      "[Epoch 17/50] [Batch 262/300] [D loss: 0.752752] [G loss: 0.543244] time: 0:26:43.952135\n",
      "0.93309516\n",
      "[Epoch 17/50] [Batch 263/300] [D loss: 0.752781] [G loss: 0.544097] time: 0:26:44.259194\n",
      "0.9256039\n",
      "[Epoch 17/50] [Batch 264/300] [D loss: 0.752750] [G loss: 0.528460] time: 0:26:44.561156\n",
      "0.8978923\n",
      "[Epoch 17/50] [Batch 265/300] [D loss: 0.752762] [G loss: 0.514966] time: 0:26:44.857134\n",
      "0.83385974\n",
      "[Epoch 17/50] [Batch 266/300] [D loss: 0.752771] [G loss: 0.580471] time: 0:26:45.171810\n",
      "0.9755928\n",
      "[Epoch 17/50] [Batch 267/300] [D loss: 0.752766] [G loss: 0.523260] time: 0:26:45.474287\n",
      "0.94598645\n",
      "[Epoch 17/50] [Batch 268/300] [D loss: 0.752767] [G loss: 0.582166] time: 0:26:45.747722\n",
      "0.9384815\n",
      "[Epoch 17/50] [Batch 269/300] [D loss: 0.752757] [G loss: 0.555205] time: 0:26:46.052944\n",
      "0.9524521\n",
      "[Epoch 17/50] [Batch 270/300] [D loss: 0.752747] [G loss: 0.542787] time: 0:26:46.366276\n",
      "0.9709694\n",
      "[Epoch 17/50] [Batch 271/300] [D loss: 0.752719] [G loss: 0.526361] time: 0:26:46.682225\n",
      "0.913829\n",
      "[Epoch 17/50] [Batch 272/300] [D loss: 0.752755] [G loss: 0.554368] time: 0:26:46.980293\n",
      "0.87457347\n",
      "[Epoch 17/50] [Batch 273/300] [D loss: 0.752737] [G loss: 0.567425] time: 0:26:47.272803\n",
      "0.93628424\n",
      "[Epoch 17/50] [Batch 274/300] [D loss: 0.752719] [G loss: 0.547756] time: 0:26:47.576856\n",
      "0.8962758\n",
      "[Epoch 17/50] [Batch 275/300] [D loss: 0.752748] [G loss: 0.551859] time: 0:26:47.873433\n",
      "0.93163556\n",
      "[Epoch 17/50] [Batch 276/300] [D loss: 0.752773] [G loss: 0.576124] time: 0:26:48.153665\n",
      "0.92179924\n",
      "[Epoch 17/50] [Batch 277/300] [D loss: 0.752760] [G loss: 0.539084] time: 0:26:48.426931\n",
      "0.98355293\n",
      "[Epoch 17/50] [Batch 278/300] [D loss: 0.752785] [G loss: 0.595556] time: 0:26:48.723711\n",
      "0.8923895\n",
      "[Epoch 17/50] [Batch 279/300] [D loss: 0.752740] [G loss: 0.533677] time: 0:26:49.018876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8759349\n",
      "[Epoch 17/50] [Batch 280/300] [D loss: 0.752737] [G loss: 0.547597] time: 0:26:49.325390\n",
      "0.91750664\n",
      "[Epoch 17/50] [Batch 281/300] [D loss: 0.752746] [G loss: 0.521286] time: 0:26:49.622712\n",
      "0.9002196\n",
      "[Epoch 17/50] [Batch 282/300] [D loss: 0.752753] [G loss: 0.543298] time: 0:26:49.928716\n",
      "0.89995986\n",
      "[Epoch 17/50] [Batch 283/300] [D loss: 0.752756] [G loss: 0.552266] time: 0:26:50.243262\n",
      "0.94984204\n",
      "[Epoch 17/50] [Batch 284/300] [D loss: 0.752759] [G loss: 0.565496] time: 0:26:50.542212\n",
      "0.9200523\n",
      "[Epoch 17/50] [Batch 285/300] [D loss: 0.752744] [G loss: 0.536021] time: 0:26:50.843081\n",
      "0.93131584\n",
      "[Epoch 17/50] [Batch 286/300] [D loss: 0.752755] [G loss: 0.538942] time: 0:26:51.144798\n",
      "0.8805364\n",
      "[Epoch 17/50] [Batch 287/300] [D loss: 0.752745] [G loss: 0.536296] time: 0:26:51.455554\n",
      "0.93810296\n",
      "[Epoch 17/50] [Batch 288/300] [D loss: 0.752759] [G loss: 0.562048] time: 0:26:51.741315\n",
      "0.8963237\n",
      "[Epoch 17/50] [Batch 289/300] [D loss: 0.752724] [G loss: 0.573871] time: 0:26:52.034140\n",
      "0.8851132\n",
      "[Epoch 17/50] [Batch 290/300] [D loss: 0.752752] [G loss: 0.580988] time: 0:26:52.333445\n",
      "0.92402405\n",
      "[Epoch 17/50] [Batch 291/300] [D loss: 0.752764] [G loss: 0.569859] time: 0:26:52.603926\n",
      "0.9393258\n",
      "[Epoch 17/50] [Batch 292/300] [D loss: 0.752732] [G loss: 0.548243] time: 0:26:52.880635\n",
      "0.9094303\n",
      "[Epoch 17/50] [Batch 293/300] [D loss: 0.752803] [G loss: 0.513756] time: 0:26:53.204144\n",
      "0.9478001\n",
      "[Epoch 17/50] [Batch 294/300] [D loss: 0.752771] [G loss: 0.585583] time: 0:26:53.505832\n",
      "0.91501456\n",
      "[Epoch 17/50] [Batch 295/300] [D loss: 0.752759] [G loss: 0.530737] time: 0:26:53.801384\n",
      "0.92369825\n",
      "[Epoch 17/50] [Batch 296/300] [D loss: 0.752805] [G loss: 0.560641] time: 0:26:54.102507\n",
      "0.8891179\n",
      "[Epoch 17/50] [Batch 297/300] [D loss: 0.752741] [G loss: 0.541539] time: 0:26:54.409911\n",
      "0.92669153\n",
      "[Epoch 17/50] [Batch 298/300] [D loss: 0.752760] [G loss: 0.541545] time: 0:26:54.688468\n",
      "0.8993239\n",
      "[Epoch 17/50] [Batch 299/300] [D loss: 0.752762] [G loss: 0.588075] time: 0:26:55.000022\n",
      "0.90750664\n",
      "[Epoch 18/50] [Batch 0/300] [D loss: 0.752750] [G loss: 0.546835] time: 0:26:55.286610\n",
      "0.9295222\n",
      "[Epoch 18/50] [Batch 1/300] [D loss: 0.752783] [G loss: 0.582234] time: 0:26:55.595722\n",
      "0.9532283\n",
      "[Epoch 18/50] [Batch 2/300] [D loss: 0.752712] [G loss: 0.586440] time: 0:26:55.894531\n",
      "0.98145795\n",
      "[Epoch 18/50] [Batch 3/300] [D loss: 0.752748] [G loss: 0.557959] time: 0:26:56.213289\n",
      "0.8894083\n",
      "[Epoch 18/50] [Batch 4/300] [D loss: 0.752754] [G loss: 0.550083] time: 0:26:56.502885\n",
      "0.91637355\n",
      "[Epoch 18/50] [Batch 5/300] [D loss: 0.752735] [G loss: 0.599503] time: 0:26:56.806277\n",
      "0.9332561\n",
      "[Epoch 18/50] [Batch 6/300] [D loss: 0.752728] [G loss: 0.580662] time: 0:26:57.108355\n",
      "0.91030884\n",
      "[Epoch 18/50] [Batch 7/300] [D loss: 0.752782] [G loss: 0.579423] time: 0:26:57.418014\n",
      "0.95042324\n",
      "[Epoch 18/50] [Batch 8/300] [D loss: 0.752723] [G loss: 0.588187] time: 0:26:57.737408\n",
      "0.9076562\n",
      "[Epoch 18/50] [Batch 9/300] [D loss: 0.752744] [G loss: 0.576496] time: 0:26:58.035260\n",
      "0.90621394\n",
      "[Epoch 18/50] [Batch 10/300] [D loss: 0.752733] [G loss: 0.614483] time: 0:26:58.333242\n",
      "0.90565777\n",
      "[Epoch 18/50] [Batch 11/300] [D loss: 0.752724] [G loss: 0.583140] time: 0:26:58.628275\n",
      "0.93405247\n",
      "[Epoch 18/50] [Batch 12/300] [D loss: 0.752749] [G loss: 0.544304] time: 0:26:58.946370\n",
      "0.87904745\n",
      "[Epoch 18/50] [Batch 13/300] [D loss: 0.752748] [G loss: 0.586178] time: 0:26:59.249295\n",
      "0.9023798\n",
      "[Epoch 18/50] [Batch 14/300] [D loss: 0.752722] [G loss: 0.564729] time: 0:26:59.550179\n",
      "0.9324978\n",
      "[Epoch 18/50] [Batch 15/300] [D loss: 0.752726] [G loss: 0.530019] time: 0:26:59.841417\n",
      "0.9130048\n",
      "[Epoch 18/50] [Batch 16/300] [D loss: 0.752770] [G loss: 0.534136] time: 0:27:00.145867\n",
      "0.9321273\n",
      "[Epoch 18/50] [Batch 18/300] [D loss: 0.752710] [G loss: 0.534514] time: 0:27:00.450208\n",
      "0.91191745\n",
      "[Epoch 18/50] [Batch 19/300] [D loss: 0.752729] [G loss: 0.509430] time: 0:27:00.748175\n",
      "0.94840056\n",
      "[Epoch 18/50] [Batch 20/300] [D loss: 0.752732] [G loss: 0.544952] time: 0:27:01.037883\n",
      "0.94782114\n",
      "[Epoch 18/50] [Batch 21/300] [D loss: 0.752725] [G loss: 0.512167] time: 0:27:01.342908\n",
      "0.9286986\n",
      "[Epoch 18/50] [Batch 22/300] [D loss: 0.752723] [G loss: 0.544700] time: 0:27:01.643326\n",
      "0.9317296\n",
      "[Epoch 18/50] [Batch 23/300] [D loss: 0.752722] [G loss: 0.508512] time: 0:27:01.944726\n",
      "0.95411867\n",
      "[Epoch 18/50] [Batch 24/300] [D loss: 0.752700] [G loss: 0.539617] time: 0:27:02.226776\n",
      "0.9404478\n",
      "[Epoch 18/50] [Batch 25/300] [D loss: 0.752743] [G loss: 0.525877] time: 0:27:02.513911\n",
      "0.9449684\n",
      "[Epoch 18/50] [Batch 26/300] [D loss: 0.752740] [G loss: 0.535012] time: 0:27:02.808634\n",
      "0.915828\n",
      "[Epoch 18/50] [Batch 27/300] [D loss: 0.752735] [G loss: 0.520731] time: 0:27:03.107535\n",
      "0.94268227\n",
      "[Epoch 18/50] [Batch 28/300] [D loss: 0.752751] [G loss: 0.570236] time: 0:27:03.424631\n",
      "0.9112285\n",
      "[Epoch 18/50] [Batch 29/300] [D loss: 0.752706] [G loss: 0.562479] time: 0:27:03.718578\n",
      "0.93598205\n",
      "[Epoch 18/50] [Batch 30/300] [D loss: 0.752728] [G loss: 0.557937] time: 0:27:04.016912\n",
      "0.9134667\n",
      "[Epoch 18/50] [Batch 31/300] [D loss: 0.752753] [G loss: 0.544178] time: 0:27:04.313622\n",
      "0.9458356\n",
      "[Epoch 18/50] [Batch 32/300] [D loss: 0.752709] [G loss: 0.544011] time: 0:27:04.606748\n",
      "0.9448848\n",
      "[Epoch 18/50] [Batch 33/300] [D loss: 0.752755] [G loss: 0.540281] time: 0:27:04.913205\n",
      "0.9175124\n",
      "[Epoch 18/50] [Batch 34/300] [D loss: 0.752715] [G loss: 0.581474] time: 0:27:05.203015\n",
      "0.92801243\n",
      "[Epoch 18/50] [Batch 35/300] [D loss: 0.752722] [G loss: 0.508705] time: 0:27:05.504519\n",
      "0.96934813\n",
      "[Epoch 18/50] [Batch 36/300] [D loss: 0.752718] [G loss: 0.548035] time: 0:27:05.791486\n",
      "0.94249916\n",
      "[Epoch 18/50] [Batch 37/300] [D loss: 0.752750] [G loss: 0.507363] time: 0:27:06.054129\n",
      "0.97141653\n",
      "[Epoch 18/50] [Batch 38/300] [D loss: 0.752771] [G loss: 0.521028] time: 0:27:06.362266\n",
      "0.9085675\n",
      "[Epoch 18/50] [Batch 39/300] [D loss: 0.752760] [G loss: 0.601190] time: 0:27:06.658875\n",
      "0.962774\n",
      "[Epoch 18/50] [Batch 40/300] [D loss: 0.752779] [G loss: 0.580417] time: 0:27:06.943539\n",
      "0.8876322\n",
      "[Epoch 18/50] [Batch 41/300] [D loss: 0.752735] [G loss: 0.508787] time: 0:27:07.244303\n",
      "0.89913917\n",
      "[Epoch 18/50] [Batch 42/300] [D loss: 0.752732] [G loss: 0.571207] time: 0:27:07.528767\n",
      "0.9466763\n",
      "[Epoch 18/50] [Batch 43/300] [D loss: 0.752742] [G loss: 0.521369] time: 0:27:07.837276\n",
      "0.91557527\n",
      "[Epoch 18/50] [Batch 44/300] [D loss: 0.752746] [G loss: 0.575896] time: 0:27:08.140059\n",
      "0.90861964\n",
      "[Epoch 18/50] [Batch 45/300] [D loss: 0.752747] [G loss: 0.538297] time: 0:27:08.440308\n",
      "0.9166424\n",
      "[Epoch 18/50] [Batch 46/300] [D loss: 0.752715] [G loss: 0.560533] time: 0:27:08.734719\n",
      "0.93719906\n",
      "[Epoch 18/50] [Batch 47/300] [D loss: 0.752723] [G loss: 0.561949] time: 0:27:09.030341\n",
      "0.96239233\n",
      "[Epoch 18/50] [Batch 48/300] [D loss: 0.752732] [G loss: 0.548735] time: 0:27:09.305378\n",
      "0.90350443\n",
      "[Epoch 18/50] [Batch 49/300] [D loss: 0.752761] [G loss: 0.543995] time: 0:27:09.601167\n",
      "0.9379695\n",
      "[Epoch 18/50] [Batch 50/300] [D loss: 0.752759] [G loss: 0.551836] time: 0:27:09.916230\n",
      "0.92119366\n",
      "[Epoch 18/50] [Batch 51/300] [D loss: 0.752741] [G loss: 0.578831] time: 0:27:10.201624\n",
      "0.9323966\n",
      "[Epoch 18/50] [Batch 52/300] [D loss: 0.752755] [G loss: 0.553158] time: 0:27:10.493751\n",
      "0.9292709\n",
      "[Epoch 18/50] [Batch 53/300] [D loss: 0.752725] [G loss: 0.563619] time: 0:27:10.778712\n",
      "0.9043631\n",
      "[Epoch 18/50] [Batch 54/300] [D loss: 0.752753] [G loss: 0.543394] time: 0:27:11.080158\n",
      "0.91253537\n",
      "[Epoch 18/50] [Batch 55/300] [D loss: 0.752729] [G loss: 0.570225] time: 0:27:11.378469\n",
      "0.9157257\n",
      "[Epoch 18/50] [Batch 56/300] [D loss: 0.752702] [G loss: 0.519838] time: 0:27:11.681617\n",
      "0.9453294\n",
      "[Epoch 18/50] [Batch 57/300] [D loss: 0.752731] [G loss: 0.511747] time: 0:27:11.982715\n",
      "0.9413636\n",
      "[Epoch 18/50] [Batch 58/300] [D loss: 0.752747] [G loss: 0.553084] time: 0:27:12.267699\n",
      "0.95033664\n",
      "[Epoch 18/50] [Batch 59/300] [D loss: 0.752715] [G loss: 0.594539] time: 0:27:12.557252\n",
      "0.9730983\n",
      "[Epoch 18/50] [Batch 60/300] [D loss: 0.752723] [G loss: 0.508050] time: 0:27:12.851492\n",
      "0.9627226\n",
      "[Epoch 18/50] [Batch 61/300] [D loss: 0.752738] [G loss: 0.537142] time: 0:27:13.120482\n",
      "0.89089996\n",
      "[Epoch 18/50] [Batch 62/300] [D loss: 0.752747] [G loss: 0.532351] time: 0:27:13.407278\n",
      "0.9127682\n",
      "[Epoch 18/50] [Batch 63/300] [D loss: 0.752744] [G loss: 0.554781] time: 0:27:13.691712\n",
      "0.9601651\n",
      "[Epoch 18/50] [Batch 64/300] [D loss: 0.752725] [G loss: 0.592565] time: 0:27:13.996651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91145235\n",
      "[Epoch 18/50] [Batch 65/300] [D loss: 0.752736] [G loss: 0.542387] time: 0:27:14.296841\n",
      "0.93851167\n",
      "[Epoch 18/50] [Batch 66/300] [D loss: 0.752766] [G loss: 0.573741] time: 0:27:14.576512\n",
      "0.9352539\n",
      "[Epoch 18/50] [Batch 67/300] [D loss: 0.752710] [G loss: 0.501235] time: 0:27:14.853963\n",
      "0.87874484\n",
      "[Epoch 18/50] [Batch 68/300] [D loss: 0.752728] [G loss: 0.597336] time: 0:27:15.152699\n",
      "0.9176202\n",
      "[Epoch 18/50] [Batch 69/300] [D loss: 0.752720] [G loss: 0.560829] time: 0:27:15.451583\n",
      "0.9283026\n",
      "[Epoch 18/50] [Batch 70/300] [D loss: 0.752749] [G loss: 0.533385] time: 0:27:15.734868\n",
      "0.9503603\n",
      "[Epoch 18/50] [Batch 71/300] [D loss: 0.752716] [G loss: 0.514564] time: 0:27:16.016077\n",
      "0.9441068\n",
      "[Epoch 18/50] [Batch 72/300] [D loss: 0.752780] [G loss: 0.581961] time: 0:27:16.303947\n",
      "0.94715923\n",
      "[Epoch 18/50] [Batch 73/300] [D loss: 0.752728] [G loss: 0.607577] time: 0:27:16.607658\n",
      "0.9080527\n",
      "[Epoch 18/50] [Batch 74/300] [D loss: 0.752723] [G loss: 0.551201] time: 0:27:16.893202\n",
      "0.88569736\n",
      "[Epoch 18/50] [Batch 75/300] [D loss: 0.752734] [G loss: 0.537197] time: 0:27:17.189516\n",
      "0.9448681\n",
      "[Epoch 18/50] [Batch 76/300] [D loss: 0.752705] [G loss: 0.579079] time: 0:27:17.481476\n",
      "0.91044384\n",
      "[Epoch 18/50] [Batch 77/300] [D loss: 0.752754] [G loss: 0.565774] time: 0:27:17.768779\n",
      "0.9277613\n",
      "[Epoch 18/50] [Batch 78/300] [D loss: 0.752721] [G loss: 0.533262] time: 0:27:18.057519\n",
      "0.9156439\n",
      "[Epoch 18/50] [Batch 79/300] [D loss: 0.752737] [G loss: 0.551014] time: 0:27:18.351685\n",
      "0.9134583\n",
      "[Epoch 18/50] [Batch 80/300] [D loss: 0.752727] [G loss: 0.531093] time: 0:27:18.647193\n",
      "0.9166896\n",
      "[Epoch 18/50] [Batch 81/300] [D loss: 0.752729] [G loss: 0.529106] time: 0:27:18.959179\n",
      "0.93441033\n",
      "[Epoch 18/50] [Batch 82/300] [D loss: 0.752724] [G loss: 0.571504] time: 0:27:19.239754\n",
      "0.94447565\n",
      "[Epoch 18/50] [Batch 83/300] [D loss: 0.752722] [G loss: 0.555067] time: 0:27:19.541336\n",
      "0.9748884\n",
      "[Epoch 18/50] [Batch 84/300] [D loss: 0.752702] [G loss: 0.512436] time: 0:27:19.847211\n",
      "0.9331201\n",
      "[Epoch 18/50] [Batch 85/300] [D loss: 0.752729] [G loss: 0.535751] time: 0:27:20.146961\n",
      "0.91059834\n",
      "[Epoch 18/50] [Batch 86/300] [D loss: 0.752715] [G loss: 0.575388] time: 0:27:20.445430\n",
      "0.95573634\n",
      "[Epoch 18/50] [Batch 87/300] [D loss: 0.752729] [G loss: 0.583815] time: 0:27:20.744690\n",
      "0.90551686\n",
      "[Epoch 18/50] [Batch 88/300] [D loss: 0.752714] [G loss: 0.569541] time: 0:27:21.040531\n",
      "0.9059448\n",
      "[Epoch 18/50] [Batch 89/300] [D loss: 0.752722] [G loss: 0.528655] time: 0:27:21.320447\n",
      "0.9134216\n",
      "[Epoch 18/50] [Batch 90/300] [D loss: 0.752751] [G loss: 0.578582] time: 0:27:21.619681\n",
      "0.9427367\n",
      "[Epoch 18/50] [Batch 91/300] [D loss: 0.752756] [G loss: 0.530670] time: 0:27:21.914205\n",
      "0.92628497\n",
      "[Epoch 18/50] [Batch 92/300] [D loss: 0.752754] [G loss: 0.549148] time: 0:27:22.217286\n",
      "0.9451595\n",
      "[Epoch 18/50] [Batch 93/300] [D loss: 0.752749] [G loss: 0.540207] time: 0:27:22.517732\n",
      "0.9074187\n",
      "[Epoch 18/50] [Batch 94/300] [D loss: 0.752790] [G loss: 0.524547] time: 0:27:22.825037\n",
      "0.8525073\n",
      "[Epoch 18/50] [Batch 95/300] [D loss: 0.752752] [G loss: 0.545253] time: 0:27:23.112050\n",
      "0.8942411\n",
      "[Epoch 18/50] [Batch 96/300] [D loss: 0.752725] [G loss: 0.517454] time: 0:27:23.395132\n",
      "0.8914558\n",
      "[Epoch 18/50] [Batch 97/300] [D loss: 0.752746] [G loss: 0.525396] time: 0:27:23.702301\n",
      "0.97571737\n",
      "[Epoch 18/50] [Batch 98/300] [D loss: 0.752703] [G loss: 0.539289] time: 0:27:23.999813\n",
      "0.89001817\n",
      "[Epoch 18/50] [Batch 99/300] [D loss: 0.752738] [G loss: 0.503334] time: 0:27:24.273099\n",
      "0.887827\n",
      "[Epoch 18/50] [Batch 100/300] [D loss: 0.752735] [G loss: 0.537795] time: 0:27:24.568743\n",
      "0.9312648\n",
      "[Epoch 18/50] [Batch 101/300] [D loss: 0.752762] [G loss: 0.549927] time: 0:27:24.850400\n",
      "0.9312516\n",
      "[Epoch 18/50] [Batch 102/300] [D loss: 0.752718] [G loss: 0.521831] time: 0:27:25.141886\n",
      "0.9357129\n",
      "[Epoch 18/50] [Batch 103/300] [D loss: 0.752747] [G loss: 0.514325] time: 0:27:25.409478\n",
      "0.91841346\n",
      "[Epoch 18/50] [Batch 104/300] [D loss: 0.752726] [G loss: 0.508815] time: 0:27:25.705502\n",
      "0.938999\n",
      "[Epoch 18/50] [Batch 105/300] [D loss: 0.752770] [G loss: 0.527582] time: 0:27:26.009598\n",
      "0.94185543\n",
      "[Epoch 18/50] [Batch 106/300] [D loss: 0.752742] [G loss: 0.562081] time: 0:27:26.295538\n",
      "0.96429545\n",
      "[Epoch 18/50] [Batch 107/300] [D loss: 0.752761] [G loss: 0.535734] time: 0:27:26.602619\n",
      "0.91358566\n",
      "[Epoch 18/50] [Batch 108/300] [D loss: 0.752719] [G loss: 0.561477] time: 0:27:26.907430\n",
      "0.8817217\n",
      "[Epoch 18/50] [Batch 109/300] [D loss: 0.752723] [G loss: 0.538804] time: 0:27:27.216841\n",
      "0.9074323\n",
      "[Epoch 18/50] [Batch 110/300] [D loss: 0.752755] [G loss: 0.571910] time: 0:27:27.534044\n",
      "0.9554586\n",
      "[Epoch 18/50] [Batch 111/300] [D loss: 0.752752] [G loss: 0.524500] time: 0:27:27.821858\n",
      "0.89530784\n",
      "[Epoch 18/50] [Batch 112/300] [D loss: 0.752721] [G loss: 0.520371] time: 0:27:28.121506\n",
      "0.9706158\n",
      "[Epoch 18/50] [Batch 113/300] [D loss: 0.752745] [G loss: 0.569641] time: 0:27:28.416237\n",
      "0.8844926\n",
      "[Epoch 18/50] [Batch 114/300] [D loss: 0.752702] [G loss: 0.515311] time: 0:27:28.715698\n",
      "0.91607124\n",
      "[Epoch 18/50] [Batch 115/300] [D loss: 0.752731] [G loss: 0.516693] time: 0:27:28.998285\n",
      "0.91601485\n",
      "[Epoch 18/50] [Batch 116/300] [D loss: 0.752743] [G loss: 0.571505] time: 0:27:29.302742\n",
      "0.9158036\n",
      "[Epoch 18/50] [Batch 117/300] [D loss: 0.752731] [G loss: 0.605628] time: 0:27:29.580580\n",
      "0.90856284\n",
      "[Epoch 18/50] [Batch 118/300] [D loss: 0.752715] [G loss: 0.539270] time: 0:27:29.867115\n",
      "0.93693995\n",
      "[Epoch 18/50] [Batch 119/300] [D loss: 0.752742] [G loss: 0.579397] time: 0:27:30.168271\n",
      "0.9819835\n",
      "[Epoch 18/50] [Batch 120/300] [D loss: 0.752735] [G loss: 0.543122] time: 0:27:30.476687\n",
      "0.90931344\n",
      "[Epoch 18/50] [Batch 121/300] [D loss: 0.752733] [G loss: 0.554964] time: 0:27:30.791757\n",
      "0.90267754\n",
      "[Epoch 18/50] [Batch 122/300] [D loss: 0.752723] [G loss: 0.542229] time: 0:27:31.090013\n",
      "0.9328987\n",
      "[Epoch 18/50] [Batch 123/300] [D loss: 0.752706] [G loss: 0.546896] time: 0:27:31.375039\n",
      "0.91237503\n",
      "[Epoch 18/50] [Batch 124/300] [D loss: 0.752735] [G loss: 0.540974] time: 0:27:31.671704\n",
      "0.93220186\n",
      "[Epoch 18/50] [Batch 125/300] [D loss: 0.752767] [G loss: 0.558996] time: 0:27:31.977531\n",
      "0.89851445\n",
      "[Epoch 18/50] [Batch 126/300] [D loss: 0.752746] [G loss: 0.535785] time: 0:27:32.281863\n",
      "0.9453426\n",
      "[Epoch 18/50] [Batch 127/300] [D loss: 0.752715] [G loss: 0.558854] time: 0:27:32.580695\n",
      "0.92130584\n",
      "[Epoch 18/50] [Batch 128/300] [D loss: 0.752691] [G loss: 0.564109] time: 0:27:32.896665\n",
      "0.8832901\n",
      "[Epoch 18/50] [Batch 129/300] [D loss: 0.752720] [G loss: 0.546117] time: 0:27:33.193340\n",
      "0.9076298\n",
      "[Epoch 18/50] [Batch 130/300] [D loss: 0.752706] [G loss: 0.586332] time: 0:27:33.469442\n",
      "0.8818507\n",
      "[Epoch 18/50] [Batch 131/300] [D loss: 0.752743] [G loss: 0.529985] time: 0:27:33.764228\n",
      "0.95441455\n",
      "[Epoch 18/50] [Batch 132/300] [D loss: 0.752745] [G loss: 0.563675] time: 0:27:34.060304\n",
      "0.9043577\n",
      "[Epoch 18/50] [Batch 133/300] [D loss: 0.752715] [G loss: 0.586732] time: 0:27:34.349047\n",
      "0.91151094\n",
      "[Epoch 18/50] [Batch 134/300] [D loss: 0.752716] [G loss: 0.573738] time: 0:27:34.652775\n",
      "0.97139186\n",
      "[Epoch 18/50] [Batch 135/300] [D loss: 0.752750] [G loss: 0.522470] time: 0:27:34.962754\n",
      "0.9173642\n",
      "[Epoch 18/50] [Batch 136/300] [D loss: 0.752706] [G loss: 0.542587] time: 0:27:35.263751\n",
      "0.93752235\n",
      "[Epoch 18/50] [Batch 137/300] [D loss: 0.752719] [G loss: 0.542940] time: 0:27:35.554844\n",
      "0.91004187\n",
      "[Epoch 18/50] [Batch 138/300] [D loss: 0.752693] [G loss: 0.526416] time: 0:27:35.868362\n",
      "0.9069097\n",
      "[Epoch 18/50] [Batch 139/300] [D loss: 0.752705] [G loss: 0.555966] time: 0:27:36.169168\n",
      "0.9313188\n",
      "[Epoch 18/50] [Batch 140/300] [D loss: 0.752709] [G loss: 0.531108] time: 0:27:36.474011\n",
      "0.88919145\n",
      "[Epoch 18/50] [Batch 141/300] [D loss: 0.752738] [G loss: 0.572679] time: 0:27:36.755289\n",
      "0.9413965\n",
      "[Epoch 18/50] [Batch 142/300] [D loss: 0.752753] [G loss: 0.550877] time: 0:27:37.057516\n",
      "0.93353486\n",
      "[Epoch 18/50] [Batch 143/300] [D loss: 0.752707] [G loss: 0.528022] time: 0:27:37.343433\n",
      "0.95576113\n",
      "[Epoch 18/50] [Batch 144/300] [D loss: 0.752706] [G loss: 0.554779] time: 0:27:37.639814\n",
      "0.9400399\n",
      "[Epoch 18/50] [Batch 145/300] [D loss: 0.752726] [G loss: 0.529637] time: 0:27:37.935802\n",
      "0.90293026\n",
      "[Epoch 18/50] [Batch 146/300] [D loss: 0.752704] [G loss: 0.511373] time: 0:27:38.238507\n",
      "0.8780177\n",
      "[Epoch 18/50] [Batch 147/300] [D loss: 0.752687] [G loss: 0.533949] time: 0:27:38.554961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9586167\n",
      "[Epoch 18/50] [Batch 148/300] [D loss: 0.752788] [G loss: 0.506126] time: 0:27:38.861253\n",
      "0.98390937\n",
      "[Epoch 18/50] [Batch 149/300] [D loss: 0.752718] [G loss: 0.512480] time: 0:27:39.167717\n",
      "0.9198253\n",
      "[Epoch 18/50] [Batch 150/300] [D loss: 0.752722] [G loss: 0.533464] time: 0:27:39.454048\n",
      "0.88852715\n",
      "[Epoch 18/50] [Batch 151/300] [D loss: 0.752703] [G loss: 0.600097] time: 0:27:39.761939\n",
      "0.9598167\n",
      "[Epoch 18/50] [Batch 152/300] [D loss: 0.752738] [G loss: 0.519480] time: 0:27:40.047573\n",
      "0.8942887\n",
      "[Epoch 18/50] [Batch 153/300] [D loss: 0.752725] [G loss: 0.536987] time: 0:27:40.348416\n",
      "0.924969\n",
      "[Epoch 18/50] [Batch 154/300] [D loss: 0.752677] [G loss: 0.525515] time: 0:27:40.641932\n",
      "0.93406886\n",
      "[Epoch 18/50] [Batch 155/300] [D loss: 0.752713] [G loss: 0.543047] time: 0:27:40.945985\n",
      "0.9192455\n",
      "[Epoch 18/50] [Batch 156/300] [D loss: 0.752735] [G loss: 0.582113] time: 0:27:41.224349\n",
      "0.88075495\n",
      "[Epoch 18/50] [Batch 157/300] [D loss: 0.752710] [G loss: 0.586274] time: 0:27:41.520772\n",
      "0.9451849\n",
      "[Epoch 18/50] [Batch 158/300] [D loss: 0.752756] [G loss: 0.557756] time: 0:27:41.812163\n",
      "0.97054386\n",
      "[Epoch 18/50] [Batch 159/300] [D loss: 0.752730] [G loss: 0.563251] time: 0:27:42.110096\n",
      "0.9160294\n",
      "[Epoch 18/50] [Batch 160/300] [D loss: 0.752742] [G loss: 0.543460] time: 0:27:42.427887\n",
      "0.9289022\n",
      "[Epoch 18/50] [Batch 161/300] [D loss: 0.752709] [G loss: 0.511349] time: 0:27:42.732527\n",
      "0.90869117\n",
      "[Epoch 18/50] [Batch 162/300] [D loss: 0.752729] [G loss: 0.511692] time: 0:27:43.043864\n",
      "0.8939006\n",
      "[Epoch 18/50] [Batch 163/300] [D loss: 0.752705] [G loss: 0.541891] time: 0:27:43.350155\n",
      "0.8653378\n",
      "[Epoch 18/50] [Batch 164/300] [D loss: 0.752726] [G loss: 0.532686] time: 0:27:43.652160\n",
      "0.912494\n",
      "[Epoch 18/50] [Batch 165/300] [D loss: 0.752718] [G loss: 0.521502] time: 0:27:43.942598\n",
      "0.97109956\n",
      "[Epoch 18/50] [Batch 166/300] [D loss: 0.752738] [G loss: 0.558886] time: 0:27:44.243894\n",
      "0.93201256\n",
      "[Epoch 18/50] [Batch 167/300] [D loss: 0.752716] [G loss: 0.516325] time: 0:27:44.543119\n",
      "0.93783313\n",
      "[Epoch 18/50] [Batch 168/300] [D loss: 0.752713] [G loss: 0.560557] time: 0:27:44.843994\n",
      "0.9170449\n",
      "[Epoch 18/50] [Batch 169/300] [D loss: 0.752716] [G loss: 0.574286] time: 0:27:45.147330\n",
      "0.9456079\n",
      "[Epoch 18/50] [Batch 170/300] [D loss: 0.752711] [G loss: 0.590765] time: 0:27:45.434542\n",
      "0.916918\n",
      "[Epoch 18/50] [Batch 171/300] [D loss: 0.752715] [G loss: 0.553038] time: 0:27:45.729931\n",
      "0.90607196\n",
      "[Epoch 18/50] [Batch 172/300] [D loss: 0.752724] [G loss: 0.642684] time: 0:27:46.013853\n",
      "0.94641304\n",
      "[Epoch 18/50] [Batch 173/300] [D loss: 0.752707] [G loss: 0.552092] time: 0:27:46.319102\n",
      "0.8912193\n",
      "[Epoch 18/50] [Batch 174/300] [D loss: 0.752720] [G loss: 0.567659] time: 0:27:46.616113\n",
      "0.9473714\n",
      "[Epoch 18/50] [Batch 175/300] [D loss: 0.752699] [G loss: 0.579987] time: 0:27:46.900750\n",
      "0.9335389\n",
      "[Epoch 18/50] [Batch 176/300] [D loss: 0.752722] [G loss: 0.550991] time: 0:27:47.196373\n",
      "0.93142956\n",
      "[Epoch 18/50] [Batch 177/300] [D loss: 0.752702] [G loss: 0.535221] time: 0:27:47.508134\n",
      "0.9152692\n",
      "[Epoch 18/50] [Batch 178/300] [D loss: 0.752719] [G loss: 0.608124] time: 0:27:47.823043\n",
      "0.97037154\n",
      "[Epoch 18/50] [Batch 179/300] [D loss: 0.752723] [G loss: 0.532979] time: 0:27:48.128097\n",
      "0.9460643\n",
      "[Epoch 18/50] [Batch 180/300] [D loss: 0.752699] [G loss: 0.550976] time: 0:27:48.405569\n",
      "0.88105506\n",
      "[Epoch 18/50] [Batch 181/300] [D loss: 0.752714] [G loss: 0.540172] time: 0:27:48.711132\n",
      "0.9143055\n",
      "[Epoch 18/50] [Batch 182/300] [D loss: 0.752720] [G loss: 0.584109] time: 0:27:49.008904\n",
      "0.9677584\n",
      "[Epoch 18/50] [Batch 183/300] [D loss: 0.752728] [G loss: 0.533095] time: 0:27:49.301444\n",
      "0.941925\n",
      "[Epoch 18/50] [Batch 184/300] [D loss: 0.752729] [G loss: 0.541283] time: 0:27:49.597307\n",
      "0.93357366\n",
      "[Epoch 18/50] [Batch 185/300] [D loss: 0.752728] [G loss: 0.517415] time: 0:27:49.885415\n",
      "0.91730326\n",
      "[Epoch 18/50] [Batch 186/300] [D loss: 0.752717] [G loss: 0.529475] time: 0:27:50.194364\n",
      "0.9090119\n",
      "[Epoch 18/50] [Batch 187/300] [D loss: 0.752730] [G loss: 0.575299] time: 0:27:50.497972\n",
      "0.935225\n",
      "[Epoch 18/50] [Batch 188/300] [D loss: 0.752741] [G loss: 0.539263] time: 0:27:50.811581\n",
      "0.90795094\n",
      "[Epoch 18/50] [Batch 189/300] [D loss: 0.752727] [G loss: 0.560305] time: 0:27:51.111137\n",
      "0.9026775\n",
      "[Epoch 18/50] [Batch 190/300] [D loss: 0.752712] [G loss: 0.562044] time: 0:27:51.397921\n",
      "0.9816881\n",
      "[Epoch 18/50] [Batch 191/300] [D loss: 0.752710] [G loss: 0.570849] time: 0:27:51.694363\n",
      "0.9364677\n",
      "[Epoch 18/50] [Batch 192/300] [D loss: 0.752719] [G loss: 0.519899] time: 0:27:51.989279\n",
      "0.9361983\n",
      "[Epoch 18/50] [Batch 193/300] [D loss: 0.752711] [G loss: 0.538278] time: 0:27:52.265566\n",
      "0.8750415\n",
      "[Epoch 18/50] [Batch 194/300] [D loss: 0.752722] [G loss: 0.573464] time: 0:27:52.568102\n",
      "0.92918134\n",
      "[Epoch 18/50] [Batch 195/300] [D loss: 0.752715] [G loss: 0.544676] time: 0:27:52.873442\n",
      "0.8602057\n",
      "[Epoch 18/50] [Batch 196/300] [D loss: 0.752708] [G loss: 0.573386] time: 0:27:53.151476\n",
      "0.8950503\n",
      "[Epoch 18/50] [Batch 197/300] [D loss: 0.752692] [G loss: 0.529677] time: 0:27:53.446603\n",
      "0.8970087\n",
      "[Epoch 18/50] [Batch 198/300] [D loss: 0.752704] [G loss: 0.534986] time: 0:27:53.725509\n",
      "0.9478865\n",
      "[Epoch 18/50] [Batch 199/300] [D loss: 0.752720] [G loss: 0.521598] time: 0:27:53.998348\n",
      "0.9512534\n",
      "[Epoch 18/50] [Batch 200/300] [D loss: 0.752732] [G loss: 0.544741] time: 0:27:54.291623\n",
      "0.9458132\n",
      "[Epoch 18/50] [Batch 201/300] [D loss: 0.752722] [G loss: 0.542204] time: 0:27:54.587500\n",
      "0.934052\n",
      "[Epoch 18/50] [Batch 202/300] [D loss: 0.752702] [G loss: 0.517536] time: 0:27:54.878607\n",
      "0.94625515\n",
      "[Epoch 18/50] [Batch 203/300] [D loss: 0.752716] [G loss: 0.598160] time: 0:27:55.177528\n",
      "0.9198206\n",
      "[Epoch 18/50] [Batch 204/300] [D loss: 0.752713] [G loss: 0.564389] time: 0:27:55.461112\n",
      "0.9462022\n",
      "[Epoch 18/50] [Batch 205/300] [D loss: 0.752679] [G loss: 0.551962] time: 0:27:55.738316\n",
      "0.94390965\n",
      "[Epoch 18/50] [Batch 206/300] [D loss: 0.752728] [G loss: 0.509254] time: 0:27:56.014918\n",
      "0.90263724\n",
      "[Epoch 18/50] [Batch 207/300] [D loss: 0.752734] [G loss: 0.524393] time: 0:27:56.312376\n",
      "0.92419523\n",
      "[Epoch 18/50] [Batch 208/300] [D loss: 0.752729] [G loss: 0.500624] time: 0:27:56.608421\n",
      "0.91766065\n",
      "[Epoch 18/50] [Batch 209/300] [D loss: 0.752696] [G loss: 0.562580] time: 0:27:56.891225\n",
      "0.9246908\n",
      "[Epoch 18/50] [Batch 210/300] [D loss: 0.752719] [G loss: 0.565207] time: 0:27:57.188929\n",
      "0.9426984\n",
      "[Epoch 18/50] [Batch 211/300] [D loss: 0.752716] [G loss: 0.558800] time: 0:27:57.474267\n",
      "0.9092346\n",
      "[Epoch 18/50] [Batch 212/300] [D loss: 0.752709] [G loss: 0.527614] time: 0:27:57.771951\n",
      "0.9283381\n",
      "[Epoch 18/50] [Batch 213/300] [D loss: 0.752693] [G loss: 0.552621] time: 0:27:58.069094\n",
      "0.9617674\n",
      "[Epoch 18/50] [Batch 214/300] [D loss: 0.752724] [G loss: 0.575489] time: 0:27:58.380981\n",
      "0.93053865\n",
      "[Epoch 18/50] [Batch 215/300] [D loss: 0.752718] [G loss: 0.514228] time: 0:27:58.673919\n",
      "0.90864396\n",
      "[Epoch 18/50] [Batch 216/300] [D loss: 0.752724] [G loss: 0.510480] time: 0:27:58.963739\n",
      "0.90856975\n",
      "[Epoch 18/50] [Batch 217/300] [D loss: 0.752703] [G loss: 0.560899] time: 0:27:59.285665\n",
      "0.9254927\n",
      "[Epoch 18/50] [Batch 218/300] [D loss: 0.752725] [G loss: 0.546516] time: 0:27:59.595163\n",
      "0.9155399\n",
      "[Epoch 18/50] [Batch 219/300] [D loss: 0.752693] [G loss: 0.529557] time: 0:27:59.877515\n",
      "0.92556024\n",
      "[Epoch 18/50] [Batch 220/300] [D loss: 0.752734] [G loss: 0.565666] time: 0:28:00.179957\n",
      "0.8653279\n",
      "[Epoch 18/50] [Batch 221/300] [D loss: 0.752724] [G loss: 0.593721] time: 0:28:00.472256\n",
      "0.93664426\n",
      "[Epoch 18/50] [Batch 222/300] [D loss: 0.752723] [G loss: 0.538107] time: 0:28:00.766779\n",
      "0.91143316\n",
      "[Epoch 18/50] [Batch 223/300] [D loss: 0.752708] [G loss: 0.545156] time: 0:28:01.053644\n",
      "0.9073227\n",
      "[Epoch 18/50] [Batch 224/300] [D loss: 0.752693] [G loss: 0.627603] time: 0:28:01.365457\n",
      "0.9371888\n",
      "[Epoch 18/50] [Batch 225/300] [D loss: 0.752729] [G loss: 0.607593] time: 0:28:01.660303\n",
      "0.90861034\n",
      "[Epoch 18/50] [Batch 226/300] [D loss: 0.752677] [G loss: 0.569543] time: 0:28:01.948154\n",
      "0.94571304\n",
      "[Epoch 18/50] [Batch 227/300] [D loss: 0.752756] [G loss: 0.552230] time: 0:28:02.253418\n",
      "0.92629176\n",
      "[Epoch 18/50] [Batch 228/300] [D loss: 0.752711] [G loss: 0.544053] time: 0:28:02.552309\n",
      "0.92487854\n",
      "[Epoch 18/50] [Batch 229/300] [D loss: 0.752721] [G loss: 0.580119] time: 0:28:02.834151\n",
      "0.9410221\n",
      "[Epoch 18/50] [Batch 230/300] [D loss: 0.752719] [G loss: 0.585031] time: 0:28:03.131406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9116261\n",
      "[Epoch 18/50] [Batch 231/300] [D loss: 0.752679] [G loss: 0.566810] time: 0:28:03.437373\n",
      "0.93502504\n",
      "[Epoch 18/50] [Batch 232/300] [D loss: 0.752682] [G loss: 0.558997] time: 0:28:03.735872\n",
      "0.9084839\n",
      "[Epoch 18/50] [Batch 233/300] [D loss: 0.752704] [G loss: 0.538695] time: 0:28:04.047313\n",
      "0.9466327\n",
      "[Epoch 18/50] [Batch 234/300] [D loss: 0.752736] [G loss: 0.513433] time: 0:28:04.330438\n",
      "0.9755907\n",
      "[Epoch 18/50] [Batch 235/300] [D loss: 0.752729] [G loss: 0.559344] time: 0:28:04.635049\n",
      "0.92433953\n",
      "[Epoch 18/50] [Batch 236/300] [D loss: 0.752696] [G loss: 0.541827] time: 0:28:04.929098\n",
      "0.91014576\n",
      "[Epoch 18/50] [Batch 237/300] [D loss: 0.752706] [G loss: 0.556122] time: 0:28:05.239024\n",
      "0.95234543\n",
      "[Epoch 18/50] [Batch 238/300] [D loss: 0.752717] [G loss: 0.534593] time: 0:28:05.542800\n",
      "0.9293739\n",
      "[Epoch 18/50] [Batch 239/300] [D loss: 0.752696] [G loss: 0.531688] time: 0:28:05.848551\n",
      "0.94618195\n",
      "[Epoch 18/50] [Batch 240/300] [D loss: 0.752708] [G loss: 0.540143] time: 0:28:06.137558\n",
      "0.903737\n",
      "[Epoch 18/50] [Batch 241/300] [D loss: 0.752697] [G loss: 0.512281] time: 0:28:06.438989\n",
      "0.9376522\n",
      "[Epoch 18/50] [Batch 242/300] [D loss: 0.752715] [G loss: 0.558174] time: 0:28:06.731762\n",
      "0.94284254\n",
      "[Epoch 18/50] [Batch 243/300] [D loss: 0.752716] [G loss: 0.520574] time: 0:28:07.040894\n",
      "0.9418445\n",
      "[Epoch 18/50] [Batch 244/300] [D loss: 0.752732] [G loss: 0.517085] time: 0:28:07.349741\n",
      "0.96165556\n",
      "[Epoch 18/50] [Batch 245/300] [D loss: 0.752706] [G loss: 0.546448] time: 0:28:07.631837\n",
      "0.9317369\n",
      "[Epoch 18/50] [Batch 246/300] [D loss: 0.752702] [G loss: 0.511063] time: 0:28:07.923213\n",
      "0.89920133\n",
      "[Epoch 18/50] [Batch 247/300] [D loss: 0.752722] [G loss: 0.564519] time: 0:28:08.221514\n",
      "0.9714362\n",
      "[Epoch 18/50] [Batch 248/300] [D loss: 0.752709] [G loss: 0.549632] time: 0:28:08.529015\n",
      "0.9032404\n",
      "[Epoch 18/50] [Batch 249/300] [D loss: 0.752714] [G loss: 0.514229] time: 0:28:08.803674\n",
      "0.8723274\n",
      "[Epoch 18/50] [Batch 250/300] [D loss: 0.752690] [G loss: 0.579459] time: 0:28:09.102224\n",
      "0.9381771\n",
      "[Epoch 18/50] [Batch 251/300] [D loss: 0.752741] [G loss: 0.504836] time: 0:28:09.383195\n",
      "0.96695846\n",
      "[Epoch 18/50] [Batch 252/300] [D loss: 0.752726] [G loss: 0.642531] time: 0:28:09.675256\n",
      "0.9669313\n",
      "[Epoch 18/50] [Batch 253/300] [D loss: 0.752737] [G loss: 0.568012] time: 0:28:09.980097\n",
      "0.94572943\n",
      "[Epoch 18/50] [Batch 254/300] [D loss: 0.752717] [G loss: 0.565560] time: 0:28:10.283207\n",
      "0.98172766\n",
      "[Epoch 18/50] [Batch 255/300] [D loss: 0.752696] [G loss: 0.576474] time: 0:28:10.577609\n",
      "0.97454065\n",
      "[Epoch 18/50] [Batch 256/300] [D loss: 0.752720] [G loss: 0.527636] time: 0:28:10.864586\n",
      "0.9339997\n",
      "[Epoch 18/50] [Batch 257/300] [D loss: 0.752727] [G loss: 0.552504] time: 0:28:11.162231\n",
      "0.9066488\n",
      "[Epoch 18/50] [Batch 258/300] [D loss: 0.752722] [G loss: 0.526770] time: 0:28:11.479516\n",
      "0.92179555\n",
      "[Epoch 18/50] [Batch 259/300] [D loss: 0.752717] [G loss: 0.518610] time: 0:28:11.776351\n",
      "0.92515415\n",
      "[Epoch 18/50] [Batch 260/300] [D loss: 0.752707] [G loss: 0.544917] time: 0:28:12.082429\n",
      "0.9173126\n",
      "[Epoch 18/50] [Batch 261/300] [D loss: 0.752697] [G loss: 0.532151] time: 0:28:12.380664\n",
      "0.8909331\n",
      "[Epoch 18/50] [Batch 262/300] [D loss: 0.752701] [G loss: 0.553406] time: 0:28:12.678404\n",
      "0.9270579\n",
      "[Epoch 18/50] [Batch 263/300] [D loss: 0.752676] [G loss: 0.526826] time: 0:28:13.000293\n",
      "0.93888205\n",
      "[Epoch 18/50] [Batch 264/300] [D loss: 0.752728] [G loss: 0.522675] time: 0:28:13.300702\n",
      "0.9178336\n",
      "[Epoch 18/50] [Batch 265/300] [D loss: 0.752712] [G loss: 0.563387] time: 0:28:13.592063\n",
      "0.89200735\n",
      "[Epoch 18/50] [Batch 266/300] [D loss: 0.752671] [G loss: 0.528538] time: 0:28:13.895160\n",
      "0.8898441\n",
      "[Epoch 18/50] [Batch 267/300] [D loss: 0.752708] [G loss: 0.528862] time: 0:28:14.197096\n",
      "0.9387379\n",
      "[Epoch 18/50] [Batch 268/300] [D loss: 0.752696] [G loss: 0.524126] time: 0:28:14.497272\n",
      "0.96066695\n",
      "[Epoch 18/50] [Batch 269/300] [D loss: 0.752662] [G loss: 0.560729] time: 0:28:14.790867\n",
      "0.912956\n",
      "[Epoch 18/50] [Batch 270/300] [D loss: 0.752685] [G loss: 0.549318] time: 0:28:15.084105\n",
      "0.9693563\n",
      "[Epoch 18/50] [Batch 271/300] [D loss: 0.752704] [G loss: 0.519071] time: 0:28:15.374546\n",
      "0.8951768\n",
      "[Epoch 18/50] [Batch 272/300] [D loss: 0.752677] [G loss: 0.535254] time: 0:28:15.680062\n",
      "0.9440594\n",
      "[Epoch 18/50] [Batch 273/300] [D loss: 0.752705] [G loss: 0.563991] time: 0:28:15.990036\n",
      "0.91746706\n",
      "[Epoch 18/50] [Batch 274/300] [D loss: 0.752690] [G loss: 0.533724] time: 0:28:16.286061\n",
      "0.9539911\n",
      "[Epoch 18/50] [Batch 275/300] [D loss: 0.752694] [G loss: 0.573899] time: 0:28:16.587197\n",
      "0.93023676\n",
      "[Epoch 18/50] [Batch 276/300] [D loss: 0.752703] [G loss: 0.513672] time: 0:28:16.875177\n",
      "0.92227626\n",
      "[Epoch 18/50] [Batch 277/300] [D loss: 0.752690] [G loss: 0.510264] time: 0:28:17.162158\n",
      "0.89618057\n",
      "[Epoch 18/50] [Batch 278/300] [D loss: 0.752701] [G loss: 0.539167] time: 0:28:17.465206\n",
      "0.8819172\n",
      "[Epoch 18/50] [Batch 279/300] [D loss: 0.752696] [G loss: 0.507916] time: 0:28:17.770348\n",
      "0.8899403\n",
      "[Epoch 18/50] [Batch 280/300] [D loss: 0.752732] [G loss: 0.535533] time: 0:28:18.064380\n",
      "0.9103353\n",
      "[Epoch 18/50] [Batch 281/300] [D loss: 0.752711] [G loss: 0.512732] time: 0:28:18.358503\n",
      "0.9732161\n",
      "[Epoch 18/50] [Batch 282/300] [D loss: 0.752712] [G loss: 0.595719] time: 0:28:18.661651\n",
      "0.9483006\n",
      "[Epoch 18/50] [Batch 283/300] [D loss: 0.752705] [G loss: 0.527795] time: 0:28:18.957352\n",
      "0.92991\n",
      "[Epoch 18/50] [Batch 284/300] [D loss: 0.752714] [G loss: 0.563389] time: 0:28:19.255126\n",
      "0.97595173\n",
      "[Epoch 18/50] [Batch 285/300] [D loss: 0.752716] [G loss: 0.502469] time: 0:28:19.552787\n",
      "0.8851873\n",
      "[Epoch 18/50] [Batch 286/300] [D loss: 0.752705] [G loss: 0.536124] time: 0:28:19.838475\n",
      "0.93374604\n",
      "[Epoch 18/50] [Batch 287/300] [D loss: 0.752721] [G loss: 0.515976] time: 0:28:20.127043\n",
      "0.887225\n",
      "[Epoch 18/50] [Batch 288/300] [D loss: 0.752704] [G loss: 0.553532] time: 0:28:20.436061\n",
      "0.92736393\n",
      "[Epoch 18/50] [Batch 289/300] [D loss: 0.752669] [G loss: 0.521265] time: 0:28:20.732242\n",
      "0.9138956\n",
      "[Epoch 18/50] [Batch 290/300] [D loss: 0.752688] [G loss: 0.568568] time: 0:28:21.009349\n",
      "0.95908374\n",
      "[Epoch 18/50] [Batch 291/300] [D loss: 0.752675] [G loss: 0.518221] time: 0:28:21.319243\n",
      "0.9405031\n",
      "[Epoch 18/50] [Batch 292/300] [D loss: 0.752669] [G loss: 0.556855] time: 0:28:21.621080\n",
      "0.9032045\n",
      "[Epoch 18/50] [Batch 293/300] [D loss: 0.752722] [G loss: 0.566870] time: 0:28:21.912485\n",
      "0.89182633\n",
      "[Epoch 18/50] [Batch 294/300] [D loss: 0.752676] [G loss: 0.554372] time: 0:28:22.182772\n",
      "0.9002356\n",
      "[Epoch 18/50] [Batch 295/300] [D loss: 0.752695] [G loss: 0.541561] time: 0:28:22.486311\n",
      "0.9224949\n",
      "[Epoch 18/50] [Batch 296/300] [D loss: 0.752725] [G loss: 0.542222] time: 0:28:22.783921\n",
      "0.93692476\n",
      "[Epoch 18/50] [Batch 297/300] [D loss: 0.752735] [G loss: 0.534881] time: 0:28:23.074544\n",
      "0.93933463\n",
      "[Epoch 18/50] [Batch 298/300] [D loss: 0.752722] [G loss: 0.530275] time: 0:28:23.374604\n",
      "0.9256653\n",
      "[Epoch 18/50] [Batch 299/300] [D loss: 0.752668] [G loss: 0.537886] time: 0:28:23.644830\n",
      "0.9099994\n",
      "[Epoch 19/50] [Batch 0/300] [D loss: 0.752712] [G loss: 0.537117] time: 0:28:23.936626\n",
      "0.9530689\n",
      "[Epoch 19/50] [Batch 1/300] [D loss: 0.752706] [G loss: 0.581878] time: 0:28:24.253229\n",
      "0.9106891\n",
      "[Epoch 19/50] [Batch 2/300] [D loss: 0.752689] [G loss: 0.531854] time: 0:28:24.539826\n",
      "0.92715573\n",
      "[Epoch 19/50] [Batch 3/300] [D loss: 0.752686] [G loss: 0.532628] time: 0:28:24.817455\n",
      "0.9623602\n",
      "[Epoch 19/50] [Batch 4/300] [D loss: 0.752687] [G loss: 0.537729] time: 0:28:25.097212\n",
      "0.9277912\n",
      "[Epoch 19/50] [Batch 5/300] [D loss: 0.752706] [G loss: 0.530291] time: 0:28:25.412179\n",
      "0.93914336\n",
      "[Epoch 19/50] [Batch 6/300] [D loss: 0.752741] [G loss: 0.554262] time: 0:28:25.716149\n",
      "0.8969128\n",
      "[Epoch 19/50] [Batch 7/300] [D loss: 0.752698] [G loss: 0.582924] time: 0:28:26.003777\n",
      "0.91426104\n",
      "[Epoch 19/50] [Batch 8/300] [D loss: 0.752706] [G loss: 0.530826] time: 0:28:26.321744\n",
      "0.9456715\n",
      "[Epoch 19/50] [Batch 9/300] [D loss: 0.752685] [G loss: 0.537195] time: 0:28:26.612765\n",
      "0.971719\n",
      "[Epoch 19/50] [Batch 10/300] [D loss: 0.752695] [G loss: 0.590147] time: 0:28:26.904907\n",
      "0.95545655\n",
      "[Epoch 19/50] [Batch 11/300] [D loss: 0.752680] [G loss: 0.543468] time: 0:28:27.186572\n",
      "0.9528486\n",
      "[Epoch 19/50] [Batch 12/300] [D loss: 0.752716] [G loss: 0.564743] time: 0:28:27.487723\n",
      "0.9317644\n",
      "[Epoch 19/50] [Batch 13/300] [D loss: 0.752689] [G loss: 0.630510] time: 0:28:27.761174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742574\n",
      "[Epoch 19/50] [Batch 14/300] [D loss: 0.752698] [G loss: 0.559811] time: 0:28:28.057292\n",
      "0.90852946\n",
      "[Epoch 19/50] [Batch 15/300] [D loss: 0.752699] [G loss: 0.565099] time: 0:28:28.361385\n",
      "0.89590496\n",
      "[Epoch 19/50] [Batch 16/300] [D loss: 0.752696] [G loss: 0.502914] time: 0:28:28.670638\n",
      "0.96895534\n",
      "[Epoch 19/50] [Batch 17/300] [D loss: 0.752726] [G loss: 0.516383] time: 0:28:28.973718\n",
      "0.8994107\n",
      "[Epoch 19/50] [Batch 19/300] [D loss: 0.752691] [G loss: 0.513041] time: 0:28:29.277931\n",
      "0.9292361\n",
      "[Epoch 19/50] [Batch 20/300] [D loss: 0.752667] [G loss: 0.548284] time: 0:28:29.558672\n",
      "0.9123375\n",
      "[Epoch 19/50] [Batch 21/300] [D loss: 0.752692] [G loss: 0.584015] time: 0:28:29.853764\n",
      "0.91791344\n",
      "[Epoch 19/50] [Batch 22/300] [D loss: 0.752694] [G loss: 0.527890] time: 0:28:30.146503\n",
      "0.9582103\n",
      "[Epoch 19/50] [Batch 23/300] [D loss: 0.752721] [G loss: 0.515077] time: 0:28:30.430266\n",
      "0.92067474\n",
      "[Epoch 19/50] [Batch 24/300] [D loss: 0.752679] [G loss: 0.542943] time: 0:28:30.721250\n",
      "0.8995366\n",
      "[Epoch 19/50] [Batch 25/300] [D loss: 0.752688] [G loss: 0.521608] time: 0:28:31.022280\n",
      "0.9002616\n",
      "[Epoch 19/50] [Batch 26/300] [D loss: 0.752681] [G loss: 0.524694] time: 0:28:31.327842\n",
      "0.92799264\n",
      "[Epoch 19/50] [Batch 27/300] [D loss: 0.752717] [G loss: 0.518827] time: 0:28:31.620342\n",
      "0.94700366\n",
      "[Epoch 19/50] [Batch 28/300] [D loss: 0.752674] [G loss: 0.568640] time: 0:28:31.894946\n",
      "0.9468166\n",
      "[Epoch 19/50] [Batch 29/300] [D loss: 0.752723] [G loss: 0.523984] time: 0:28:32.189423\n",
      "0.9375265\n",
      "[Epoch 19/50] [Batch 30/300] [D loss: 0.752714] [G loss: 0.553988] time: 0:28:32.493798\n",
      "0.9127126\n",
      "[Epoch 19/50] [Batch 31/300] [D loss: 0.752678] [G loss: 0.541629] time: 0:28:32.790660\n",
      "0.92050725\n",
      "[Epoch 19/50] [Batch 32/300] [D loss: 0.752684] [G loss: 0.537788] time: 0:28:33.097415\n",
      "0.8922839\n",
      "[Epoch 19/50] [Batch 33/300] [D loss: 0.752681] [G loss: 0.512906] time: 0:28:33.398021\n",
      "0.9287308\n",
      "[Epoch 19/50] [Batch 34/300] [D loss: 0.752700] [G loss: 0.556398] time: 0:28:33.715609\n",
      "0.92254305\n",
      "[Epoch 19/50] [Batch 35/300] [D loss: 0.752697] [G loss: 0.522708] time: 0:28:34.011526\n",
      "0.9531908\n",
      "[Epoch 19/50] [Batch 36/300] [D loss: 0.752723] [G loss: 0.517940] time: 0:28:34.311994\n",
      "0.91196465\n",
      "[Epoch 19/50] [Batch 37/300] [D loss: 0.752692] [G loss: 0.540401] time: 0:28:34.600129\n",
      "0.91993994\n",
      "[Epoch 19/50] [Batch 38/300] [D loss: 0.752705] [G loss: 0.526683] time: 0:28:34.876029\n",
      "0.9549668\n",
      "[Epoch 19/50] [Batch 39/300] [D loss: 0.752701] [G loss: 0.534340] time: 0:28:35.170072\n",
      "0.934742\n",
      "[Epoch 19/50] [Batch 40/300] [D loss: 0.752677] [G loss: 0.531429] time: 0:28:35.461487\n",
      "0.93605775\n",
      "[Epoch 19/50] [Batch 41/300] [D loss: 0.752668] [G loss: 0.550231] time: 0:28:35.770537\n",
      "0.9379347\n",
      "[Epoch 19/50] [Batch 42/300] [D loss: 0.752678] [G loss: 0.580408] time: 0:28:36.060267\n",
      "0.934875\n",
      "[Epoch 19/50] [Batch 43/300] [D loss: 0.752705] [G loss: 0.555092] time: 0:28:36.337948\n",
      "0.9150931\n",
      "[Epoch 19/50] [Batch 44/300] [D loss: 0.752676] [G loss: 0.581011] time: 0:28:36.636487\n",
      "0.9442504\n",
      "[Epoch 19/50] [Batch 45/300] [D loss: 0.752694] [G loss: 0.528134] time: 0:28:36.938115\n",
      "0.8811143\n",
      "[Epoch 19/50] [Batch 46/300] [D loss: 0.752690] [G loss: 0.540791] time: 0:28:37.224709\n",
      "0.86845404\n",
      "[Epoch 19/50] [Batch 47/300] [D loss: 0.752671] [G loss: 0.529975] time: 0:28:37.533858\n",
      "0.94661474\n",
      "[Epoch 19/50] [Batch 48/300] [D loss: 0.752724] [G loss: 0.554166] time: 0:28:37.853586\n",
      "0.93501186\n",
      "[Epoch 19/50] [Batch 49/300] [D loss: 0.752673] [G loss: 0.542609] time: 0:28:38.135063\n",
      "0.91503257\n",
      "[Epoch 19/50] [Batch 50/300] [D loss: 0.752701] [G loss: 0.522138] time: 0:28:38.428336\n",
      "0.88334686\n",
      "[Epoch 19/50] [Batch 51/300] [D loss: 0.752695] [G loss: 0.525920] time: 0:28:38.716345\n",
      "0.90767765\n",
      "[Epoch 19/50] [Batch 52/300] [D loss: 0.752682] [G loss: 0.573787] time: 0:28:39.008513\n",
      "0.8760812\n",
      "[Epoch 19/50] [Batch 53/300] [D loss: 0.752686] [G loss: 0.584439] time: 0:28:39.311070\n",
      "0.90874726\n",
      "[Epoch 19/50] [Batch 54/300] [D loss: 0.752707] [G loss: 0.506550] time: 0:28:39.587953\n",
      "0.92050844\n",
      "[Epoch 19/50] [Batch 55/300] [D loss: 0.752695] [G loss: 0.578382] time: 0:28:39.870914\n",
      "0.9463475\n",
      "[Epoch 19/50] [Batch 56/300] [D loss: 0.752721] [G loss: 0.517421] time: 0:28:40.167308\n",
      "0.92446345\n",
      "[Epoch 19/50] [Batch 57/300] [D loss: 0.752705] [G loss: 0.569029] time: 0:28:40.470035\n",
      "0.9262328\n",
      "[Epoch 19/50] [Batch 58/300] [D loss: 0.752711] [G loss: 0.512262] time: 0:28:40.764724\n",
      "0.947956\n",
      "[Epoch 19/50] [Batch 59/300] [D loss: 0.752687] [G loss: 0.541056] time: 0:28:41.057619\n",
      "0.92913264\n",
      "[Epoch 19/50] [Batch 60/300] [D loss: 0.752685] [G loss: 0.558672] time: 0:28:41.349473\n",
      "0.920109\n",
      "[Epoch 19/50] [Batch 61/300] [D loss: 0.752693] [G loss: 0.521351] time: 0:28:41.645031\n",
      "0.92486817\n",
      "[Epoch 19/50] [Batch 62/300] [D loss: 0.752694] [G loss: 0.535371] time: 0:28:41.938356\n",
      "0.91515225\n",
      "[Epoch 19/50] [Batch 63/300] [D loss: 0.752669] [G loss: 0.517399] time: 0:28:42.226278\n",
      "0.97650033\n",
      "[Epoch 19/50] [Batch 64/300] [D loss: 0.752693] [G loss: 0.561674] time: 0:28:42.497449\n",
      "0.91282725\n",
      "[Epoch 19/50] [Batch 65/300] [D loss: 0.752674] [G loss: 0.550248] time: 0:28:42.799178\n",
      "0.9417847\n",
      "[Epoch 19/50] [Batch 66/300] [D loss: 0.752723] [G loss: 0.524953] time: 0:28:43.095921\n",
      "0.93500185\n",
      "[Epoch 19/50] [Batch 67/300] [D loss: 0.752678] [G loss: 0.553514] time: 0:28:43.392246\n",
      "0.9138389\n",
      "[Epoch 19/50] [Batch 68/300] [D loss: 0.752699] [G loss: 0.568944] time: 0:28:43.687848\n",
      "0.90179175\n",
      "[Epoch 19/50] [Batch 69/300] [D loss: 0.752683] [G loss: 0.554923] time: 0:28:43.994430\n",
      "0.9480919\n",
      "[Epoch 19/50] [Batch 70/300] [D loss: 0.752667] [G loss: 0.542669] time: 0:28:44.305894\n",
      "0.9054006\n",
      "[Epoch 19/50] [Batch 71/300] [D loss: 0.752689] [G loss: 0.511475] time: 0:28:44.584296\n",
      "0.9604635\n",
      "[Epoch 19/50] [Batch 72/300] [D loss: 0.752677] [G loss: 0.546782] time: 0:28:44.873604\n",
      "0.9212133\n",
      "[Epoch 19/50] [Batch 73/300] [D loss: 0.752690] [G loss: 0.501954] time: 0:28:45.188358\n",
      "0.91963077\n",
      "[Epoch 19/50] [Batch 74/300] [D loss: 0.752679] [G loss: 0.546268] time: 0:28:45.490132\n",
      "0.9617563\n",
      "[Epoch 19/50] [Batch 75/300] [D loss: 0.752706] [G loss: 0.550533] time: 0:28:45.784651\n",
      "0.87375855\n",
      "[Epoch 19/50] [Batch 76/300] [D loss: 0.752668] [G loss: 0.518804] time: 0:28:46.082011\n",
      "0.9253686\n",
      "[Epoch 19/50] [Batch 77/300] [D loss: 0.752679] [G loss: 0.555098] time: 0:28:46.376770\n",
      "0.92661554\n",
      "[Epoch 19/50] [Batch 78/300] [D loss: 0.752695] [G loss: 0.536010] time: 0:28:46.669912\n",
      "0.9090514\n",
      "[Epoch 19/50] [Batch 79/300] [D loss: 0.752689] [G loss: 0.553080] time: 0:28:46.973325\n",
      "0.925083\n",
      "[Epoch 19/50] [Batch 80/300] [D loss: 0.752677] [G loss: 0.524304] time: 0:28:47.259096\n",
      "0.9052348\n",
      "[Epoch 19/50] [Batch 81/300] [D loss: 0.752678] [G loss: 0.526745] time: 0:28:47.537833\n",
      "0.94514066\n",
      "[Epoch 19/50] [Batch 82/300] [D loss: 0.752678] [G loss: 0.554641] time: 0:28:47.834228\n",
      "0.90473264\n",
      "[Epoch 19/50] [Batch 83/300] [D loss: 0.752669] [G loss: 0.516621] time: 0:28:48.118741\n",
      "0.9043486\n",
      "[Epoch 19/50] [Batch 84/300] [D loss: 0.752694] [G loss: 0.533463] time: 0:28:48.401019\n",
      "0.9565401\n",
      "[Epoch 19/50] [Batch 85/300] [D loss: 0.752690] [G loss: 0.565503] time: 0:28:48.716334\n",
      "0.9385242\n",
      "[Epoch 19/50] [Batch 86/300] [D loss: 0.752714] [G loss: 0.517356] time: 0:28:49.012921\n",
      "0.94860286\n",
      "[Epoch 19/50] [Batch 87/300] [D loss: 0.752648] [G loss: 0.505383] time: 0:28:49.333671\n",
      "0.8956768\n",
      "[Epoch 19/50] [Batch 88/300] [D loss: 0.752651] [G loss: 0.536229] time: 0:28:49.628866\n",
      "0.9447927\n",
      "[Epoch 19/50] [Batch 89/300] [D loss: 0.752678] [G loss: 0.530698] time: 0:28:49.935497\n",
      "0.9334052\n",
      "[Epoch 19/50] [Batch 90/300] [D loss: 0.752676] [G loss: 0.575913] time: 0:28:50.242583\n",
      "0.93042165\n",
      "[Epoch 19/50] [Batch 91/300] [D loss: 0.752701] [G loss: 0.535123] time: 0:28:50.534045\n",
      "0.89351183\n",
      "[Epoch 19/50] [Batch 92/300] [D loss: 0.752691] [G loss: 0.560742] time: 0:28:50.838551\n",
      "0.90617204\n",
      "[Epoch 19/50] [Batch 93/300] [D loss: 0.752698] [G loss: 0.540822] time: 0:28:51.142715\n",
      "0.9043565\n",
      "[Epoch 19/50] [Batch 94/300] [D loss: 0.752680] [G loss: 0.560234] time: 0:28:51.424000\n",
      "0.9196684\n",
      "[Epoch 19/50] [Batch 95/300] [D loss: 0.752685] [G loss: 0.516827] time: 0:28:51.727510\n",
      "0.9181885\n",
      "[Epoch 19/50] [Batch 96/300] [D loss: 0.752709] [G loss: 0.517062] time: 0:28:52.025371\n",
      "0.9312725\n",
      "[Epoch 19/50] [Batch 97/300] [D loss: 0.752707] [G loss: 0.534620] time: 0:28:52.331448\n",
      "0.9014966\n",
      "[Epoch 19/50] [Batch 98/300] [D loss: 0.752667] [G loss: 0.503813] time: 0:28:52.637140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94621724\n",
      "[Epoch 19/50] [Batch 99/300] [D loss: 0.752692] [G loss: 0.536709] time: 0:28:52.950884\n",
      "0.9086325\n",
      "[Epoch 19/50] [Batch 100/300] [D loss: 0.752702] [G loss: 0.558145] time: 0:28:53.247945\n",
      "0.90594167\n",
      "[Epoch 19/50] [Batch 101/300] [D loss: 0.752661] [G loss: 0.530633] time: 0:28:53.559588\n",
      "0.91981506\n",
      "[Epoch 19/50] [Batch 102/300] [D loss: 0.752695] [G loss: 0.534754] time: 0:28:53.864264\n",
      "0.8800494\n",
      "[Epoch 19/50] [Batch 103/300] [D loss: 0.752638] [G loss: 0.507395] time: 0:28:54.166477\n",
      "0.91315776\n",
      "[Epoch 19/50] [Batch 104/300] [D loss: 0.752677] [G loss: 0.510926] time: 0:28:54.479955\n",
      "0.942401\n",
      "[Epoch 19/50] [Batch 105/300] [D loss: 0.752683] [G loss: 0.563303] time: 0:28:54.788602\n",
      "0.90571994\n",
      "[Epoch 19/50] [Batch 106/300] [D loss: 0.752696] [G loss: 0.519499] time: 0:28:55.072746\n",
      "0.89279634\n",
      "[Epoch 19/50] [Batch 107/300] [D loss: 0.752667] [G loss: 0.547939] time: 0:28:55.378452\n",
      "0.95066786\n",
      "[Epoch 19/50] [Batch 108/300] [D loss: 0.752685] [G loss: 0.512777] time: 0:28:55.664990\n",
      "0.88759345\n",
      "[Epoch 19/50] [Batch 109/300] [D loss: 0.752716] [G loss: 0.518293] time: 0:28:55.948936\n",
      "0.9160776\n",
      "[Epoch 19/50] [Batch 110/300] [D loss: 0.752706] [G loss: 0.515562] time: 0:28:56.245111\n",
      "0.91909987\n",
      "[Epoch 19/50] [Batch 111/300] [D loss: 0.752685] [G loss: 0.512120] time: 0:28:56.544934\n",
      "0.9325679\n",
      "[Epoch 19/50] [Batch 112/300] [D loss: 0.752719] [G loss: 0.581656] time: 0:28:56.831763\n",
      "0.9036467\n",
      "[Epoch 19/50] [Batch 113/300] [D loss: 0.752702] [G loss: 0.522142] time: 0:28:57.134763\n",
      "0.9406576\n",
      "[Epoch 19/50] [Batch 114/300] [D loss: 0.752683] [G loss: 0.578668] time: 0:28:57.438990\n",
      "0.9008579\n",
      "[Epoch 19/50] [Batch 115/300] [D loss: 0.752682] [G loss: 0.524501] time: 0:28:57.724695\n",
      "0.9351328\n",
      "[Epoch 19/50] [Batch 116/300] [D loss: 0.752672] [G loss: 0.571218] time: 0:28:58.020754\n",
      "0.90604687\n",
      "[Epoch 19/50] [Batch 117/300] [D loss: 0.752693] [G loss: 0.566686] time: 0:28:58.318042\n",
      "0.9337909\n",
      "[Epoch 19/50] [Batch 118/300] [D loss: 0.752683] [G loss: 0.530968] time: 0:28:58.603593\n",
      "0.97594625\n",
      "[Epoch 19/50] [Batch 119/300] [D loss: 0.752670] [G loss: 0.558863] time: 0:28:58.884141\n",
      "0.9288977\n",
      "[Epoch 19/50] [Batch 120/300] [D loss: 0.752693] [G loss: 0.518568] time: 0:28:59.185753\n",
      "0.94507617\n",
      "[Epoch 19/50] [Batch 121/300] [D loss: 0.752698] [G loss: 0.532671] time: 0:28:59.483202\n",
      "0.9270058\n",
      "[Epoch 19/50] [Batch 122/300] [D loss: 0.752653] [G loss: 0.496172] time: 0:28:59.757431\n",
      "0.9523139\n",
      "[Epoch 19/50] [Batch 123/300] [D loss: 0.752682] [G loss: 0.542613] time: 0:29:00.051986\n",
      "0.90816313\n",
      "[Epoch 19/50] [Batch 124/300] [D loss: 0.752724] [G loss: 0.497209] time: 0:29:00.332490\n",
      "0.9354451\n",
      "[Epoch 19/50] [Batch 125/300] [D loss: 0.752698] [G loss: 0.560237] time: 0:29:00.636580\n",
      "0.9140711\n",
      "[Epoch 19/50] [Batch 126/300] [D loss: 0.752706] [G loss: 0.506656] time: 0:29:00.949259\n",
      "0.8960929\n",
      "[Epoch 19/50] [Batch 127/300] [D loss: 0.752650] [G loss: 0.517612] time: 0:29:01.229980\n",
      "0.8932848\n",
      "[Epoch 19/50] [Batch 128/300] [D loss: 0.752649] [G loss: 0.521179] time: 0:29:01.526749\n",
      "0.90872216\n",
      "[Epoch 19/50] [Batch 129/300] [D loss: 0.752652] [G loss: 0.510097] time: 0:29:01.833367\n",
      "0.93097466\n",
      "[Epoch 19/50] [Batch 130/300] [D loss: 0.752672] [G loss: 0.555808] time: 0:29:02.119537\n",
      "0.9307318\n",
      "[Epoch 19/50] [Batch 131/300] [D loss: 0.752623] [G loss: 0.547426] time: 0:29:02.404010\n",
      "0.9504028\n",
      "[Epoch 19/50] [Batch 132/300] [D loss: 0.752702] [G loss: 0.607350] time: 0:29:02.706775\n",
      "0.9046503\n",
      "[Epoch 19/50] [Batch 133/300] [D loss: 0.752677] [G loss: 0.513204] time: 0:29:03.007505\n",
      "0.91489667\n",
      "[Epoch 19/50] [Batch 134/300] [D loss: 0.752681] [G loss: 0.506675] time: 0:29:03.298811\n",
      "0.888515\n",
      "[Epoch 19/50] [Batch 135/300] [D loss: 0.752689] [G loss: 0.506389] time: 0:29:03.603020\n",
      "0.9455807\n",
      "[Epoch 19/50] [Batch 136/300] [D loss: 0.752655] [G loss: 0.535718] time: 0:29:03.901274\n",
      "0.9506213\n",
      "[Epoch 19/50] [Batch 137/300] [D loss: 0.752680] [G loss: 0.519755] time: 0:29:04.196798\n",
      "0.8899331\n",
      "[Epoch 19/50] [Batch 138/300] [D loss: 0.752695] [G loss: 0.511636] time: 0:29:04.498026\n",
      "0.90802866\n",
      "[Epoch 19/50] [Batch 139/300] [D loss: 0.752697] [G loss: 0.548309] time: 0:29:04.765236\n",
      "0.9182692\n",
      "[Epoch 19/50] [Batch 140/300] [D loss: 0.752658] [G loss: 0.543367] time: 0:29:05.062690\n",
      "0.9222283\n",
      "[Epoch 19/50] [Batch 141/300] [D loss: 0.752675] [G loss: 0.505278] time: 0:29:05.381815\n",
      "0.9101363\n",
      "[Epoch 19/50] [Batch 142/300] [D loss: 0.752685] [G loss: 0.589449] time: 0:29:05.683779\n",
      "0.9459041\n",
      "[Epoch 19/50] [Batch 143/300] [D loss: 0.752657] [G loss: 0.523504] time: 0:29:05.982210\n",
      "0.91080993\n",
      "[Epoch 19/50] [Batch 144/300] [D loss: 0.752698] [G loss: 0.529583] time: 0:29:06.289603\n",
      "0.9193483\n",
      "[Epoch 19/50] [Batch 145/300] [D loss: 0.752665] [G loss: 0.502657] time: 0:29:06.599995\n",
      "0.970735\n",
      "[Epoch 19/50] [Batch 146/300] [D loss: 0.752687] [G loss: 0.514962] time: 0:29:06.880686\n",
      "0.8748073\n",
      "[Epoch 19/50] [Batch 147/300] [D loss: 0.752722] [G loss: 0.517700] time: 0:29:07.173489\n",
      "0.88045615\n",
      "[Epoch 19/50] [Batch 148/300] [D loss: 0.752656] [G loss: 0.536022] time: 0:29:07.453708\n",
      "0.9059233\n",
      "[Epoch 19/50] [Batch 149/300] [D loss: 0.752674] [G loss: 0.516846] time: 0:29:07.745857\n",
      "0.92273015\n",
      "[Epoch 19/50] [Batch 150/300] [D loss: 0.752680] [G loss: 0.567820] time: 0:29:08.045792\n",
      "0.8609991\n",
      "[Epoch 19/50] [Batch 151/300] [D loss: 0.752708] [G loss: 0.573439] time: 0:29:08.346929\n",
      "0.931343\n",
      "[Epoch 19/50] [Batch 152/300] [D loss: 0.752691] [G loss: 0.534776] time: 0:29:08.629846\n",
      "0.8892594\n",
      "[Epoch 19/50] [Batch 153/300] [D loss: 0.752709] [G loss: 0.508651] time: 0:29:08.925702\n",
      "0.9079234\n",
      "[Epoch 19/50] [Batch 154/300] [D loss: 0.752666] [G loss: 0.545410] time: 0:29:09.228241\n",
      "0.93345785\n",
      "[Epoch 19/50] [Batch 155/300] [D loss: 0.752673] [G loss: 0.544581] time: 0:29:09.513919\n",
      "0.9357117\n",
      "[Epoch 19/50] [Batch 156/300] [D loss: 0.752665] [G loss: 0.538712] time: 0:29:09.805582\n",
      "0.9493067\n",
      "[Epoch 19/50] [Batch 157/300] [D loss: 0.752693] [G loss: 0.537447] time: 0:29:10.088751\n",
      "0.9357775\n",
      "[Epoch 19/50] [Batch 158/300] [D loss: 0.752668] [G loss: 0.525180] time: 0:29:10.389905\n",
      "0.9031298\n",
      "[Epoch 19/50] [Batch 159/300] [D loss: 0.752670] [G loss: 0.501623] time: 0:29:10.675633\n",
      "0.9494168\n",
      "[Epoch 19/50] [Batch 160/300] [D loss: 0.752714] [G loss: 0.573429] time: 0:29:10.974036\n",
      "0.9219675\n",
      "[Epoch 19/50] [Batch 161/300] [D loss: 0.752685] [G loss: 0.553525] time: 0:29:11.272079\n",
      "0.909853\n",
      "[Epoch 19/50] [Batch 162/300] [D loss: 0.752685] [G loss: 0.520575] time: 0:29:11.555600\n",
      "0.87525254\n",
      "[Epoch 19/50] [Batch 163/300] [D loss: 0.752680] [G loss: 0.569831] time: 0:29:11.848464\n",
      "0.9336149\n",
      "[Epoch 19/50] [Batch 164/300] [D loss: 0.752670] [G loss: 0.552113] time: 0:29:12.154120\n",
      "0.84709954\n",
      "[Epoch 19/50] [Batch 165/300] [D loss: 0.752658] [G loss: 0.567378] time: 0:29:12.453547\n",
      "0.9246897\n",
      "[Epoch 19/50] [Batch 166/300] [D loss: 0.752702] [G loss: 0.557946] time: 0:29:12.776475\n",
      "0.9141774\n",
      "[Epoch 19/50] [Batch 167/300] [D loss: 0.752660] [G loss: 0.543899] time: 0:29:13.083694\n",
      "0.88171726\n",
      "[Epoch 19/50] [Batch 168/300] [D loss: 0.752686] [G loss: 0.525658] time: 0:29:13.396380\n",
      "0.94566613\n",
      "[Epoch 19/50] [Batch 169/300] [D loss: 0.752671] [G loss: 0.511909] time: 0:29:13.701213\n",
      "0.9106526\n",
      "[Epoch 19/50] [Batch 170/300] [D loss: 0.752650] [G loss: 0.535732] time: 0:29:13.984585\n",
      "0.8969009\n",
      "[Epoch 19/50] [Batch 171/300] [D loss: 0.752676] [G loss: 0.550667] time: 0:29:14.280090\n",
      "0.90830535\n",
      "[Epoch 19/50] [Batch 172/300] [D loss: 0.752666] [G loss: 0.579357] time: 0:29:14.586661\n",
      "0.8808555\n",
      "[Epoch 19/50] [Batch 173/300] [D loss: 0.752682] [G loss: 0.556790] time: 0:29:14.869433\n",
      "0.90820307\n",
      "[Epoch 19/50] [Batch 174/300] [D loss: 0.752667] [G loss: 0.524671] time: 0:29:15.186925\n",
      "0.908109\n",
      "[Epoch 19/50] [Batch 175/300] [D loss: 0.752699] [G loss: 0.504625] time: 0:29:15.492133\n",
      "0.88933873\n",
      "[Epoch 19/50] [Batch 176/300] [D loss: 0.752645] [G loss: 0.559243] time: 0:29:15.800345\n",
      "0.97636956\n",
      "[Epoch 19/50] [Batch 177/300] [D loss: 0.752657] [G loss: 0.523702] time: 0:29:16.093062\n",
      "0.94511694\n",
      "[Epoch 19/50] [Batch 178/300] [D loss: 0.752702] [G loss: 0.511920] time: 0:29:16.387925\n",
      "0.9163618\n",
      "[Epoch 19/50] [Batch 179/300] [D loss: 0.752692] [G loss: 0.563439] time: 0:29:16.682280\n",
      "0.93718535\n",
      "[Epoch 19/50] [Batch 180/300] [D loss: 0.752685] [G loss: 0.531344] time: 0:29:16.994625\n",
      "0.8780911\n",
      "[Epoch 19/50] [Batch 181/300] [D loss: 0.752666] [G loss: 0.533647] time: 0:29:17.283792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94630414\n",
      "[Epoch 19/50] [Batch 182/300] [D loss: 0.752692] [G loss: 0.545868] time: 0:29:17.586214\n",
      "0.91572195\n",
      "[Epoch 19/50] [Batch 183/300] [D loss: 0.752699] [G loss: 0.491850] time: 0:29:17.880350\n",
      "0.917245\n",
      "[Epoch 19/50] [Batch 184/300] [D loss: 0.752676] [G loss: 0.521754] time: 0:29:18.193375\n",
      "0.9563454\n",
      "[Epoch 19/50] [Batch 185/300] [D loss: 0.752677] [G loss: 0.510790] time: 0:29:18.497386\n",
      "0.9405651\n",
      "[Epoch 19/50] [Batch 186/300] [D loss: 0.752691] [G loss: 0.546578] time: 0:29:18.794080\n",
      "0.9136915\n",
      "[Epoch 19/50] [Batch 187/300] [D loss: 0.752650] [G loss: 0.551853] time: 0:29:19.082758\n",
      "0.9310668\n",
      "[Epoch 19/50] [Batch 188/300] [D loss: 0.752701] [G loss: 0.510840] time: 0:29:19.395467\n",
      "0.9064133\n",
      "[Epoch 19/50] [Batch 189/300] [D loss: 0.752646] [G loss: 0.524600] time: 0:29:19.709117\n",
      "0.92555904\n",
      "[Epoch 19/50] [Batch 190/300] [D loss: 0.752668] [G loss: 0.515303] time: 0:29:20.010344\n",
      "0.9057806\n",
      "[Epoch 19/50] [Batch 191/300] [D loss: 0.752660] [G loss: 0.510011] time: 0:29:20.315518\n",
      "0.97648025\n",
      "[Epoch 19/50] [Batch 192/300] [D loss: 0.752708] [G loss: 0.521442] time: 0:29:20.617942\n",
      "0.9532599\n",
      "[Epoch 19/50] [Batch 193/300] [D loss: 0.752678] [G loss: 0.499104] time: 0:29:20.913803\n",
      "0.8953808\n",
      "[Epoch 19/50] [Batch 194/300] [D loss: 0.752642] [G loss: 0.573006] time: 0:29:21.203618\n",
      "0.87748617\n",
      "[Epoch 19/50] [Batch 195/300] [D loss: 0.752702] [G loss: 0.538157] time: 0:29:21.506940\n",
      "0.9141109\n",
      "[Epoch 19/50] [Batch 196/300] [D loss: 0.752712] [G loss: 0.516276] time: 0:29:21.805056\n",
      "0.9019508\n",
      "[Epoch 19/50] [Batch 197/300] [D loss: 0.752657] [G loss: 0.584518] time: 0:29:22.085322\n",
      "0.9332078\n",
      "[Epoch 19/50] [Batch 198/300] [D loss: 0.752669] [G loss: 0.545888] time: 0:29:22.377901\n",
      "0.90535444\n",
      "[Epoch 19/50] [Batch 199/300] [D loss: 0.752661] [G loss: 0.537895] time: 0:29:22.676439\n",
      "0.930317\n",
      "[Epoch 19/50] [Batch 200/300] [D loss: 0.752678] [G loss: 0.536989] time: 0:29:22.971079\n",
      "0.86151904\n",
      "[Epoch 19/50] [Batch 201/300] [D loss: 0.752657] [G loss: 0.526684] time: 0:29:23.271858\n",
      "0.90845126\n",
      "[Epoch 19/50] [Batch 202/300] [D loss: 0.752663] [G loss: 0.521334] time: 0:29:23.562546\n",
      "0.9232104\n",
      "[Epoch 19/50] [Batch 203/300] [D loss: 0.752699] [G loss: 0.511079] time: 0:29:23.844759\n",
      "0.8812482\n",
      "[Epoch 19/50] [Batch 204/300] [D loss: 0.752637] [G loss: 0.520522] time: 0:29:24.149202\n",
      "0.9188151\n",
      "[Epoch 19/50] [Batch 205/300] [D loss: 0.752660] [G loss: 0.572820] time: 0:29:24.445956\n",
      "0.88628864\n",
      "[Epoch 19/50] [Batch 206/300] [D loss: 0.752666] [G loss: 0.549103] time: 0:29:24.721882\n",
      "0.8695288\n",
      "[Epoch 19/50] [Batch 207/300] [D loss: 0.752679] [G loss: 0.545904] time: 0:29:25.004213\n",
      "0.91465217\n",
      "[Epoch 19/50] [Batch 208/300] [D loss: 0.752669] [G loss: 0.529293] time: 0:29:25.304156\n",
      "0.8920639\n",
      "[Epoch 19/50] [Batch 209/300] [D loss: 0.752647] [G loss: 0.549335] time: 0:29:25.602920\n",
      "0.9054594\n",
      "[Epoch 19/50] [Batch 210/300] [D loss: 0.752661] [G loss: 0.528700] time: 0:29:25.894575\n",
      "0.9366935\n",
      "[Epoch 19/50] [Batch 211/300] [D loss: 0.752677] [G loss: 0.545127] time: 0:29:26.193070\n",
      "0.95218366\n",
      "[Epoch 19/50] [Batch 212/300] [D loss: 0.752666] [G loss: 0.530995] time: 0:29:26.479770\n",
      "0.9492144\n",
      "[Epoch 19/50] [Batch 213/300] [D loss: 0.752692] [G loss: 0.509475] time: 0:29:26.790617\n",
      "0.94047886\n",
      "[Epoch 19/50] [Batch 214/300] [D loss: 0.752669] [G loss: 0.576455] time: 0:29:27.078104\n",
      "0.8763918\n",
      "[Epoch 19/50] [Batch 215/300] [D loss: 0.752668] [G loss: 0.527831] time: 0:29:27.378315\n",
      "0.90680677\n",
      "[Epoch 19/50] [Batch 216/300] [D loss: 0.752664] [G loss: 0.526580] time: 0:29:27.686846\n",
      "0.9240429\n",
      "[Epoch 19/50] [Batch 217/300] [D loss: 0.752701] [G loss: 0.546013] time: 0:29:27.990079\n",
      "0.9499245\n",
      "[Epoch 19/50] [Batch 218/300] [D loss: 0.752685] [G loss: 0.526391] time: 0:29:28.277622\n",
      "0.94475013\n",
      "[Epoch 19/50] [Batch 219/300] [D loss: 0.752712] [G loss: 0.510270] time: 0:29:28.574842\n",
      "0.8419893\n",
      "[Epoch 19/50] [Batch 220/300] [D loss: 0.752652] [G loss: 0.555613] time: 0:29:28.874417\n",
      "0.9086008\n",
      "[Epoch 19/50] [Batch 221/300] [D loss: 0.752646] [G loss: 0.525374] time: 0:29:29.177846\n",
      "0.9427965\n",
      "[Epoch 19/50] [Batch 222/300] [D loss: 0.752667] [G loss: 0.556840] time: 0:29:29.484677\n",
      "0.914233\n",
      "[Epoch 19/50] [Batch 223/300] [D loss: 0.752684] [G loss: 0.524751] time: 0:29:29.770533\n",
      "0.98283833\n",
      "[Epoch 19/50] [Batch 224/300] [D loss: 0.752661] [G loss: 0.571364] time: 0:29:30.033137\n",
      "0.9182727\n",
      "[Epoch 19/50] [Batch 225/300] [D loss: 0.752670] [G loss: 0.497859] time: 0:29:30.323625\n",
      "0.9027877\n",
      "[Epoch 19/50] [Batch 226/300] [D loss: 0.752636] [G loss: 0.534047] time: 0:29:30.605315\n",
      "0.97759676\n",
      "[Epoch 19/50] [Batch 227/300] [D loss: 0.752671] [G loss: 0.516551] time: 0:29:30.909504\n",
      "0.93787676\n",
      "[Epoch 19/50] [Batch 228/300] [D loss: 0.752673] [G loss: 0.569099] time: 0:29:31.194338\n",
      "0.9342087\n",
      "[Epoch 19/50] [Batch 229/300] [D loss: 0.752656] [G loss: 0.552903] time: 0:29:31.483400\n",
      "0.9166077\n",
      "[Epoch 19/50] [Batch 230/300] [D loss: 0.752656] [G loss: 0.530767] time: 0:29:31.773585\n",
      "0.9318559\n",
      "[Epoch 19/50] [Batch 231/300] [D loss: 0.752656] [G loss: 0.570759] time: 0:29:32.076297\n",
      "0.91392976\n",
      "[Epoch 19/50] [Batch 232/300] [D loss: 0.752638] [G loss: 0.536072] time: 0:29:32.375475\n",
      "0.9564405\n",
      "[Epoch 19/50] [Batch 233/300] [D loss: 0.752669] [G loss: 0.501716] time: 0:29:32.677872\n",
      "0.9319561\n",
      "[Epoch 19/50] [Batch 234/300] [D loss: 0.752649] [G loss: 0.542671] time: 0:29:32.964469\n",
      "0.91362906\n",
      "[Epoch 19/50] [Batch 235/300] [D loss: 0.752676] [G loss: 0.526734] time: 0:29:33.260334\n",
      "0.9035814\n",
      "[Epoch 19/50] [Batch 236/300] [D loss: 0.752665] [G loss: 0.536329] time: 0:29:33.568306\n",
      "0.9062547\n",
      "[Epoch 19/50] [Batch 237/300] [D loss: 0.752668] [G loss: 0.552228] time: 0:29:33.868148\n",
      "0.9398094\n",
      "[Epoch 19/50] [Batch 238/300] [D loss: 0.752660] [G loss: 0.545169] time: 0:29:34.171143\n",
      "0.9540534\n",
      "[Epoch 19/50] [Batch 239/300] [D loss: 0.752654] [G loss: 0.542942] time: 0:29:34.459504\n",
      "0.95229715\n",
      "[Epoch 19/50] [Batch 240/300] [D loss: 0.752654] [G loss: 0.504860] time: 0:29:34.740452\n",
      "0.8908686\n",
      "[Epoch 19/50] [Batch 241/300] [D loss: 0.752656] [G loss: 0.553386] time: 0:29:35.028857\n",
      "0.8996182\n",
      "[Epoch 19/50] [Batch 242/300] [D loss: 0.752701] [G loss: 0.553151] time: 0:29:35.332134\n",
      "0.899044\n",
      "[Epoch 19/50] [Batch 243/300] [D loss: 0.752666] [G loss: 0.560528] time: 0:29:35.624135\n",
      "0.8994622\n",
      "[Epoch 19/50] [Batch 244/300] [D loss: 0.752669] [G loss: 0.559058] time: 0:29:35.921743\n",
      "0.90318924\n",
      "[Epoch 19/50] [Batch 245/300] [D loss: 0.752646] [G loss: 0.539730] time: 0:29:36.220323\n",
      "0.9236812\n",
      "[Epoch 19/50] [Batch 246/300] [D loss: 0.752651] [G loss: 0.572151] time: 0:29:36.523591\n",
      "0.8716828\n",
      "[Epoch 19/50] [Batch 247/300] [D loss: 0.752650] [G loss: 0.551092] time: 0:29:36.835521\n",
      "0.85402864\n",
      "[Epoch 19/50] [Batch 248/300] [D loss: 0.752672] [G loss: 0.551362] time: 0:29:37.146255\n",
      "0.9353098\n",
      "[Epoch 19/50] [Batch 249/300] [D loss: 0.752674] [G loss: 0.611265] time: 0:29:37.441637\n",
      "0.8812446\n",
      "[Epoch 19/50] [Batch 250/300] [D loss: 0.752650] [G loss: 0.547517] time: 0:29:37.726000\n",
      "0.87272483\n",
      "[Epoch 19/50] [Batch 251/300] [D loss: 0.752675] [G loss: 0.549204] time: 0:29:38.017256\n",
      "0.9425938\n",
      "[Epoch 19/50] [Batch 252/300] [D loss: 0.752663] [G loss: 0.524047] time: 0:29:38.302908\n",
      "0.88414603\n",
      "[Epoch 19/50] [Batch 253/300] [D loss: 0.752666] [G loss: 0.532690] time: 0:29:38.601594\n",
      "0.92957133\n",
      "[Epoch 19/50] [Batch 254/300] [D loss: 0.752665] [G loss: 0.519820] time: 0:29:38.881870\n",
      "0.9493961\n",
      "[Epoch 19/50] [Batch 255/300] [D loss: 0.752670] [G loss: 0.526679] time: 0:29:39.179572\n",
      "0.95520896\n",
      "[Epoch 19/50] [Batch 256/300] [D loss: 0.752652] [G loss: 0.514137] time: 0:29:39.450615\n",
      "0.9111123\n",
      "[Epoch 19/50] [Batch 257/300] [D loss: 0.752659] [G loss: 0.561556] time: 0:29:39.745089\n",
      "0.94154257\n",
      "[Epoch 19/50] [Batch 258/300] [D loss: 0.752635] [G loss: 0.566748] time: 0:29:40.017584\n",
      "0.91099375\n",
      "[Epoch 19/50] [Batch 259/300] [D loss: 0.752646] [G loss: 0.572819] time: 0:29:40.310560\n",
      "0.938883\n",
      "[Epoch 19/50] [Batch 260/300] [D loss: 0.752674] [G loss: 0.562719] time: 0:29:40.616311\n",
      "0.9218111\n",
      "[Epoch 19/50] [Batch 261/300] [D loss: 0.752669] [G loss: 0.576268] time: 0:29:40.916292\n",
      "0.9140606\n",
      "[Epoch 19/50] [Batch 262/300] [D loss: 0.752664] [G loss: 0.529157] time: 0:29:41.214519\n",
      "0.93642\n",
      "[Epoch 19/50] [Batch 263/300] [D loss: 0.752674] [G loss: 0.522036] time: 0:29:41.501498\n",
      "0.9192555\n",
      "[Epoch 19/50] [Batch 264/300] [D loss: 0.752673] [G loss: 0.508648] time: 0:29:41.786066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9446912\n",
      "[Epoch 19/50] [Batch 265/300] [D loss: 0.752645] [G loss: 0.579407] time: 0:29:42.069654\n",
      "0.8820195\n",
      "[Epoch 19/50] [Batch 266/300] [D loss: 0.752649] [G loss: 0.561210] time: 0:29:42.350394\n",
      "0.93309927\n",
      "[Epoch 19/50] [Batch 267/300] [D loss: 0.752665] [G loss: 0.518414] time: 0:29:42.635340\n",
      "0.9053679\n",
      "[Epoch 19/50] [Batch 268/300] [D loss: 0.752660] [G loss: 0.586470] time: 0:29:42.930630\n",
      "0.93059486\n",
      "[Epoch 19/50] [Batch 269/300] [D loss: 0.752635] [G loss: 0.614168] time: 0:29:43.231151\n",
      "0.9553353\n",
      "[Epoch 19/50] [Batch 270/300] [D loss: 0.752663] [G loss: 0.515431] time: 0:29:43.530435\n",
      "0.93073016\n",
      "[Epoch 19/50] [Batch 271/300] [D loss: 0.752662] [G loss: 0.504042] time: 0:29:43.816126\n",
      "0.9305596\n",
      "[Epoch 19/50] [Batch 272/300] [D loss: 0.752679] [G loss: 0.508533] time: 0:29:44.122992\n",
      "0.9337681\n",
      "[Epoch 19/50] [Batch 273/300] [D loss: 0.752665] [G loss: 0.529107] time: 0:29:44.409230\n",
      "0.96190214\n",
      "[Epoch 19/50] [Batch 274/300] [D loss: 0.752662] [G loss: 0.484225] time: 0:29:44.682303\n",
      "0.9424786\n",
      "[Epoch 19/50] [Batch 275/300] [D loss: 0.752682] [G loss: 0.543437] time: 0:29:44.956241\n",
      "0.87501603\n",
      "[Epoch 19/50] [Batch 276/300] [D loss: 0.752668] [G loss: 0.548913] time: 0:29:45.249601\n",
      "0.91058826\n",
      "[Epoch 19/50] [Batch 277/300] [D loss: 0.752674] [G loss: 0.537907] time: 0:29:45.552092\n",
      "0.8988471\n",
      "[Epoch 19/50] [Batch 278/300] [D loss: 0.752668] [G loss: 0.517582] time: 0:29:45.842575\n",
      "0.9305308\n",
      "[Epoch 19/50] [Batch 279/300] [D loss: 0.752650] [G loss: 0.575487] time: 0:29:46.136058\n",
      "0.94633484\n",
      "[Epoch 19/50] [Batch 280/300] [D loss: 0.752684] [G loss: 0.520736] time: 0:29:46.429633\n",
      "0.8716175\n",
      "[Epoch 19/50] [Batch 281/300] [D loss: 0.752709] [G loss: 0.570612] time: 0:29:46.711106\n",
      "0.9351744\n",
      "[Epoch 19/50] [Batch 282/300] [D loss: 0.752661] [G loss: 0.539443] time: 0:29:47.011239\n",
      "0.91033345\n",
      "[Epoch 19/50] [Batch 283/300] [D loss: 0.752625] [G loss: 0.579708] time: 0:29:47.314747\n",
      "0.87664086\n",
      "[Epoch 19/50] [Batch 284/300] [D loss: 0.752651] [G loss: 0.560969] time: 0:29:47.612999\n",
      "0.9117257\n",
      "[Epoch 19/50] [Batch 285/300] [D loss: 0.752664] [G loss: 0.533713] time: 0:29:47.913550\n",
      "0.8839726\n",
      "[Epoch 19/50] [Batch 286/300] [D loss: 0.752674] [G loss: 0.515970] time: 0:29:48.208194\n",
      "0.94289345\n",
      "[Epoch 19/50] [Batch 287/300] [D loss: 0.752684] [G loss: 0.518035] time: 0:29:48.502737\n",
      "0.94751096\n",
      "[Epoch 19/50] [Batch 288/300] [D loss: 0.752662] [G loss: 0.582873] time: 0:29:48.786887\n",
      "0.9149823\n",
      "[Epoch 19/50] [Batch 289/300] [D loss: 0.752671] [G loss: 0.519923] time: 0:29:49.096710\n",
      "0.92534393\n",
      "[Epoch 19/50] [Batch 290/300] [D loss: 0.752667] [G loss: 0.538466] time: 0:29:49.401641\n",
      "0.97109014\n",
      "[Epoch 19/50] [Batch 291/300] [D loss: 0.752665] [G loss: 0.538537] time: 0:29:49.704777\n",
      "0.9565484\n",
      "[Epoch 19/50] [Batch 292/300] [D loss: 0.752678] [G loss: 0.553093] time: 0:29:50.013367\n",
      "0.94248694\n",
      "[Epoch 19/50] [Batch 293/300] [D loss: 0.752668] [G loss: 0.517128] time: 0:29:50.318424\n",
      "0.88393253\n",
      "[Epoch 19/50] [Batch 294/300] [D loss: 0.752672] [G loss: 0.530912] time: 0:29:50.633705\n",
      "0.905744\n",
      "[Epoch 19/50] [Batch 295/300] [D loss: 0.752665] [G loss: 0.529594] time: 0:29:50.924602\n",
      "0.91035074\n",
      "[Epoch 19/50] [Batch 296/300] [D loss: 0.752679] [G loss: 0.542586] time: 0:29:51.210594\n",
      "0.91785914\n",
      "[Epoch 19/50] [Batch 297/300] [D loss: 0.752664] [G loss: 0.527532] time: 0:29:51.508337\n",
      "0.9430421\n",
      "[Epoch 19/50] [Batch 298/300] [D loss: 0.752651] [G loss: 0.522116] time: 0:29:51.790198\n",
      "0.91141933\n",
      "[Epoch 19/50] [Batch 299/300] [D loss: 0.752637] [G loss: 0.549774] time: 0:29:52.081342\n",
      "0.98235005\n",
      "[Epoch 20/50] [Batch 0/300] [D loss: 0.752661] [G loss: 0.526911] time: 0:29:52.389161\n",
      "0.87187773\n",
      "[Epoch 20/50] [Batch 1/300] [D loss: 0.752637] [G loss: 0.601065] time: 0:29:52.684239\n",
      "0.9496067\n",
      "[Epoch 20/50] [Batch 2/300] [D loss: 0.752682] [G loss: 0.535415] time: 0:29:52.994595\n",
      "0.9307222\n",
      "[Epoch 20/50] [Batch 3/300] [D loss: 0.752659] [G loss: 0.529056] time: 0:29:53.286970\n",
      "0.94779307\n",
      "[Epoch 20/50] [Batch 4/300] [D loss: 0.752663] [G loss: 0.532973] time: 0:29:53.598222\n",
      "0.9201684\n",
      "[Epoch 20/50] [Batch 5/300] [D loss: 0.752643] [G loss: 0.538713] time: 0:29:53.886443\n",
      "0.91815686\n",
      "[Epoch 20/50] [Batch 6/300] [D loss: 0.752624] [G loss: 0.533512] time: 0:29:54.165922\n",
      "0.97603583\n",
      "[Epoch 20/50] [Batch 7/300] [D loss: 0.752673] [G loss: 0.572838] time: 0:29:54.444491\n",
      "0.93606186\n",
      "[Epoch 20/50] [Batch 8/300] [D loss: 0.752676] [G loss: 0.520313] time: 0:29:54.746344\n",
      "0.9413955\n",
      "[Epoch 20/50] [Batch 9/300] [D loss: 0.752667] [G loss: 0.527850] time: 0:29:55.053782\n",
      "0.93340796\n",
      "[Epoch 20/50] [Batch 10/300] [D loss: 0.752671] [G loss: 0.541965] time: 0:29:55.329123\n",
      "0.9330279\n",
      "[Epoch 20/50] [Batch 11/300] [D loss: 0.752655] [G loss: 0.525067] time: 0:29:55.618713\n",
      "0.9256501\n",
      "[Epoch 20/50] [Batch 12/300] [D loss: 0.752659] [G loss: 0.515796] time: 0:29:55.921354\n",
      "0.8952777\n",
      "[Epoch 20/50] [Batch 13/300] [D loss: 0.752661] [G loss: 0.534576] time: 0:29:56.224607\n",
      "0.9208424\n",
      "[Epoch 20/50] [Batch 14/300] [D loss: 0.752648] [G loss: 0.593007] time: 0:29:56.533820\n",
      "0.88947344\n",
      "[Epoch 20/50] [Batch 15/300] [D loss: 0.752631] [G loss: 0.544093] time: 0:29:56.827032\n",
      "0.93486327\n",
      "[Epoch 20/50] [Batch 16/300] [D loss: 0.752627] [G loss: 0.544246] time: 0:29:57.123000\n",
      "0.9173994\n",
      "[Epoch 20/50] [Batch 17/300] [D loss: 0.752672] [G loss: 0.517333] time: 0:29:57.434443\n",
      "0.93161243\n",
      "[Epoch 20/50] [Batch 18/300] [D loss: 0.752666] [G loss: 0.532005] time: 0:29:57.732003\n",
      "0.8991545\n",
      "[Epoch 20/50] [Batch 20/300] [D loss: 0.752648] [G loss: 0.502744] time: 0:29:58.045180\n",
      "0.9332803\n",
      "[Epoch 20/50] [Batch 21/300] [D loss: 0.752663] [G loss: 0.516465] time: 0:29:58.345491\n",
      "0.88530546\n",
      "[Epoch 20/50] [Batch 22/300] [D loss: 0.752638] [G loss: 0.517884] time: 0:29:58.648585\n",
      "0.92186785\n",
      "[Epoch 20/50] [Batch 23/300] [D loss: 0.752644] [G loss: 0.512062] time: 0:29:58.953363\n",
      "0.88940614\n",
      "[Epoch 20/50] [Batch 24/300] [D loss: 0.752659] [G loss: 0.538131] time: 0:29:59.252136\n",
      "0.9146711\n",
      "[Epoch 20/50] [Batch 25/300] [D loss: 0.752648] [G loss: 0.501917] time: 0:29:59.549090\n",
      "0.90571004\n",
      "[Epoch 20/50] [Batch 26/300] [D loss: 0.752634] [G loss: 0.530029] time: 0:29:59.844644\n",
      "0.94849974\n",
      "[Epoch 20/50] [Batch 27/300] [D loss: 0.752636] [G loss: 0.506231] time: 0:30:00.144229\n",
      "0.91172105\n",
      "[Epoch 20/50] [Batch 28/300] [D loss: 0.752658] [G loss: 0.513216] time: 0:30:00.444823\n",
      "0.8838286\n",
      "[Epoch 20/50] [Batch 29/300] [D loss: 0.752655] [G loss: 0.532511] time: 0:30:00.725537\n",
      "0.9180577\n",
      "[Epoch 20/50] [Batch 30/300] [D loss: 0.752656] [G loss: 0.525018] time: 0:30:01.024019\n",
      "0.95243627\n",
      "[Epoch 20/50] [Batch 31/300] [D loss: 0.752658] [G loss: 0.508887] time: 0:30:01.326171\n",
      "0.90887004\n",
      "[Epoch 20/50] [Batch 32/300] [D loss: 0.752666] [G loss: 0.512934] time: 0:30:01.610152\n",
      "0.92361975\n",
      "[Epoch 20/50] [Batch 33/300] [D loss: 0.752664] [G loss: 0.523311] time: 0:30:01.892714\n",
      "0.9503122\n",
      "[Epoch 20/50] [Batch 34/300] [D loss: 0.752637] [G loss: 0.500498] time: 0:30:02.213865\n",
      "0.88565135\n",
      "[Epoch 20/50] [Batch 35/300] [D loss: 0.752654] [G loss: 0.558649] time: 0:30:02.512876\n",
      "0.9079499\n",
      "[Epoch 20/50] [Batch 36/300] [D loss: 0.752628] [G loss: 0.569748] time: 0:30:02.808487\n",
      "0.93777084\n",
      "[Epoch 20/50] [Batch 37/300] [D loss: 0.752635] [G loss: 0.510775] time: 0:30:03.099077\n",
      "0.9323757\n",
      "[Epoch 20/50] [Batch 38/300] [D loss: 0.752655] [G loss: 0.553274] time: 0:30:03.400932\n",
      "0.9278309\n",
      "[Epoch 20/50] [Batch 39/300] [D loss: 0.752636] [G loss: 0.518679] time: 0:30:03.704105\n",
      "0.95358133\n",
      "[Epoch 20/50] [Batch 40/300] [D loss: 0.752685] [G loss: 0.520467] time: 0:30:04.009032\n",
      "0.95314115\n",
      "[Epoch 20/50] [Batch 41/300] [D loss: 0.752634] [G loss: 0.497390] time: 0:30:04.302497\n",
      "0.92238194\n",
      "[Epoch 20/50] [Batch 42/300] [D loss: 0.752650] [G loss: 0.523804] time: 0:30:04.599411\n",
      "0.8803024\n",
      "[Epoch 20/50] [Batch 43/300] [D loss: 0.752636] [G loss: 0.547624] time: 0:30:04.898867\n",
      "0.9304948\n",
      "[Epoch 20/50] [Batch 44/300] [D loss: 0.752658] [G loss: 0.508672] time: 0:30:05.200134\n",
      "0.94622827\n",
      "[Epoch 20/50] [Batch 45/300] [D loss: 0.752640] [G loss: 0.522853] time: 0:30:05.518823\n",
      "0.8828294\n",
      "[Epoch 20/50] [Batch 46/300] [D loss: 0.752665] [G loss: 0.523307] time: 0:30:05.805567\n",
      "0.9185571\n",
      "[Epoch 20/50] [Batch 47/300] [D loss: 0.752670] [G loss: 0.502428] time: 0:30:06.094905\n",
      "0.9065962\n",
      "[Epoch 20/50] [Batch 48/300] [D loss: 0.752646] [G loss: 0.521834] time: 0:30:06.397014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9260089\n",
      "[Epoch 20/50] [Batch 49/300] [D loss: 0.752654] [G loss: 0.504844] time: 0:30:06.702655\n",
      "0.9329342\n",
      "[Epoch 20/50] [Batch 50/300] [D loss: 0.752640] [G loss: 0.537053] time: 0:30:07.017174\n",
      "0.9081777\n",
      "[Epoch 20/50] [Batch 51/300] [D loss: 0.752627] [G loss: 0.547570] time: 0:30:07.314207\n",
      "0.8971073\n",
      "[Epoch 20/50] [Batch 52/300] [D loss: 0.752628] [G loss: 0.564039] time: 0:30:07.615217\n",
      "0.93878525\n",
      "[Epoch 20/50] [Batch 53/300] [D loss: 0.752647] [G loss: 0.513173] time: 0:30:07.927883\n",
      "0.9442447\n",
      "[Epoch 20/50] [Batch 54/300] [D loss: 0.752674] [G loss: 0.523595] time: 0:30:08.219632\n",
      "0.96692103\n",
      "[Epoch 20/50] [Batch 55/300] [D loss: 0.752645] [G loss: 0.520909] time: 0:30:08.525084\n",
      "0.90286833\n",
      "[Epoch 20/50] [Batch 56/300] [D loss: 0.752664] [G loss: 0.515721] time: 0:30:08.827888\n",
      "0.96977\n",
      "[Epoch 20/50] [Batch 57/300] [D loss: 0.752656] [G loss: 0.530722] time: 0:30:09.132520\n",
      "0.929957\n",
      "[Epoch 20/50] [Batch 58/300] [D loss: 0.752649] [G loss: 0.522071] time: 0:30:09.438105\n",
      "0.9220147\n",
      "[Epoch 20/50] [Batch 59/300] [D loss: 0.752660] [G loss: 0.548436] time: 0:30:09.741057\n",
      "0.9710968\n",
      "[Epoch 20/50] [Batch 60/300] [D loss: 0.752636] [G loss: 0.518845] time: 0:30:10.039028\n",
      "0.9016997\n",
      "[Epoch 20/50] [Batch 61/300] [D loss: 0.752654] [G loss: 0.528753] time: 0:30:10.347444\n",
      "0.8974137\n",
      "[Epoch 20/50] [Batch 62/300] [D loss: 0.752676] [G loss: 0.554601] time: 0:30:10.633998\n",
      "0.92321235\n",
      "[Epoch 20/50] [Batch 63/300] [D loss: 0.752650] [G loss: 0.541705] time: 0:30:10.928698\n",
      "0.9480395\n",
      "[Epoch 20/50] [Batch 64/300] [D loss: 0.752656] [G loss: 0.527242] time: 0:30:11.223345\n",
      "0.8921235\n",
      "[Epoch 20/50] [Batch 65/300] [D loss: 0.752641] [G loss: 0.562027] time: 0:30:11.516046\n",
      "0.89487845\n",
      "[Epoch 20/50] [Batch 66/300] [D loss: 0.752676] [G loss: 0.557382] time: 0:30:11.811303\n",
      "0.93895006\n",
      "[Epoch 20/50] [Batch 67/300] [D loss: 0.752650] [G loss: 0.535809] time: 0:30:12.116521\n",
      "0.9339468\n",
      "[Epoch 20/50] [Batch 68/300] [D loss: 0.752636] [G loss: 0.528773] time: 0:30:12.428077\n",
      "0.94310904\n",
      "[Epoch 20/50] [Batch 69/300] [D loss: 0.752651] [G loss: 0.500973] time: 0:30:12.728162\n",
      "0.9117515\n",
      "[Epoch 20/50] [Batch 70/300] [D loss: 0.752640] [G loss: 0.543861] time: 0:30:13.017723\n",
      "0.93387717\n",
      "[Epoch 20/50] [Batch 71/300] [D loss: 0.752661] [G loss: 0.535156] time: 0:30:13.427587\n",
      "0.9671723\n",
      "[Epoch 20/50] [Batch 72/300] [D loss: 0.752652] [G loss: 0.507225] time: 0:30:13.725651\n",
      "0.9378883\n",
      "[Epoch 20/50] [Batch 73/300] [D loss: 0.752660] [G loss: 0.510497] time: 0:30:14.008525\n",
      "0.93993646\n",
      "[Epoch 20/50] [Batch 74/300] [D loss: 0.752664] [G loss: 0.543302] time: 0:30:14.311997\n",
      "0.9559216\n",
      "[Epoch 20/50] [Batch 75/300] [D loss: 0.752664] [G loss: 0.508953] time: 0:30:14.604009\n",
      "0.92513496\n",
      "[Epoch 20/50] [Batch 76/300] [D loss: 0.752662] [G loss: 0.513877] time: 0:30:14.890159\n",
      "0.9458969\n",
      "[Epoch 20/50] [Batch 77/300] [D loss: 0.752647] [G loss: 0.552743] time: 0:30:15.201997\n",
      "0.9114664\n",
      "[Epoch 20/50] [Batch 78/300] [D loss: 0.752658] [G loss: 0.530767] time: 0:30:15.494470\n",
      "0.9610036\n",
      "[Epoch 20/50] [Batch 79/300] [D loss: 0.752660] [G loss: 0.516971] time: 0:30:15.793697\n",
      "0.906902\n",
      "[Epoch 20/50] [Batch 80/300] [D loss: 0.752650] [G loss: 0.529370] time: 0:30:16.088444\n",
      "0.917186\n",
      "[Epoch 20/50] [Batch 81/300] [D loss: 0.752638] [G loss: 0.524013] time: 0:30:16.380915\n",
      "0.92551947\n",
      "[Epoch 20/50] [Batch 82/300] [D loss: 0.752627] [G loss: 0.517336] time: 0:30:16.673795\n",
      "0.90663177\n",
      "[Epoch 20/50] [Batch 83/300] [D loss: 0.752670] [G loss: 0.519040] time: 0:30:16.964302\n",
      "0.88582605\n",
      "[Epoch 20/50] [Batch 84/300] [D loss: 0.752629] [G loss: 0.522369] time: 0:30:17.253814\n",
      "0.91675967\n",
      "[Epoch 20/50] [Batch 85/300] [D loss: 0.752624] [G loss: 0.525126] time: 0:30:17.551840\n",
      "0.8662095\n",
      "[Epoch 20/50] [Batch 86/300] [D loss: 0.752628] [G loss: 0.536175] time: 0:30:17.851697\n",
      "0.9375637\n",
      "[Epoch 20/50] [Batch 87/300] [D loss: 0.752636] [G loss: 0.515493] time: 0:30:18.149138\n",
      "0.9261339\n",
      "[Epoch 20/50] [Batch 88/300] [D loss: 0.752651] [G loss: 0.527136] time: 0:30:18.446320\n",
      "0.9747286\n",
      "[Epoch 20/50] [Batch 89/300] [D loss: 0.752661] [G loss: 0.508380] time: 0:30:18.747044\n",
      "0.8991688\n",
      "[Epoch 20/50] [Batch 90/300] [D loss: 0.752638] [G loss: 0.518960] time: 0:30:19.040084\n",
      "0.9323668\n",
      "[Epoch 20/50] [Batch 91/300] [D loss: 0.752669] [G loss: 0.511238] time: 0:30:19.343365\n",
      "0.8985993\n",
      "[Epoch 20/50] [Batch 92/300] [D loss: 0.752647] [G loss: 0.532146] time: 0:30:19.637365\n",
      "0.9171045\n",
      "[Epoch 20/50] [Batch 93/300] [D loss: 0.752657] [G loss: 0.558738] time: 0:30:19.954566\n",
      "0.9350166\n",
      "[Epoch 20/50] [Batch 94/300] [D loss: 0.752644] [G loss: 0.514944] time: 0:30:20.253464\n",
      "0.9457509\n",
      "[Epoch 20/50] [Batch 95/300] [D loss: 0.752643] [G loss: 0.552604] time: 0:30:20.545008\n",
      "0.89115304\n",
      "[Epoch 20/50] [Batch 96/300] [D loss: 0.752631] [G loss: 0.520283] time: 0:30:20.830344\n",
      "0.8869584\n",
      "[Epoch 20/50] [Batch 97/300] [D loss: 0.752641] [G loss: 0.550117] time: 0:30:21.117779\n",
      "0.91094714\n",
      "[Epoch 20/50] [Batch 98/300] [D loss: 0.752636] [G loss: 0.537573] time: 0:30:21.427691\n",
      "0.8740542\n",
      "[Epoch 20/50] [Batch 99/300] [D loss: 0.752640] [G loss: 0.546433] time: 0:30:21.716106\n",
      "0.95536333\n",
      "[Epoch 20/50] [Batch 100/300] [D loss: 0.752617] [G loss: 0.543398] time: 0:30:22.029490\n",
      "0.9286278\n",
      "[Epoch 20/50] [Batch 101/300] [D loss: 0.752653] [G loss: 0.524071] time: 0:30:22.304979\n",
      "0.9507506\n",
      "[Epoch 20/50] [Batch 102/300] [D loss: 0.752638] [G loss: 0.559579] time: 0:30:22.615840\n",
      "0.9076042\n",
      "[Epoch 20/50] [Batch 103/300] [D loss: 0.752663] [G loss: 0.510337] time: 0:30:22.916602\n",
      "0.9518339\n",
      "[Epoch 20/50] [Batch 104/300] [D loss: 0.752643] [G loss: 0.497727] time: 0:30:23.210877\n",
      "0.9709018\n",
      "[Epoch 20/50] [Batch 105/300] [D loss: 0.752667] [G loss: 0.534573] time: 0:30:23.519815\n",
      "0.9350038\n",
      "[Epoch 20/50] [Batch 106/300] [D loss: 0.752652] [G loss: 0.506916] time: 0:30:23.821013\n",
      "0.9378228\n",
      "[Epoch 20/50] [Batch 107/300] [D loss: 0.752657] [G loss: 0.505052] time: 0:30:24.114363\n",
      "0.883241\n",
      "[Epoch 20/50] [Batch 108/300] [D loss: 0.752607] [G loss: 0.510143] time: 0:30:24.415921\n",
      "0.9191722\n",
      "[Epoch 20/50] [Batch 109/300] [D loss: 0.752654] [G loss: 0.525012] time: 0:30:24.729374\n",
      "0.9388748\n",
      "[Epoch 20/50] [Batch 110/300] [D loss: 0.752642] [G loss: 0.511475] time: 0:30:25.032386\n",
      "0.93149185\n",
      "[Epoch 20/50] [Batch 111/300] [D loss: 0.752641] [G loss: 0.522304] time: 0:30:25.338551\n",
      "0.91660684\n",
      "[Epoch 20/50] [Batch 112/300] [D loss: 0.752637] [G loss: 0.582655] time: 0:30:25.643561\n",
      "0.8864539\n",
      "[Epoch 20/50] [Batch 113/300] [D loss: 0.752649] [G loss: 0.541524] time: 0:30:25.934986\n",
      "0.9311817\n",
      "[Epoch 20/50] [Batch 114/300] [D loss: 0.752632] [G loss: 0.549955] time: 0:30:26.238029\n",
      "0.9052265\n",
      "[Epoch 20/50] [Batch 115/300] [D loss: 0.752643] [G loss: 0.554386] time: 0:30:26.539313\n",
      "0.9278972\n",
      "[Epoch 20/50] [Batch 116/300] [D loss: 0.752662] [G loss: 0.526270] time: 0:30:26.820679\n",
      "0.9462846\n",
      "[Epoch 20/50] [Batch 117/300] [D loss: 0.752643] [G loss: 0.515283] time: 0:30:27.120787\n",
      "0.92836684\n",
      "[Epoch 20/50] [Batch 118/300] [D loss: 0.752629] [G loss: 0.575694] time: 0:30:27.400976\n",
      "0.9071525\n",
      "[Epoch 20/50] [Batch 119/300] [D loss: 0.752650] [G loss: 0.524451] time: 0:30:27.701885\n",
      "0.93704027\n",
      "[Epoch 20/50] [Batch 120/300] [D loss: 0.752635] [G loss: 0.518576] time: 0:30:28.003747\n",
      "0.93181586\n",
      "[Epoch 20/50] [Batch 121/300] [D loss: 0.752660] [G loss: 0.507673] time: 0:30:28.292777\n",
      "0.9117016\n",
      "[Epoch 20/50] [Batch 122/300] [D loss: 0.752640] [G loss: 0.502530] time: 0:30:28.604392\n",
      "0.91725445\n",
      "[Epoch 20/50] [Batch 123/300] [D loss: 0.752648] [G loss: 0.563582] time: 0:30:28.885451\n",
      "0.98327273\n",
      "[Epoch 20/50] [Batch 124/300] [D loss: 0.752645] [G loss: 0.528575] time: 0:30:29.188562\n",
      "0.9199381\n",
      "[Epoch 20/50] [Batch 125/300] [D loss: 0.752631] [G loss: 0.546877] time: 0:30:29.476787\n",
      "0.9396129\n",
      "[Epoch 20/50] [Batch 126/300] [D loss: 0.752628] [G loss: 0.493430] time: 0:30:29.789798\n",
      "0.9468315\n",
      "[Epoch 20/50] [Batch 127/300] [D loss: 0.752620] [G loss: 0.513086] time: 0:30:30.071681\n",
      "0.9438722\n",
      "[Epoch 20/50] [Batch 128/300] [D loss: 0.752625] [G loss: 0.551999] time: 0:30:30.373377\n",
      "0.9227893\n",
      "[Epoch 20/50] [Batch 129/300] [D loss: 0.752651] [G loss: 0.542853] time: 0:30:30.665486\n",
      "0.9201882\n",
      "[Epoch 20/50] [Batch 130/300] [D loss: 0.752612] [G loss: 0.566789] time: 0:30:30.978626\n",
      "0.9133963\n",
      "[Epoch 20/50] [Batch 131/300] [D loss: 0.752635] [G loss: 0.526367] time: 0:30:31.281528\n",
      "0.97183806\n",
      "[Epoch 20/50] [Batch 132/300] [D loss: 0.752638] [G loss: 0.554190] time: 0:30:31.591876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92631894\n",
      "[Epoch 20/50] [Batch 133/300] [D loss: 0.752655] [G loss: 0.495720] time: 0:30:31.893171\n",
      "0.9051209\n",
      "[Epoch 20/50] [Batch 134/300] [D loss: 0.752644] [G loss: 0.564502] time: 0:30:32.188386\n",
      "0.93655866\n",
      "[Epoch 20/50] [Batch 135/300] [D loss: 0.752660] [G loss: 0.510579] time: 0:30:32.497356\n",
      "0.93531054\n",
      "[Epoch 20/50] [Batch 136/300] [D loss: 0.752655] [G loss: 0.512705] time: 0:30:32.797686\n",
      "0.9459944\n",
      "[Epoch 20/50] [Batch 137/300] [D loss: 0.752616] [G loss: 0.498548] time: 0:30:33.092235\n",
      "0.8830406\n",
      "[Epoch 20/50] [Batch 138/300] [D loss: 0.752640] [G loss: 0.542680] time: 0:30:33.384206\n",
      "0.9362324\n",
      "[Epoch 20/50] [Batch 139/300] [D loss: 0.752658] [G loss: 0.523821] time: 0:30:33.684472\n",
      "0.88294727\n",
      "[Epoch 20/50] [Batch 140/300] [D loss: 0.752622] [G loss: 0.538490] time: 0:30:33.976543\n",
      "0.9550378\n",
      "[Epoch 20/50] [Batch 141/300] [D loss: 0.752616] [G loss: 0.568356] time: 0:30:34.283793\n",
      "0.9003325\n",
      "[Epoch 20/50] [Batch 142/300] [D loss: 0.752637] [G loss: 0.523587] time: 0:30:34.582415\n",
      "0.9096622\n",
      "[Epoch 20/50] [Batch 143/300] [D loss: 0.752640] [G loss: 0.506030] time: 0:30:34.869459\n",
      "0.91140336\n",
      "[Epoch 20/50] [Batch 144/300] [D loss: 0.752638] [G loss: 0.540460] time: 0:30:35.171939\n",
      "0.94075537\n",
      "[Epoch 20/50] [Batch 145/300] [D loss: 0.752643] [G loss: 0.500736] time: 0:30:35.472533\n",
      "0.93299\n",
      "[Epoch 20/50] [Batch 146/300] [D loss: 0.752634] [G loss: 0.526652] time: 0:30:35.773913\n",
      "0.9336222\n",
      "[Epoch 20/50] [Batch 147/300] [D loss: 0.752642] [G loss: 0.560222] time: 0:30:36.070564\n",
      "0.9061912\n",
      "[Epoch 20/50] [Batch 148/300] [D loss: 0.752601] [G loss: 0.521897] time: 0:30:36.369504\n",
      "0.944946\n",
      "[Epoch 20/50] [Batch 149/300] [D loss: 0.752652] [G loss: 0.493516] time: 0:30:36.671074\n",
      "0.9423129\n",
      "[Epoch 20/50] [Batch 150/300] [D loss: 0.752617] [G loss: 0.536531] time: 0:30:36.964680\n",
      "0.9644282\n",
      "[Epoch 20/50] [Batch 151/300] [D loss: 0.752648] [G loss: 0.556056] time: 0:30:37.243343\n",
      "0.9076455\n",
      "[Epoch 20/50] [Batch 152/300] [D loss: 0.752648] [G loss: 0.535256] time: 0:30:37.536365\n",
      "0.9297986\n",
      "[Epoch 20/50] [Batch 153/300] [D loss: 0.752616] [G loss: 0.564175] time: 0:30:37.834642\n",
      "0.90501714\n",
      "[Epoch 20/50] [Batch 154/300] [D loss: 0.752652] [G loss: 0.520477] time: 0:30:38.118773\n",
      "0.9149189\n",
      "[Epoch 20/50] [Batch 155/300] [D loss: 0.752646] [G loss: 0.554935] time: 0:30:38.416865\n",
      "0.9704775\n",
      "[Epoch 20/50] [Batch 156/300] [D loss: 0.752639] [G loss: 0.518985] time: 0:30:38.719559\n",
      "0.911689\n",
      "[Epoch 20/50] [Batch 157/300] [D loss: 0.752608] [G loss: 0.564691] time: 0:30:39.019825\n",
      "0.9312484\n",
      "[Epoch 20/50] [Batch 158/300] [D loss: 0.752652] [G loss: 0.541982] time: 0:30:39.316751\n",
      "0.9317004\n",
      "[Epoch 20/50] [Batch 159/300] [D loss: 0.752641] [G loss: 0.511339] time: 0:30:39.609604\n",
      "0.88042516\n",
      "[Epoch 20/50] [Batch 160/300] [D loss: 0.752644] [G loss: 0.535871] time: 0:30:39.908171\n",
      "0.9390592\n",
      "[Epoch 20/50] [Batch 161/300] [D loss: 0.752635] [G loss: 0.550690] time: 0:30:40.204032\n",
      "0.95160073\n",
      "[Epoch 20/50] [Batch 162/300] [D loss: 0.752627] [G loss: 0.518060] time: 0:30:40.503585\n",
      "0.86876374\n",
      "[Epoch 20/50] [Batch 163/300] [D loss: 0.752594] [G loss: 0.534195] time: 0:30:40.810963\n",
      "0.94616693\n",
      "[Epoch 20/50] [Batch 164/300] [D loss: 0.752620] [G loss: 0.509606] time: 0:30:41.101655\n",
      "0.96464485\n",
      "[Epoch 20/50] [Batch 165/300] [D loss: 0.752631] [G loss: 0.502275] time: 0:30:41.415594\n",
      "0.90064937\n",
      "[Epoch 20/50] [Batch 166/300] [D loss: 0.752602] [G loss: 0.530030] time: 0:30:41.718488\n",
      "0.9379322\n",
      "[Epoch 20/50] [Batch 167/300] [D loss: 0.752601] [G loss: 0.517142] time: 0:30:42.015714\n",
      "0.952451\n",
      "[Epoch 20/50] [Batch 168/300] [D loss: 0.752630] [G loss: 0.502149] time: 0:30:42.316187\n",
      "0.9413104\n",
      "[Epoch 20/50] [Batch 169/300] [D loss: 0.752615] [G loss: 0.592886] time: 0:30:42.622627\n",
      "0.90829563\n",
      "[Epoch 20/50] [Batch 170/300] [D loss: 0.752641] [G loss: 0.542290] time: 0:30:42.911429\n",
      "0.89689255\n",
      "[Epoch 20/50] [Batch 171/300] [D loss: 0.752635] [G loss: 0.572579] time: 0:30:43.202148\n",
      "0.91035706\n",
      "[Epoch 20/50] [Batch 172/300] [D loss: 0.752660] [G loss: 0.532577] time: 0:30:43.507899\n",
      "0.90890485\n",
      "[Epoch 20/50] [Batch 173/300] [D loss: 0.752627] [G loss: 0.526946] time: 0:30:43.809610\n",
      "0.93118334\n",
      "[Epoch 20/50] [Batch 174/300] [D loss: 0.752629] [G loss: 0.542986] time: 0:30:44.124933\n",
      "0.9171913\n",
      "[Epoch 20/50] [Batch 175/300] [D loss: 0.752599] [G loss: 0.548301] time: 0:30:44.432220\n",
      "0.9415479\n",
      "[Epoch 20/50] [Batch 176/300] [D loss: 0.752603] [G loss: 0.579413] time: 0:30:44.725625\n",
      "0.9364378\n",
      "[Epoch 20/50] [Batch 177/300] [D loss: 0.752641] [G loss: 0.562320] time: 0:30:45.022012\n",
      "0.9208774\n",
      "[Epoch 20/50] [Batch 178/300] [D loss: 0.752649] [G loss: 0.531551] time: 0:30:45.324275\n",
      "0.8722274\n",
      "[Epoch 20/50] [Batch 179/300] [D loss: 0.752623] [G loss: 0.504693] time: 0:30:45.628284\n",
      "0.946266\n",
      "[Epoch 20/50] [Batch 180/300] [D loss: 0.752660] [G loss: 0.546423] time: 0:30:45.923982\n",
      "0.9284699\n",
      "[Epoch 20/50] [Batch 181/300] [D loss: 0.752647] [G loss: 0.521622] time: 0:30:46.213925\n",
      "0.91876364\n",
      "[Epoch 20/50] [Batch 182/300] [D loss: 0.752628] [G loss: 0.547392] time: 0:30:46.497360\n",
      "0.91523415\n",
      "[Epoch 20/50] [Batch 183/300] [D loss: 0.752627] [G loss: 0.546247] time: 0:30:46.816023\n",
      "0.942229\n",
      "[Epoch 20/50] [Batch 184/300] [D loss: 0.752647] [G loss: 0.532300] time: 0:30:47.141802\n",
      "0.9330453\n",
      "[Epoch 20/50] [Batch 185/300] [D loss: 0.752620] [G loss: 0.525871] time: 0:30:47.436695\n",
      "0.94479465\n",
      "[Epoch 20/50] [Batch 186/300] [D loss: 0.752621] [G loss: 0.529271] time: 0:30:47.739391\n",
      "0.914593\n",
      "[Epoch 20/50] [Batch 187/300] [D loss: 0.752652] [G loss: 0.525419] time: 0:30:48.017486\n",
      "0.91223234\n",
      "[Epoch 20/50] [Batch 188/300] [D loss: 0.752643] [G loss: 0.502449] time: 0:30:48.321410\n",
      "0.9286518\n",
      "[Epoch 20/50] [Batch 189/300] [D loss: 0.752628] [G loss: 0.519317] time: 0:30:48.599369\n",
      "0.88056165\n",
      "[Epoch 20/50] [Batch 190/300] [D loss: 0.752625] [G loss: 0.516393] time: 0:30:48.895370\n",
      "0.9064768\n",
      "[Epoch 20/50] [Batch 191/300] [D loss: 0.752617] [G loss: 0.582716] time: 0:30:49.184088\n",
      "0.9760987\n",
      "[Epoch 20/50] [Batch 192/300] [D loss: 0.752629] [G loss: 0.558735] time: 0:30:49.478379\n",
      "0.8871216\n",
      "[Epoch 20/50] [Batch 193/300] [D loss: 0.752638] [G loss: 0.548866] time: 0:30:49.785053\n",
      "0.91520196\n",
      "[Epoch 20/50] [Batch 194/300] [D loss: 0.752641] [G loss: 0.522856] time: 0:30:50.062148\n",
      "0.94052273\n",
      "[Epoch 20/50] [Batch 195/300] [D loss: 0.752643] [G loss: 0.507428] time: 0:30:50.355070\n",
      "0.9533785\n",
      "[Epoch 20/50] [Batch 196/300] [D loss: 0.752645] [G loss: 0.540843] time: 0:30:50.664063\n",
      "0.96971965\n",
      "[Epoch 20/50] [Batch 197/300] [D loss: 0.752655] [G loss: 0.493715] time: 0:30:50.942930\n",
      "0.90377456\n",
      "[Epoch 20/50] [Batch 198/300] [D loss: 0.752629] [G loss: 0.514177] time: 0:30:51.224869\n",
      "0.86984634\n",
      "[Epoch 20/50] [Batch 199/300] [D loss: 0.752622] [G loss: 0.542346] time: 0:30:51.523719\n",
      "0.8853151\n",
      "[Epoch 20/50] [Batch 200/300] [D loss: 0.752607] [G loss: 0.524314] time: 0:30:51.810592\n",
      "0.9322443\n",
      "[Epoch 20/50] [Batch 201/300] [D loss: 0.752656] [G loss: 0.516021] time: 0:30:52.112697\n",
      "0.91047263\n",
      "[Epoch 20/50] [Batch 202/300] [D loss: 0.752674] [G loss: 0.514576] time: 0:30:52.420087\n",
      "0.87879795\n",
      "[Epoch 20/50] [Batch 203/300] [D loss: 0.752623] [G loss: 0.560332] time: 0:30:52.722493\n",
      "0.9545159\n",
      "[Epoch 20/50] [Batch 204/300] [D loss: 0.752634] [G loss: 0.518747] time: 0:30:53.019757\n",
      "0.9532184\n",
      "[Epoch 20/50] [Batch 205/300] [D loss: 0.752614] [G loss: 0.514111] time: 0:30:53.318498\n",
      "0.9224987\n",
      "[Epoch 20/50] [Batch 206/300] [D loss: 0.752624] [G loss: 0.532763] time: 0:30:53.618144\n",
      "0.93480486\n",
      "[Epoch 20/50] [Batch 207/300] [D loss: 0.752631] [G loss: 0.546432] time: 0:30:53.928774\n",
      "0.90666825\n",
      "[Epoch 20/50] [Batch 208/300] [D loss: 0.752628] [G loss: 0.521195] time: 0:30:54.249000\n",
      "0.93838817\n",
      "[Epoch 20/50] [Batch 209/300] [D loss: 0.752606] [G loss: 0.541322] time: 0:30:54.550596\n",
      "0.913583\n",
      "[Epoch 20/50] [Batch 210/300] [D loss: 0.752650] [G loss: 0.526827] time: 0:30:54.837821\n",
      "0.9221818\n",
      "[Epoch 20/50] [Batch 211/300] [D loss: 0.752623] [G loss: 0.495112] time: 0:30:55.144175\n",
      "0.9270366\n",
      "[Epoch 20/50] [Batch 212/300] [D loss: 0.752649] [G loss: 0.504221] time: 0:30:55.439059\n",
      "0.8698067\n",
      "[Epoch 20/50] [Batch 213/300] [D loss: 0.752629] [G loss: 0.518011] time: 0:30:55.744751\n",
      "0.88281876\n",
      "[Epoch 20/50] [Batch 214/300] [D loss: 0.752632] [G loss: 0.582248] time: 0:30:56.040101\n",
      "0.96461016\n",
      "[Epoch 20/50] [Batch 215/300] [D loss: 0.752614] [G loss: 0.541185] time: 0:30:56.328375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94640326\n",
      "[Epoch 20/50] [Batch 216/300] [D loss: 0.752631] [G loss: 0.601952] time: 0:30:56.636741\n",
      "0.972524\n",
      "[Epoch 20/50] [Batch 217/300] [D loss: 0.752632] [G loss: 0.543204] time: 0:30:56.931738\n",
      "0.95559055\n",
      "[Epoch 20/50] [Batch 218/300] [D loss: 0.752650] [G loss: 0.548357] time: 0:30:57.236491\n",
      "0.9523263\n",
      "[Epoch 20/50] [Batch 219/300] [D loss: 0.752623] [G loss: 0.505709] time: 0:30:57.528704\n",
      "0.8761966\n",
      "[Epoch 20/50] [Batch 220/300] [D loss: 0.752639] [G loss: 0.543612] time: 0:30:57.830762\n",
      "0.8948503\n",
      "[Epoch 20/50] [Batch 221/300] [D loss: 0.752657] [G loss: 0.536575] time: 0:30:58.116139\n",
      "0.93918747\n",
      "[Epoch 20/50] [Batch 222/300] [D loss: 0.752634] [G loss: 0.520657] time: 0:30:58.402975\n",
      "0.9057178\n",
      "[Epoch 20/50] [Batch 223/300] [D loss: 0.752655] [G loss: 0.549730] time: 0:30:58.703562\n",
      "0.9127967\n",
      "[Epoch 20/50] [Batch 224/300] [D loss: 0.752646] [G loss: 0.551065] time: 0:30:59.004028\n",
      "0.8857983\n",
      "[Epoch 20/50] [Batch 225/300] [D loss: 0.752593] [G loss: 0.557633] time: 0:30:59.301986\n",
      "0.91576904\n",
      "[Epoch 20/50] [Batch 226/300] [D loss: 0.752621] [G loss: 0.577637] time: 0:30:59.602121\n",
      "0.9325123\n",
      "[Epoch 20/50] [Batch 227/300] [D loss: 0.752607] [G loss: 0.531313] time: 0:30:59.910338\n",
      "0.88202333\n",
      "[Epoch 20/50] [Batch 228/300] [D loss: 0.752643] [G loss: 0.503462] time: 0:31:00.198530\n",
      "0.93300843\n",
      "[Epoch 20/50] [Batch 229/300] [D loss: 0.752623] [G loss: 0.563947] time: 0:31:00.504321\n",
      "0.8990503\n",
      "[Epoch 20/50] [Batch 230/300] [D loss: 0.752649] [G loss: 0.522860] time: 0:31:00.809678\n",
      "0.9208193\n",
      "[Epoch 20/50] [Batch 231/300] [D loss: 0.752623] [G loss: 0.521040] time: 0:31:01.112074\n",
      "0.92590165\n",
      "[Epoch 20/50] [Batch 232/300] [D loss: 0.752635] [G loss: 0.531247] time: 0:31:01.411438\n",
      "0.960679\n",
      "[Epoch 20/50] [Batch 233/300] [D loss: 0.752688] [G loss: 0.551110] time: 0:31:01.705299\n",
      "0.90504456\n",
      "[Epoch 20/50] [Batch 234/300] [D loss: 0.752635] [G loss: 0.525400] time: 0:31:01.989470\n",
      "0.96901697\n",
      "[Epoch 20/50] [Batch 235/300] [D loss: 0.752639] [G loss: 0.566397] time: 0:31:02.276123\n",
      "0.96436787\n",
      "[Epoch 20/50] [Batch 236/300] [D loss: 0.752640] [G loss: 0.526582] time: 0:31:02.587144\n",
      "0.9360034\n",
      "[Epoch 20/50] [Batch 237/300] [D loss: 0.752622] [G loss: 0.544325] time: 0:31:02.880856\n",
      "0.88172865\n",
      "[Epoch 20/50] [Batch 238/300] [D loss: 0.752643] [G loss: 0.542368] time: 0:31:03.168238\n",
      "0.9066482\n",
      "[Epoch 20/50] [Batch 239/300] [D loss: 0.752624] [G loss: 0.534618] time: 0:31:03.466222\n",
      "0.9335334\n",
      "[Epoch 20/50] [Batch 240/300] [D loss: 0.752646] [G loss: 0.541665] time: 0:31:03.765590\n",
      "0.94319487\n",
      "[Epoch 20/50] [Batch 241/300] [D loss: 0.752608] [G loss: 0.533847] time: 0:31:04.070056\n",
      "0.91598964\n",
      "[Epoch 20/50] [Batch 242/300] [D loss: 0.752604] [G loss: 0.559342] time: 0:31:04.357525\n",
      "0.90554905\n",
      "[Epoch 20/50] [Batch 243/300] [D loss: 0.752660] [G loss: 0.502271] time: 0:31:04.646335\n",
      "0.8870508\n",
      "[Epoch 20/50] [Batch 244/300] [D loss: 0.752593] [G loss: 0.521783] time: 0:31:04.951372\n",
      "0.9475913\n",
      "[Epoch 20/50] [Batch 245/300] [D loss: 0.752605] [G loss: 0.504660] time: 0:31:05.235577\n",
      "0.89205575\n",
      "[Epoch 20/50] [Batch 246/300] [D loss: 0.752638] [G loss: 0.542830] time: 0:31:05.525129\n",
      "0.8606375\n",
      "[Epoch 20/50] [Batch 247/300] [D loss: 0.752619] [G loss: 0.539020] time: 0:31:05.824577\n",
      "0.9182804\n",
      "[Epoch 20/50] [Batch 248/300] [D loss: 0.752634] [G loss: 0.513768] time: 0:31:06.135488\n",
      "0.93140227\n",
      "[Epoch 20/50] [Batch 249/300] [D loss: 0.752618] [G loss: 0.571557] time: 0:31:06.437487\n",
      "0.960398\n",
      "[Epoch 20/50] [Batch 250/300] [D loss: 0.752619] [G loss: 0.525068] time: 0:31:06.737158\n",
      "0.8906574\n",
      "[Epoch 20/50] [Batch 251/300] [D loss: 0.752631] [G loss: 0.512300] time: 0:31:07.026950\n",
      "0.9276375\n",
      "[Epoch 20/50] [Batch 252/300] [D loss: 0.752635] [G loss: 0.521699] time: 0:31:07.327749\n",
      "0.93076086\n",
      "[Epoch 20/50] [Batch 253/300] [D loss: 0.752627] [G loss: 0.547614] time: 0:31:07.622323\n",
      "0.9302922\n",
      "[Epoch 20/50] [Batch 254/300] [D loss: 0.752644] [G loss: 0.571917] time: 0:31:07.917884\n",
      "0.9173519\n",
      "[Epoch 20/50] [Batch 255/300] [D loss: 0.752642] [G loss: 0.580468] time: 0:31:08.214703\n",
      "0.911792\n",
      "[Epoch 20/50] [Batch 256/300] [D loss: 0.752620] [G loss: 0.530908] time: 0:31:08.528488\n",
      "0.932507\n",
      "[Epoch 20/50] [Batch 257/300] [D loss: 0.752615] [G loss: 0.541303] time: 0:31:08.837029\n",
      "0.89941984\n",
      "[Epoch 20/50] [Batch 258/300] [D loss: 0.752613] [G loss: 0.515222] time: 0:31:09.138433\n",
      "0.9388582\n",
      "[Epoch 20/50] [Batch 259/300] [D loss: 0.752615] [G loss: 0.501036] time: 0:31:09.439483\n",
      "0.8867204\n",
      "[Epoch 20/50] [Batch 260/300] [D loss: 0.752622] [G loss: 0.520024] time: 0:31:09.737629\n",
      "0.8872199\n",
      "[Epoch 20/50] [Batch 261/300] [D loss: 0.752626] [G loss: 0.515564] time: 0:31:10.035547\n",
      "0.9083522\n",
      "[Epoch 20/50] [Batch 262/300] [D loss: 0.752623] [G loss: 0.510799] time: 0:31:10.325856\n",
      "0.95889044\n",
      "[Epoch 20/50] [Batch 263/300] [D loss: 0.752619] [G loss: 0.533999] time: 0:31:10.628298\n",
      "0.9758578\n",
      "[Epoch 20/50] [Batch 264/300] [D loss: 0.752656] [G loss: 0.511524] time: 0:31:10.912854\n",
      "0.93335897\n",
      "[Epoch 20/50] [Batch 265/300] [D loss: 0.752614] [G loss: 0.499723] time: 0:31:11.215091\n",
      "0.9173603\n",
      "[Epoch 20/50] [Batch 266/300] [D loss: 0.752614] [G loss: 0.517740] time: 0:31:11.510826\n",
      "0.86770797\n",
      "[Epoch 20/50] [Batch 267/300] [D loss: 0.752637] [G loss: 0.515101] time: 0:31:11.810791\n",
      "0.91173697\n",
      "[Epoch 20/50] [Batch 268/300] [D loss: 0.752605] [G loss: 0.541185] time: 0:31:12.107402\n",
      "0.9270714\n",
      "[Epoch 20/50] [Batch 269/300] [D loss: 0.752626] [G loss: 0.545175] time: 0:31:12.414920\n",
      "0.94585675\n",
      "[Epoch 20/50] [Batch 270/300] [D loss: 0.752636] [G loss: 0.519617] time: 0:31:12.711182\n",
      "0.9393621\n",
      "[Epoch 20/50] [Batch 271/300] [D loss: 0.752628] [G loss: 0.572226] time: 0:31:12.993672\n",
      "0.94115806\n",
      "[Epoch 20/50] [Batch 272/300] [D loss: 0.752639] [G loss: 0.537697] time: 0:31:13.281021\n",
      "0.8885185\n",
      "[Epoch 20/50] [Batch 273/300] [D loss: 0.752593] [G loss: 0.552851] time: 0:31:13.580063\n",
      "0.89281225\n",
      "[Epoch 20/50] [Batch 274/300] [D loss: 0.752635] [G loss: 0.509339] time: 0:31:13.877323\n",
      "0.91436577\n",
      "[Epoch 20/50] [Batch 275/300] [D loss: 0.752631] [G loss: 0.543287] time: 0:31:14.187035\n",
      "0.9389708\n",
      "[Epoch 20/50] [Batch 276/300] [D loss: 0.752627] [G loss: 0.501522] time: 0:31:14.488574\n",
      "0.89216447\n",
      "[Epoch 20/50] [Batch 277/300] [D loss: 0.752598] [G loss: 0.507308] time: 0:31:14.785477\n",
      "0.95247847\n",
      "[Epoch 20/50] [Batch 278/300] [D loss: 0.752676] [G loss: 0.500976] time: 0:31:15.084010\n",
      "0.9056998\n",
      "[Epoch 20/50] [Batch 279/300] [D loss: 0.752617] [G loss: 0.578920] time: 0:31:15.349627\n",
      "0.93948096\n",
      "[Epoch 20/50] [Batch 280/300] [D loss: 0.752623] [G loss: 0.548141] time: 0:31:15.627986\n",
      "0.93461746\n",
      "[Epoch 20/50] [Batch 281/300] [D loss: 0.752633] [G loss: 0.543850] time: 0:31:15.936387\n",
      "0.8596886\n",
      "[Epoch 20/50] [Batch 282/300] [D loss: 0.752647] [G loss: 0.541870] time: 0:31:16.240414\n",
      "0.92082906\n",
      "[Epoch 20/50] [Batch 283/300] [D loss: 0.752607] [G loss: 0.557701] time: 0:31:16.529944\n",
      "0.8705068\n",
      "[Epoch 20/50] [Batch 284/300] [D loss: 0.752683] [G loss: 0.529679] time: 0:31:16.831486\n",
      "0.94236827\n",
      "[Epoch 20/50] [Batch 285/300] [D loss: 0.752616] [G loss: 0.531679] time: 0:31:17.145839\n",
      "0.91045165\n",
      "[Epoch 20/50] [Batch 286/300] [D loss: 0.752611] [G loss: 0.522986] time: 0:31:17.448562\n",
      "0.8958299\n",
      "[Epoch 20/50] [Batch 287/300] [D loss: 0.752616] [G loss: 0.530421] time: 0:31:17.735374\n",
      "0.88809925\n",
      "[Epoch 20/50] [Batch 288/300] [D loss: 0.752632] [G loss: 0.540179] time: 0:31:18.038209\n",
      "0.93499583\n",
      "[Epoch 20/50] [Batch 289/300] [D loss: 0.752616] [G loss: 0.590307] time: 0:31:18.337120\n",
      "0.9059703\n",
      "[Epoch 20/50] [Batch 290/300] [D loss: 0.752621] [G loss: 0.526070] time: 0:31:18.632206\n",
      "0.90373635\n",
      "[Epoch 20/50] [Batch 291/300] [D loss: 0.752622] [G loss: 0.516252] time: 0:31:18.916403\n",
      "0.90977716\n",
      "[Epoch 20/50] [Batch 292/300] [D loss: 0.752613] [G loss: 0.503087] time: 0:31:19.203610\n",
      "0.9314502\n",
      "[Epoch 20/50] [Batch 293/300] [D loss: 0.752613] [G loss: 0.535442] time: 0:31:19.505211\n",
      "0.93593764\n",
      "[Epoch 20/50] [Batch 294/300] [D loss: 0.752624] [G loss: 0.506469] time: 0:31:19.806054\n",
      "0.9168124\n",
      "[Epoch 20/50] [Batch 295/300] [D loss: 0.752623] [G loss: 0.494712] time: 0:31:20.096847\n",
      "0.89469343\n",
      "[Epoch 20/50] [Batch 296/300] [D loss: 0.752617] [G loss: 0.524221] time: 0:31:20.411997\n",
      "0.88561076\n",
      "[Epoch 20/50] [Batch 297/300] [D loss: 0.752617] [G loss: 0.528766] time: 0:31:20.722347\n",
      "0.96901625\n",
      "[Epoch 20/50] [Batch 298/300] [D loss: 0.752654] [G loss: 0.499321] time: 0:31:21.023155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95975024\n",
      "[Epoch 20/50] [Batch 299/300] [D loss: 0.752630] [G loss: 0.549157] time: 0:31:21.316314\n",
      "0.9384115\n",
      "[Epoch 21/50] [Batch 0/300] [D loss: 0.752641] [G loss: 0.526925] time: 0:31:21.636514\n",
      "0.8992984\n",
      "[Epoch 21/50] [Batch 1/300] [D loss: 0.752595] [G loss: 0.506835] time: 0:31:21.947310\n",
      "0.938812\n",
      "[Epoch 21/50] [Batch 2/300] [D loss: 0.752628] [G loss: 0.525879] time: 0:31:22.250126\n",
      "0.9488821\n",
      "[Epoch 21/50] [Batch 3/300] [D loss: 0.752626] [G loss: 0.507053] time: 0:31:22.548644\n",
      "0.94241023\n",
      "[Epoch 21/50] [Batch 4/300] [D loss: 0.752627] [G loss: 0.517419] time: 0:31:22.854951\n",
      "0.9289238\n",
      "[Epoch 21/50] [Batch 5/300] [D loss: 0.752629] [G loss: 0.499871] time: 0:31:23.141940\n",
      "0.92465407\n",
      "[Epoch 21/50] [Batch 6/300] [D loss: 0.752604] [G loss: 0.521602] time: 0:31:23.461153\n",
      "0.9773278\n",
      "[Epoch 21/50] [Batch 7/300] [D loss: 0.752613] [G loss: 0.504442] time: 0:31:23.745169\n",
      "0.96830726\n",
      "[Epoch 21/50] [Batch 8/300] [D loss: 0.752642] [G loss: 0.541217] time: 0:31:24.043943\n",
      "0.92536825\n",
      "[Epoch 21/50] [Batch 9/300] [D loss: 0.752610] [G loss: 0.534846] time: 0:31:24.351990\n",
      "0.9053886\n",
      "[Epoch 21/50] [Batch 10/300] [D loss: 0.752619] [G loss: 0.525686] time: 0:31:24.641420\n",
      "0.94205254\n",
      "[Epoch 21/50] [Batch 11/300] [D loss: 0.752612] [G loss: 0.541886] time: 0:31:24.952806\n",
      "0.94475436\n",
      "[Epoch 21/50] [Batch 12/300] [D loss: 0.752606] [G loss: 0.503287] time: 0:31:25.253746\n",
      "0.8919874\n",
      "[Epoch 21/50] [Batch 13/300] [D loss: 0.752627] [G loss: 0.578042] time: 0:31:25.553565\n",
      "0.9512797\n",
      "[Epoch 21/50] [Batch 14/300] [D loss: 0.752644] [G loss: 0.528783] time: 0:31:25.849461\n",
      "0.91626066\n",
      "[Epoch 21/50] [Batch 15/300] [D loss: 0.752633] [G loss: 0.533152] time: 0:31:26.153250\n",
      "0.9213874\n",
      "[Epoch 21/50] [Batch 16/300] [D loss: 0.752639] [G loss: 0.515559] time: 0:31:26.469446\n",
      "0.9280947\n",
      "[Epoch 21/50] [Batch 17/300] [D loss: 0.752631] [G loss: 0.545684] time: 0:31:26.768429\n",
      "0.9466749\n",
      "[Epoch 21/50] [Batch 18/300] [D loss: 0.752598] [G loss: 0.536572] time: 0:31:27.074928\n",
      "0.8998135\n",
      "[Epoch 21/50] [Batch 19/300] [D loss: 0.752617] [G loss: 0.559577] time: 0:31:27.374223\n",
      "0.9150724\n",
      "[Epoch 21/50] [Batch 21/300] [D loss: 0.752612] [G loss: 0.570271] time: 0:31:27.691055\n",
      "0.9505872\n",
      "[Epoch 21/50] [Batch 22/300] [D loss: 0.752619] [G loss: 0.558744] time: 0:31:27.997204\n",
      "0.94358635\n",
      "[Epoch 21/50] [Batch 23/300] [D loss: 0.752620] [G loss: 0.567157] time: 0:31:28.284485\n",
      "0.96661645\n",
      "[Epoch 21/50] [Batch 24/300] [D loss: 0.752648] [G loss: 0.547901] time: 0:31:28.584508\n",
      "0.89878845\n",
      "[Epoch 21/50] [Batch 25/300] [D loss: 0.752644] [G loss: 0.540427] time: 0:31:28.869096\n",
      "0.9038744\n",
      "[Epoch 21/50] [Batch 26/300] [D loss: 0.752615] [G loss: 0.531387] time: 0:31:29.169340\n",
      "0.8996382\n",
      "[Epoch 21/50] [Batch 27/300] [D loss: 0.752611] [G loss: 0.510682] time: 0:31:29.483407\n",
      "0.9745453\n",
      "[Epoch 21/50] [Batch 28/300] [D loss: 0.752603] [G loss: 0.519525] time: 0:31:29.773242\n",
      "0.8989837\n",
      "[Epoch 21/50] [Batch 29/300] [D loss: 0.752623] [G loss: 0.502794] time: 0:31:30.070805\n",
      "0.8877577\n",
      "[Epoch 21/50] [Batch 30/300] [D loss: 0.752590] [G loss: 0.503495] time: 0:31:30.358301\n",
      "0.86807626\n",
      "[Epoch 21/50] [Batch 31/300] [D loss: 0.752609] [G loss: 0.495867] time: 0:31:30.656156\n",
      "0.901104\n",
      "[Epoch 21/50] [Batch 32/300] [D loss: 0.752624] [G loss: 0.535230] time: 0:31:30.962068\n",
      "0.88121146\n",
      "[Epoch 21/50] [Batch 33/300] [D loss: 0.752618] [G loss: 0.508586] time: 0:31:31.252114\n",
      "0.8845282\n",
      "[Epoch 21/50] [Batch 34/300] [D loss: 0.752613] [G loss: 0.529995] time: 0:31:31.539974\n",
      "0.9081702\n",
      "[Epoch 21/50] [Batch 35/300] [D loss: 0.752632] [G loss: 0.539605] time: 0:31:31.822387\n",
      "0.9559763\n",
      "[Epoch 21/50] [Batch 36/300] [D loss: 0.752618] [G loss: 0.512433] time: 0:31:32.119968\n",
      "0.89576006\n",
      "[Epoch 21/50] [Batch 37/300] [D loss: 0.752595] [G loss: 0.553679] time: 0:31:32.414508\n",
      "0.90543646\n",
      "[Epoch 21/50] [Batch 38/300] [D loss: 0.752618] [G loss: 0.583038] time: 0:31:32.695522\n",
      "0.94427323\n",
      "[Epoch 21/50] [Batch 39/300] [D loss: 0.752603] [G loss: 0.531246] time: 0:31:32.982184\n",
      "0.9118028\n",
      "[Epoch 21/50] [Batch 40/300] [D loss: 0.752608] [G loss: 0.573238] time: 0:31:33.290489\n",
      "0.98158103\n",
      "[Epoch 21/50] [Batch 41/300] [D loss: 0.752651] [G loss: 0.515131] time: 0:31:33.584735\n",
      "0.9384535\n",
      "[Epoch 21/50] [Batch 42/300] [D loss: 0.752633] [G loss: 0.512608] time: 0:31:33.889951\n",
      "0.88646597\n",
      "[Epoch 21/50] [Batch 43/300] [D loss: 0.752621] [G loss: 0.556590] time: 0:31:34.198383\n",
      "0.8861644\n",
      "[Epoch 21/50] [Batch 44/300] [D loss: 0.752592] [G loss: 0.599689] time: 0:31:34.482050\n",
      "0.90721726\n",
      "[Epoch 21/50] [Batch 45/300] [D loss: 0.752630] [G loss: 0.534804] time: 0:31:34.773411\n",
      "0.93972\n",
      "[Epoch 21/50] [Batch 46/300] [D loss: 0.752610] [G loss: 0.510796] time: 0:31:35.091088\n",
      "0.8781728\n",
      "[Epoch 21/50] [Batch 47/300] [D loss: 0.752605] [G loss: 0.560743] time: 0:31:35.400859\n",
      "0.9134193\n",
      "[Epoch 21/50] [Batch 48/300] [D loss: 0.752616] [G loss: 0.558938] time: 0:31:35.684272\n",
      "0.9224209\n",
      "[Epoch 21/50] [Batch 49/300] [D loss: 0.752594] [G loss: 0.536928] time: 0:31:35.994218\n",
      "0.94562083\n",
      "[Epoch 21/50] [Batch 50/300] [D loss: 0.752670] [G loss: 0.532722] time: 0:31:36.296632\n",
      "0.8961788\n",
      "[Epoch 21/50] [Batch 51/300] [D loss: 0.752616] [G loss: 0.558357] time: 0:31:36.592374\n",
      "0.9027229\n",
      "[Epoch 21/50] [Batch 52/300] [D loss: 0.752619] [G loss: 0.535165] time: 0:31:36.889595\n",
      "0.93690753\n",
      "[Epoch 21/50] [Batch 53/300] [D loss: 0.752594] [G loss: 0.530848] time: 0:31:37.183423\n",
      "0.97222227\n",
      "[Epoch 21/50] [Batch 54/300] [D loss: 0.752610] [G loss: 0.527555] time: 0:31:37.485401\n",
      "0.92100054\n",
      "[Epoch 21/50] [Batch 55/300] [D loss: 0.752626] [G loss: 0.544027] time: 0:31:37.782691\n",
      "0.95343286\n",
      "[Epoch 21/50] [Batch 56/300] [D loss: 0.752614] [G loss: 0.537035] time: 0:31:38.068860\n",
      "0.90589577\n",
      "[Epoch 21/50] [Batch 57/300] [D loss: 0.752637] [G loss: 0.512193] time: 0:31:38.372624\n",
      "0.93159693\n",
      "[Epoch 21/50] [Batch 58/300] [D loss: 0.752614] [G loss: 0.518927] time: 0:31:38.669595\n",
      "0.9150068\n",
      "[Epoch 21/50] [Batch 59/300] [D loss: 0.752633] [G loss: 0.517864] time: 0:31:38.970099\n",
      "0.8877566\n",
      "[Epoch 21/50] [Batch 60/300] [D loss: 0.752642] [G loss: 0.537088] time: 0:31:39.270534\n",
      "0.94861954\n",
      "[Epoch 21/50] [Batch 61/300] [D loss: 0.752616] [G loss: 0.494394] time: 0:31:39.574919\n",
      "0.9114618\n",
      "[Epoch 21/50] [Batch 62/300] [D loss: 0.752600] [G loss: 0.518815] time: 0:31:39.872037\n",
      "0.9409179\n",
      "[Epoch 21/50] [Batch 63/300] [D loss: 0.752619] [G loss: 0.524075] time: 0:31:40.154251\n",
      "0.88125354\n",
      "[Epoch 21/50] [Batch 64/300] [D loss: 0.752624] [G loss: 0.510005] time: 0:31:40.451335\n",
      "0.9332091\n",
      "[Epoch 21/50] [Batch 65/300] [D loss: 0.752611] [G loss: 0.539458] time: 0:31:40.756253\n",
      "0.92931455\n",
      "[Epoch 21/50] [Batch 66/300] [D loss: 0.752640] [G loss: 0.499678] time: 0:31:41.058347\n",
      "0.9448003\n",
      "[Epoch 21/50] [Batch 67/300] [D loss: 0.752600] [G loss: 0.511223] time: 0:31:41.355014\n",
      "0.937769\n",
      "[Epoch 21/50] [Batch 68/300] [D loss: 0.752634] [G loss: 0.521151] time: 0:31:41.659185\n",
      "0.91539574\n",
      "[Epoch 21/50] [Batch 69/300] [D loss: 0.752600] [G loss: 0.527043] time: 0:31:41.948038\n",
      "0.9168563\n",
      "[Epoch 21/50] [Batch 70/300] [D loss: 0.752627] [G loss: 0.522952] time: 0:31:42.254818\n",
      "0.93302387\n",
      "[Epoch 21/50] [Batch 71/300] [D loss: 0.752603] [G loss: 0.508729] time: 0:31:42.564339\n",
      "0.93545103\n",
      "[Epoch 21/50] [Batch 72/300] [D loss: 0.752597] [G loss: 0.532719] time: 0:31:42.883802\n",
      "0.968822\n",
      "[Epoch 21/50] [Batch 73/300] [D loss: 0.752608] [G loss: 0.537354] time: 0:31:43.165722\n",
      "0.97029406\n",
      "[Epoch 21/50] [Batch 74/300] [D loss: 0.752607] [G loss: 0.495403] time: 0:31:43.459566\n",
      "0.9019997\n",
      "[Epoch 21/50] [Batch 75/300] [D loss: 0.752609] [G loss: 0.511819] time: 0:31:43.753368\n",
      "0.8799173\n",
      "[Epoch 21/50] [Batch 76/300] [D loss: 0.752638] [G loss: 0.516698] time: 0:31:44.045262\n",
      "0.9089644\n",
      "[Epoch 21/50] [Batch 77/300] [D loss: 0.752623] [G loss: 0.500744] time: 0:31:44.357477\n",
      "0.90869904\n",
      "[Epoch 21/50] [Batch 78/300] [D loss: 0.752610] [G loss: 0.522204] time: 0:31:44.640425\n",
      "0.9154318\n",
      "[Epoch 21/50] [Batch 79/300] [D loss: 0.752641] [G loss: 0.541439] time: 0:31:44.927748\n",
      "0.9301288\n",
      "[Epoch 21/50] [Batch 80/300] [D loss: 0.752602] [G loss: 0.534479] time: 0:31:45.233836\n",
      "0.911509\n",
      "[Epoch 21/50] [Batch 81/300] [D loss: 0.752631] [G loss: 0.518235] time: 0:31:45.544535\n",
      "0.8885446\n",
      "[Epoch 21/50] [Batch 82/300] [D loss: 0.752607] [G loss: 0.518816] time: 0:31:45.832417\n",
      "0.9174645\n",
      "[Epoch 21/50] [Batch 83/300] [D loss: 0.752594] [G loss: 0.551779] time: 0:31:46.130478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9064644\n",
      "[Epoch 21/50] [Batch 84/300] [D loss: 0.752615] [G loss: 0.529185] time: 0:31:46.431012\n",
      "0.9111686\n",
      "[Epoch 21/50] [Batch 85/300] [D loss: 0.752645] [G loss: 0.567616] time: 0:31:46.745415\n",
      "0.9415651\n",
      "[Epoch 21/50] [Batch 86/300] [D loss: 0.752600] [G loss: 0.523098] time: 0:31:47.045935\n",
      "0.8958685\n",
      "[Epoch 21/50] [Batch 87/300] [D loss: 0.752592] [G loss: 0.540762] time: 0:31:47.345490\n",
      "0.95237064\n",
      "[Epoch 21/50] [Batch 88/300] [D loss: 0.752604] [G loss: 0.508636] time: 0:31:47.652582\n",
      "0.96696025\n",
      "[Epoch 21/50] [Batch 89/300] [D loss: 0.752600] [G loss: 0.520132] time: 0:31:47.964967\n",
      "0.97101754\n",
      "[Epoch 21/50] [Batch 90/300] [D loss: 0.752579] [G loss: 0.531637] time: 0:31:48.264417\n",
      "0.9071441\n",
      "[Epoch 21/50] [Batch 91/300] [D loss: 0.752615] [G loss: 0.545891] time: 0:31:48.551419\n",
      "0.936037\n",
      "[Epoch 21/50] [Batch 92/300] [D loss: 0.752628] [G loss: 0.527818] time: 0:31:48.855400\n",
      "0.89858603\n",
      "[Epoch 21/50] [Batch 93/300] [D loss: 0.752609] [G loss: 0.516278] time: 0:31:49.164541\n",
      "0.91653746\n",
      "[Epoch 21/50] [Batch 94/300] [D loss: 0.752608] [G loss: 0.524651] time: 0:31:49.449700\n",
      "0.9258432\n",
      "[Epoch 21/50] [Batch 95/300] [D loss: 0.752611] [G loss: 0.511930] time: 0:31:49.748605\n",
      "0.8939232\n",
      "[Epoch 21/50] [Batch 96/300] [D loss: 0.752593] [G loss: 0.510641] time: 0:31:50.029150\n",
      "0.9484828\n",
      "[Epoch 21/50] [Batch 97/300] [D loss: 0.752604] [G loss: 0.519392] time: 0:31:50.333906\n",
      "0.95938754\n",
      "[Epoch 21/50] [Batch 98/300] [D loss: 0.752640] [G loss: 0.577799] time: 0:31:50.629499\n",
      "0.93471026\n",
      "[Epoch 21/50] [Batch 99/300] [D loss: 0.752614] [G loss: 0.592719] time: 0:31:50.927499\n",
      "0.92351705\n",
      "[Epoch 21/50] [Batch 100/300] [D loss: 0.752611] [G loss: 0.522865] time: 0:31:51.226872\n",
      "0.9283938\n",
      "[Epoch 21/50] [Batch 101/300] [D loss: 0.752631] [G loss: 0.549780] time: 0:31:51.522570\n",
      "0.9630938\n",
      "[Epoch 21/50] [Batch 102/300] [D loss: 0.752605] [G loss: 0.534853] time: 0:31:51.831595\n",
      "0.9333423\n",
      "[Epoch 21/50] [Batch 103/300] [D loss: 0.752599] [G loss: 0.508436] time: 0:31:52.121458\n",
      "0.91937774\n",
      "[Epoch 21/50] [Batch 104/300] [D loss: 0.752601] [G loss: 0.522587] time: 0:31:52.420439\n",
      "0.93569785\n",
      "[Epoch 21/50] [Batch 105/300] [D loss: 0.752608] [G loss: 0.534766] time: 0:31:52.735842\n",
      "0.9550994\n",
      "[Epoch 21/50] [Batch 106/300] [D loss: 0.752586] [G loss: 0.528930] time: 0:31:53.033507\n",
      "0.9403046\n",
      "[Epoch 21/50] [Batch 107/300] [D loss: 0.752623] [G loss: 0.507465] time: 0:31:53.338014\n",
      "0.9368806\n",
      "[Epoch 21/50] [Batch 108/300] [D loss: 0.752595] [G loss: 0.547113] time: 0:31:53.629091\n",
      "0.95921487\n",
      "[Epoch 21/50] [Batch 109/300] [D loss: 0.752651] [G loss: 0.530723] time: 0:31:53.920992\n",
      "0.9002082\n",
      "[Epoch 21/50] [Batch 110/300] [D loss: 0.752604] [G loss: 0.543851] time: 0:31:54.227204\n",
      "0.8996784\n",
      "[Epoch 21/50] [Batch 111/300] [D loss: 0.752590] [G loss: 0.520714] time: 0:31:54.530950\n",
      "0.9257464\n",
      "[Epoch 21/50] [Batch 112/300] [D loss: 0.752612] [G loss: 0.541933] time: 0:31:54.822982\n",
      "0.9199164\n",
      "[Epoch 21/50] [Batch 113/300] [D loss: 0.752622] [G loss: 0.509567] time: 0:31:55.116098\n",
      "0.91955775\n",
      "[Epoch 21/50] [Batch 114/300] [D loss: 0.752595] [G loss: 0.538594] time: 0:31:55.391131\n",
      "0.949827\n",
      "[Epoch 21/50] [Batch 115/300] [D loss: 0.752621] [G loss: 0.527211] time: 0:31:55.691861\n",
      "0.89357203\n",
      "[Epoch 21/50] [Batch 116/300] [D loss: 0.752616] [G loss: 0.519928] time: 0:31:55.988378\n",
      "0.9464746\n",
      "[Epoch 21/50] [Batch 117/300] [D loss: 0.752604] [G loss: 0.500976] time: 0:31:56.297832\n",
      "0.98308104\n",
      "[Epoch 21/50] [Batch 118/300] [D loss: 0.752593] [G loss: 0.575782] time: 0:31:56.593803\n",
      "0.908036\n",
      "[Epoch 21/50] [Batch 119/300] [D loss: 0.752574] [G loss: 0.540210] time: 0:31:56.887985\n",
      "0.9244177\n",
      "[Epoch 21/50] [Batch 120/300] [D loss: 0.752593] [G loss: 0.549089] time: 0:31:57.171463\n",
      "0.89696985\n",
      "[Epoch 21/50] [Batch 121/300] [D loss: 0.752590] [G loss: 0.548569] time: 0:31:57.479980\n",
      "0.8992133\n",
      "[Epoch 21/50] [Batch 122/300] [D loss: 0.752610] [G loss: 0.543091] time: 0:31:57.926381\n",
      "0.9467888\n",
      "[Epoch 21/50] [Batch 123/300] [D loss: 0.752614] [G loss: 0.521027] time: 0:31:58.234353\n",
      "0.9245611\n",
      "[Epoch 21/50] [Batch 124/300] [D loss: 0.752601] [G loss: 0.504075] time: 0:31:58.540087\n",
      "0.9213822\n",
      "[Epoch 21/50] [Batch 125/300] [D loss: 0.752641] [G loss: 0.566658] time: 0:31:58.844287\n",
      "0.8680236\n",
      "[Epoch 21/50] [Batch 126/300] [D loss: 0.752611] [G loss: 0.499779] time: 0:31:59.143932\n",
      "0.9043494\n",
      "[Epoch 21/50] [Batch 127/300] [D loss: 0.752588] [G loss: 0.539501] time: 0:31:59.448502\n",
      "0.96930647\n",
      "[Epoch 21/50] [Batch 128/300] [D loss: 0.752641] [G loss: 0.515961] time: 0:31:59.726184\n",
      "0.9163244\n",
      "[Epoch 21/50] [Batch 129/300] [D loss: 0.752615] [G loss: 0.540868] time: 0:32:00.011214\n",
      "0.9544589\n",
      "[Epoch 21/50] [Batch 130/300] [D loss: 0.752615] [G loss: 0.534252] time: 0:32:00.303701\n",
      "0.8986768\n",
      "[Epoch 21/50] [Batch 131/300] [D loss: 0.752607] [G loss: 0.505477] time: 0:32:00.595540\n",
      "0.94318813\n",
      "[Epoch 21/50] [Batch 132/300] [D loss: 0.752599] [G loss: 0.533725] time: 0:32:00.915530\n",
      "0.9261765\n",
      "[Epoch 21/50] [Batch 133/300] [D loss: 0.752614] [G loss: 0.517572] time: 0:32:01.217333\n",
      "0.9138177\n",
      "[Epoch 21/50] [Batch 134/300] [D loss: 0.752611] [G loss: 0.492339] time: 0:32:01.521224\n",
      "0.9053612\n",
      "[Epoch 21/50] [Batch 135/300] [D loss: 0.752607] [G loss: 0.504975] time: 0:32:01.799846\n",
      "0.9165433\n",
      "[Epoch 21/50] [Batch 136/300] [D loss: 0.752587] [G loss: 0.507730] time: 0:32:02.092903\n",
      "0.9470384\n",
      "[Epoch 21/50] [Batch 137/300] [D loss: 0.752602] [G loss: 0.549212] time: 0:32:02.397781\n",
      "0.96171355\n",
      "[Epoch 21/50] [Batch 138/300] [D loss: 0.752616] [G loss: 0.516984] time: 0:32:02.692481\n",
      "0.9075978\n",
      "[Epoch 21/50] [Batch 139/300] [D loss: 0.752592] [G loss: 0.502803] time: 0:32:02.995045\n",
      "0.9093931\n",
      "[Epoch 21/50] [Batch 140/300] [D loss: 0.752576] [G loss: 0.520288] time: 0:32:03.294492\n",
      "0.9163668\n",
      "[Epoch 21/50] [Batch 141/300] [D loss: 0.752612] [G loss: 0.530620] time: 0:32:03.568786\n",
      "0.94506073\n",
      "[Epoch 21/50] [Batch 142/300] [D loss: 0.752610] [G loss: 0.550835] time: 0:32:03.870842\n",
      "0.9413033\n",
      "[Epoch 21/50] [Batch 143/300] [D loss: 0.752594] [G loss: 0.534884] time: 0:32:04.165773\n",
      "0.913966\n",
      "[Epoch 21/50] [Batch 144/300] [D loss: 0.752601] [G loss: 0.520749] time: 0:32:04.467819\n",
      "0.91396475\n",
      "[Epoch 21/50] [Batch 145/300] [D loss: 0.752585] [G loss: 0.517702] time: 0:32:04.756847\n",
      "0.9058662\n",
      "[Epoch 21/50] [Batch 146/300] [D loss: 0.752597] [G loss: 0.510048] time: 0:32:05.057144\n",
      "0.9211251\n",
      "[Epoch 21/50] [Batch 147/300] [D loss: 0.752587] [G loss: 0.540703] time: 0:32:05.358760\n",
      "0.908076\n",
      "[Epoch 21/50] [Batch 148/300] [D loss: 0.752602] [G loss: 0.511188] time: 0:32:05.656632\n",
      "0.91884905\n",
      "[Epoch 21/50] [Batch 149/300] [D loss: 0.752578] [G loss: 0.524814] time: 0:32:05.967962\n",
      "0.9317031\n",
      "[Epoch 21/50] [Batch 150/300] [D loss: 0.752612] [G loss: 0.498208] time: 0:32:06.271264\n",
      "0.90249044\n",
      "[Epoch 21/50] [Batch 151/300] [D loss: 0.752606] [G loss: 0.517760] time: 0:32:06.566558\n",
      "0.90941316\n",
      "[Epoch 21/50] [Batch 152/300] [D loss: 0.752607] [G loss: 0.495901] time: 0:32:06.862984\n",
      "0.90569\n",
      "[Epoch 21/50] [Batch 153/300] [D loss: 0.752583] [G loss: 0.521508] time: 0:32:07.168492\n",
      "0.9216886\n",
      "[Epoch 21/50] [Batch 154/300] [D loss: 0.752601] [G loss: 0.505489] time: 0:32:07.469285\n",
      "0.92005277\n",
      "[Epoch 21/50] [Batch 155/300] [D loss: 0.752595] [G loss: 0.570412] time: 0:32:07.782383\n",
      "0.9330022\n",
      "[Epoch 21/50] [Batch 156/300] [D loss: 0.752604] [G loss: 0.521961] time: 0:32:08.089420\n",
      "0.9077539\n",
      "[Epoch 21/50] [Batch 157/300] [D loss: 0.752606] [G loss: 0.496104] time: 0:32:08.397433\n",
      "0.8909877\n",
      "[Epoch 21/50] [Batch 158/300] [D loss: 0.752599] [G loss: 0.487125] time: 0:32:08.692567\n",
      "0.8901221\n",
      "[Epoch 21/50] [Batch 159/300] [D loss: 0.752598] [G loss: 0.517224] time: 0:32:08.980703\n",
      "0.98282427\n",
      "[Epoch 21/50] [Batch 160/300] [D loss: 0.752588] [G loss: 0.532637] time: 0:32:09.288889\n",
      "0.9390425\n",
      "[Epoch 21/50] [Batch 161/300] [D loss: 0.752590] [G loss: 0.530264] time: 0:32:09.584293\n",
      "0.9329379\n",
      "[Epoch 21/50] [Batch 162/300] [D loss: 0.752614] [G loss: 0.482989] time: 0:32:09.877312\n",
      "0.9102171\n",
      "[Epoch 21/50] [Batch 163/300] [D loss: 0.752587] [G loss: 0.514204] time: 0:32:10.146256\n",
      "0.9431796\n",
      "[Epoch 21/50] [Batch 164/300] [D loss: 0.752611] [G loss: 0.486093] time: 0:32:10.433531\n",
      "0.98369545\n",
      "[Epoch 21/50] [Batch 165/300] [D loss: 0.752603] [G loss: 0.510503] time: 0:32:10.733098\n",
      "0.9219175\n",
      "[Epoch 21/50] [Batch 166/300] [D loss: 0.752589] [G loss: 0.531680] time: 0:32:11.009449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9053671\n",
      "[Epoch 21/50] [Batch 167/300] [D loss: 0.752589] [G loss: 0.523171] time: 0:32:11.319174\n",
      "0.9057912\n",
      "[Epoch 21/50] [Batch 168/300] [D loss: 0.752618] [G loss: 0.512063] time: 0:32:11.613432\n",
      "0.94379663\n",
      "[Epoch 21/50] [Batch 169/300] [D loss: 0.752602] [G loss: 0.497470] time: 0:32:11.910936\n",
      "0.9384927\n",
      "[Epoch 21/50] [Batch 170/300] [D loss: 0.752606] [G loss: 0.519132] time: 0:32:12.205097\n",
      "0.98351455\n",
      "[Epoch 21/50] [Batch 171/300] [D loss: 0.752611] [G loss: 0.535471] time: 0:32:12.504014\n",
      "0.93694776\n",
      "[Epoch 21/50] [Batch 172/300] [D loss: 0.752594] [G loss: 0.528740] time: 0:32:12.806009\n",
      "0.8944549\n",
      "[Epoch 21/50] [Batch 173/300] [D loss: 0.752614] [G loss: 0.520785] time: 0:32:13.091457\n",
      "0.92184186\n",
      "[Epoch 21/50] [Batch 174/300] [D loss: 0.752583] [G loss: 0.507230] time: 0:32:13.375169\n",
      "0.922888\n",
      "[Epoch 21/50] [Batch 175/300] [D loss: 0.752587] [G loss: 0.517936] time: 0:32:13.677143\n",
      "0.8604808\n",
      "[Epoch 21/50] [Batch 176/300] [D loss: 0.752588] [G loss: 0.550104] time: 0:32:13.968511\n",
      "0.93734264\n",
      "[Epoch 21/50] [Batch 177/300] [D loss: 0.752605] [G loss: 0.518787] time: 0:32:14.268332\n",
      "0.92888886\n",
      "[Epoch 21/50] [Batch 178/300] [D loss: 0.752588] [G loss: 0.553677] time: 0:32:14.556902\n",
      "0.907274\n",
      "[Epoch 21/50] [Batch 179/300] [D loss: 0.752596] [G loss: 0.509570] time: 0:32:14.840110\n",
      "0.91622686\n",
      "[Epoch 21/50] [Batch 180/300] [D loss: 0.752597] [G loss: 0.509049] time: 0:32:15.122817\n",
      "0.8994023\n",
      "[Epoch 21/50] [Batch 181/300] [D loss: 0.752615] [G loss: 0.501244] time: 0:32:15.405929\n",
      "0.87306947\n",
      "[Epoch 21/50] [Batch 182/300] [D loss: 0.752603] [G loss: 0.577378] time: 0:32:15.704104\n",
      "0.8692639\n",
      "[Epoch 21/50] [Batch 183/300] [D loss: 0.752598] [G loss: 0.534179] time: 0:32:15.999164\n",
      "0.91650575\n",
      "[Epoch 21/50] [Batch 184/300] [D loss: 0.752596] [G loss: 0.538811] time: 0:32:16.288505\n",
      "0.9279842\n",
      "[Epoch 21/50] [Batch 185/300] [D loss: 0.752586] [G loss: 0.516410] time: 0:32:16.589151\n",
      "0.91945934\n",
      "[Epoch 21/50] [Batch 186/300] [D loss: 0.752616] [G loss: 0.552841] time: 0:32:16.884019\n",
      "0.934897\n",
      "[Epoch 21/50] [Batch 187/300] [D loss: 0.752587] [G loss: 0.502499] time: 0:32:17.176262\n",
      "0.92568827\n",
      "[Epoch 21/50] [Batch 188/300] [D loss: 0.752585] [G loss: 0.538446] time: 0:32:17.483552\n",
      "0.91427463\n",
      "[Epoch 21/50] [Batch 189/300] [D loss: 0.752607] [G loss: 0.534344] time: 0:32:17.780314\n",
      "0.95315355\n",
      "[Epoch 21/50] [Batch 190/300] [D loss: 0.752613] [G loss: 0.528638] time: 0:32:18.067594\n",
      "0.95398635\n",
      "[Epoch 21/50] [Batch 191/300] [D loss: 0.752610] [G loss: 0.561479] time: 0:32:18.377327\n",
      "0.94310546\n",
      "[Epoch 21/50] [Batch 192/300] [D loss: 0.752593] [G loss: 0.510878] time: 0:32:18.675561\n",
      "0.9397457\n",
      "[Epoch 21/50] [Batch 193/300] [D loss: 0.752612] [G loss: 0.529513] time: 0:32:18.972802\n",
      "0.8407448\n",
      "[Epoch 21/50] [Batch 194/300] [D loss: 0.752578] [G loss: 0.531602] time: 0:32:19.273719\n",
      "0.91746324\n",
      "[Epoch 21/50] [Batch 195/300] [D loss: 0.752588] [G loss: 0.557777] time: 0:32:19.595006\n",
      "0.9694899\n",
      "[Epoch 21/50] [Batch 196/300] [D loss: 0.752599] [G loss: 0.525513] time: 0:32:19.892933\n",
      "0.8875578\n",
      "[Epoch 21/50] [Batch 197/300] [D loss: 0.752574] [G loss: 0.539176] time: 0:32:20.162781\n",
      "0.8789263\n",
      "[Epoch 21/50] [Batch 198/300] [D loss: 0.752589] [G loss: 0.538651] time: 0:32:20.457554\n",
      "0.91708845\n",
      "[Epoch 21/50] [Batch 199/300] [D loss: 0.752591] [G loss: 0.516888] time: 0:32:20.762109\n",
      "0.8906036\n",
      "[Epoch 21/50] [Batch 200/300] [D loss: 0.752586] [G loss: 0.597208] time: 0:32:21.069172\n",
      "0.90799385\n",
      "[Epoch 21/50] [Batch 201/300] [D loss: 0.752596] [G loss: 0.520386] time: 0:32:21.363997\n",
      "0.969841\n",
      "[Epoch 21/50] [Batch 202/300] [D loss: 0.752601] [G loss: 0.513385] time: 0:32:21.657222\n",
      "0.881566\n",
      "[Epoch 21/50] [Batch 203/300] [D loss: 0.752574] [G loss: 0.521613] time: 0:32:21.925685\n",
      "0.91180545\n",
      "[Epoch 21/50] [Batch 204/300] [D loss: 0.752598] [G loss: 0.490997] time: 0:32:22.210741\n",
      "0.8977137\n",
      "[Epoch 21/50] [Batch 205/300] [D loss: 0.752612] [G loss: 0.529003] time: 0:32:22.501678\n",
      "0.9153138\n",
      "[Epoch 21/50] [Batch 206/300] [D loss: 0.752611] [G loss: 0.510272] time: 0:32:22.791898\n",
      "0.93023515\n",
      "[Epoch 21/50] [Batch 207/300] [D loss: 0.752601] [G loss: 0.497399] time: 0:32:23.094599\n",
      "0.95077324\n",
      "[Epoch 21/50] [Batch 208/300] [D loss: 0.752582] [G loss: 0.520429] time: 0:32:23.413033\n",
      "0.9456969\n",
      "[Epoch 21/50] [Batch 209/300] [D loss: 0.752592] [G loss: 0.525318] time: 0:32:23.702763\n",
      "0.94077295\n",
      "[Epoch 21/50] [Batch 210/300] [D loss: 0.752611] [G loss: 0.505315] time: 0:32:23.997559\n",
      "0.9013505\n",
      "[Epoch 21/50] [Batch 211/300] [D loss: 0.752594] [G loss: 0.562926] time: 0:32:24.305931\n",
      "0.87388605\n",
      "[Epoch 21/50] [Batch 212/300] [D loss: 0.752591] [G loss: 0.516963] time: 0:32:24.614827\n",
      "0.908341\n",
      "[Epoch 21/50] [Batch 213/300] [D loss: 0.752603] [G loss: 0.527800] time: 0:32:24.921508\n",
      "0.9454553\n",
      "[Epoch 21/50] [Batch 214/300] [D loss: 0.752608] [G loss: 0.548728] time: 0:32:25.231104\n",
      "0.883301\n",
      "[Epoch 21/50] [Batch 215/300] [D loss: 0.752607] [G loss: 0.546849] time: 0:32:25.532479\n",
      "0.9424551\n",
      "[Epoch 21/50] [Batch 216/300] [D loss: 0.752605] [G loss: 0.538294] time: 0:32:25.838730\n",
      "0.968029\n",
      "[Epoch 21/50] [Batch 217/300] [D loss: 0.752609] [G loss: 0.502481] time: 0:32:26.147666\n",
      "0.9599881\n",
      "[Epoch 21/50] [Batch 218/300] [D loss: 0.752588] [G loss: 0.501589] time: 0:32:26.436760\n",
      "0.9266365\n",
      "[Epoch 21/50] [Batch 219/300] [D loss: 0.752586] [G loss: 0.532625] time: 0:32:26.724038\n",
      "0.9243714\n",
      "[Epoch 21/50] [Batch 220/300] [D loss: 0.752617] [G loss: 0.521113] time: 0:32:27.029005\n",
      "0.8789522\n",
      "[Epoch 21/50] [Batch 221/300] [D loss: 0.752599] [G loss: 0.550191] time: 0:32:27.353721\n",
      "0.9549493\n",
      "[Epoch 21/50] [Batch 222/300] [D loss: 0.752609] [G loss: 0.533294] time: 0:32:27.660679\n",
      "0.97652525\n",
      "[Epoch 21/50] [Batch 223/300] [D loss: 0.752590] [G loss: 0.547511] time: 0:32:27.964938\n",
      "0.940011\n",
      "[Epoch 21/50] [Batch 224/300] [D loss: 0.752581] [G loss: 0.537204] time: 0:32:28.234958\n",
      "0.93873096\n",
      "[Epoch 21/50] [Batch 225/300] [D loss: 0.752597] [G loss: 0.498813] time: 0:32:28.537355\n",
      "0.8960832\n",
      "[Epoch 21/50] [Batch 226/300] [D loss: 0.752581] [G loss: 0.570351] time: 0:32:28.839712\n",
      "0.8911509\n",
      "[Epoch 21/50] [Batch 227/300] [D loss: 0.752598] [G loss: 0.541340] time: 0:32:29.144463\n",
      "0.8827321\n",
      "[Epoch 21/50] [Batch 228/300] [D loss: 0.752578] [G loss: 0.508232] time: 0:32:29.445227\n",
      "0.9302915\n",
      "[Epoch 21/50] [Batch 229/300] [D loss: 0.752582] [G loss: 0.522359] time: 0:32:29.753599\n",
      "0.93077093\n",
      "[Epoch 21/50] [Batch 230/300] [D loss: 0.752596] [G loss: 0.500303] time: 0:32:30.051496\n",
      "0.9233458\n",
      "[Epoch 21/50] [Batch 231/300] [D loss: 0.752605] [G loss: 0.526400] time: 0:32:30.332594\n",
      "0.9716125\n",
      "[Epoch 21/50] [Batch 232/300] [D loss: 0.752607] [G loss: 0.523909] time: 0:32:30.634335\n",
      "0.94314\n",
      "[Epoch 21/50] [Batch 233/300] [D loss: 0.752595] [G loss: 0.528764] time: 0:32:30.914579\n",
      "0.9044099\n",
      "[Epoch 21/50] [Batch 234/300] [D loss: 0.752592] [G loss: 0.526552] time: 0:32:31.219125\n",
      "0.9193204\n",
      "[Epoch 21/50] [Batch 235/300] [D loss: 0.752595] [G loss: 0.504933] time: 0:32:31.521686\n",
      "0.9433499\n",
      "[Epoch 21/50] [Batch 236/300] [D loss: 0.752560] [G loss: 0.526399] time: 0:32:31.823786\n",
      "0.9075611\n",
      "[Epoch 21/50] [Batch 237/300] [D loss: 0.752570] [G loss: 0.545049] time: 0:32:32.126577\n",
      "0.88388366\n",
      "[Epoch 21/50] [Batch 238/300] [D loss: 0.752583] [G loss: 0.508314] time: 0:32:32.434614\n",
      "0.89577264\n",
      "[Epoch 21/50] [Batch 239/300] [D loss: 0.752607] [G loss: 0.529764] time: 0:32:32.755467\n",
      "0.9140311\n",
      "[Epoch 21/50] [Batch 240/300] [D loss: 0.752577] [G loss: 0.560720] time: 0:32:33.058181\n",
      "0.93154854\n",
      "[Epoch 21/50] [Batch 241/300] [D loss: 0.752580] [G loss: 0.578548] time: 0:32:33.370312\n",
      "0.9212373\n",
      "[Epoch 21/50] [Batch 242/300] [D loss: 0.752577] [G loss: 0.550513] time: 0:32:33.676622\n",
      "0.95031375\n",
      "[Epoch 21/50] [Batch 243/300] [D loss: 0.752620] [G loss: 0.516697] time: 0:32:33.975638\n",
      "0.9053595\n",
      "[Epoch 21/50] [Batch 244/300] [D loss: 0.752591] [G loss: 0.521512] time: 0:32:34.287340\n",
      "0.915174\n",
      "[Epoch 21/50] [Batch 245/300] [D loss: 0.752625] [G loss: 0.513148] time: 0:32:34.591079\n",
      "0.885369\n",
      "[Epoch 21/50] [Batch 246/300] [D loss: 0.752586] [G loss: 0.502789] time: 0:32:34.887631\n",
      "0.9641735\n",
      "[Epoch 21/50] [Batch 247/300] [D loss: 0.752573] [G loss: 0.498834] time: 0:32:35.195946\n",
      "0.88961655\n",
      "[Epoch 21/50] [Batch 248/300] [D loss: 0.752567] [G loss: 0.551512] time: 0:32:35.480473\n",
      "0.8812354\n",
      "[Epoch 21/50] [Batch 249/300] [D loss: 0.752586] [G loss: 0.520891] time: 0:32:35.778386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185526\n",
      "[Epoch 21/50] [Batch 250/300] [D loss: 0.752574] [G loss: 0.511481] time: 0:32:36.064113\n",
      "0.92741483\n",
      "[Epoch 21/50] [Batch 251/300] [D loss: 0.752592] [G loss: 0.515634] time: 0:32:36.381895\n",
      "0.9425051\n",
      "[Epoch 21/50] [Batch 252/300] [D loss: 0.752595] [G loss: 0.566331] time: 0:32:36.678320\n",
      "0.9057377\n",
      "[Epoch 21/50] [Batch 253/300] [D loss: 0.752586] [G loss: 0.505904] time: 0:32:36.979606\n",
      "0.93719846\n",
      "[Epoch 21/50] [Batch 254/300] [D loss: 0.752581] [G loss: 0.537619] time: 0:32:37.291930\n",
      "0.9760745\n",
      "[Epoch 21/50] [Batch 255/300] [D loss: 0.752584] [G loss: 0.530960] time: 0:32:37.597605\n",
      "0.9118669\n",
      "[Epoch 21/50] [Batch 256/300] [D loss: 0.752593] [G loss: 0.525747] time: 0:32:37.900085\n",
      "0.950579\n",
      "[Epoch 21/50] [Batch 257/300] [D loss: 0.752579] [G loss: 0.505470] time: 0:32:38.201556\n",
      "0.9324474\n",
      "[Epoch 21/50] [Batch 258/300] [D loss: 0.752615] [G loss: 0.526089] time: 0:32:38.492847\n",
      "0.9534893\n",
      "[Epoch 21/50] [Batch 259/300] [D loss: 0.752602] [G loss: 0.538821] time: 0:32:38.797704\n",
      "0.91208667\n",
      "[Epoch 21/50] [Batch 260/300] [D loss: 0.752573] [G loss: 0.513520] time: 0:32:39.095594\n",
      "0.92478853\n",
      "[Epoch 21/50] [Batch 261/300] [D loss: 0.752580] [G loss: 0.514376] time: 0:32:39.381363\n",
      "0.95052046\n",
      "[Epoch 21/50] [Batch 262/300] [D loss: 0.752571] [G loss: 0.509629] time: 0:32:39.680993\n",
      "0.912189\n",
      "[Epoch 21/50] [Batch 263/300] [D loss: 0.752601] [G loss: 0.502523] time: 0:32:39.965919\n",
      "0.96952695\n",
      "[Epoch 21/50] [Batch 264/300] [D loss: 0.752610] [G loss: 0.517061] time: 0:32:40.258312\n",
      "0.91332656\n",
      "[Epoch 21/50] [Batch 265/300] [D loss: 0.752584] [G loss: 0.521953] time: 0:32:40.551160\n",
      "0.9390084\n",
      "[Epoch 21/50] [Batch 266/300] [D loss: 0.752579] [G loss: 0.536779] time: 0:32:40.869131\n",
      "0.9311907\n",
      "[Epoch 21/50] [Batch 267/300] [D loss: 0.752586] [G loss: 0.508285] time: 0:32:41.137789\n",
      "0.98124045\n",
      "[Epoch 21/50] [Batch 268/300] [D loss: 0.752555] [G loss: 0.589893] time: 0:32:41.435209\n",
      "0.9351673\n",
      "[Epoch 21/50] [Batch 269/300] [D loss: 0.752603] [G loss: 0.501663] time: 0:32:41.737272\n",
      "0.953624\n",
      "[Epoch 21/50] [Batch 270/300] [D loss: 0.752609] [G loss: 0.500819] time: 0:32:42.043930\n",
      "0.9166603\n",
      "[Epoch 21/50] [Batch 271/300] [D loss: 0.752591] [G loss: 0.552234] time: 0:32:42.352581\n",
      "0.89723915\n",
      "[Epoch 21/50] [Batch 272/300] [D loss: 0.752574] [G loss: 0.520733] time: 0:32:42.649071\n",
      "0.94507796\n",
      "[Epoch 21/50] [Batch 273/300] [D loss: 0.752591] [G loss: 0.505659] time: 0:32:42.948583\n",
      "0.9373631\n",
      "[Epoch 21/50] [Batch 274/300] [D loss: 0.752598] [G loss: 0.514221] time: 0:32:43.251398\n",
      "0.920651\n",
      "[Epoch 21/50] [Batch 275/300] [D loss: 0.752587] [G loss: 0.530886] time: 0:32:43.540824\n",
      "0.8988171\n",
      "[Epoch 21/50] [Batch 276/300] [D loss: 0.752574] [G loss: 0.538998] time: 0:32:43.835927\n",
      "0.93275934\n",
      "[Epoch 21/50] [Batch 277/300] [D loss: 0.752568] [G loss: 0.518605] time: 0:32:44.115516\n",
      "0.88189584\n",
      "[Epoch 21/50] [Batch 278/300] [D loss: 0.752576] [G loss: 0.511635] time: 0:32:44.420860\n",
      "0.8805435\n",
      "[Epoch 21/50] [Batch 279/300] [D loss: 0.752597] [G loss: 0.505753] time: 0:32:44.720166\n",
      "0.88934994\n",
      "[Epoch 21/50] [Batch 280/300] [D loss: 0.752607] [G loss: 0.505032] time: 0:32:45.030414\n",
      "0.9369119\n",
      "[Epoch 21/50] [Batch 281/300] [D loss: 0.752580] [G loss: 0.554655] time: 0:32:45.324249\n",
      "0.9094866\n",
      "[Epoch 21/50] [Batch 282/300] [D loss: 0.752593] [G loss: 0.529164] time: 0:32:45.638868\n",
      "0.9157319\n",
      "[Epoch 21/50] [Batch 283/300] [D loss: 0.752591] [G loss: 0.514973] time: 0:32:45.935102\n",
      "0.88768935\n",
      "[Epoch 21/50] [Batch 284/300] [D loss: 0.752601] [G loss: 0.499768] time: 0:32:46.221788\n",
      "0.8776168\n",
      "[Epoch 21/50] [Batch 285/300] [D loss: 0.752590] [G loss: 0.537795] time: 0:32:46.504720\n",
      "0.89608806\n",
      "[Epoch 21/50] [Batch 286/300] [D loss: 0.752580] [G loss: 0.512602] time: 0:32:46.802596\n",
      "0.92964774\n",
      "[Epoch 21/50] [Batch 287/300] [D loss: 0.752606] [G loss: 0.536099] time: 0:32:47.107702\n",
      "0.93881106\n",
      "[Epoch 21/50] [Batch 288/300] [D loss: 0.752587] [G loss: 0.532374] time: 0:32:47.396206\n",
      "0.95293576\n",
      "[Epoch 21/50] [Batch 289/300] [D loss: 0.752591] [G loss: 0.514274] time: 0:32:47.680974\n",
      "0.9311156\n",
      "[Epoch 21/50] [Batch 290/300] [D loss: 0.752577] [G loss: 0.510330] time: 0:32:47.954081\n",
      "0.9211001\n",
      "[Epoch 21/50] [Batch 291/300] [D loss: 0.752599] [G loss: 0.518913] time: 0:32:48.260773\n",
      "0.93008095\n",
      "[Epoch 21/50] [Batch 292/300] [D loss: 0.752582] [G loss: 0.510372] time: 0:32:48.568494\n",
      "0.91257066\n",
      "[Epoch 21/50] [Batch 293/300] [D loss: 0.752578] [G loss: 0.504844] time: 0:32:48.866030\n",
      "0.9083333\n",
      "[Epoch 21/50] [Batch 294/300] [D loss: 0.752559] [G loss: 0.523900] time: 0:32:49.158974\n",
      "0.9285652\n",
      "[Epoch 21/50] [Batch 295/300] [D loss: 0.752582] [G loss: 0.523578] time: 0:32:49.451115\n",
      "0.9756501\n",
      "[Epoch 21/50] [Batch 296/300] [D loss: 0.752575] [G loss: 0.552513] time: 0:32:49.744294\n",
      "0.8775509\n",
      "[Epoch 21/50] [Batch 297/300] [D loss: 0.752612] [G loss: 0.507827] time: 0:32:50.035117\n",
      "0.93719363\n",
      "[Epoch 21/50] [Batch 298/300] [D loss: 0.752577] [G loss: 0.514181] time: 0:32:50.337445\n",
      "0.9163073\n",
      "[Epoch 21/50] [Batch 299/300] [D loss: 0.752575] [G loss: 0.517230] time: 0:32:50.636677\n",
      "0.94766814\n",
      "[Epoch 22/50] [Batch 0/300] [D loss: 0.752568] [G loss: 0.547298] time: 0:32:50.921027\n",
      "0.8999748\n",
      "[Epoch 22/50] [Batch 1/300] [D loss: 0.752614] [G loss: 0.508647] time: 0:32:51.208365\n",
      "0.89962244\n",
      "[Epoch 22/50] [Batch 2/300] [D loss: 0.752562] [G loss: 0.549380] time: 0:32:51.515251\n",
      "0.8883705\n",
      "[Epoch 22/50] [Batch 3/300] [D loss: 0.752589] [G loss: 0.541240] time: 0:32:51.809634\n",
      "0.91626143\n",
      "[Epoch 22/50] [Batch 4/300] [D loss: 0.752574] [G loss: 0.556073] time: 0:32:52.096931\n",
      "0.8817901\n",
      "[Epoch 22/50] [Batch 5/300] [D loss: 0.752573] [G loss: 0.568887] time: 0:32:52.390340\n",
      "0.9163634\n",
      "[Epoch 22/50] [Batch 6/300] [D loss: 0.752594] [G loss: 0.555581] time: 0:32:52.678247\n",
      "0.90654045\n",
      "[Epoch 22/50] [Batch 7/300] [D loss: 0.752597] [G loss: 0.509476] time: 0:32:52.993627\n",
      "0.9461215\n",
      "[Epoch 22/50] [Batch 8/300] [D loss: 0.752595] [G loss: 0.552727] time: 0:32:53.302672\n",
      "0.9158285\n",
      "[Epoch 22/50] [Batch 9/300] [D loss: 0.752616] [G loss: 0.500754] time: 0:32:53.597238\n",
      "0.91203076\n",
      "[Epoch 22/50] [Batch 10/300] [D loss: 0.752593] [G loss: 0.526973] time: 0:32:53.900882\n",
      "0.93216413\n",
      "[Epoch 22/50] [Batch 11/300] [D loss: 0.752570] [G loss: 0.523391] time: 0:32:54.206023\n",
      "0.9125088\n",
      "[Epoch 22/50] [Batch 12/300] [D loss: 0.752586] [G loss: 0.523834] time: 0:32:54.497293\n",
      "0.9288668\n",
      "[Epoch 22/50] [Batch 13/300] [D loss: 0.752573] [G loss: 0.553917] time: 0:32:54.786031\n",
      "0.8888426\n",
      "[Epoch 22/50] [Batch 14/300] [D loss: 0.752552] [G loss: 0.515787] time: 0:32:55.092337\n",
      "0.8728976\n",
      "[Epoch 22/50] [Batch 15/300] [D loss: 0.752571] [G loss: 0.514785] time: 0:32:55.388611\n",
      "0.93310475\n",
      "[Epoch 22/50] [Batch 16/300] [D loss: 0.752584] [G loss: 0.493581] time: 0:32:55.690317\n",
      "0.90480024\n",
      "[Epoch 22/50] [Batch 17/300] [D loss: 0.752564] [G loss: 0.515724] time: 0:32:55.953126\n",
      "0.9466348\n",
      "[Epoch 22/50] [Batch 18/300] [D loss: 0.752607] [G loss: 0.538731] time: 0:32:56.253598\n",
      "0.8841138\n",
      "[Epoch 22/50] [Batch 19/300] [D loss: 0.752613] [G loss: 0.511964] time: 0:32:56.527217\n",
      "0.9301717\n",
      "[Epoch 22/50] [Batch 20/300] [D loss: 0.752596] [G loss: 0.549643] time: 0:32:56.824923\n",
      "0.9220938\n",
      "[Epoch 22/50] [Batch 22/300] [D loss: 0.752586] [G loss: 0.493356] time: 0:32:57.130105\n",
      "0.9229588\n",
      "[Epoch 22/50] [Batch 23/300] [D loss: 0.752595] [G loss: 0.502328] time: 0:32:57.437309\n",
      "0.91725904\n",
      "[Epoch 22/50] [Batch 24/300] [D loss: 0.752561] [G loss: 0.495949] time: 0:32:57.733149\n",
      "0.9309015\n",
      "[Epoch 22/50] [Batch 25/300] [D loss: 0.752571] [G loss: 0.509545] time: 0:32:58.040083\n",
      "0.94644433\n",
      "[Epoch 22/50] [Batch 26/300] [D loss: 0.752602] [G loss: 0.509953] time: 0:32:58.347379\n",
      "0.89994496\n",
      "[Epoch 22/50] [Batch 27/300] [D loss: 0.752588] [G loss: 0.497715] time: 0:32:58.644292\n",
      "0.9398567\n",
      "[Epoch 22/50] [Batch 28/300] [D loss: 0.752584] [G loss: 0.526452] time: 0:32:58.931418\n",
      "0.9238308\n",
      "[Epoch 22/50] [Batch 29/300] [D loss: 0.752575] [G loss: 0.545351] time: 0:32:59.214551\n",
      "0.89254874\n",
      "[Epoch 22/50] [Batch 30/300] [D loss: 0.752574] [G loss: 0.515985] time: 0:32:59.518796\n",
      "0.9173853\n",
      "[Epoch 22/50] [Batch 31/300] [D loss: 0.752579] [G loss: 0.515637] time: 0:32:59.839599\n",
      "0.954904\n",
      "[Epoch 22/50] [Batch 32/300] [D loss: 0.752589] [G loss: 0.494783] time: 0:33:00.147294\n",
      "0.8970757\n",
      "[Epoch 22/50] [Batch 33/300] [D loss: 0.752606] [G loss: 0.503723] time: 0:33:00.455082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90691596\n",
      "[Epoch 22/50] [Batch 34/300] [D loss: 0.752608] [G loss: 0.513106] time: 0:33:00.759220\n",
      "0.85581344\n",
      "[Epoch 22/50] [Batch 35/300] [D loss: 0.752594] [G loss: 0.532408] time: 0:33:01.044159\n",
      "0.9719177\n",
      "[Epoch 22/50] [Batch 36/300] [D loss: 0.752582] [G loss: 0.553011] time: 0:33:01.330638\n",
      "0.9301408\n",
      "[Epoch 22/50] [Batch 37/300] [D loss: 0.752572] [G loss: 0.550875] time: 0:33:01.625266\n",
      "0.93015665\n",
      "[Epoch 22/50] [Batch 38/300] [D loss: 0.752607] [G loss: 0.511518] time: 0:33:01.938451\n",
      "0.9084597\n",
      "[Epoch 22/50] [Batch 39/300] [D loss: 0.752600] [G loss: 0.508081] time: 0:33:02.259698\n",
      "0.95044905\n",
      "[Epoch 22/50] [Batch 40/300] [D loss: 0.752579] [G loss: 0.506864] time: 0:33:02.557631\n",
      "0.9110017\n",
      "[Epoch 22/50] [Batch 41/300] [D loss: 0.752579] [G loss: 0.505309] time: 0:33:02.856257\n",
      "0.9162324\n",
      "[Epoch 22/50] [Batch 42/300] [D loss: 0.752566] [G loss: 0.562510] time: 0:33:03.158574\n",
      "0.93371105\n",
      "[Epoch 22/50] [Batch 43/300] [D loss: 0.752590] [G loss: 0.507479] time: 0:33:03.461970\n",
      "0.9246852\n",
      "[Epoch 22/50] [Batch 44/300] [D loss: 0.752592] [G loss: 0.530501] time: 0:33:03.776859\n",
      "0.95662975\n",
      "[Epoch 22/50] [Batch 45/300] [D loss: 0.752586] [G loss: 0.506648] time: 0:33:04.078393\n",
      "0.89315414\n",
      "[Epoch 22/50] [Batch 46/300] [D loss: 0.752576] [G loss: 0.522421] time: 0:33:04.395274\n",
      "0.9223941\n",
      "[Epoch 22/50] [Batch 47/300] [D loss: 0.752591] [G loss: 0.510371] time: 0:33:04.675549\n",
      "0.89848995\n",
      "[Epoch 22/50] [Batch 48/300] [D loss: 0.752577] [G loss: 0.536963] time: 0:33:04.957475\n",
      "0.95825505\n",
      "[Epoch 22/50] [Batch 49/300] [D loss: 0.752599] [G loss: 0.512317] time: 0:33:05.254934\n",
      "0.9274513\n",
      "[Epoch 22/50] [Batch 50/300] [D loss: 0.752553] [G loss: 0.532888] time: 0:33:05.557032\n",
      "0.9136772\n",
      "[Epoch 22/50] [Batch 51/300] [D loss: 0.752575] [G loss: 0.505390] time: 0:33:05.865137\n",
      "0.9217623\n",
      "[Epoch 22/50] [Batch 52/300] [D loss: 0.752586] [G loss: 0.538519] time: 0:33:06.160228\n",
      "0.9529353\n",
      "[Epoch 22/50] [Batch 53/300] [D loss: 0.752586] [G loss: 0.513172] time: 0:33:06.472874\n",
      "0.895727\n",
      "[Epoch 22/50] [Batch 54/300] [D loss: 0.752616] [G loss: 0.530976] time: 0:33:06.773125\n",
      "0.91287273\n",
      "[Epoch 22/50] [Batch 55/300] [D loss: 0.752569] [G loss: 0.508099] time: 0:33:07.083129\n",
      "0.9752571\n",
      "[Epoch 22/50] [Batch 56/300] [D loss: 0.752611] [G loss: 0.508262] time: 0:33:07.397538\n",
      "0.9608223\n",
      "[Epoch 22/50] [Batch 57/300] [D loss: 0.752588] [G loss: 0.494375] time: 0:33:07.705275\n",
      "0.95108837\n",
      "[Epoch 22/50] [Batch 58/300] [D loss: 0.752569] [G loss: 0.499785] time: 0:33:08.020266\n",
      "0.9233747\n",
      "[Epoch 22/50] [Batch 59/300] [D loss: 0.752568] [G loss: 0.500403] time: 0:33:08.327259\n",
      "0.9517739\n",
      "[Epoch 22/50] [Batch 60/300] [D loss: 0.752569] [G loss: 0.514293] time: 0:33:08.635802\n",
      "0.9474909\n",
      "[Epoch 22/50] [Batch 61/300] [D loss: 0.752572] [G loss: 0.534391] time: 0:33:08.941676\n",
      "0.9528673\n",
      "[Epoch 22/50] [Batch 62/300] [D loss: 0.752582] [G loss: 0.499934] time: 0:33:09.245909\n",
      "0.91330296\n",
      "[Epoch 22/50] [Batch 63/300] [D loss: 0.752569] [G loss: 0.522933] time: 0:33:09.544397\n",
      "0.9689524\n",
      "[Epoch 22/50] [Batch 64/300] [D loss: 0.752599] [G loss: 0.504514] time: 0:33:09.835198\n",
      "0.93664044\n",
      "[Epoch 22/50] [Batch 65/300] [D loss: 0.752578] [G loss: 0.519102] time: 0:33:10.127561\n",
      "0.91217023\n",
      "[Epoch 22/50] [Batch 66/300] [D loss: 0.752563] [G loss: 0.516395] time: 0:33:10.418221\n",
      "0.9518698\n",
      "[Epoch 22/50] [Batch 67/300] [D loss: 0.752596] [G loss: 0.522786] time: 0:33:10.732945\n",
      "0.91630286\n",
      "[Epoch 22/50] [Batch 68/300] [D loss: 0.752594] [G loss: 0.517180] time: 0:33:11.011920\n",
      "0.94501424\n",
      "[Epoch 22/50] [Batch 69/300] [D loss: 0.752598] [G loss: 0.510145] time: 0:33:11.304791\n",
      "0.89874905\n",
      "[Epoch 22/50] [Batch 70/300] [D loss: 0.752571] [G loss: 0.495153] time: 0:33:11.598522\n",
      "0.9290634\n",
      "[Epoch 22/50] [Batch 71/300] [D loss: 0.752568] [G loss: 0.492470] time: 0:33:11.907265\n",
      "0.9394943\n",
      "[Epoch 22/50] [Batch 72/300] [D loss: 0.752602] [G loss: 0.509893] time: 0:33:12.231996\n",
      "0.889972\n",
      "[Epoch 22/50] [Batch 73/300] [D loss: 0.752586] [G loss: 0.554717] time: 0:33:12.544423\n",
      "0.87499255\n",
      "[Epoch 22/50] [Batch 74/300] [D loss: 0.752573] [G loss: 0.520618] time: 0:33:12.845341\n",
      "0.9248657\n",
      "[Epoch 22/50] [Batch 75/300] [D loss: 0.752575] [G loss: 0.500899] time: 0:33:13.141078\n",
      "0.92700726\n",
      "[Epoch 22/50] [Batch 76/300] [D loss: 0.752567] [G loss: 0.511352] time: 0:33:13.438526\n",
      "0.94859916\n",
      "[Epoch 22/50] [Batch 77/300] [D loss: 0.752572] [G loss: 0.507070] time: 0:33:13.735004\n",
      "0.9296117\n",
      "[Epoch 22/50] [Batch 78/300] [D loss: 0.752589] [G loss: 0.486976] time: 0:33:14.042866\n",
      "0.9252561\n",
      "[Epoch 22/50] [Batch 79/300] [D loss: 0.752577] [G loss: 0.540714] time: 0:33:14.340954\n",
      "0.9520256\n",
      "[Epoch 22/50] [Batch 80/300] [D loss: 0.752551] [G loss: 0.501468] time: 0:33:14.627150\n",
      "0.9173848\n",
      "[Epoch 22/50] [Batch 81/300] [D loss: 0.752568] [G loss: 0.484396] time: 0:33:14.926989\n",
      "0.8851285\n",
      "[Epoch 22/50] [Batch 82/300] [D loss: 0.752605] [G loss: 0.505589] time: 0:33:15.217542\n",
      "0.88884217\n",
      "[Epoch 22/50] [Batch 83/300] [D loss: 0.752569] [G loss: 0.529000] time: 0:33:15.526368\n",
      "0.92826635\n",
      "[Epoch 22/50] [Batch 84/300] [D loss: 0.752576] [G loss: 0.538550] time: 0:33:15.833065\n",
      "0.919004\n",
      "[Epoch 22/50] [Batch 85/300] [D loss: 0.752576] [G loss: 0.543771] time: 0:33:16.144827\n",
      "0.9328771\n",
      "[Epoch 22/50] [Batch 86/300] [D loss: 0.752598] [G loss: 0.502294] time: 0:33:16.447789\n",
      "0.91936\n",
      "[Epoch 22/50] [Batch 87/300] [D loss: 0.752571] [G loss: 0.516216] time: 0:33:16.754003\n",
      "0.9247325\n",
      "[Epoch 22/50] [Batch 88/300] [D loss: 0.752569] [G loss: 0.555110] time: 0:33:17.072392\n",
      "0.93903416\n",
      "[Epoch 22/50] [Batch 89/300] [D loss: 0.752606] [G loss: 0.503184] time: 0:33:17.377272\n",
      "0.94759685\n",
      "[Epoch 22/50] [Batch 90/300] [D loss: 0.752611] [G loss: 0.545702] time: 0:33:17.688491\n",
      "0.8991146\n",
      "[Epoch 22/50] [Batch 91/300] [D loss: 0.752599] [G loss: 0.511132] time: 0:33:17.992318\n",
      "0.96153265\n",
      "[Epoch 22/50] [Batch 92/300] [D loss: 0.752562] [G loss: 0.492304] time: 0:33:18.278222\n",
      "0.9184651\n",
      "[Epoch 22/50] [Batch 93/300] [D loss: 0.752594] [G loss: 0.519057] time: 0:33:18.595500\n",
      "0.9140776\n",
      "[Epoch 22/50] [Batch 94/300] [D loss: 0.752559] [G loss: 0.517833] time: 0:33:18.892738\n",
      "0.87158823\n",
      "[Epoch 22/50] [Batch 95/300] [D loss: 0.752563] [G loss: 0.503551] time: 0:33:19.174532\n",
      "0.9271911\n",
      "[Epoch 22/50] [Batch 96/300] [D loss: 0.752549] [G loss: 0.520858] time: 0:33:19.461758\n",
      "0.90972805\n",
      "[Epoch 22/50] [Batch 97/300] [D loss: 0.752571] [G loss: 0.517245] time: 0:33:19.753215\n",
      "0.8984216\n",
      "[Epoch 22/50] [Batch 98/300] [D loss: 0.752580] [G loss: 0.543379] time: 0:33:20.039491\n",
      "0.8813445\n",
      "[Epoch 22/50] [Batch 99/300] [D loss: 0.752589] [G loss: 0.515764] time: 0:33:20.351851\n",
      "0.92698365\n",
      "[Epoch 22/50] [Batch 100/300] [D loss: 0.752560] [G loss: 0.563297] time: 0:33:20.657414\n",
      "0.92646104\n",
      "[Epoch 22/50] [Batch 101/300] [D loss: 0.752563] [G loss: 0.545456] time: 0:33:20.964083\n",
      "0.9270211\n",
      "[Epoch 22/50] [Batch 102/300] [D loss: 0.752558] [G loss: 0.529101] time: 0:33:21.253272\n",
      "0.94594127\n",
      "[Epoch 22/50] [Batch 103/300] [D loss: 0.752598] [G loss: 0.499600] time: 0:33:21.549885\n",
      "0.9064457\n",
      "[Epoch 22/50] [Batch 104/300] [D loss: 0.752580] [G loss: 0.506513] time: 0:33:21.849360\n",
      "0.94466877\n",
      "[Epoch 22/50] [Batch 105/300] [D loss: 0.752575] [G loss: 0.498788] time: 0:33:22.147915\n",
      "0.91260475\n",
      "[Epoch 22/50] [Batch 106/300] [D loss: 0.752550] [G loss: 0.533364] time: 0:33:22.451582\n",
      "0.9317563\n",
      "[Epoch 22/50] [Batch 107/300] [D loss: 0.752569] [G loss: 0.539228] time: 0:33:22.728921\n",
      "0.94608825\n",
      "[Epoch 22/50] [Batch 108/300] [D loss: 0.752583] [G loss: 0.492814] time: 0:33:23.035117\n",
      "0.9106746\n",
      "[Epoch 22/50] [Batch 109/300] [D loss: 0.752596] [G loss: 0.504912] time: 0:33:23.329111\n",
      "0.9202385\n",
      "[Epoch 22/50] [Batch 110/300] [D loss: 0.752546] [G loss: 0.523440] time: 0:33:23.628160\n",
      "0.91583043\n",
      "[Epoch 22/50] [Batch 111/300] [D loss: 0.752562] [G loss: 0.516346] time: 0:33:23.922625\n",
      "0.92756206\n",
      "[Epoch 22/50] [Batch 112/300] [D loss: 0.752556] [G loss: 0.496483] time: 0:33:24.216883\n",
      "0.8942079\n",
      "[Epoch 22/50] [Batch 113/300] [D loss: 0.752574] [G loss: 0.518384] time: 0:33:24.510816\n",
      "0.8987339\n",
      "[Epoch 22/50] [Batch 114/300] [D loss: 0.752584] [G loss: 0.499610] time: 0:33:24.803117\n",
      "0.9585622\n",
      "[Epoch 22/50] [Batch 115/300] [D loss: 0.752574] [G loss: 0.518393] time: 0:33:25.102450\n",
      "0.9423376\n",
      "[Epoch 22/50] [Batch 116/300] [D loss: 0.752566] [G loss: 0.533017] time: 0:33:25.407672\n",
      "0.97563124\n",
      "[Epoch 22/50] [Batch 117/300] [D loss: 0.752537] [G loss: 0.528802] time: 0:33:25.700806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742848\n",
      "[Epoch 22/50] [Batch 118/300] [D loss: 0.752573] [G loss: 0.497716] time: 0:33:25.983200\n",
      "0.9117396\n",
      "[Epoch 22/50] [Batch 119/300] [D loss: 0.752559] [G loss: 0.539387] time: 0:33:26.284871\n",
      "0.904695\n",
      "[Epoch 22/50] [Batch 120/300] [D loss: 0.752563] [G loss: 0.515638] time: 0:33:26.583005\n",
      "0.90205073\n",
      "[Epoch 22/50] [Batch 121/300] [D loss: 0.752563] [G loss: 0.496736] time: 0:33:26.878802\n",
      "0.89969444\n",
      "[Epoch 22/50] [Batch 122/300] [D loss: 0.752568] [G loss: 0.502173] time: 0:33:27.174670\n",
      "0.8681312\n",
      "[Epoch 22/50] [Batch 123/300] [D loss: 0.752552] [G loss: 0.528600] time: 0:33:27.461909\n",
      "0.85866517\n",
      "[Epoch 22/50] [Batch 124/300] [D loss: 0.752574] [G loss: 0.526040] time: 0:33:27.750719\n",
      "0.9464653\n",
      "[Epoch 22/50] [Batch 125/300] [D loss: 0.752563] [G loss: 0.553830] time: 0:33:28.037806\n",
      "0.9035508\n",
      "[Epoch 22/50] [Batch 126/300] [D loss: 0.752584] [G loss: 0.527096] time: 0:33:28.336276\n",
      "0.945128\n",
      "[Epoch 22/50] [Batch 127/300] [D loss: 0.752572] [G loss: 0.545296] time: 0:33:28.625674\n",
      "0.906513\n",
      "[Epoch 22/50] [Batch 128/300] [D loss: 0.752565] [G loss: 0.521815] time: 0:33:28.927460\n",
      "0.9466956\n",
      "[Epoch 22/50] [Batch 129/300] [D loss: 0.752553] [G loss: 0.530676] time: 0:33:29.226478\n",
      "0.93012816\n",
      "[Epoch 22/50] [Batch 130/300] [D loss: 0.752566] [G loss: 0.539353] time: 0:33:29.500059\n",
      "0.9080465\n",
      "[Epoch 22/50] [Batch 131/300] [D loss: 0.752589] [G loss: 0.528636] time: 0:33:29.796016\n",
      "0.88492745\n",
      "[Epoch 22/50] [Batch 132/300] [D loss: 0.752569] [G loss: 0.512452] time: 0:33:30.103821\n",
      "0.90275604\n",
      "[Epoch 22/50] [Batch 133/300] [D loss: 0.752598] [G loss: 0.496990] time: 0:33:30.408188\n",
      "0.9765386\n",
      "[Epoch 22/50] [Batch 134/300] [D loss: 0.752560] [G loss: 0.553371] time: 0:33:30.688224\n",
      "0.9167735\n",
      "[Epoch 22/50] [Batch 135/300] [D loss: 0.752582] [G loss: 0.507600] time: 0:33:30.977081\n",
      "0.90486956\n",
      "[Epoch 22/50] [Batch 136/300] [D loss: 0.752597] [G loss: 0.521606] time: 0:33:31.294333\n",
      "0.90404147\n",
      "[Epoch 22/50] [Batch 137/300] [D loss: 0.752563] [G loss: 0.525763] time: 0:33:31.607820\n",
      "0.89220905\n",
      "[Epoch 22/50] [Batch 138/300] [D loss: 0.752583] [G loss: 0.506592] time: 0:33:31.917165\n",
      "0.93327594\n",
      "[Epoch 22/50] [Batch 139/300] [D loss: 0.752563] [G loss: 0.504100] time: 0:33:32.233756\n",
      "0.91017103\n",
      "[Epoch 22/50] [Batch 140/300] [D loss: 0.752551] [G loss: 0.541517] time: 0:33:32.518151\n",
      "0.9761997\n",
      "[Epoch 22/50] [Batch 141/300] [D loss: 0.752563] [G loss: 0.493625] time: 0:33:32.834439\n",
      "0.97869486\n",
      "[Epoch 22/50] [Batch 142/300] [D loss: 0.752591] [G loss: 0.531035] time: 0:33:33.134039\n",
      "0.91634995\n",
      "[Epoch 22/50] [Batch 143/300] [D loss: 0.752561] [G loss: 0.500131] time: 0:33:33.428232\n",
      "0.91753215\n",
      "[Epoch 22/50] [Batch 144/300] [D loss: 0.752555] [G loss: 0.568783] time: 0:33:33.732266\n",
      "0.9274042\n",
      "[Epoch 22/50] [Batch 145/300] [D loss: 0.752544] [G loss: 0.519134] time: 0:33:34.027912\n",
      "0.9363437\n",
      "[Epoch 22/50] [Batch 146/300] [D loss: 0.752573] [G loss: 0.510505] time: 0:33:34.324970\n",
      "0.9087661\n",
      "[Epoch 22/50] [Batch 147/300] [D loss: 0.752558] [G loss: 0.525879] time: 0:33:34.644401\n",
      "0.9533443\n",
      "[Epoch 22/50] [Batch 148/300] [D loss: 0.752576] [G loss: 0.499102] time: 0:33:34.949986\n",
      "0.9116044\n",
      "[Epoch 22/50] [Batch 149/300] [D loss: 0.752558] [G loss: 0.515137] time: 0:33:35.248694\n",
      "0.9469023\n",
      "[Epoch 22/50] [Batch 150/300] [D loss: 0.752547] [G loss: 0.508952] time: 0:33:35.535448\n",
      "0.9385485\n",
      "[Epoch 22/50] [Batch 151/300] [D loss: 0.752563] [G loss: 0.520282] time: 0:33:35.829160\n",
      "0.92435503\n",
      "[Epoch 22/50] [Batch 152/300] [D loss: 0.752552] [G loss: 0.498538] time: 0:33:36.101765\n",
      "0.94564\n",
      "[Epoch 22/50] [Batch 153/300] [D loss: 0.752562] [G loss: 0.544780] time: 0:33:36.403597\n",
      "0.91073996\n",
      "[Epoch 22/50] [Batch 154/300] [D loss: 0.752578] [G loss: 0.541155] time: 0:33:36.703504\n",
      "0.9182894\n",
      "[Epoch 22/50] [Batch 155/300] [D loss: 0.752580] [G loss: 0.515437] time: 0:33:37.009357\n",
      "0.90762955\n",
      "[Epoch 22/50] [Batch 156/300] [D loss: 0.752568] [G loss: 0.554963] time: 0:33:37.319591\n",
      "0.8937383\n",
      "[Epoch 22/50] [Batch 157/300] [D loss: 0.752566] [G loss: 0.544814] time: 0:33:37.610914\n",
      "0.89353585\n",
      "[Epoch 22/50] [Batch 158/300] [D loss: 0.752575] [G loss: 0.535887] time: 0:33:37.898939\n",
      "0.93072134\n",
      "[Epoch 22/50] [Batch 159/300] [D loss: 0.752558] [G loss: 0.485856] time: 0:33:38.181269\n",
      "0.9038467\n",
      "[Epoch 22/50] [Batch 160/300] [D loss: 0.752602] [G loss: 0.524646] time: 0:33:38.489639\n",
      "0.8859553\n",
      "[Epoch 22/50] [Batch 161/300] [D loss: 0.752553] [G loss: 0.532779] time: 0:33:38.788970\n",
      "0.9566367\n",
      "[Epoch 22/50] [Batch 162/300] [D loss: 0.752564] [G loss: 0.496976] time: 0:33:39.089362\n",
      "0.9767143\n",
      "[Epoch 22/50] [Batch 163/300] [D loss: 0.752561] [G loss: 0.501518] time: 0:33:39.382434\n",
      "0.8948702\n",
      "[Epoch 22/50] [Batch 164/300] [D loss: 0.752577] [G loss: 0.502399] time: 0:33:39.682142\n",
      "0.9303184\n",
      "[Epoch 22/50] [Batch 165/300] [D loss: 0.752555] [G loss: 0.491986] time: 0:33:39.941558\n",
      "0.87869257\n",
      "[Epoch 22/50] [Batch 166/300] [D loss: 0.752575] [G loss: 0.499579] time: 0:33:40.226582\n",
      "0.9077851\n",
      "[Epoch 22/50] [Batch 167/300] [D loss: 0.752593] [G loss: 0.504444] time: 0:33:40.531339\n",
      "0.9137239\n",
      "[Epoch 22/50] [Batch 168/300] [D loss: 0.752581] [G loss: 0.487445] time: 0:33:40.829358\n",
      "0.944788\n",
      "[Epoch 22/50] [Batch 169/300] [D loss: 0.752587] [G loss: 0.542697] time: 0:33:41.118105\n",
      "0.90229726\n",
      "[Epoch 22/50] [Batch 170/300] [D loss: 0.752598] [G loss: 0.505794] time: 0:33:41.411478\n",
      "0.92342067\n",
      "[Epoch 22/50] [Batch 171/300] [D loss: 0.752550] [G loss: 0.511541] time: 0:33:41.711501\n",
      "0.89155656\n",
      "[Epoch 22/50] [Batch 172/300] [D loss: 0.752552] [G loss: 0.503099] time: 0:33:42.017006\n",
      "0.9427771\n",
      "[Epoch 22/50] [Batch 173/300] [D loss: 0.752544] [G loss: 0.516040] time: 0:33:42.315267\n",
      "0.8840029\n",
      "[Epoch 22/50] [Batch 174/300] [D loss: 0.752554] [G loss: 0.553540] time: 0:33:42.611172\n",
      "0.94092077\n",
      "[Epoch 22/50] [Batch 175/300] [D loss: 0.752563] [G loss: 0.504439] time: 0:33:42.915580\n",
      "0.9756345\n",
      "[Epoch 22/50] [Batch 176/300] [D loss: 0.752569] [G loss: 0.524512] time: 0:33:43.211049\n",
      "0.8741193\n",
      "[Epoch 22/50] [Batch 177/300] [D loss: 0.752571] [G loss: 0.542864] time: 0:33:43.519154\n",
      "0.9396844\n",
      "[Epoch 22/50] [Batch 178/300] [D loss: 0.752541] [G loss: 0.514115] time: 0:33:43.941796\n",
      "0.88651305\n",
      "[Epoch 22/50] [Batch 179/300] [D loss: 0.752553] [G loss: 0.508630] time: 0:33:44.248417\n",
      "0.9497814\n",
      "[Epoch 22/50] [Batch 180/300] [D loss: 0.752575] [G loss: 0.538041] time: 0:33:44.550598\n",
      "0.8936758\n",
      "[Epoch 22/50] [Batch 181/300] [D loss: 0.752558] [G loss: 0.534229] time: 0:33:44.851728\n",
      "0.91958064\n",
      "[Epoch 22/50] [Batch 182/300] [D loss: 0.752567] [G loss: 0.529915] time: 0:33:45.145401\n",
      "0.8844792\n",
      "[Epoch 22/50] [Batch 183/300] [D loss: 0.752545] [G loss: 0.521791] time: 0:33:45.434444\n",
      "0.89140826\n",
      "[Epoch 22/50] [Batch 184/300] [D loss: 0.752578] [G loss: 0.498121] time: 0:33:45.719858\n",
      "0.9478013\n",
      "[Epoch 22/50] [Batch 185/300] [D loss: 0.752566] [G loss: 0.536220] time: 0:33:46.018676\n",
      "0.95256805\n",
      "[Epoch 22/50] [Batch 186/300] [D loss: 0.752567] [G loss: 0.582234] time: 0:33:46.325603\n",
      "0.93731624\n",
      "[Epoch 22/50] [Batch 187/300] [D loss: 0.752607] [G loss: 0.505567] time: 0:33:46.602960\n",
      "0.9030861\n",
      "[Epoch 22/50] [Batch 188/300] [D loss: 0.752565] [G loss: 0.521216] time: 0:33:46.914683\n",
      "0.95605224\n",
      "[Epoch 22/50] [Batch 189/300] [D loss: 0.752563] [G loss: 0.541264] time: 0:33:47.200155\n",
      "0.9636373\n",
      "[Epoch 22/50] [Batch 190/300] [D loss: 0.752580] [G loss: 0.574677] time: 0:33:47.500876\n",
      "0.91553134\n",
      "[Epoch 22/50] [Batch 191/300] [D loss: 0.752568] [G loss: 0.532720] time: 0:33:47.804888\n",
      "0.94074297\n",
      "[Epoch 22/50] [Batch 192/300] [D loss: 0.752552] [G loss: 0.518008] time: 0:33:48.102455\n",
      "0.886004\n",
      "[Epoch 22/50] [Batch 193/300] [D loss: 0.752581] [G loss: 0.508870] time: 0:33:48.406756\n",
      "0.88896704\n",
      "[Epoch 22/50] [Batch 194/300] [D loss: 0.752561] [G loss: 0.556940] time: 0:33:48.720350\n",
      "0.8886884\n",
      "[Epoch 22/50] [Batch 195/300] [D loss: 0.752561] [G loss: 0.511631] time: 0:33:49.020172\n",
      "0.9120868\n",
      "[Epoch 22/50] [Batch 196/300] [D loss: 0.752522] [G loss: 0.521133] time: 0:33:49.321096\n",
      "0.8840763\n",
      "[Epoch 22/50] [Batch 197/300] [D loss: 0.752556] [G loss: 0.506005] time: 0:33:49.625745\n",
      "0.90004975\n",
      "[Epoch 22/50] [Batch 198/300] [D loss: 0.752547] [G loss: 0.503498] time: 0:33:49.938520\n",
      "0.9175671\n",
      "[Epoch 22/50] [Batch 199/300] [D loss: 0.752567] [G loss: 0.538503] time: 0:33:50.247185\n",
      "0.93123776\n",
      "[Epoch 22/50] [Batch 200/300] [D loss: 0.752596] [G loss: 0.490884] time: 0:33:50.552531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90485865\n",
      "[Epoch 22/50] [Batch 201/300] [D loss: 0.752566] [G loss: 0.546899] time: 0:33:50.854789\n",
      "0.90608686\n",
      "[Epoch 22/50] [Batch 202/300] [D loss: 0.752554] [G loss: 0.584400] time: 0:33:51.152499\n",
      "0.8789153\n",
      "[Epoch 22/50] [Batch 203/300] [D loss: 0.752540] [G loss: 0.541035] time: 0:33:51.438425\n",
      "0.9296581\n",
      "[Epoch 22/50] [Batch 204/300] [D loss: 0.752556] [G loss: 0.557830] time: 0:33:51.746302\n",
      "0.8702827\n",
      "[Epoch 22/50] [Batch 205/300] [D loss: 0.752533] [G loss: 0.515977] time: 0:33:52.040234\n",
      "0.9383847\n",
      "[Epoch 22/50] [Batch 206/300] [D loss: 0.752559] [G loss: 0.503821] time: 0:33:52.344629\n",
      "0.95371777\n",
      "[Epoch 22/50] [Batch 207/300] [D loss: 0.752557] [G loss: 0.524015] time: 0:33:52.665381\n",
      "0.9105639\n",
      "[Epoch 22/50] [Batch 208/300] [D loss: 0.752579] [G loss: 0.522262] time: 0:33:52.972755\n",
      "0.9422888\n",
      "[Epoch 22/50] [Batch 209/300] [D loss: 0.752593] [G loss: 0.515120] time: 0:33:53.281511\n",
      "0.92165464\n",
      "[Epoch 22/50] [Batch 210/300] [D loss: 0.752560] [G loss: 0.497731] time: 0:33:53.586313\n",
      "0.93699473\n",
      "[Epoch 22/50] [Batch 211/300] [D loss: 0.752582] [G loss: 0.515094] time: 0:33:53.888946\n",
      "0.9575427\n",
      "[Epoch 22/50] [Batch 212/300] [D loss: 0.752568] [G loss: 0.516351] time: 0:33:54.185553\n",
      "0.9118926\n",
      "[Epoch 22/50] [Batch 213/300] [D loss: 0.752574] [G loss: 0.520793] time: 0:33:54.459871\n",
      "0.9219634\n",
      "[Epoch 22/50] [Batch 214/300] [D loss: 0.752588] [G loss: 0.519785] time: 0:33:54.742628\n",
      "0.88281536\n",
      "[Epoch 22/50] [Batch 215/300] [D loss: 0.752552] [G loss: 0.499419] time: 0:33:55.045913\n",
      "0.9378094\n",
      "[Epoch 22/50] [Batch 216/300] [D loss: 0.752566] [G loss: 0.497932] time: 0:33:55.342748\n",
      "0.87286395\n",
      "[Epoch 22/50] [Batch 217/300] [D loss: 0.752574] [G loss: 0.518081] time: 0:33:55.642551\n",
      "0.92276996\n",
      "[Epoch 22/50] [Batch 218/300] [D loss: 0.752557] [G loss: 0.533992] time: 0:33:55.950763\n",
      "0.92478997\n",
      "[Epoch 22/50] [Batch 219/300] [D loss: 0.752566] [G loss: 0.521955] time: 0:33:56.253719\n",
      "0.95229083\n",
      "[Epoch 22/50] [Batch 220/300] [D loss: 0.752569] [G loss: 0.522326] time: 0:33:56.577486\n",
      "0.878172\n",
      "[Epoch 22/50] [Batch 221/300] [D loss: 0.752557] [G loss: 0.527655] time: 0:33:56.866859\n",
      "0.9290083\n",
      "[Epoch 22/50] [Batch 222/300] [D loss: 0.752574] [G loss: 0.572245] time: 0:33:57.175870\n",
      "0.90683156\n",
      "[Epoch 22/50] [Batch 223/300] [D loss: 0.752569] [G loss: 0.516045] time: 0:33:57.483175\n",
      "0.963267\n",
      "[Epoch 22/50] [Batch 224/300] [D loss: 0.752552] [G loss: 0.520797] time: 0:33:57.777134\n",
      "0.8879185\n",
      "[Epoch 22/50] [Batch 225/300] [D loss: 0.752571] [G loss: 0.506438] time: 0:33:58.084589\n",
      "0.9445302\n",
      "[Epoch 22/50] [Batch 226/300] [D loss: 0.752568] [G loss: 0.530443] time: 0:33:58.390427\n",
      "0.9294917\n",
      "[Epoch 22/50] [Batch 227/300] [D loss: 0.752549] [G loss: 0.500223] time: 0:33:58.693564\n",
      "0.880481\n",
      "[Epoch 22/50] [Batch 228/300] [D loss: 0.752562] [G loss: 0.529343] time: 0:33:58.993250\n",
      "0.8893774\n",
      "[Epoch 22/50] [Batch 229/300] [D loss: 0.752564] [G loss: 0.538831] time: 0:33:59.298710\n",
      "0.90868074\n",
      "[Epoch 22/50] [Batch 230/300] [D loss: 0.752564] [G loss: 0.511772] time: 0:33:59.620745\n",
      "0.90899426\n",
      "[Epoch 22/50] [Batch 231/300] [D loss: 0.752564] [G loss: 0.496365] time: 0:33:59.924952\n",
      "0.9186514\n",
      "[Epoch 22/50] [Batch 232/300] [D loss: 0.752555] [G loss: 0.549046] time: 0:34:00.236766\n",
      "0.8995933\n",
      "[Epoch 22/50] [Batch 233/300] [D loss: 0.752549] [G loss: 0.503010] time: 0:34:00.554785\n",
      "0.9390085\n",
      "[Epoch 22/50] [Batch 234/300] [D loss: 0.752546] [G loss: 0.524051] time: 0:34:00.860876\n",
      "0.8915055\n",
      "[Epoch 22/50] [Batch 235/300] [D loss: 0.752565] [G loss: 0.502277] time: 0:34:01.155138\n",
      "0.8908713\n",
      "[Epoch 22/50] [Batch 236/300] [D loss: 0.752545] [G loss: 0.509212] time: 0:34:01.454538\n",
      "0.901817\n",
      "[Epoch 22/50] [Batch 237/300] [D loss: 0.752559] [G loss: 0.512388] time: 0:34:01.769451\n",
      "0.9377896\n",
      "[Epoch 22/50] [Batch 238/300] [D loss: 0.752558] [G loss: 0.532844] time: 0:34:02.081749\n",
      "0.9333215\n",
      "[Epoch 22/50] [Batch 239/300] [D loss: 0.752548] [G loss: 0.504868] time: 0:34:02.362840\n",
      "0.91480494\n",
      "[Epoch 22/50] [Batch 240/300] [D loss: 0.752599] [G loss: 0.502391] time: 0:34:02.644323\n",
      "0.9046332\n",
      "[Epoch 22/50] [Batch 241/300] [D loss: 0.752575] [G loss: 0.537132] time: 0:34:02.940128\n",
      "0.8801287\n",
      "[Epoch 22/50] [Batch 242/300] [D loss: 0.752554] [G loss: 0.540921] time: 0:34:03.262720\n",
      "0.9468451\n",
      "[Epoch 22/50] [Batch 243/300] [D loss: 0.752551] [G loss: 0.517207] time: 0:34:03.562557\n",
      "0.9584513\n",
      "[Epoch 22/50] [Batch 244/300] [D loss: 0.752542] [G loss: 0.521314] time: 0:34:03.865332\n",
      "0.9184479\n",
      "[Epoch 22/50] [Batch 245/300] [D loss: 0.752570] [G loss: 0.509234] time: 0:34:04.147016\n",
      "0.88914305\n",
      "[Epoch 22/50] [Batch 246/300] [D loss: 0.752561] [G loss: 0.511419] time: 0:34:04.448790\n",
      "0.8522633\n",
      "[Epoch 22/50] [Batch 247/300] [D loss: 0.752577] [G loss: 0.522742] time: 0:34:04.752094\n",
      "0.9733878\n",
      "[Epoch 22/50] [Batch 248/300] [D loss: 0.752558] [G loss: 0.520143] time: 0:34:05.059614\n",
      "0.9599232\n",
      "[Epoch 22/50] [Batch 249/300] [D loss: 0.752574] [G loss: 0.547396] time: 0:34:05.356356\n",
      "0.88797885\n",
      "[Epoch 22/50] [Batch 250/300] [D loss: 0.752555] [G loss: 0.499903] time: 0:34:05.663375\n",
      "0.9116134\n",
      "[Epoch 22/50] [Batch 251/300] [D loss: 0.752552] [G loss: 0.515508] time: 0:34:05.957307\n",
      "0.93483907\n",
      "[Epoch 22/50] [Batch 252/300] [D loss: 0.752530] [G loss: 0.511375] time: 0:34:06.256985\n",
      "0.9221053\n",
      "[Epoch 22/50] [Batch 253/300] [D loss: 0.752553] [G loss: 0.536637] time: 0:34:06.559970\n",
      "0.93338424\n",
      "[Epoch 22/50] [Batch 254/300] [D loss: 0.752547] [G loss: 0.520619] time: 0:34:06.852153\n",
      "0.91625553\n",
      "[Epoch 22/50] [Batch 255/300] [D loss: 0.752550] [G loss: 0.543988] time: 0:34:07.160374\n",
      "0.8856403\n",
      "[Epoch 22/50] [Batch 256/300] [D loss: 0.752550] [G loss: 0.539405] time: 0:34:07.480979\n",
      "0.9589568\n",
      "[Epoch 22/50] [Batch 257/300] [D loss: 0.752537] [G loss: 0.531407] time: 0:34:07.783213\n",
      "0.9318976\n",
      "[Epoch 22/50] [Batch 258/300] [D loss: 0.752564] [G loss: 0.533361] time: 0:34:08.067105\n",
      "0.9185092\n",
      "[Epoch 22/50] [Batch 259/300] [D loss: 0.752551] [G loss: 0.516295] time: 0:34:08.368988\n",
      "0.94126624\n",
      "[Epoch 22/50] [Batch 260/300] [D loss: 0.752532] [G loss: 0.517015] time: 0:34:08.667622\n",
      "0.90950376\n",
      "[Epoch 22/50] [Batch 261/300] [D loss: 0.752571] [G loss: 0.519078] time: 0:34:08.965647\n",
      "0.9057252\n",
      "[Epoch 22/50] [Batch 262/300] [D loss: 0.752556] [G loss: 0.497829] time: 0:34:09.268646\n",
      "0.9203119\n",
      "[Epoch 22/50] [Batch 263/300] [D loss: 0.752548] [G loss: 0.554727] time: 0:34:09.566043\n",
      "0.913012\n",
      "[Epoch 22/50] [Batch 264/300] [D loss: 0.752570] [G loss: 0.525877] time: 0:34:09.870931\n",
      "0.9143382\n",
      "[Epoch 22/50] [Batch 265/300] [D loss: 0.752559] [G loss: 0.515577] time: 0:34:10.163179\n",
      "0.89331627\n",
      "[Epoch 22/50] [Batch 266/300] [D loss: 0.752562] [G loss: 0.533607] time: 0:34:10.468624\n",
      "0.87784696\n",
      "[Epoch 22/50] [Batch 267/300] [D loss: 0.752563] [G loss: 0.536333] time: 0:34:10.766396\n",
      "0.914231\n",
      "[Epoch 22/50] [Batch 268/300] [D loss: 0.752553] [G loss: 0.507523] time: 0:34:11.071956\n",
      "0.9294413\n",
      "[Epoch 22/50] [Batch 269/300] [D loss: 0.752577] [G loss: 0.533170] time: 0:34:11.373327\n",
      "0.9463782\n",
      "[Epoch 22/50] [Batch 270/300] [D loss: 0.752547] [G loss: 0.516022] time: 0:34:11.684410\n",
      "0.9642895\n",
      "[Epoch 22/50] [Batch 271/300] [D loss: 0.752557] [G loss: 0.519616] time: 0:34:11.985331\n",
      "0.91930586\n",
      "[Epoch 22/50] [Batch 272/300] [D loss: 0.752549] [G loss: 0.543809] time: 0:34:12.269221\n",
      "0.9398857\n",
      "[Epoch 22/50] [Batch 273/300] [D loss: 0.752566] [G loss: 0.557265] time: 0:34:12.567799\n",
      "0.9086764\n",
      "[Epoch 22/50] [Batch 274/300] [D loss: 0.752555] [G loss: 0.543896] time: 0:34:12.865261\n",
      "0.92916226\n",
      "[Epoch 22/50] [Batch 275/300] [D loss: 0.752571] [G loss: 0.508525] time: 0:34:13.165783\n",
      "0.9404779\n",
      "[Epoch 22/50] [Batch 276/300] [D loss: 0.752529] [G loss: 0.498208] time: 0:34:13.484292\n",
      "0.93876004\n",
      "[Epoch 22/50] [Batch 277/300] [D loss: 0.752564] [G loss: 0.519913] time: 0:34:13.775929\n",
      "0.90529674\n",
      "[Epoch 22/50] [Batch 278/300] [D loss: 0.752543] [G loss: 0.517908] time: 0:34:14.074386\n",
      "0.8933384\n",
      "[Epoch 22/50] [Batch 279/300] [D loss: 0.752547] [G loss: 0.516917] time: 0:34:14.377588\n",
      "0.91809076\n",
      "[Epoch 22/50] [Batch 280/300] [D loss: 0.752547] [G loss: 0.581337] time: 0:34:14.680226\n",
      "0.91794986\n",
      "[Epoch 22/50] [Batch 281/300] [D loss: 0.752533] [G loss: 0.508566] time: 0:34:14.981569\n",
      "0.94093174\n",
      "[Epoch 22/50] [Batch 282/300] [D loss: 0.752550] [G loss: 0.527382] time: 0:34:15.285200\n",
      "0.9249954\n",
      "[Epoch 22/50] [Batch 283/300] [D loss: 0.752572] [G loss: 0.505440] time: 0:34:15.612697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97141594\n",
      "[Epoch 22/50] [Batch 284/300] [D loss: 0.752557] [G loss: 0.539227] time: 0:34:15.909931\n",
      "0.920693\n",
      "[Epoch 22/50] [Batch 285/300] [D loss: 0.752553] [G loss: 0.523210] time: 0:34:16.210115\n",
      "0.93809533\n",
      "[Epoch 22/50] [Batch 286/300] [D loss: 0.752553] [G loss: 0.514242] time: 0:34:16.516427\n",
      "0.962966\n",
      "[Epoch 22/50] [Batch 287/300] [D loss: 0.752557] [G loss: 0.508089] time: 0:34:16.814758\n",
      "0.8862297\n",
      "[Epoch 22/50] [Batch 288/300] [D loss: 0.752556] [G loss: 0.506480] time: 0:34:17.112310\n",
      "0.9350068\n",
      "[Epoch 22/50] [Batch 289/300] [D loss: 0.752535] [G loss: 0.513032] time: 0:34:17.413777\n",
      "0.93256956\n",
      "[Epoch 22/50] [Batch 290/300] [D loss: 0.752553] [G loss: 0.517622] time: 0:34:17.718262\n",
      "0.94739264\n",
      "[Epoch 22/50] [Batch 291/300] [D loss: 0.752564] [G loss: 0.511993] time: 0:34:17.997276\n",
      "0.91762835\n",
      "[Epoch 22/50] [Batch 292/300] [D loss: 0.752556] [G loss: 0.524465] time: 0:34:18.301788\n",
      "0.9217735\n",
      "[Epoch 22/50] [Batch 293/300] [D loss: 0.752549] [G loss: 0.552141] time: 0:34:18.602387\n",
      "0.9338078\n",
      "[Epoch 22/50] [Batch 294/300] [D loss: 0.752567] [G loss: 0.521694] time: 0:34:18.911527\n",
      "0.9530547\n",
      "[Epoch 22/50] [Batch 295/300] [D loss: 0.752553] [G loss: 0.512522] time: 0:34:19.199589\n",
      "0.90665954\n",
      "[Epoch 22/50] [Batch 296/300] [D loss: 0.752569] [G loss: 0.547950] time: 0:34:19.501743\n",
      "0.885276\n",
      "[Epoch 22/50] [Batch 297/300] [D loss: 0.752554] [G loss: 0.512091] time: 0:34:19.793690\n",
      "0.9434491\n",
      "[Epoch 22/50] [Batch 298/300] [D loss: 0.752551] [G loss: 0.540027] time: 0:34:20.079821\n",
      "0.88308734\n",
      "[Epoch 22/50] [Batch 299/300] [D loss: 0.752560] [G loss: 0.495500] time: 0:34:20.382148\n",
      "0.966557\n",
      "[Epoch 23/50] [Batch 0/300] [D loss: 0.752586] [G loss: 0.495072] time: 0:34:20.676762\n",
      "0.88654286\n",
      "[Epoch 23/50] [Batch 1/300] [D loss: 0.752535] [G loss: 0.510416] time: 0:34:20.970958\n",
      "0.8676634\n",
      "[Epoch 23/50] [Batch 2/300] [D loss: 0.752565] [G loss: 0.509620] time: 0:34:21.277608\n",
      "0.91632295\n",
      "[Epoch 23/50] [Batch 3/300] [D loss: 0.752570] [G loss: 0.560994] time: 0:34:21.576811\n",
      "0.95360327\n",
      "[Epoch 23/50] [Batch 4/300] [D loss: 0.752523] [G loss: 0.529656] time: 0:34:21.875193\n",
      "0.9548834\n",
      "[Epoch 23/50] [Batch 5/300] [D loss: 0.752545] [G loss: 0.519589] time: 0:34:22.175798\n",
      "0.900225\n",
      "[Epoch 23/50] [Batch 6/300] [D loss: 0.752562] [G loss: 0.528006] time: 0:34:22.476192\n",
      "0.94601727\n",
      "[Epoch 23/50] [Batch 7/300] [D loss: 0.752559] [G loss: 0.556657] time: 0:34:22.771619\n",
      "0.9528599\n",
      "[Epoch 23/50] [Batch 8/300] [D loss: 0.752553] [G loss: 0.508201] time: 0:34:23.056492\n",
      "0.9412398\n",
      "[Epoch 23/50] [Batch 9/300] [D loss: 0.752600] [G loss: 0.504085] time: 0:34:23.337146\n",
      "0.94654256\n",
      "[Epoch 23/50] [Batch 10/300] [D loss: 0.752543] [G loss: 0.538366] time: 0:34:23.613426\n",
      "0.91917086\n",
      "[Epoch 23/50] [Batch 11/300] [D loss: 0.752551] [G loss: 0.540935] time: 0:34:23.916862\n",
      "0.97628194\n",
      "[Epoch 23/50] [Batch 12/300] [D loss: 0.752560] [G loss: 0.530722] time: 0:34:24.214985\n",
      "0.9317116\n",
      "[Epoch 23/50] [Batch 13/300] [D loss: 0.752564] [G loss: 0.512807] time: 0:34:24.507908\n",
      "0.96010786\n",
      "[Epoch 23/50] [Batch 14/300] [D loss: 0.752566] [G loss: 0.513071] time: 0:34:24.828981\n",
      "0.93801457\n",
      "[Epoch 23/50] [Batch 15/300] [D loss: 0.752566] [G loss: 0.509194] time: 0:34:25.127267\n",
      "0.92022824\n",
      "[Epoch 23/50] [Batch 16/300] [D loss: 0.752576] [G loss: 0.517026] time: 0:34:25.435602\n",
      "0.8894486\n",
      "[Epoch 23/50] [Batch 17/300] [D loss: 0.752566] [G loss: 0.542966] time: 0:34:25.747140\n",
      "0.9369882\n",
      "[Epoch 23/50] [Batch 18/300] [D loss: 0.752537] [G loss: 0.505247] time: 0:34:26.055533\n",
      "0.9694889\n",
      "[Epoch 23/50] [Batch 19/300] [D loss: 0.752567] [G loss: 0.519313] time: 0:34:26.336808\n",
      "0.87924\n",
      "[Epoch 23/50] [Batch 20/300] [D loss: 0.752551] [G loss: 0.557682] time: 0:34:26.620613\n",
      "0.92510587\n",
      "[Epoch 23/50] [Batch 21/300] [D loss: 0.752545] [G loss: 0.510062] time: 0:34:26.923695\n",
      "0.896692\n",
      "[Epoch 23/50] [Batch 23/300] [D loss: 0.752555] [G loss: 0.519241] time: 0:34:27.233686\n",
      "0.9603706\n",
      "[Epoch 23/50] [Batch 24/300] [D loss: 0.752549] [G loss: 0.515010] time: 0:34:27.527810\n",
      "0.8982088\n",
      "[Epoch 23/50] [Batch 25/300] [D loss: 0.752543] [G loss: 0.539308] time: 0:34:27.819161\n",
      "0.91272545\n",
      "[Epoch 23/50] [Batch 26/300] [D loss: 0.752553] [G loss: 0.543450] time: 0:34:28.114446\n",
      "0.95763993\n",
      "[Epoch 23/50] [Batch 27/300] [D loss: 0.752547] [G loss: 0.531208] time: 0:34:28.417017\n",
      "0.8872239\n",
      "[Epoch 23/50] [Batch 28/300] [D loss: 0.752556] [G loss: 0.555991] time: 0:34:28.706057\n",
      "0.9288127\n",
      "[Epoch 23/50] [Batch 29/300] [D loss: 0.752551] [G loss: 0.497268] time: 0:34:29.018532\n",
      "0.95412415\n",
      "[Epoch 23/50] [Batch 30/300] [D loss: 0.752541] [G loss: 0.507021] time: 0:34:29.316385\n",
      "0.91116303\n",
      "[Epoch 23/50] [Batch 31/300] [D loss: 0.752540] [G loss: 0.528520] time: 0:34:29.606611\n",
      "0.95857763\n",
      "[Epoch 23/50] [Batch 32/300] [D loss: 0.752536] [G loss: 0.496220] time: 0:34:29.916616\n",
      "0.91254383\n",
      "[Epoch 23/50] [Batch 33/300] [D loss: 0.752511] [G loss: 0.521586] time: 0:34:30.214957\n",
      "0.9115519\n",
      "[Epoch 23/50] [Batch 34/300] [D loss: 0.752535] [G loss: 0.506088] time: 0:34:30.514178\n",
      "0.8772907\n",
      "[Epoch 23/50] [Batch 35/300] [D loss: 0.752524] [G loss: 0.522296] time: 0:34:30.806531\n",
      "0.90596527\n",
      "[Epoch 23/50] [Batch 36/300] [D loss: 0.752534] [G loss: 0.505463] time: 0:34:31.113603\n",
      "0.9082334\n",
      "[Epoch 23/50] [Batch 37/300] [D loss: 0.752579] [G loss: 0.505378] time: 0:34:31.426669\n",
      "0.9485143\n",
      "[Epoch 23/50] [Batch 38/300] [D loss: 0.752540] [G loss: 0.518806] time: 0:34:31.727144\n",
      "0.9228465\n",
      "[Epoch 23/50] [Batch 39/300] [D loss: 0.752552] [G loss: 0.520407] time: 0:34:32.029709\n",
      "0.93753785\n",
      "[Epoch 23/50] [Batch 40/300] [D loss: 0.752543] [G loss: 0.507035] time: 0:34:32.332686\n",
      "0.8747401\n",
      "[Epoch 23/50] [Batch 41/300] [D loss: 0.752529] [G loss: 0.525709] time: 0:34:32.629759\n",
      "0.9344732\n",
      "[Epoch 23/50] [Batch 42/300] [D loss: 0.752555] [G loss: 0.550123] time: 0:34:32.933731\n",
      "0.9474664\n",
      "[Epoch 23/50] [Batch 43/300] [D loss: 0.752563] [G loss: 0.520833] time: 0:34:33.219072\n",
      "0.8737664\n",
      "[Epoch 23/50] [Batch 44/300] [D loss: 0.752527] [G loss: 0.512045] time: 0:34:33.518324\n",
      "0.93568903\n",
      "[Epoch 23/50] [Batch 45/300] [D loss: 0.752535] [G loss: 0.530271] time: 0:34:33.831987\n",
      "0.9506139\n",
      "[Epoch 23/50] [Batch 46/300] [D loss: 0.752571] [G loss: 0.510395] time: 0:34:34.122586\n",
      "0.9311881\n",
      "[Epoch 23/50] [Batch 47/300] [D loss: 0.752522] [G loss: 0.521320] time: 0:34:34.422363\n",
      "0.9365365\n",
      "[Epoch 23/50] [Batch 48/300] [D loss: 0.752547] [G loss: 0.497400] time: 0:34:34.703844\n",
      "0.93309957\n",
      "[Epoch 23/50] [Batch 49/300] [D loss: 0.752536] [G loss: 0.524504] time: 0:34:35.006286\n",
      "0.90269715\n",
      "[Epoch 23/50] [Batch 50/300] [D loss: 0.752563] [G loss: 0.513902] time: 0:34:35.302485\n",
      "0.921799\n",
      "[Epoch 23/50] [Batch 51/300] [D loss: 0.752547] [G loss: 0.517552] time: 0:34:35.613526\n",
      "0.9412381\n",
      "[Epoch 23/50] [Batch 52/300] [D loss: 0.752555] [G loss: 0.532170] time: 0:34:35.908232\n",
      "0.9536616\n",
      "[Epoch 23/50] [Batch 53/300] [D loss: 0.752529] [G loss: 0.517142] time: 0:34:36.193139\n",
      "0.93192625\n",
      "[Epoch 23/50] [Batch 54/300] [D loss: 0.752535] [G loss: 0.501573] time: 0:34:36.480895\n",
      "0.89744097\n",
      "[Epoch 23/50] [Batch 55/300] [D loss: 0.752540] [G loss: 0.488743] time: 0:34:36.758129\n",
      "0.91710466\n",
      "[Epoch 23/50] [Batch 56/300] [D loss: 0.752557] [G loss: 0.522349] time: 0:34:37.062757\n",
      "0.93165255\n",
      "[Epoch 23/50] [Batch 57/300] [D loss: 0.752559] [G loss: 0.513130] time: 0:34:37.365550\n",
      "0.93005794\n",
      "[Epoch 23/50] [Batch 58/300] [D loss: 0.752556] [G loss: 0.501166] time: 0:34:37.669652\n",
      "0.9214949\n",
      "[Epoch 23/50] [Batch 59/300] [D loss: 0.752514] [G loss: 0.533135] time: 0:34:37.975248\n",
      "0.93766135\n",
      "[Epoch 23/50] [Batch 60/300] [D loss: 0.752539] [G loss: 0.542027] time: 0:34:38.278152\n",
      "0.9052147\n",
      "[Epoch 23/50] [Batch 61/300] [D loss: 0.752530] [G loss: 0.539771] time: 0:34:38.551240\n",
      "0.87819296\n",
      "[Epoch 23/50] [Batch 62/300] [D loss: 0.752540] [G loss: 0.532933] time: 0:34:38.846839\n",
      "0.93992776\n",
      "[Epoch 23/50] [Batch 63/300] [D loss: 0.752554] [G loss: 0.507422] time: 0:34:39.148883\n",
      "0.905425\n",
      "[Epoch 23/50] [Batch 64/300] [D loss: 0.752545] [G loss: 0.484499] time: 0:34:39.448333\n",
      "0.89186734\n",
      "[Epoch 23/50] [Batch 65/300] [D loss: 0.752544] [G loss: 0.510978] time: 0:34:39.744327\n",
      "0.93756294\n",
      "[Epoch 23/50] [Batch 66/300] [D loss: 0.752560] [G loss: 0.503356] time: 0:34:40.048161\n",
      "0.9303935\n",
      "[Epoch 23/50] [Batch 67/300] [D loss: 0.752542] [G loss: 0.525981] time: 0:34:40.348331\n",
      "0.9132995\n",
      "[Epoch 23/50] [Batch 68/300] [D loss: 0.752562] [G loss: 0.508881] time: 0:34:40.647289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90670365\n",
      "[Epoch 23/50] [Batch 69/300] [D loss: 0.752531] [G loss: 0.512372] time: 0:34:40.937437\n",
      "0.8793602\n",
      "[Epoch 23/50] [Batch 70/300] [D loss: 0.752549] [G loss: 0.530658] time: 0:34:41.236594\n",
      "0.9237082\n",
      "[Epoch 23/50] [Batch 71/300] [D loss: 0.752538] [G loss: 0.528171] time: 0:34:41.528570\n",
      "0.91925097\n",
      "[Epoch 23/50] [Batch 72/300] [D loss: 0.752575] [G loss: 0.497462] time: 0:34:41.819768\n",
      "0.9307189\n",
      "[Epoch 23/50] [Batch 73/300] [D loss: 0.752548] [G loss: 0.513488] time: 0:34:42.125252\n",
      "0.9481123\n",
      "[Epoch 23/50] [Batch 74/300] [D loss: 0.752546] [G loss: 0.514403] time: 0:34:42.405868\n",
      "0.9829647\n",
      "[Epoch 23/50] [Batch 75/300] [D loss: 0.752555] [G loss: 0.513513] time: 0:34:42.682313\n",
      "0.89222264\n",
      "[Epoch 23/50] [Batch 76/300] [D loss: 0.752531] [G loss: 0.520825] time: 0:34:42.965152\n",
      "0.9084874\n",
      "[Epoch 23/50] [Batch 77/300] [D loss: 0.752552] [G loss: 0.529070] time: 0:34:43.264443\n",
      "0.9597953\n",
      "[Epoch 23/50] [Batch 78/300] [D loss: 0.752515] [G loss: 0.494348] time: 0:34:43.565605\n",
      "0.8995707\n",
      "[Epoch 23/50] [Batch 79/300] [D loss: 0.752562] [G loss: 0.538393] time: 0:34:43.869676\n",
      "0.9484951\n",
      "[Epoch 23/50] [Batch 80/300] [D loss: 0.752542] [G loss: 0.505566] time: 0:34:44.149341\n",
      "0.9155629\n",
      "[Epoch 23/50] [Batch 81/300] [D loss: 0.752536] [G loss: 0.502968] time: 0:34:44.448693\n",
      "0.9319022\n",
      "[Epoch 23/50] [Batch 82/300] [D loss: 0.752562] [G loss: 0.524370] time: 0:34:44.757987\n",
      "0.9320092\n",
      "[Epoch 23/50] [Batch 83/300] [D loss: 0.752572] [G loss: 0.521610] time: 0:34:45.055193\n",
      "0.8820889\n",
      "[Epoch 23/50] [Batch 84/300] [D loss: 0.752525] [G loss: 0.496399] time: 0:34:45.333612\n",
      "0.9455096\n",
      "[Epoch 23/50] [Batch 85/300] [D loss: 0.752547] [G loss: 0.490769] time: 0:34:45.643772\n",
      "0.89140815\n",
      "[Epoch 23/50] [Batch 86/300] [D loss: 0.752502] [G loss: 0.518776] time: 0:34:45.947900\n",
      "0.90804416\n",
      "[Epoch 23/50] [Batch 87/300] [D loss: 0.752550] [G loss: 0.489260] time: 0:34:46.249317\n",
      "0.8995678\n",
      "[Epoch 23/50] [Batch 88/300] [D loss: 0.752542] [G loss: 0.499630] time: 0:34:46.547412\n",
      "0.89975744\n",
      "[Epoch 23/50] [Batch 89/300] [D loss: 0.752542] [G loss: 0.525231] time: 0:34:46.852658\n",
      "0.89139503\n",
      "[Epoch 23/50] [Batch 90/300] [D loss: 0.752533] [G loss: 0.498277] time: 0:34:47.159258\n",
      "0.938922\n",
      "[Epoch 23/50] [Batch 91/300] [D loss: 0.752559] [G loss: 0.515587] time: 0:34:47.459349\n",
      "0.88546944\n",
      "[Epoch 23/50] [Batch 92/300] [D loss: 0.752518] [G loss: 0.505022] time: 0:34:47.766307\n",
      "0.93476135\n",
      "[Epoch 23/50] [Batch 93/300] [D loss: 0.752558] [G loss: 0.507831] time: 0:34:48.057303\n",
      "0.9818116\n",
      "[Epoch 23/50] [Batch 94/300] [D loss: 0.752573] [G loss: 0.513948] time: 0:34:48.367475\n",
      "0.92863315\n",
      "[Epoch 23/50] [Batch 95/300] [D loss: 0.752524] [G loss: 0.510071] time: 0:34:48.669492\n",
      "0.9345536\n",
      "[Epoch 23/50] [Batch 96/300] [D loss: 0.752563] [G loss: 0.545770] time: 0:34:48.970930\n",
      "0.9326561\n",
      "[Epoch 23/50] [Batch 97/300] [D loss: 0.752555] [G loss: 0.508684] time: 0:34:49.274334\n",
      "0.9193582\n",
      "[Epoch 23/50] [Batch 98/300] [D loss: 0.752540] [G loss: 0.488923] time: 0:34:49.589232\n",
      "0.8861563\n",
      "[Epoch 23/50] [Batch 99/300] [D loss: 0.752559] [G loss: 0.506267] time: 0:34:49.915259\n",
      "0.9753546\n",
      "[Epoch 23/50] [Batch 100/300] [D loss: 0.752542] [G loss: 0.531967] time: 0:34:50.202834\n",
      "0.88933235\n",
      "[Epoch 23/50] [Batch 101/300] [D loss: 0.752557] [G loss: 0.508242] time: 0:34:50.509987\n",
      "0.9253569\n",
      "[Epoch 23/50] [Batch 102/300] [D loss: 0.752541] [G loss: 0.496639] time: 0:34:50.804777\n",
      "0.91873974\n",
      "[Epoch 23/50] [Batch 103/300] [D loss: 0.752559] [G loss: 0.515075] time: 0:34:51.109470\n",
      "0.8918598\n",
      "[Epoch 23/50] [Batch 104/300] [D loss: 0.752577] [G loss: 0.518284] time: 0:34:51.411350\n",
      "0.9114449\n",
      "[Epoch 23/50] [Batch 105/300] [D loss: 0.752554] [G loss: 0.534917] time: 0:34:51.695486\n",
      "0.9711044\n",
      "[Epoch 23/50] [Batch 106/300] [D loss: 0.752548] [G loss: 0.507808] time: 0:34:51.980819\n",
      "0.92942375\n",
      "[Epoch 23/50] [Batch 107/300] [D loss: 0.752513] [G loss: 0.507792] time: 0:34:52.284436\n",
      "0.9198515\n",
      "[Epoch 23/50] [Batch 108/300] [D loss: 0.752540] [G loss: 0.533164] time: 0:34:52.590639\n",
      "0.9507466\n",
      "[Epoch 23/50] [Batch 109/300] [D loss: 0.752567] [G loss: 0.496929] time: 0:34:52.883469\n",
      "0.905222\n",
      "[Epoch 23/50] [Batch 110/300] [D loss: 0.752553] [G loss: 0.541502] time: 0:34:53.179854\n",
      "0.9161357\n",
      "[Epoch 23/50] [Batch 111/300] [D loss: 0.752549] [G loss: 0.504351] time: 0:34:53.488197\n",
      "0.8839701\n",
      "[Epoch 23/50] [Batch 112/300] [D loss: 0.752545] [G loss: 0.512888] time: 0:34:53.788729\n",
      "0.90596884\n",
      "[Epoch 23/50] [Batch 113/300] [D loss: 0.752527] [G loss: 0.528466] time: 0:34:54.092535\n",
      "0.92534524\n",
      "[Epoch 23/50] [Batch 114/300] [D loss: 0.752518] [G loss: 0.504433] time: 0:34:54.393248\n",
      "0.90524095\n",
      "[Epoch 23/50] [Batch 115/300] [D loss: 0.752544] [G loss: 0.509252] time: 0:34:54.700215\n",
      "0.9229705\n",
      "[Epoch 23/50] [Batch 116/300] [D loss: 0.752555] [G loss: 0.498603] time: 0:34:54.994794\n",
      "0.9393859\n",
      "[Epoch 23/50] [Batch 117/300] [D loss: 0.752552] [G loss: 0.536499] time: 0:34:55.304454\n",
      "0.89224386\n",
      "[Epoch 23/50] [Batch 118/300] [D loss: 0.752550] [G loss: 0.532879] time: 0:34:55.582487\n",
      "0.92314845\n",
      "[Epoch 23/50] [Batch 119/300] [D loss: 0.752530] [G loss: 0.525139] time: 0:34:55.876134\n",
      "0.95685536\n",
      "[Epoch 23/50] [Batch 120/300] [D loss: 0.752545] [G loss: 0.532954] time: 0:34:56.165276\n",
      "0.9115713\n",
      "[Epoch 23/50] [Batch 121/300] [D loss: 0.752544] [G loss: 0.504222] time: 0:34:56.462919\n",
      "0.89280874\n",
      "[Epoch 23/50] [Batch 122/300] [D loss: 0.752539] [G loss: 0.532635] time: 0:34:56.759561\n",
      "0.86557156\n",
      "[Epoch 23/50] [Batch 123/300] [D loss: 0.752523] [G loss: 0.538661] time: 0:34:57.074617\n",
      "0.93621665\n",
      "[Epoch 23/50] [Batch 124/300] [D loss: 0.752514] [G loss: 0.542713] time: 0:34:57.381682\n",
      "0.90975934\n",
      "[Epoch 23/50] [Batch 125/300] [D loss: 0.752513] [G loss: 0.506743] time: 0:34:57.684550\n",
      "0.91848344\n",
      "[Epoch 23/50] [Batch 126/300] [D loss: 0.752546] [G loss: 0.504713] time: 0:34:57.995108\n",
      "0.9478748\n",
      "[Epoch 23/50] [Batch 127/300] [D loss: 0.752546] [G loss: 0.519068] time: 0:34:58.300208\n",
      "0.91346025\n",
      "[Epoch 23/50] [Batch 128/300] [D loss: 0.752537] [G loss: 0.512500] time: 0:34:58.615506\n",
      "0.97710425\n",
      "[Epoch 23/50] [Batch 129/300] [D loss: 0.752541] [G loss: 0.501356] time: 0:34:58.924075\n",
      "0.8704937\n",
      "[Epoch 23/50] [Batch 130/300] [D loss: 0.752555] [G loss: 0.517291] time: 0:34:59.218907\n",
      "0.89331466\n",
      "[Epoch 23/50] [Batch 131/300] [D loss: 0.752582] [G loss: 0.531796] time: 0:34:59.513886\n",
      "0.91540784\n",
      "[Epoch 23/50] [Batch 132/300] [D loss: 0.752547] [G loss: 0.487290] time: 0:34:59.818073\n",
      "0.95849633\n",
      "[Epoch 23/50] [Batch 133/300] [D loss: 0.752537] [G loss: 0.532937] time: 0:35:00.110128\n",
      "0.91992396\n",
      "[Epoch 23/50] [Batch 134/300] [D loss: 0.752531] [G loss: 0.496445] time: 0:35:00.425358\n",
      "0.92144036\n",
      "[Epoch 23/50] [Batch 135/300] [D loss: 0.752542] [G loss: 0.546454] time: 0:35:00.733526\n",
      "0.94493324\n",
      "[Epoch 23/50] [Batch 136/300] [D loss: 0.752550] [G loss: 0.525330] time: 0:35:01.032518\n",
      "0.8993643\n",
      "[Epoch 23/50] [Batch 137/300] [D loss: 0.752534] [G loss: 0.495274] time: 0:35:01.332745\n",
      "0.9168112\n",
      "[Epoch 23/50] [Batch 138/300] [D loss: 0.752539] [G loss: 0.495926] time: 0:35:01.631758\n",
      "0.970716\n",
      "[Epoch 23/50] [Batch 139/300] [D loss: 0.752536] [G loss: 0.504038] time: 0:35:01.950182\n",
      "0.91405845\n",
      "[Epoch 23/50] [Batch 140/300] [D loss: 0.752545] [G loss: 0.537237] time: 0:35:02.234403\n",
      "0.8897457\n",
      "[Epoch 23/50] [Batch 141/300] [D loss: 0.752533] [G loss: 0.487811] time: 0:35:02.545843\n",
      "0.91287494\n",
      "[Epoch 23/50] [Batch 142/300] [D loss: 0.752526] [G loss: 0.551269] time: 0:35:02.865796\n",
      "0.9058438\n",
      "[Epoch 23/50] [Batch 143/300] [D loss: 0.752555] [G loss: 0.502950] time: 0:35:03.157151\n",
      "0.8856187\n",
      "[Epoch 23/50] [Batch 144/300] [D loss: 0.752534] [G loss: 0.520028] time: 0:35:03.461860\n",
      "0.9138949\n",
      "[Epoch 23/50] [Batch 145/300] [D loss: 0.752548] [G loss: 0.520623] time: 0:35:03.772707\n",
      "0.90429187\n",
      "[Epoch 23/50] [Batch 146/300] [D loss: 0.752545] [G loss: 0.506798] time: 0:35:04.073116\n",
      "0.9387166\n",
      "[Epoch 23/50] [Batch 147/300] [D loss: 0.752505] [G loss: 0.495172] time: 0:35:04.358556\n",
      "0.94157785\n",
      "[Epoch 23/50] [Batch 148/300] [D loss: 0.752558] [G loss: 0.503107] time: 0:35:04.661707\n",
      "0.9298391\n",
      "[Epoch 23/50] [Batch 149/300] [D loss: 0.752543] [G loss: 0.547373] time: 0:35:04.959623\n",
      "0.93219\n",
      "[Epoch 23/50] [Batch 150/300] [D loss: 0.752579] [G loss: 0.510715] time: 0:35:05.263276\n",
      "0.91846734\n",
      "[Epoch 23/50] [Batch 151/300] [D loss: 0.752530] [G loss: 0.503030] time: 0:35:05.572384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9377225\n",
      "[Epoch 23/50] [Batch 152/300] [D loss: 0.752546] [G loss: 0.494928] time: 0:35:05.889216\n",
      "0.9140944\n",
      "[Epoch 23/50] [Batch 153/300] [D loss: 0.752504] [G loss: 0.513418] time: 0:35:06.189372\n",
      "0.92897016\n",
      "[Epoch 23/50] [Batch 154/300] [D loss: 0.752532] [G loss: 0.494706] time: 0:35:06.489072\n",
      "0.92500424\n",
      "[Epoch 23/50] [Batch 155/300] [D loss: 0.752542] [G loss: 0.503074] time: 0:35:06.786556\n",
      "0.91608524\n",
      "[Epoch 23/50] [Batch 156/300] [D loss: 0.752545] [G loss: 0.523513] time: 0:35:07.076861\n",
      "0.9301708\n",
      "[Epoch 23/50] [Batch 157/300] [D loss: 0.752547] [G loss: 0.492024] time: 0:35:07.378375\n",
      "0.8813185\n",
      "[Epoch 23/50] [Batch 158/300] [D loss: 0.752554] [G loss: 0.521912] time: 0:35:07.685726\n",
      "0.94153756\n",
      "[Epoch 23/50] [Batch 159/300] [D loss: 0.752505] [G loss: 0.504874] time: 0:35:07.960494\n",
      "0.9431231\n",
      "[Epoch 23/50] [Batch 160/300] [D loss: 0.752526] [G loss: 0.572880] time: 0:35:08.259098\n",
      "0.9030945\n",
      "[Epoch 23/50] [Batch 161/300] [D loss: 0.752543] [G loss: 0.505554] time: 0:35:08.553667\n",
      "0.9196206\n",
      "[Epoch 23/50] [Batch 162/300] [D loss: 0.752515] [G loss: 0.527686] time: 0:35:08.847660\n",
      "0.9210868\n",
      "[Epoch 23/50] [Batch 163/300] [D loss: 0.752538] [G loss: 0.556403] time: 0:35:09.145000\n",
      "0.897794\n",
      "[Epoch 23/50] [Batch 164/300] [D loss: 0.752533] [G loss: 0.527010] time: 0:35:09.456203\n",
      "0.9330015\n",
      "[Epoch 23/50] [Batch 165/300] [D loss: 0.752542] [G loss: 0.515743] time: 0:35:09.751732\n",
      "0.8851382\n",
      "[Epoch 23/50] [Batch 166/300] [D loss: 0.752527] [G loss: 0.529030] time: 0:35:10.066460\n",
      "0.85301\n",
      "[Epoch 23/50] [Batch 167/300] [D loss: 0.752565] [G loss: 0.517705] time: 0:35:10.368233\n",
      "0.92388207\n",
      "[Epoch 23/50] [Batch 168/300] [D loss: 0.752555] [G loss: 0.541690] time: 0:35:10.671078\n",
      "0.94221574\n",
      "[Epoch 23/50] [Batch 169/300] [D loss: 0.752531] [G loss: 0.499980] time: 0:35:10.962283\n",
      "0.88406914\n",
      "[Epoch 23/50] [Batch 170/300] [D loss: 0.752561] [G loss: 0.522125] time: 0:35:11.266522\n",
      "0.90770555\n",
      "[Epoch 23/50] [Batch 171/300] [D loss: 0.752550] [G loss: 0.500228] time: 0:35:11.547793\n",
      "0.9430216\n",
      "[Epoch 23/50] [Batch 172/300] [D loss: 0.752558] [G loss: 0.512507] time: 0:35:11.846102\n",
      "0.90594345\n",
      "[Epoch 23/50] [Batch 173/300] [D loss: 0.752542] [G loss: 0.545549] time: 0:35:12.115232\n",
      "0.9331565\n",
      "[Epoch 23/50] [Batch 174/300] [D loss: 0.752525] [G loss: 0.488483] time: 0:35:12.425888\n",
      "0.9046087\n",
      "[Epoch 23/50] [Batch 175/300] [D loss: 0.752517] [G loss: 0.506814] time: 0:35:12.711295\n",
      "0.8759274\n",
      "[Epoch 23/50] [Batch 176/300] [D loss: 0.752534] [G loss: 0.520443] time: 0:35:13.013602\n",
      "0.95053405\n",
      "[Epoch 23/50] [Batch 177/300] [D loss: 0.752504] [G loss: 0.527334] time: 0:35:13.329461\n",
      "0.94146806\n",
      "[Epoch 23/50] [Batch 178/300] [D loss: 0.752553] [G loss: 0.514319] time: 0:35:13.618242\n",
      "0.880935\n",
      "[Epoch 23/50] [Batch 179/300] [D loss: 0.752551] [G loss: 0.494863] time: 0:35:13.928255\n",
      "0.9168864\n",
      "[Epoch 23/50] [Batch 180/300] [D loss: 0.752532] [G loss: 0.525627] time: 0:35:14.230426\n",
      "0.9428515\n",
      "[Epoch 23/50] [Batch 181/300] [D loss: 0.752546] [G loss: 0.534116] time: 0:35:14.516188\n",
      "0.90728575\n",
      "[Epoch 23/50] [Batch 182/300] [D loss: 0.752537] [G loss: 0.512506] time: 0:35:14.826108\n",
      "0.97582024\n",
      "[Epoch 23/50] [Batch 183/300] [D loss: 0.752527] [G loss: 0.508074] time: 0:35:15.134359\n",
      "0.94687366\n",
      "[Epoch 23/50] [Batch 184/300] [D loss: 0.752530] [G loss: 0.503030] time: 0:35:15.439865\n",
      "0.9249248\n",
      "[Epoch 23/50] [Batch 185/300] [D loss: 0.752542] [G loss: 0.541016] time: 0:35:15.738996\n",
      "0.9179209\n",
      "[Epoch 23/50] [Batch 186/300] [D loss: 0.752552] [G loss: 0.518495] time: 0:35:16.053854\n",
      "0.89638954\n",
      "[Epoch 23/50] [Batch 187/300] [D loss: 0.752546] [G loss: 0.496936] time: 0:35:16.348487\n",
      "0.9342585\n",
      "[Epoch 23/50] [Batch 188/300] [D loss: 0.752530] [G loss: 0.499327] time: 0:35:16.657786\n",
      "0.9052002\n",
      "[Epoch 23/50] [Batch 189/300] [D loss: 0.752524] [G loss: 0.562578] time: 0:35:16.959056\n",
      "0.96459824\n",
      "[Epoch 23/50] [Batch 190/300] [D loss: 0.752534] [G loss: 0.519287] time: 0:35:17.262946\n",
      "0.9458708\n",
      "[Epoch 23/50] [Batch 191/300] [D loss: 0.752556] [G loss: 0.493222] time: 0:35:17.560664\n",
      "0.9086278\n",
      "[Epoch 23/50] [Batch 192/300] [D loss: 0.752557] [G loss: 0.497268] time: 0:35:17.860185\n",
      "0.9683936\n",
      "[Epoch 23/50] [Batch 193/300] [D loss: 0.752531] [G loss: 0.508982] time: 0:35:18.168553\n",
      "0.90939873\n",
      "[Epoch 23/50] [Batch 194/300] [D loss: 0.752535] [G loss: 0.547415] time: 0:35:18.472398\n",
      "0.943897\n",
      "[Epoch 23/50] [Batch 195/300] [D loss: 0.752533] [G loss: 0.519319] time: 0:35:18.760736\n",
      "0.91939026\n",
      "[Epoch 23/50] [Batch 196/300] [D loss: 0.752551] [G loss: 0.509733] time: 0:35:19.061963\n",
      "0.85360736\n",
      "[Epoch 23/50] [Batch 197/300] [D loss: 0.752517] [G loss: 0.499814] time: 0:35:19.347257\n",
      "0.9078651\n",
      "[Epoch 23/50] [Batch 198/300] [D loss: 0.752532] [G loss: 0.518191] time: 0:35:19.642549\n",
      "0.90250665\n",
      "[Epoch 23/50] [Batch 199/300] [D loss: 0.752533] [G loss: 0.559810] time: 0:35:19.957748\n",
      "0.9116726\n",
      "[Epoch 23/50] [Batch 200/300] [D loss: 0.752540] [G loss: 0.528678] time: 0:35:20.266602\n",
      "0.96728706\n",
      "[Epoch 23/50] [Batch 201/300] [D loss: 0.752511] [G loss: 0.505063] time: 0:35:20.572574\n",
      "0.89112514\n",
      "[Epoch 23/50] [Batch 202/300] [D loss: 0.752519] [G loss: 0.559518] time: 0:35:20.876001\n",
      "0.8920755\n",
      "[Epoch 23/50] [Batch 203/300] [D loss: 0.752533] [G loss: 0.535608] time: 0:35:21.183325\n",
      "0.9161014\n",
      "[Epoch 23/50] [Batch 204/300] [D loss: 0.752515] [G loss: 0.501988] time: 0:35:21.488480\n",
      "0.9320073\n",
      "[Epoch 23/50] [Batch 205/300] [D loss: 0.752536] [G loss: 0.507919] time: 0:35:21.799095\n",
      "0.92722493\n",
      "[Epoch 23/50] [Batch 206/300] [D loss: 0.752558] [G loss: 0.571062] time: 0:35:22.116061\n",
      "0.93186396\n",
      "[Epoch 23/50] [Batch 207/300] [D loss: 0.752551] [G loss: 0.505756] time: 0:35:22.401942\n",
      "0.96194285\n",
      "[Epoch 23/50] [Batch 208/300] [D loss: 0.752544] [G loss: 0.505608] time: 0:35:22.724714\n",
      "0.93536514\n",
      "[Epoch 23/50] [Batch 209/300] [D loss: 0.752549] [G loss: 0.491198] time: 0:35:23.025258\n",
      "0.8838124\n",
      "[Epoch 23/50] [Batch 210/300] [D loss: 0.752516] [G loss: 0.519415] time: 0:35:23.465936\n",
      "0.89160174\n",
      "[Epoch 23/50] [Batch 211/300] [D loss: 0.752536] [G loss: 0.507168] time: 0:35:23.748028\n",
      "0.9774253\n",
      "[Epoch 23/50] [Batch 212/300] [D loss: 0.752532] [G loss: 0.526659] time: 0:35:24.055972\n",
      "0.92750293\n",
      "[Epoch 23/50] [Batch 213/300] [D loss: 0.752530] [G loss: 0.543137] time: 0:35:24.342581\n",
      "0.94787997\n",
      "[Epoch 23/50] [Batch 214/300] [D loss: 0.752519] [G loss: 0.518986] time: 0:35:24.658135\n",
      "0.9267611\n",
      "[Epoch 23/50] [Batch 215/300] [D loss: 0.752525] [G loss: 0.499733] time: 0:35:24.958906\n",
      "0.935904\n",
      "[Epoch 23/50] [Batch 216/300] [D loss: 0.752544] [G loss: 0.506930] time: 0:35:25.247067\n",
      "0.94822675\n",
      "[Epoch 23/50] [Batch 217/300] [D loss: 0.752546] [G loss: 0.509928] time: 0:35:25.553115\n",
      "0.9124622\n",
      "[Epoch 23/50] [Batch 218/300] [D loss: 0.752529] [G loss: 0.514548] time: 0:35:25.863328\n",
      "0.9159152\n",
      "[Epoch 23/50] [Batch 219/300] [D loss: 0.752517] [G loss: 0.530334] time: 0:35:26.157481\n",
      "0.9392004\n",
      "[Epoch 23/50] [Batch 220/300] [D loss: 0.752565] [G loss: 0.534841] time: 0:35:26.453504\n",
      "0.9376227\n",
      "[Epoch 23/50] [Batch 221/300] [D loss: 0.752527] [G loss: 0.512127] time: 0:35:26.741695\n",
      "0.939123\n",
      "[Epoch 23/50] [Batch 222/300] [D loss: 0.752553] [G loss: 0.504182] time: 0:35:27.042599\n",
      "0.9123602\n",
      "[Epoch 23/50] [Batch 223/300] [D loss: 0.752543] [G loss: 0.523329] time: 0:35:27.337617\n",
      "0.88113445\n",
      "[Epoch 23/50] [Batch 224/300] [D loss: 0.752561] [G loss: 0.482800] time: 0:35:27.632280\n",
      "0.89742446\n",
      "[Epoch 23/50] [Batch 225/300] [D loss: 0.752525] [G loss: 0.519869] time: 0:35:27.920965\n",
      "0.8950696\n",
      "[Epoch 23/50] [Batch 226/300] [D loss: 0.752525] [G loss: 0.501638] time: 0:35:28.204803\n",
      "0.9479115\n",
      "[Epoch 23/50] [Batch 227/300] [D loss: 0.752526] [G loss: 0.507858] time: 0:35:28.494952\n",
      "0.90562135\n",
      "[Epoch 23/50] [Batch 228/300] [D loss: 0.752531] [G loss: 0.512456] time: 0:35:28.803908\n",
      "0.89281934\n",
      "[Epoch 23/50] [Batch 229/300] [D loss: 0.752569] [G loss: 0.521793] time: 0:35:29.121736\n",
      "0.8911109\n",
      "[Epoch 23/50] [Batch 230/300] [D loss: 0.752504] [G loss: 0.535794] time: 0:35:29.423236\n",
      "0.9471875\n",
      "[Epoch 23/50] [Batch 231/300] [D loss: 0.752537] [G loss: 0.507772] time: 0:35:29.731403\n",
      "0.9577644\n",
      "[Epoch 23/50] [Batch 232/300] [D loss: 0.752535] [G loss: 0.525239] time: 0:35:30.028628\n",
      "0.944148\n",
      "[Epoch 23/50] [Batch 233/300] [D loss: 0.752492] [G loss: 0.505364] time: 0:35:30.311059\n",
      "0.91272235\n",
      "[Epoch 23/50] [Batch 234/300] [D loss: 0.752523] [G loss: 0.492281] time: 0:35:30.608255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9273603\n",
      "[Epoch 23/50] [Batch 235/300] [D loss: 0.752517] [G loss: 0.541432] time: 0:35:30.910336\n",
      "0.9128608\n",
      "[Epoch 23/50] [Batch 236/300] [D loss: 0.752550] [G loss: 0.514566] time: 0:35:31.199445\n",
      "0.97687596\n",
      "[Epoch 23/50] [Batch 237/300] [D loss: 0.752549] [G loss: 0.507209] time: 0:35:31.467818\n",
      "0.89639217\n",
      "[Epoch 23/50] [Batch 238/300] [D loss: 0.752540] [G loss: 0.529966] time: 0:35:31.756318\n",
      "0.9233454\n",
      "[Epoch 23/50] [Batch 239/300] [D loss: 0.752533] [G loss: 0.505376] time: 0:35:32.049669\n",
      "0.9203603\n",
      "[Epoch 23/50] [Batch 240/300] [D loss: 0.752537] [G loss: 0.498088] time: 0:35:32.336726\n",
      "0.9317046\n",
      "[Epoch 23/50] [Batch 241/300] [D loss: 0.752517] [G loss: 0.515308] time: 0:35:32.625588\n",
      "0.94472796\n",
      "[Epoch 23/50] [Batch 242/300] [D loss: 0.752565] [G loss: 0.546797] time: 0:35:32.934025\n",
      "0.9393192\n",
      "[Epoch 23/50] [Batch 243/300] [D loss: 0.752554] [G loss: 0.488482] time: 0:35:33.234980\n",
      "0.9419891\n",
      "[Epoch 23/50] [Batch 244/300] [D loss: 0.752539] [G loss: 0.552565] time: 0:35:33.551309\n",
      "0.92050457\n",
      "[Epoch 23/50] [Batch 245/300] [D loss: 0.752520] [G loss: 0.528403] time: 0:35:33.849053\n",
      "0.911675\n",
      "[Epoch 23/50] [Batch 246/300] [D loss: 0.752515] [G loss: 0.497600] time: 0:35:34.142124\n",
      "0.9387199\n",
      "[Epoch 23/50] [Batch 247/300] [D loss: 0.752532] [G loss: 0.545180] time: 0:35:34.460424\n",
      "0.9148038\n",
      "[Epoch 23/50] [Batch 248/300] [D loss: 0.752550] [G loss: 0.515260] time: 0:35:34.749010\n",
      "0.9064625\n",
      "[Epoch 23/50] [Batch 249/300] [D loss: 0.752553] [G loss: 0.501647] time: 0:35:35.028826\n",
      "0.95445037\n",
      "[Epoch 23/50] [Batch 250/300] [D loss: 0.752503] [G loss: 0.539024] time: 0:35:35.318223\n",
      "0.9393477\n",
      "[Epoch 23/50] [Batch 251/300] [D loss: 0.752527] [G loss: 0.508111] time: 0:35:35.609247\n",
      "0.90331006\n",
      "[Epoch 23/50] [Batch 252/300] [D loss: 0.752539] [G loss: 0.502100] time: 0:35:35.907799\n",
      "0.93099356\n",
      "[Epoch 23/50] [Batch 253/300] [D loss: 0.752537] [G loss: 0.526181] time: 0:35:36.199658\n",
      "0.8941963\n",
      "[Epoch 23/50] [Batch 254/300] [D loss: 0.752521] [G loss: 0.518119] time: 0:35:36.490255\n",
      "0.92741394\n",
      "[Epoch 23/50] [Batch 255/300] [D loss: 0.752531] [G loss: 0.486379] time: 0:35:36.798846\n",
      "0.9316346\n",
      "[Epoch 23/50] [Batch 256/300] [D loss: 0.752532] [G loss: 0.547117] time: 0:35:37.095468\n",
      "0.9530484\n",
      "[Epoch 23/50] [Batch 257/300] [D loss: 0.752526] [G loss: 0.503729] time: 0:35:37.393859\n",
      "0.90264416\n",
      "[Epoch 23/50] [Batch 258/300] [D loss: 0.752518] [G loss: 0.523883] time: 0:35:37.696210\n",
      "0.9422405\n",
      "[Epoch 23/50] [Batch 259/300] [D loss: 0.752527] [G loss: 0.505708] time: 0:35:37.992027\n",
      "0.93155354\n",
      "[Epoch 23/50] [Batch 260/300] [D loss: 0.752539] [G loss: 0.498380] time: 0:35:38.304422\n",
      "0.93214697\n",
      "[Epoch 23/50] [Batch 261/300] [D loss: 0.752533] [G loss: 0.509897] time: 0:35:38.615380\n",
      "0.91785747\n",
      "[Epoch 23/50] [Batch 262/300] [D loss: 0.752520] [G loss: 0.513466] time: 0:35:38.888487\n",
      "0.9526034\n",
      "[Epoch 23/50] [Batch 263/300] [D loss: 0.752526] [G loss: 0.516258] time: 0:35:39.173781\n",
      "0.9171095\n",
      "[Epoch 23/50] [Batch 264/300] [D loss: 0.752509] [G loss: 0.517480] time: 0:35:39.459889\n",
      "0.95142764\n",
      "[Epoch 23/50] [Batch 265/300] [D loss: 0.752543] [G loss: 0.497290] time: 0:35:39.748517\n",
      "0.9615179\n",
      "[Epoch 23/50] [Batch 266/300] [D loss: 0.752533] [G loss: 0.489821] time: 0:35:40.045918\n",
      "0.9139323\n",
      "[Epoch 23/50] [Batch 267/300] [D loss: 0.752530] [G loss: 0.522822] time: 0:35:40.336004\n",
      "0.91471624\n",
      "[Epoch 23/50] [Batch 268/300] [D loss: 0.752531] [G loss: 0.534575] time: 0:35:40.644039\n",
      "0.86794025\n",
      "[Epoch 23/50] [Batch 269/300] [D loss: 0.752529] [G loss: 0.492874] time: 0:35:40.929061\n",
      "0.98257923\n",
      "[Epoch 23/50] [Batch 270/300] [D loss: 0.752541] [G loss: 0.481730] time: 0:35:41.233405\n",
      "0.94117\n",
      "[Epoch 23/50] [Batch 271/300] [D loss: 0.752523] [G loss: 0.540208] time: 0:35:41.518337\n",
      "0.9093345\n",
      "[Epoch 23/50] [Batch 272/300] [D loss: 0.752526] [G loss: 0.513266] time: 0:35:41.815083\n",
      "0.9104565\n",
      "[Epoch 23/50] [Batch 273/300] [D loss: 0.752538] [G loss: 0.497620] time: 0:35:42.106050\n",
      "0.9222765\n",
      "[Epoch 23/50] [Batch 274/300] [D loss: 0.752534] [G loss: 0.491226] time: 0:35:42.414318\n",
      "0.91520905\n",
      "[Epoch 23/50] [Batch 275/300] [D loss: 0.752551] [G loss: 0.537641] time: 0:35:42.705827\n",
      "0.94179887\n",
      "[Epoch 23/50] [Batch 276/300] [D loss: 0.752540] [G loss: 0.522727] time: 0:35:43.008313\n",
      "0.93860227\n",
      "[Epoch 23/50] [Batch 277/300] [D loss: 0.752528] [G loss: 0.519562] time: 0:35:43.302134\n",
      "0.89358634\n",
      "[Epoch 23/50] [Batch 278/300] [D loss: 0.752527] [G loss: 0.550630] time: 0:35:43.590817\n",
      "0.94139594\n",
      "[Epoch 23/50] [Batch 279/300] [D loss: 0.752503] [G loss: 0.511536] time: 0:35:43.880603\n",
      "0.9140968\n",
      "[Epoch 23/50] [Batch 280/300] [D loss: 0.752535] [G loss: 0.506463] time: 0:35:44.179241\n",
      "0.9221621\n",
      "[Epoch 23/50] [Batch 281/300] [D loss: 0.752543] [G loss: 0.500032] time: 0:35:44.472169\n",
      "0.9450491\n",
      "[Epoch 23/50] [Batch 282/300] [D loss: 0.752522] [G loss: 0.513464] time: 0:35:44.770520\n",
      "0.90109426\n",
      "[Epoch 23/50] [Batch 283/300] [D loss: 0.752545] [G loss: 0.533534] time: 0:35:45.057905\n",
      "0.9132168\n",
      "[Epoch 23/50] [Batch 284/300] [D loss: 0.752512] [G loss: 0.511368] time: 0:35:45.366267\n",
      "0.909887\n",
      "[Epoch 23/50] [Batch 285/300] [D loss: 0.752520] [G loss: 0.508681] time: 0:35:45.657617\n",
      "0.9503699\n",
      "[Epoch 23/50] [Batch 286/300] [D loss: 0.752524] [G loss: 0.548710] time: 0:35:45.949746\n",
      "0.94326705\n",
      "[Epoch 23/50] [Batch 287/300] [D loss: 0.752521] [G loss: 0.510733] time: 0:35:46.251564\n",
      "0.9120771\n",
      "[Epoch 23/50] [Batch 288/300] [D loss: 0.752548] [G loss: 0.552093] time: 0:35:46.555438\n",
      "0.90101975\n",
      "[Epoch 23/50] [Batch 289/300] [D loss: 0.752528] [G loss: 0.511348] time: 0:35:46.858266\n",
      "0.9409132\n",
      "[Epoch 23/50] [Batch 290/300] [D loss: 0.752518] [G loss: 0.503791] time: 0:35:47.163890\n",
      "0.934478\n",
      "[Epoch 23/50] [Batch 291/300] [D loss: 0.752507] [G loss: 0.504074] time: 0:35:47.476462\n",
      "0.9077091\n",
      "[Epoch 23/50] [Batch 292/300] [D loss: 0.752551] [G loss: 0.511856] time: 0:35:47.776058\n",
      "0.90507364\n",
      "[Epoch 23/50] [Batch 293/300] [D loss: 0.752515] [G loss: 0.545600] time: 0:35:48.085697\n",
      "0.9295411\n",
      "[Epoch 23/50] [Batch 294/300] [D loss: 0.752543] [G loss: 0.503892] time: 0:35:48.392095\n",
      "0.9161892\n",
      "[Epoch 23/50] [Batch 295/300] [D loss: 0.752504] [G loss: 0.524864] time: 0:35:48.689236\n",
      "0.8674822\n",
      "[Epoch 23/50] [Batch 296/300] [D loss: 0.752518] [G loss: 0.505398] time: 0:35:48.982739\n",
      "0.9382785\n",
      "[Epoch 23/50] [Batch 297/300] [D loss: 0.752536] [G loss: 0.495741] time: 0:35:49.276725\n",
      "0.936254\n",
      "[Epoch 23/50] [Batch 298/300] [D loss: 0.752539] [G loss: 0.505630] time: 0:35:49.583432\n",
      "0.93096113\n",
      "[Epoch 23/50] [Batch 299/300] [D loss: 0.752538] [G loss: 0.539867] time: 0:35:49.898857\n",
      "0.9587465\n",
      "[Epoch 24/50] [Batch 0/300] [D loss: 0.752538] [G loss: 0.524675] time: 0:35:50.202506\n",
      "0.94468004\n",
      "[Epoch 24/50] [Batch 1/300] [D loss: 0.752546] [G loss: 0.529782] time: 0:35:50.493380\n",
      "0.90757924\n",
      "[Epoch 24/50] [Batch 2/300] [D loss: 0.752514] [G loss: 0.510863] time: 0:35:50.788953\n",
      "0.8964693\n",
      "[Epoch 24/50] [Batch 3/300] [D loss: 0.752521] [G loss: 0.496128] time: 0:35:51.094797\n",
      "0.91395026\n",
      "[Epoch 24/50] [Batch 4/300] [D loss: 0.752538] [G loss: 0.525000] time: 0:35:51.422718\n",
      "0.92036533\n",
      "[Epoch 24/50] [Batch 5/300] [D loss: 0.752515] [G loss: 0.500614] time: 0:35:51.709455\n",
      "0.926732\n",
      "[Epoch 24/50] [Batch 6/300] [D loss: 0.752544] [G loss: 0.498216] time: 0:35:52.003846\n",
      "0.91427046\n",
      "[Epoch 24/50] [Batch 7/300] [D loss: 0.752523] [G loss: 0.539276] time: 0:35:52.300368\n",
      "0.93199444\n",
      "[Epoch 24/50] [Batch 8/300] [D loss: 0.752520] [G loss: 0.515245] time: 0:35:52.592030\n",
      "0.91635674\n",
      "[Epoch 24/50] [Batch 9/300] [D loss: 0.752506] [G loss: 0.504197] time: 0:35:52.889942\n",
      "0.9345271\n",
      "[Epoch 24/50] [Batch 10/300] [D loss: 0.752537] [G loss: 0.511051] time: 0:35:53.181842\n",
      "0.9223501\n",
      "[Epoch 24/50] [Batch 11/300] [D loss: 0.752548] [G loss: 0.484928] time: 0:35:53.486250\n",
      "0.91708994\n",
      "[Epoch 24/50] [Batch 12/300] [D loss: 0.752533] [G loss: 0.545933] time: 0:35:53.796552\n",
      "0.9158678\n",
      "[Epoch 24/50] [Batch 13/300] [D loss: 0.752518] [G loss: 0.518418] time: 0:35:54.099847\n",
      "0.9462108\n",
      "[Epoch 24/50] [Batch 14/300] [D loss: 0.752514] [G loss: 0.495702] time: 0:35:54.421439\n",
      "0.94542795\n",
      "[Epoch 24/50] [Batch 15/300] [D loss: 0.752549] [G loss: 0.520664] time: 0:35:54.700654\n",
      "0.89845705\n",
      "[Epoch 24/50] [Batch 16/300] [D loss: 0.752517] [G loss: 0.531495] time: 0:35:55.008669\n",
      "0.90231234\n",
      "[Epoch 24/50] [Batch 17/300] [D loss: 0.752520] [G loss: 0.519125] time: 0:35:55.309901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083893\n",
      "[Epoch 24/50] [Batch 18/300] [D loss: 0.752519] [G loss: 0.536658] time: 0:35:55.610107\n",
      "0.9725635\n",
      "[Epoch 24/50] [Batch 19/300] [D loss: 0.752545] [G loss: 0.494603] time: 0:35:55.938868\n",
      "0.9332759\n",
      "[Epoch 24/50] [Batch 20/300] [D loss: 0.752537] [G loss: 0.501124] time: 0:35:56.235376\n",
      "0.9243703\n",
      "[Epoch 24/50] [Batch 21/300] [D loss: 0.752535] [G loss: 0.526377] time: 0:35:56.529704\n",
      "0.92746574\n",
      "[Epoch 24/50] [Batch 22/300] [D loss: 0.752520] [G loss: 0.517869] time: 0:35:56.851817\n",
      "0.9667628\n",
      "[Epoch 24/50] [Batch 24/300] [D loss: 0.752509] [G loss: 0.502183] time: 0:35:57.126087\n",
      "0.90489936\n",
      "[Epoch 24/50] [Batch 25/300] [D loss: 0.752517] [G loss: 0.511396] time: 0:35:57.433814\n",
      "0.9306288\n",
      "[Epoch 24/50] [Batch 26/300] [D loss: 0.752526] [G loss: 0.495783] time: 0:35:57.729241\n",
      "0.91794187\n",
      "[Epoch 24/50] [Batch 27/300] [D loss: 0.752525] [G loss: 0.489357] time: 0:35:58.026730\n",
      "0.93161005\n",
      "[Epoch 24/50] [Batch 28/300] [D loss: 0.752540] [G loss: 0.499153] time: 0:35:58.297391\n",
      "0.93854564\n",
      "[Epoch 24/50] [Batch 29/300] [D loss: 0.752524] [G loss: 0.493384] time: 0:35:58.606507\n",
      "0.91593593\n",
      "[Epoch 24/50] [Batch 30/300] [D loss: 0.752546] [G loss: 0.485150] time: 0:35:58.909755\n",
      "0.93243647\n",
      "[Epoch 24/50] [Batch 31/300] [D loss: 0.752534] [G loss: 0.489893] time: 0:35:59.217182\n",
      "0.95335704\n",
      "[Epoch 24/50] [Batch 32/300] [D loss: 0.752524] [G loss: 0.505892] time: 0:35:59.518638\n",
      "0.9290011\n",
      "[Epoch 24/50] [Batch 33/300] [D loss: 0.752530] [G loss: 0.488599] time: 0:35:59.804544\n",
      "0.9342866\n",
      "[Epoch 24/50] [Batch 34/300] [D loss: 0.752537] [G loss: 0.497849] time: 0:36:00.099680\n",
      "0.9191925\n",
      "[Epoch 24/50] [Batch 35/300] [D loss: 0.752515] [G loss: 0.535250] time: 0:36:00.399190\n",
      "0.92743087\n",
      "[Epoch 24/50] [Batch 36/300] [D loss: 0.752513] [G loss: 0.507866] time: 0:36:00.706265\n",
      "0.9058315\n",
      "[Epoch 24/50] [Batch 37/300] [D loss: 0.752532] [G loss: 0.497638] time: 0:36:01.016574\n",
      "0.9130073\n",
      "[Epoch 24/50] [Batch 38/300] [D loss: 0.752514] [G loss: 0.492540] time: 0:36:01.330444\n",
      "0.9362493\n",
      "[Epoch 24/50] [Batch 39/300] [D loss: 0.752507] [G loss: 0.496013] time: 0:36:01.634258\n",
      "0.90770954\n",
      "[Epoch 24/50] [Batch 40/300] [D loss: 0.752520] [G loss: 0.490130] time: 0:36:01.937052\n",
      "0.95251036\n",
      "[Epoch 24/50] [Batch 41/300] [D loss: 0.752514] [G loss: 0.509113] time: 0:36:02.250678\n",
      "0.8960199\n",
      "[Epoch 24/50] [Batch 42/300] [D loss: 0.752529] [G loss: 0.502479] time: 0:36:02.534633\n",
      "0.9057868\n",
      "[Epoch 24/50] [Batch 43/300] [D loss: 0.752513] [G loss: 0.491576] time: 0:36:02.837444\n",
      "0.91567355\n",
      "[Epoch 24/50] [Batch 44/300] [D loss: 0.752514] [G loss: 0.511264] time: 0:36:03.135898\n",
      "0.9306702\n",
      "[Epoch 24/50] [Batch 45/300] [D loss: 0.752515] [G loss: 0.498695] time: 0:36:03.435314\n",
      "0.9108939\n",
      "[Epoch 24/50] [Batch 46/300] [D loss: 0.752495] [G loss: 0.515519] time: 0:36:03.736609\n",
      "0.8936588\n",
      "[Epoch 24/50] [Batch 47/300] [D loss: 0.752520] [G loss: 0.490044] time: 0:36:04.039498\n",
      "0.94982934\n",
      "[Epoch 24/50] [Batch 48/300] [D loss: 0.752529] [G loss: 0.506414] time: 0:36:04.356492\n",
      "0.8988219\n",
      "[Epoch 24/50] [Batch 49/300] [D loss: 0.752551] [G loss: 0.513996] time: 0:36:04.658219\n",
      "0.9375963\n",
      "[Epoch 24/50] [Batch 50/300] [D loss: 0.752538] [G loss: 0.510283] time: 0:36:04.947701\n",
      "0.95873356\n",
      "[Epoch 24/50] [Batch 51/300] [D loss: 0.752525] [G loss: 0.504183] time: 0:36:05.245501\n",
      "0.93064404\n",
      "[Epoch 24/50] [Batch 52/300] [D loss: 0.752524] [G loss: 0.514789] time: 0:36:05.551169\n",
      "0.9057475\n",
      "[Epoch 24/50] [Batch 53/300] [D loss: 0.752542] [G loss: 0.515005] time: 0:36:05.858534\n",
      "0.90364623\n",
      "[Epoch 24/50] [Batch 54/300] [D loss: 0.752509] [G loss: 0.516142] time: 0:36:06.131090\n",
      "0.93314695\n",
      "[Epoch 24/50] [Batch 55/300] [D loss: 0.752513] [G loss: 0.537845] time: 0:36:06.447063\n",
      "0.90066487\n",
      "[Epoch 24/50] [Batch 56/300] [D loss: 0.752508] [G loss: 0.487125] time: 0:36:06.754341\n",
      "0.94603175\n",
      "[Epoch 24/50] [Batch 57/300] [D loss: 0.752531] [G loss: 0.494232] time: 0:36:07.042362\n",
      "0.8885495\n",
      "[Epoch 24/50] [Batch 58/300] [D loss: 0.752523] [G loss: 0.527124] time: 0:36:07.338636\n",
      "0.89952636\n",
      "[Epoch 24/50] [Batch 59/300] [D loss: 0.752542] [G loss: 0.531166] time: 0:36:07.646033\n",
      "0.9177726\n",
      "[Epoch 24/50] [Batch 60/300] [D loss: 0.752519] [G loss: 0.502578] time: 0:36:07.933096\n",
      "0.92095965\n",
      "[Epoch 24/50] [Batch 61/300] [D loss: 0.752506] [G loss: 0.512461] time: 0:36:08.222423\n",
      "0.9315045\n",
      "[Epoch 24/50] [Batch 62/300] [D loss: 0.752506] [G loss: 0.512946] time: 0:36:08.511940\n",
      "0.9167633\n",
      "[Epoch 24/50] [Batch 63/300] [D loss: 0.752522] [G loss: 0.528570] time: 0:36:08.803514\n",
      "0.8913029\n",
      "[Epoch 24/50] [Batch 64/300] [D loss: 0.752537] [G loss: 0.495454] time: 0:36:09.110343\n",
      "0.9254785\n",
      "[Epoch 24/50] [Batch 65/300] [D loss: 0.752502] [G loss: 0.506222] time: 0:36:09.422344\n",
      "0.9176267\n",
      "[Epoch 24/50] [Batch 66/300] [D loss: 0.752529] [G loss: 0.509696] time: 0:36:09.717580\n",
      "0.9839476\n",
      "[Epoch 24/50] [Batch 67/300] [D loss: 0.752519] [G loss: 0.543721] time: 0:36:10.027199\n",
      "0.89060706\n",
      "[Epoch 24/50] [Batch 68/300] [D loss: 0.752515] [G loss: 0.542677] time: 0:36:10.319329\n",
      "0.90040797\n",
      "[Epoch 24/50] [Batch 69/300] [D loss: 0.752519] [G loss: 0.501802] time: 0:36:10.611099\n",
      "0.95475173\n",
      "[Epoch 24/50] [Batch 70/300] [D loss: 0.752523] [G loss: 0.527534] time: 0:36:10.902207\n",
      "0.89041525\n",
      "[Epoch 24/50] [Batch 71/300] [D loss: 0.752530] [G loss: 0.525518] time: 0:36:11.186949\n",
      "0.9449496\n",
      "[Epoch 24/50] [Batch 72/300] [D loss: 0.752516] [G loss: 0.503461] time: 0:36:11.489646\n",
      "0.908745\n",
      "[Epoch 24/50] [Batch 73/300] [D loss: 0.752536] [G loss: 0.511695] time: 0:36:11.782805\n",
      "0.88667506\n",
      "[Epoch 24/50] [Batch 74/300] [D loss: 0.752514] [G loss: 0.527819] time: 0:36:12.066129\n",
      "0.96944904\n",
      "[Epoch 24/50] [Batch 75/300] [D loss: 0.752507] [G loss: 0.486162] time: 0:36:12.369765\n",
      "0.92951125\n",
      "[Epoch 24/50] [Batch 76/300] [D loss: 0.752544] [G loss: 0.542482] time: 0:36:12.663852\n",
      "0.9061923\n",
      "[Epoch 24/50] [Batch 77/300] [D loss: 0.752530] [G loss: 0.485347] time: 0:36:12.957783\n",
      "0.9607225\n",
      "[Epoch 24/50] [Batch 78/300] [D loss: 0.752535] [G loss: 0.502949] time: 0:36:13.268010\n",
      "0.9840803\n",
      "[Epoch 24/50] [Batch 79/300] [D loss: 0.752513] [G loss: 0.527172] time: 0:36:13.565636\n",
      "0.9409335\n",
      "[Epoch 24/50] [Batch 80/300] [D loss: 0.752564] [G loss: 0.499143] time: 0:36:13.864953\n",
      "0.9718356\n",
      "[Epoch 24/50] [Batch 81/300] [D loss: 0.752513] [G loss: 0.514318] time: 0:36:14.156492\n",
      "0.9448273\n",
      "[Epoch 24/50] [Batch 82/300] [D loss: 0.752517] [G loss: 0.539722] time: 0:36:14.454732\n",
      "0.97560674\n",
      "[Epoch 24/50] [Batch 83/300] [D loss: 0.752519] [G loss: 0.499939] time: 0:36:14.756225\n",
      "0.91746235\n",
      "[Epoch 24/50] [Batch 84/300] [D loss: 0.752512] [G loss: 0.515498] time: 0:36:15.059246\n",
      "0.91422623\n",
      "[Epoch 24/50] [Batch 85/300] [D loss: 0.752493] [G loss: 0.502396] time: 0:36:15.381589\n",
      "0.88446933\n",
      "[Epoch 24/50] [Batch 86/300] [D loss: 0.752504] [G loss: 0.529885] time: 0:36:15.688117\n",
      "0.9387966\n",
      "[Epoch 24/50] [Batch 87/300] [D loss: 0.752527] [G loss: 0.496518] time: 0:36:15.985771\n",
      "0.9197642\n",
      "[Epoch 24/50] [Batch 88/300] [D loss: 0.752523] [G loss: 0.492987] time: 0:36:16.273341\n",
      "0.92840844\n",
      "[Epoch 24/50] [Batch 89/300] [D loss: 0.752512] [G loss: 0.509458] time: 0:36:16.571469\n",
      "0.9248609\n",
      "[Epoch 24/50] [Batch 90/300] [D loss: 0.752529] [G loss: 0.495226] time: 0:36:16.869105\n",
      "0.8934372\n",
      "[Epoch 24/50] [Batch 91/300] [D loss: 0.752529] [G loss: 0.502975] time: 0:36:17.164604\n",
      "0.96014863\n",
      "[Epoch 24/50] [Batch 92/300] [D loss: 0.752505] [G loss: 0.500697] time: 0:36:17.471761\n",
      "0.9495983\n",
      "[Epoch 24/50] [Batch 93/300] [D loss: 0.752507] [G loss: 0.547794] time: 0:36:17.787557\n",
      "0.96215016\n",
      "[Epoch 24/50] [Batch 94/300] [D loss: 0.752540] [G loss: 0.504588] time: 0:36:18.078533\n",
      "0.9204866\n",
      "[Epoch 24/50] [Batch 95/300] [D loss: 0.752545] [G loss: 0.515047] time: 0:36:18.393478\n",
      "0.9533434\n",
      "[Epoch 24/50] [Batch 96/300] [D loss: 0.752550] [G loss: 0.503634] time: 0:36:18.711722\n",
      "0.91769\n",
      "[Epoch 24/50] [Batch 97/300] [D loss: 0.752516] [G loss: 0.497309] time: 0:36:19.007733\n",
      "0.93788576\n",
      "[Epoch 24/50] [Batch 98/300] [D loss: 0.752522] [G loss: 0.529454] time: 0:36:19.324470\n",
      "0.90009904\n",
      "[Epoch 24/50] [Batch 99/300] [D loss: 0.752522] [G loss: 0.511896] time: 0:36:19.611892\n",
      "0.9053466\n",
      "[Epoch 24/50] [Batch 100/300] [D loss: 0.752528] [G loss: 0.513287] time: 0:36:19.931415\n",
      "0.942761\n",
      "[Epoch 24/50] [Batch 101/300] [D loss: 0.752509] [G loss: 0.522878] time: 0:36:20.241319\n",
      "0.9085782\n",
      "[Epoch 24/50] [Batch 102/300] [D loss: 0.752496] [G loss: 0.527749] time: 0:36:20.545876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93769175\n",
      "[Epoch 24/50] [Batch 103/300] [D loss: 0.752521] [G loss: 0.514280] time: 0:36:20.860325\n",
      "0.91376466\n",
      "[Epoch 24/50] [Batch 104/300] [D loss: 0.752502] [G loss: 0.520698] time: 0:36:21.173524\n",
      "0.9524737\n",
      "[Epoch 24/50] [Batch 105/300] [D loss: 0.752507] [G loss: 0.505069] time: 0:36:21.479155\n",
      "0.9053092\n",
      "[Epoch 24/50] [Batch 106/300] [D loss: 0.752532] [G loss: 0.497799] time: 0:36:21.781983\n",
      "0.9458601\n",
      "[Epoch 24/50] [Batch 107/300] [D loss: 0.752510] [G loss: 0.517908] time: 0:36:22.078947\n",
      "0.89577013\n",
      "[Epoch 24/50] [Batch 108/300] [D loss: 0.752515] [G loss: 0.505286] time: 0:36:22.389668\n",
      "0.98317736\n",
      "[Epoch 24/50] [Batch 109/300] [D loss: 0.752513] [G loss: 0.514200] time: 0:36:22.696239\n",
      "0.9290138\n",
      "[Epoch 24/50] [Batch 110/300] [D loss: 0.752518] [G loss: 0.509964] time: 0:36:23.013954\n",
      "0.9371834\n",
      "[Epoch 24/50] [Batch 111/300] [D loss: 0.752520] [G loss: 0.530071] time: 0:36:23.318763\n",
      "0.9062695\n",
      "[Epoch 24/50] [Batch 112/300] [D loss: 0.752522] [G loss: 0.510508] time: 0:36:23.616056\n",
      "0.8862217\n",
      "[Epoch 24/50] [Batch 113/300] [D loss: 0.752495] [G loss: 0.550011] time: 0:36:23.925679\n",
      "0.9187667\n",
      "[Epoch 24/50] [Batch 114/300] [D loss: 0.752512] [G loss: 0.500389] time: 0:36:24.243052\n",
      "0.90545225\n",
      "[Epoch 24/50] [Batch 115/300] [D loss: 0.752523] [G loss: 0.513634] time: 0:36:24.555536\n",
      "0.9140392\n",
      "[Epoch 24/50] [Batch 116/300] [D loss: 0.752522] [G loss: 0.492729] time: 0:36:24.861088\n",
      "0.924264\n",
      "[Epoch 24/50] [Batch 117/300] [D loss: 0.752517] [G loss: 0.491569] time: 0:36:25.141932\n",
      "0.9028309\n",
      "[Epoch 24/50] [Batch 118/300] [D loss: 0.752506] [G loss: 0.502982] time: 0:36:25.447762\n",
      "0.93471336\n",
      "[Epoch 24/50] [Batch 119/300] [D loss: 0.752514] [G loss: 0.502507] time: 0:36:25.749008\n",
      "0.91119766\n",
      "[Epoch 24/50] [Batch 120/300] [D loss: 0.752542] [G loss: 0.514704] time: 0:36:26.055711\n",
      "0.9708991\n",
      "[Epoch 24/50] [Batch 121/300] [D loss: 0.752529] [G loss: 0.507747] time: 0:36:26.342947\n",
      "0.96767205\n",
      "[Epoch 24/50] [Batch 122/300] [D loss: 0.752528] [G loss: 0.559249] time: 0:36:26.647205\n",
      "0.9300243\n",
      "[Epoch 24/50] [Batch 123/300] [D loss: 0.752499] [G loss: 0.508730] time: 0:36:26.967940\n",
      "0.93898773\n",
      "[Epoch 24/50] [Batch 124/300] [D loss: 0.752530] [G loss: 0.526284] time: 0:36:27.276372\n",
      "0.90762687\n",
      "[Epoch 24/50] [Batch 125/300] [D loss: 0.752540] [G loss: 0.509887] time: 0:36:27.571044\n",
      "0.93695086\n",
      "[Epoch 24/50] [Batch 126/300] [D loss: 0.752530] [G loss: 0.524587] time: 0:36:27.863039\n",
      "0.945826\n",
      "[Epoch 24/50] [Batch 127/300] [D loss: 0.752528] [G loss: 0.544509] time: 0:36:28.167663\n",
      "0.924413\n",
      "[Epoch 24/50] [Batch 128/300] [D loss: 0.752521] [G loss: 0.501217] time: 0:36:28.462673\n",
      "0.9319215\n",
      "[Epoch 24/50] [Batch 129/300] [D loss: 0.752520] [G loss: 0.508362] time: 0:36:28.770574\n",
      "0.96442777\n",
      "[Epoch 24/50] [Batch 130/300] [D loss: 0.752507] [G loss: 0.513215] time: 0:36:29.083668\n",
      "0.8960344\n",
      "[Epoch 24/50] [Batch 131/300] [D loss: 0.752519] [G loss: 0.524975] time: 0:36:29.399346\n",
      "0.9615987\n",
      "[Epoch 24/50] [Batch 132/300] [D loss: 0.752537] [G loss: 0.494943] time: 0:36:29.697260\n",
      "0.9388985\n",
      "[Epoch 24/50] [Batch 133/300] [D loss: 0.752501] [G loss: 0.500092] time: 0:36:30.003040\n",
      "0.879189\n",
      "[Epoch 24/50] [Batch 134/300] [D loss: 0.752517] [G loss: 0.544795] time: 0:36:30.305222\n",
      "0.8994389\n",
      "[Epoch 24/50] [Batch 135/300] [D loss: 0.752493] [G loss: 0.499490] time: 0:36:30.605427\n",
      "0.899704\n",
      "[Epoch 24/50] [Batch 136/300] [D loss: 0.752509] [G loss: 0.509541] time: 0:36:30.910687\n",
      "0.90336066\n",
      "[Epoch 24/50] [Batch 137/300] [D loss: 0.752504] [G loss: 0.519981] time: 0:36:31.220833\n",
      "0.8963733\n",
      "[Epoch 24/50] [Batch 138/300] [D loss: 0.752542] [G loss: 0.490360] time: 0:36:31.527228\n",
      "0.9121465\n",
      "[Epoch 24/50] [Batch 139/300] [D loss: 0.752522] [G loss: 0.517906] time: 0:36:31.850573\n",
      "0.8872995\n",
      "[Epoch 24/50] [Batch 140/300] [D loss: 0.752505] [G loss: 0.519898] time: 0:36:32.147060\n",
      "0.9761568\n",
      "[Epoch 24/50] [Batch 141/300] [D loss: 0.752511] [G loss: 0.507570] time: 0:36:32.456229\n",
      "0.9424128\n",
      "[Epoch 24/50] [Batch 142/300] [D loss: 0.752511] [G loss: 0.535230] time: 0:36:32.749302\n",
      "0.9165552\n",
      "[Epoch 24/50] [Batch 143/300] [D loss: 0.752503] [G loss: 0.519088] time: 0:36:33.049976\n",
      "0.902364\n",
      "[Epoch 24/50] [Batch 144/300] [D loss: 0.752498] [G loss: 0.506298] time: 0:36:33.343714\n",
      "0.91369313\n",
      "[Epoch 24/50] [Batch 145/300] [D loss: 0.752511] [G loss: 0.534781] time: 0:36:33.654927\n",
      "0.93576986\n",
      "[Epoch 24/50] [Batch 146/300] [D loss: 0.752541] [G loss: 0.509369] time: 0:36:33.961504\n",
      "0.8877392\n",
      "[Epoch 24/50] [Batch 147/300] [D loss: 0.752501] [G loss: 0.508476] time: 0:36:34.254488\n",
      "0.8884895\n",
      "[Epoch 24/50] [Batch 148/300] [D loss: 0.752519] [G loss: 0.501151] time: 0:36:34.552421\n",
      "0.91050476\n",
      "[Epoch 24/50] [Batch 149/300] [D loss: 0.752541] [G loss: 0.485974] time: 0:36:34.861367\n",
      "0.9108114\n",
      "[Epoch 24/50] [Batch 150/300] [D loss: 0.752506] [G loss: 0.500561] time: 0:36:35.152044\n",
      "0.92607784\n",
      "[Epoch 24/50] [Batch 151/300] [D loss: 0.752512] [G loss: 0.510900] time: 0:36:35.454480\n",
      "0.9093738\n",
      "[Epoch 24/50] [Batch 152/300] [D loss: 0.752502] [G loss: 0.503915] time: 0:36:35.740580\n",
      "0.94260985\n",
      "[Epoch 24/50] [Batch 153/300] [D loss: 0.752519] [G loss: 0.485693] time: 0:36:36.022107\n",
      "0.95283914\n",
      "[Epoch 24/50] [Batch 154/300] [D loss: 0.752532] [G loss: 0.499350] time: 0:36:36.318366\n",
      "0.9153502\n",
      "[Epoch 24/50] [Batch 155/300] [D loss: 0.752504] [G loss: 0.504891] time: 0:36:36.605401\n",
      "0.9146487\n",
      "[Epoch 24/50] [Batch 156/300] [D loss: 0.752517] [G loss: 0.512291] time: 0:36:36.931929\n",
      "0.9102275\n",
      "[Epoch 24/50] [Batch 157/300] [D loss: 0.752525] [G loss: 0.545040] time: 0:36:37.242269\n",
      "0.91248006\n",
      "[Epoch 24/50] [Batch 158/300] [D loss: 0.752521] [G loss: 0.534086] time: 0:36:37.546041\n",
      "0.88895845\n",
      "[Epoch 24/50] [Batch 159/300] [D loss: 0.752490] [G loss: 0.514535] time: 0:36:37.849762\n",
      "0.9368544\n",
      "[Epoch 24/50] [Batch 160/300] [D loss: 0.752545] [G loss: 0.487454] time: 0:36:38.159670\n",
      "0.9504924\n",
      "[Epoch 24/50] [Batch 161/300] [D loss: 0.752509] [G loss: 0.500111] time: 0:36:38.458932\n",
      "0.93241024\n",
      "[Epoch 24/50] [Batch 162/300] [D loss: 0.752486] [G loss: 0.516399] time: 0:36:38.748519\n",
      "0.89814407\n",
      "[Epoch 24/50] [Batch 163/300] [D loss: 0.752517] [G loss: 0.497974] time: 0:36:39.018746\n",
      "0.90569496\n",
      "[Epoch 24/50] [Batch 164/300] [D loss: 0.752504] [G loss: 0.514199] time: 0:36:39.302860\n",
      "0.8884986\n",
      "[Epoch 24/50] [Batch 165/300] [D loss: 0.752509] [G loss: 0.498339] time: 0:36:39.614344\n",
      "0.9212112\n",
      "[Epoch 24/50] [Batch 166/300] [D loss: 0.752549] [G loss: 0.512608] time: 0:36:39.916818\n",
      "0.94509596\n",
      "[Epoch 24/50] [Batch 167/300] [D loss: 0.752508] [G loss: 0.492785] time: 0:36:40.202301\n",
      "0.9090874\n",
      "[Epoch 24/50] [Batch 168/300] [D loss: 0.752506] [G loss: 0.532759] time: 0:36:40.508511\n",
      "0.9107762\n",
      "[Epoch 24/50] [Batch 169/300] [D loss: 0.752517] [G loss: 0.508693] time: 0:36:40.821349\n",
      "0.90769213\n",
      "[Epoch 24/50] [Batch 170/300] [D loss: 0.752505] [G loss: 0.525739] time: 0:36:41.118225\n",
      "0.93787223\n",
      "[Epoch 24/50] [Batch 171/300] [D loss: 0.752523] [G loss: 0.514286] time: 0:36:41.425777\n",
      "0.94646615\n",
      "[Epoch 24/50] [Batch 172/300] [D loss: 0.752491] [G loss: 0.525926] time: 0:36:41.706015\n",
      "0.9524917\n",
      "[Epoch 24/50] [Batch 173/300] [D loss: 0.752497] [G loss: 0.517790] time: 0:36:41.992660\n",
      "0.976103\n",
      "[Epoch 24/50] [Batch 174/300] [D loss: 0.752516] [G loss: 0.530269] time: 0:36:42.303571\n",
      "0.96807355\n",
      "[Epoch 24/50] [Batch 175/300] [D loss: 0.752484] [G loss: 0.522412] time: 0:36:42.610092\n",
      "0.95616585\n",
      "[Epoch 24/50] [Batch 176/300] [D loss: 0.752530] [G loss: 0.504546] time: 0:36:42.898603\n",
      "0.9370174\n",
      "[Epoch 24/50] [Batch 177/300] [D loss: 0.752497] [G loss: 0.501779] time: 0:36:43.188185\n",
      "0.8720495\n",
      "[Epoch 24/50] [Batch 178/300] [D loss: 0.752509] [G loss: 0.521152] time: 0:36:43.486512\n",
      "0.9240785\n",
      "[Epoch 24/50] [Batch 179/300] [D loss: 0.752521] [G loss: 0.525005] time: 0:36:43.810846\n",
      "0.9276902\n",
      "[Epoch 24/50] [Batch 180/300] [D loss: 0.752529] [G loss: 0.508827] time: 0:36:44.121252\n",
      "0.89906734\n",
      "[Epoch 24/50] [Batch 181/300] [D loss: 0.752533] [G loss: 0.505833] time: 0:36:44.421569\n",
      "0.89083195\n",
      "[Epoch 24/50] [Batch 182/300] [D loss: 0.752508] [G loss: 0.510602] time: 0:36:44.711560\n",
      "0.9139901\n",
      "[Epoch 24/50] [Batch 183/300] [D loss: 0.752500] [G loss: 0.551847] time: 0:36:45.030344\n",
      "0.93223196\n",
      "[Epoch 24/50] [Batch 184/300] [D loss: 0.752503] [G loss: 0.511782] time: 0:36:45.337564\n",
      "0.9341569\n",
      "[Epoch 24/50] [Batch 185/300] [D loss: 0.752489] [G loss: 0.510461] time: 0:36:45.650075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393348\n",
      "[Epoch 24/50] [Batch 186/300] [D loss: 0.752514] [G loss: 0.495070] time: 0:36:45.935141\n",
      "0.94216686\n",
      "[Epoch 24/50] [Batch 187/300] [D loss: 0.752513] [G loss: 0.493661] time: 0:36:46.218992\n",
      "0.91478354\n",
      "[Epoch 24/50] [Batch 188/300] [D loss: 0.752500] [G loss: 0.521390] time: 0:36:46.522510\n",
      "0.9382798\n",
      "[Epoch 24/50] [Batch 189/300] [D loss: 0.752511] [G loss: 0.515692] time: 0:36:46.830515\n",
      "0.94653225\n",
      "[Epoch 24/50] [Batch 190/300] [D loss: 0.752516] [G loss: 0.561795] time: 0:36:47.137946\n",
      "0.91258717\n",
      "[Epoch 24/50] [Batch 191/300] [D loss: 0.752524] [G loss: 0.498637] time: 0:36:47.437318\n",
      "0.94023055\n",
      "[Epoch 24/50] [Batch 192/300] [D loss: 0.752510] [G loss: 0.503612] time: 0:36:47.745783\n",
      "0.9532687\n",
      "[Epoch 24/50] [Batch 193/300] [D loss: 0.752502] [G loss: 0.494927] time: 0:36:48.056340\n",
      "0.89475924\n",
      "[Epoch 24/50] [Batch 194/300] [D loss: 0.752491] [G loss: 0.552406] time: 0:36:48.359158\n",
      "0.878264\n",
      "[Epoch 24/50] [Batch 195/300] [D loss: 0.752485] [G loss: 0.545064] time: 0:36:48.645359\n",
      "0.91167617\n",
      "[Epoch 24/50] [Batch 196/300] [D loss: 0.752489] [G loss: 0.535665] time: 0:36:48.924391\n",
      "0.9048002\n",
      "[Epoch 24/50] [Batch 197/300] [D loss: 0.752508] [G loss: 0.547406] time: 0:36:49.217765\n",
      "0.93336487\n",
      "[Epoch 24/50] [Batch 198/300] [D loss: 0.752517] [G loss: 0.509200] time: 0:36:49.508762\n",
      "0.94616944\n",
      "[Epoch 24/50] [Batch 199/300] [D loss: 0.752515] [G loss: 0.485982] time: 0:36:49.803599\n",
      "0.9452557\n",
      "[Epoch 24/50] [Batch 200/300] [D loss: 0.752506] [G loss: 0.520924] time: 0:36:50.108911\n",
      "0.9317458\n",
      "[Epoch 24/50] [Batch 201/300] [D loss: 0.752526] [G loss: 0.503775] time: 0:36:50.396398\n",
      "0.89851743\n",
      "[Epoch 24/50] [Batch 202/300] [D loss: 0.752517] [G loss: 0.485327] time: 0:36:50.708524\n",
      "0.88631684\n",
      "[Epoch 24/50] [Batch 203/300] [D loss: 0.752539] [G loss: 0.507080] time: 0:36:51.020780\n",
      "0.92389303\n",
      "[Epoch 24/50] [Batch 204/300] [D loss: 0.752526] [G loss: 0.545841] time: 0:36:51.331136\n",
      "0.9135192\n",
      "[Epoch 24/50] [Batch 205/300] [D loss: 0.752504] [G loss: 0.514970] time: 0:36:51.631514\n",
      "0.9752317\n",
      "[Epoch 24/50] [Batch 206/300] [D loss: 0.752500] [G loss: 0.505407] time: 0:36:51.936337\n",
      "0.90995103\n",
      "[Epoch 24/50] [Batch 207/300] [D loss: 0.752523] [G loss: 0.517776] time: 0:36:52.241638\n",
      "0.946331\n",
      "[Epoch 24/50] [Batch 208/300] [D loss: 0.752505] [G loss: 0.502289] time: 0:36:52.547485\n",
      "0.928525\n",
      "[Epoch 24/50] [Batch 209/300] [D loss: 0.752515] [G loss: 0.507134] time: 0:36:52.838004\n",
      "0.89941937\n",
      "[Epoch 24/50] [Batch 210/300] [D loss: 0.752501] [G loss: 0.494057] time: 0:36:53.139982\n",
      "0.9320667\n",
      "[Epoch 24/50] [Batch 211/300] [D loss: 0.752515] [G loss: 0.559506] time: 0:36:53.456593\n",
      "0.91519356\n",
      "[Epoch 24/50] [Batch 212/300] [D loss: 0.752514] [G loss: 0.517940] time: 0:36:53.751383\n",
      "0.9391387\n",
      "[Epoch 24/50] [Batch 213/300] [D loss: 0.752501] [G loss: 0.515566] time: 0:36:54.056579\n",
      "0.9171965\n",
      "[Epoch 24/50] [Batch 214/300] [D loss: 0.752503] [G loss: 0.535679] time: 0:36:54.369092\n",
      "0.9178223\n",
      "[Epoch 24/50] [Batch 215/300] [D loss: 0.752528] [G loss: 0.507020] time: 0:36:54.680484\n",
      "0.884986\n",
      "[Epoch 24/50] [Batch 216/300] [D loss: 0.752503] [G loss: 0.495130] time: 0:36:54.970619\n",
      "0.9135936\n",
      "[Epoch 24/50] [Batch 217/300] [D loss: 0.752527] [G loss: 0.530510] time: 0:36:55.266498\n",
      "0.8701337\n",
      "[Epoch 24/50] [Batch 218/300] [D loss: 0.752516] [G loss: 0.509063] time: 0:36:55.576572\n",
      "0.931868\n",
      "[Epoch 24/50] [Batch 219/300] [D loss: 0.752520] [G loss: 0.514487] time: 0:36:55.884269\n",
      "0.88938904\n",
      "[Epoch 24/50] [Batch 220/300] [D loss: 0.752523] [G loss: 0.506614] time: 0:36:56.199837\n",
      "0.9337585\n",
      "[Epoch 24/50] [Batch 221/300] [D loss: 0.752522] [G loss: 0.490763] time: 0:36:56.495764\n",
      "0.91881466\n",
      "[Epoch 24/50] [Batch 222/300] [D loss: 0.752520] [G loss: 0.497037] time: 0:36:56.791678\n",
      "0.917557\n",
      "[Epoch 24/50] [Batch 223/300] [D loss: 0.752529] [G loss: 0.531904] time: 0:36:57.093277\n",
      "0.90414214\n",
      "[Epoch 24/50] [Batch 224/300] [D loss: 0.752492] [G loss: 0.499771] time: 0:36:57.400896\n",
      "0.921175\n",
      "[Epoch 24/50] [Batch 225/300] [D loss: 0.752499] [G loss: 0.495483] time: 0:36:57.713498\n",
      "0.8921575\n",
      "[Epoch 24/50] [Batch 226/300] [D loss: 0.752493] [G loss: 0.512079] time: 0:36:58.016053\n",
      "0.94927955\n",
      "[Epoch 24/50] [Batch 227/300] [D loss: 0.752510] [G loss: 0.506515] time: 0:36:58.326632\n",
      "0.9100893\n",
      "[Epoch 24/50] [Batch 228/300] [D loss: 0.752506] [G loss: 0.505791] time: 0:36:58.622019\n",
      "0.9753647\n",
      "[Epoch 24/50] [Batch 229/300] [D loss: 0.752517] [G loss: 0.525206] time: 0:36:58.932021\n",
      "0.93372875\n",
      "[Epoch 24/50] [Batch 230/300] [D loss: 0.752507] [G loss: 0.500941] time: 0:36:59.227988\n",
      "0.905317\n",
      "[Epoch 24/50] [Batch 231/300] [D loss: 0.752499] [G loss: 0.500465] time: 0:36:59.530214\n",
      "0.89575297\n",
      "[Epoch 24/50] [Batch 232/300] [D loss: 0.752527] [G loss: 0.515113] time: 0:36:59.832011\n",
      "0.9116489\n",
      "[Epoch 24/50] [Batch 233/300] [D loss: 0.752507] [G loss: 0.487005] time: 0:37:00.129751\n",
      "0.8994367\n",
      "[Epoch 24/50] [Batch 234/300] [D loss: 0.752497] [G loss: 0.504911] time: 0:37:00.415441\n",
      "0.9143575\n",
      "[Epoch 24/50] [Batch 235/300] [D loss: 0.752501] [G loss: 0.499749] time: 0:37:00.707856\n",
      "0.88006335\n",
      "[Epoch 24/50] [Batch 236/300] [D loss: 0.752488] [G loss: 0.494496] time: 0:37:01.002578\n",
      "0.93213224\n",
      "[Epoch 24/50] [Batch 237/300] [D loss: 0.752509] [G loss: 0.531839] time: 0:37:01.295837\n",
      "0.9442552\n",
      "[Epoch 24/50] [Batch 238/300] [D loss: 0.752510] [G loss: 0.527927] time: 0:37:01.573844\n",
      "0.87225825\n",
      "[Epoch 24/50] [Batch 239/300] [D loss: 0.752503] [G loss: 0.515669] time: 0:37:01.872020\n",
      "0.88386565\n",
      "[Epoch 24/50] [Batch 240/300] [D loss: 0.752483] [G loss: 0.486148] time: 0:37:02.175251\n",
      "0.9062884\n",
      "[Epoch 24/50] [Batch 241/300] [D loss: 0.752490] [G loss: 0.500103] time: 0:37:02.464674\n",
      "0.9531576\n",
      "[Epoch 24/50] [Batch 242/300] [D loss: 0.752477] [G loss: 0.482133] time: 0:37:02.758889\n",
      "0.9684213\n",
      "[Epoch 24/50] [Batch 243/300] [D loss: 0.752488] [G loss: 0.496345] time: 0:37:03.064477\n",
      "0.9216056\n",
      "[Epoch 24/50] [Batch 244/300] [D loss: 0.752525] [G loss: 0.501960] time: 0:37:03.370204\n",
      "0.88707924\n",
      "[Epoch 24/50] [Batch 245/300] [D loss: 0.752508] [G loss: 0.483169] time: 0:37:03.671992\n",
      "0.9321479\n",
      "[Epoch 24/50] [Batch 246/300] [D loss: 0.752524] [G loss: 0.569041] time: 0:37:03.975483\n",
      "0.89630055\n",
      "[Epoch 24/50] [Batch 247/300] [D loss: 0.752529] [G loss: 0.507583] time: 0:37:04.284874\n",
      "0.89857227\n",
      "[Epoch 24/50] [Batch 248/300] [D loss: 0.752500] [G loss: 0.498113] time: 0:37:04.578079\n",
      "0.9306891\n",
      "[Epoch 24/50] [Batch 249/300] [D loss: 0.752512] [G loss: 0.523878] time: 0:37:04.866969\n",
      "0.96863437\n",
      "[Epoch 24/50] [Batch 250/300] [D loss: 0.752485] [G loss: 0.493771] time: 0:37:05.165055\n",
      "0.91369796\n",
      "[Epoch 24/50] [Batch 251/300] [D loss: 0.752538] [G loss: 0.517698] time: 0:37:05.457581\n",
      "0.91995114\n",
      "[Epoch 24/50] [Batch 252/300] [D loss: 0.752501] [G loss: 0.490068] time: 0:37:05.753008\n",
      "0.94560915\n",
      "[Epoch 24/50] [Batch 253/300] [D loss: 0.752490] [G loss: 0.500602] time: 0:37:06.063949\n",
      "0.93437785\n",
      "[Epoch 24/50] [Batch 254/300] [D loss: 0.752511] [G loss: 0.527620] time: 0:37:06.352293\n",
      "0.9158185\n",
      "[Epoch 24/50] [Batch 255/300] [D loss: 0.752486] [G loss: 0.496185] time: 0:37:06.663060\n",
      "0.8796509\n",
      "[Epoch 24/50] [Batch 256/300] [D loss: 0.752516] [G loss: 0.515714] time: 0:37:07.098804\n",
      "0.9601694\n",
      "[Epoch 24/50] [Batch 257/300] [D loss: 0.752504] [G loss: 0.514827] time: 0:37:07.395766\n",
      "0.8859651\n",
      "[Epoch 24/50] [Batch 258/300] [D loss: 0.752503] [G loss: 0.498176] time: 0:37:07.716611\n",
      "0.9809041\n",
      "[Epoch 24/50] [Batch 259/300] [D loss: 0.752501] [G loss: 0.518236] time: 0:37:08.027594\n",
      "0.91362983\n",
      "[Epoch 24/50] [Batch 260/300] [D loss: 0.752518] [G loss: 0.500445] time: 0:37:08.330406\n",
      "0.96865004\n",
      "[Epoch 24/50] [Batch 261/300] [D loss: 0.752534] [G loss: 0.529822] time: 0:37:08.631992\n",
      "0.88790274\n",
      "[Epoch 24/50] [Batch 262/300] [D loss: 0.752519] [G loss: 0.492536] time: 0:37:08.940352\n",
      "0.915013\n",
      "[Epoch 24/50] [Batch 263/300] [D loss: 0.752517] [G loss: 0.541059] time: 0:37:09.235502\n",
      "0.8955021\n",
      "[Epoch 24/50] [Batch 264/300] [D loss: 0.752504] [G loss: 0.525239] time: 0:37:09.530810\n",
      "0.9185374\n",
      "[Epoch 24/50] [Batch 265/300] [D loss: 0.752517] [G loss: 0.505043] time: 0:37:09.828562\n",
      "0.9300063\n",
      "[Epoch 24/50] [Batch 266/300] [D loss: 0.752481] [G loss: 0.501070] time: 0:37:10.113511\n",
      "0.9085037\n",
      "[Epoch 24/50] [Batch 267/300] [D loss: 0.752491] [G loss: 0.545033] time: 0:37:10.414984\n",
      "0.9531112\n",
      "[Epoch 24/50] [Batch 268/300] [D loss: 0.752499] [G loss: 0.518853] time: 0:37:10.698740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8989405\n",
      "[Epoch 24/50] [Batch 269/300] [D loss: 0.752490] [G loss: 0.509798] time: 0:37:10.993336\n",
      "0.9162305\n",
      "[Epoch 24/50] [Batch 270/300] [D loss: 0.752497] [G loss: 0.525693] time: 0:37:11.298947\n",
      "0.9270225\n",
      "[Epoch 24/50] [Batch 271/300] [D loss: 0.752518] [G loss: 0.486903] time: 0:37:11.578574\n",
      "0.9312518\n",
      "[Epoch 24/50] [Batch 272/300] [D loss: 0.752527] [G loss: 0.519790] time: 0:37:11.873298\n",
      "0.8992346\n",
      "[Epoch 24/50] [Batch 273/300] [D loss: 0.752521] [G loss: 0.506378] time: 0:37:12.170212\n",
      "0.9075584\n",
      "[Epoch 24/50] [Batch 274/300] [D loss: 0.752498] [G loss: 0.536331] time: 0:37:12.454401\n",
      "0.94292045\n",
      "[Epoch 24/50] [Batch 275/300] [D loss: 0.752482] [G loss: 0.539837] time: 0:37:12.762915\n",
      "0.9356906\n",
      "[Epoch 24/50] [Batch 276/300] [D loss: 0.752482] [G loss: 0.536729] time: 0:37:13.077301\n",
      "0.9425707\n",
      "[Epoch 24/50] [Batch 277/300] [D loss: 0.752497] [G loss: 0.525215] time: 0:37:13.395009\n",
      "0.93311125\n",
      "[Epoch 24/50] [Batch 278/300] [D loss: 0.752507] [G loss: 0.495151] time: 0:37:13.692733\n",
      "0.9318798\n",
      "[Epoch 24/50] [Batch 279/300] [D loss: 0.752495] [G loss: 0.520160] time: 0:37:13.995055\n",
      "0.9397562\n",
      "[Epoch 24/50] [Batch 280/300] [D loss: 0.752507] [G loss: 0.501872] time: 0:37:14.294523\n",
      "0.9400354\n",
      "[Epoch 24/50] [Batch 281/300] [D loss: 0.752514] [G loss: 0.513811] time: 0:37:14.589603\n",
      "0.9125428\n",
      "[Epoch 24/50] [Batch 282/300] [D loss: 0.752509] [G loss: 0.495927] time: 0:37:14.893712\n",
      "0.9598222\n",
      "[Epoch 24/50] [Batch 283/300] [D loss: 0.752513] [G loss: 0.509593] time: 0:37:15.199259\n",
      "0.9505678\n",
      "[Epoch 24/50] [Batch 284/300] [D loss: 0.752481] [G loss: 0.534961] time: 0:37:15.489085\n",
      "0.9169545\n",
      "[Epoch 24/50] [Batch 285/300] [D loss: 0.752490] [G loss: 0.508542] time: 0:37:15.790630\n",
      "0.9136767\n",
      "[Epoch 24/50] [Batch 286/300] [D loss: 0.752498] [G loss: 0.490061] time: 0:37:16.090967\n",
      "0.92428285\n",
      "[Epoch 24/50] [Batch 287/300] [D loss: 0.752485] [G loss: 0.510687] time: 0:37:16.399709\n",
      "0.9292693\n",
      "[Epoch 24/50] [Batch 288/300] [D loss: 0.752495] [G loss: 0.506174] time: 0:37:16.698698\n",
      "0.9135037\n",
      "[Epoch 24/50] [Batch 289/300] [D loss: 0.752509] [G loss: 0.497842] time: 0:37:17.018326\n",
      "0.9329865\n",
      "[Epoch 24/50] [Batch 290/300] [D loss: 0.752492] [G loss: 0.513745] time: 0:37:17.310300\n",
      "0.8921264\n",
      "[Epoch 24/50] [Batch 291/300] [D loss: 0.752507] [G loss: 0.491692] time: 0:37:17.612332\n",
      "0.94620913\n",
      "[Epoch 24/50] [Batch 292/300] [D loss: 0.752502] [G loss: 0.528368] time: 0:37:17.915044\n",
      "0.90618443\n",
      "[Epoch 24/50] [Batch 293/300] [D loss: 0.752521] [G loss: 0.539748] time: 0:37:18.213953\n",
      "0.93778086\n",
      "[Epoch 24/50] [Batch 294/300] [D loss: 0.752500] [G loss: 0.499668] time: 0:37:18.537752\n",
      "0.90325505\n",
      "[Epoch 24/50] [Batch 295/300] [D loss: 0.752489] [G loss: 0.523382] time: 0:37:18.841419\n",
      "0.8900872\n",
      "[Epoch 24/50] [Batch 296/300] [D loss: 0.752488] [G loss: 0.507265] time: 0:37:19.139230\n",
      "0.95671624\n",
      "[Epoch 24/50] [Batch 297/300] [D loss: 0.752493] [G loss: 0.512138] time: 0:37:19.458332\n",
      "0.9484051\n",
      "[Epoch 24/50] [Batch 298/300] [D loss: 0.752507] [G loss: 0.485633] time: 0:37:19.767299\n",
      "0.93680376\n",
      "[Epoch 24/50] [Batch 299/300] [D loss: 0.752519] [G loss: 0.511332] time: 0:37:20.075671\n",
      "0.946492\n",
      "[Epoch 25/50] [Batch 0/300] [D loss: 0.752489] [G loss: 0.513043] time: 0:37:20.379504\n",
      "0.9453718\n",
      "[Epoch 25/50] [Batch 1/300] [D loss: 0.752494] [G loss: 0.519835] time: 0:37:20.679216\n",
      "0.9774435\n",
      "[Epoch 25/50] [Batch 2/300] [D loss: 0.752490] [G loss: 0.501913] time: 0:37:20.986316\n",
      "0.91735816\n",
      "[Epoch 25/50] [Batch 3/300] [D loss: 0.752495] [G loss: 0.521364] time: 0:37:21.295213\n",
      "0.9212747\n",
      "[Epoch 25/50] [Batch 4/300] [D loss: 0.752500] [G loss: 0.498619] time: 0:37:21.598465\n",
      "0.9576345\n",
      "[Epoch 25/50] [Batch 5/300] [D loss: 0.752503] [G loss: 0.509934] time: 0:37:21.902037\n",
      "0.9461178\n",
      "[Epoch 25/50] [Batch 6/300] [D loss: 0.752496] [G loss: 0.518793] time: 0:37:22.194358\n",
      "0.95659107\n",
      "[Epoch 25/50] [Batch 7/300] [D loss: 0.752490] [G loss: 0.541048] time: 0:37:22.494881\n",
      "0.9709005\n",
      "[Epoch 25/50] [Batch 8/300] [D loss: 0.752501] [G loss: 0.547484] time: 0:37:22.807030\n",
      "0.9430478\n",
      "[Epoch 25/50] [Batch 9/300] [D loss: 0.752495] [G loss: 0.493902] time: 0:37:23.111472\n",
      "0.9347656\n",
      "[Epoch 25/50] [Batch 10/300] [D loss: 0.752508] [G loss: 0.519337] time: 0:37:23.422724\n",
      "0.9421541\n",
      "[Epoch 25/50] [Batch 11/300] [D loss: 0.752494] [G loss: 0.554817] time: 0:37:23.715556\n",
      "0.94600326\n",
      "[Epoch 25/50] [Batch 12/300] [D loss: 0.752516] [G loss: 0.515622] time: 0:37:24.014707\n",
      "0.917856\n",
      "[Epoch 25/50] [Batch 13/300] [D loss: 0.752501] [G loss: 0.514330] time: 0:37:24.323109\n",
      "0.8998777\n",
      "[Epoch 25/50] [Batch 14/300] [D loss: 0.752493] [G loss: 0.528951] time: 0:37:24.620721\n",
      "0.9595332\n",
      "[Epoch 25/50] [Batch 15/300] [D loss: 0.752508] [G loss: 0.532538] time: 0:37:24.946779\n",
      "0.90500194\n",
      "[Epoch 25/50] [Batch 16/300] [D loss: 0.752477] [G loss: 0.512313] time: 0:37:25.219508\n",
      "0.89869446\n",
      "[Epoch 25/50] [Batch 17/300] [D loss: 0.752498] [G loss: 0.502233] time: 0:37:25.512213\n",
      "0.9118708\n",
      "[Epoch 25/50] [Batch 18/300] [D loss: 0.752498] [G loss: 0.564640] time: 0:37:25.800066\n",
      "0.92590094\n",
      "[Epoch 25/50] [Batch 19/300] [D loss: 0.752492] [G loss: 0.507402] time: 0:37:26.090229\n",
      "0.913874\n",
      "[Epoch 25/50] [Batch 20/300] [D loss: 0.752483] [G loss: 0.513033] time: 0:37:26.383923\n",
      "0.93260646\n",
      "[Epoch 25/50] [Batch 21/300] [D loss: 0.752513] [G loss: 0.507008] time: 0:37:26.664425\n",
      "0.9470232\n",
      "[Epoch 25/50] [Batch 22/300] [D loss: 0.752497] [G loss: 0.498354] time: 0:37:26.959734\n",
      "0.92047375\n",
      "[Epoch 25/50] [Batch 23/300] [D loss: 0.752489] [G loss: 0.509691] time: 0:37:27.240332\n",
      "0.9397916\n",
      "[Epoch 25/50] [Batch 25/300] [D loss: 0.752489] [G loss: 0.512219] time: 0:37:27.538828\n",
      "0.96858263\n",
      "[Epoch 25/50] [Batch 26/300] [D loss: 0.752475] [G loss: 0.490575] time: 0:37:27.831321\n",
      "0.91179043\n",
      "[Epoch 25/50] [Batch 27/300] [D loss: 0.752503] [G loss: 0.512504] time: 0:37:28.116877\n",
      "0.9306523\n",
      "[Epoch 25/50] [Batch 28/300] [D loss: 0.752494] [G loss: 0.532289] time: 0:37:28.414084\n",
      "0.9714145\n",
      "[Epoch 25/50] [Batch 29/300] [D loss: 0.752508] [G loss: 0.507305] time: 0:37:28.710423\n",
      "0.87966806\n",
      "[Epoch 25/50] [Batch 30/300] [D loss: 0.752505] [G loss: 0.494999] time: 0:37:29.008189\n",
      "0.9535918\n",
      "[Epoch 25/50] [Batch 31/300] [D loss: 0.752500] [G loss: 0.484167] time: 0:37:29.316193\n",
      "0.91664845\n",
      "[Epoch 25/50] [Batch 32/300] [D loss: 0.752488] [G loss: 0.497144] time: 0:37:29.611418\n",
      "0.93359333\n",
      "[Epoch 25/50] [Batch 33/300] [D loss: 0.752500] [G loss: 0.504047] time: 0:37:29.885258\n",
      "0.93075776\n",
      "[Epoch 25/50] [Batch 34/300] [D loss: 0.752502] [G loss: 0.512933] time: 0:37:30.174133\n",
      "0.9480121\n",
      "[Epoch 25/50] [Batch 35/300] [D loss: 0.752513] [G loss: 0.500654] time: 0:37:30.458060\n",
      "0.9409602\n",
      "[Epoch 25/50] [Batch 36/300] [D loss: 0.752496] [G loss: 0.498114] time: 0:37:30.760085\n",
      "0.95949847\n",
      "[Epoch 25/50] [Batch 37/300] [D loss: 0.752515] [G loss: 0.510027] time: 0:37:31.039397\n",
      "0.9058475\n",
      "[Epoch 25/50] [Batch 38/300] [D loss: 0.752508] [G loss: 0.529132] time: 0:37:31.333934\n",
      "0.92923975\n",
      "[Epoch 25/50] [Batch 39/300] [D loss: 0.752492] [G loss: 0.492551] time: 0:37:31.641999\n",
      "0.9169846\n",
      "[Epoch 25/50] [Batch 40/300] [D loss: 0.752510] [G loss: 0.539221] time: 0:37:31.940926\n",
      "0.91342443\n",
      "[Epoch 25/50] [Batch 41/300] [D loss: 0.752495] [G loss: 0.508991] time: 0:37:32.238792\n",
      "0.96660954\n",
      "[Epoch 25/50] [Batch 42/300] [D loss: 0.752502] [G loss: 0.503670] time: 0:37:32.515434\n",
      "0.95911914\n",
      "[Epoch 25/50] [Batch 43/300] [D loss: 0.752486] [G loss: 0.489445] time: 0:37:32.805822\n",
      "0.9064352\n",
      "[Epoch 25/50] [Batch 44/300] [D loss: 0.752499] [G loss: 0.492907] time: 0:37:33.103807\n",
      "0.8997348\n",
      "[Epoch 25/50] [Batch 45/300] [D loss: 0.752496] [G loss: 0.509241] time: 0:37:33.406541\n",
      "0.9375108\n",
      "[Epoch 25/50] [Batch 46/300] [D loss: 0.752498] [G loss: 0.514825] time: 0:37:33.704194\n",
      "0.90718025\n",
      "[Epoch 25/50] [Batch 47/300] [D loss: 0.752493] [G loss: 0.494086] time: 0:37:34.008335\n",
      "0.88917184\n",
      "[Epoch 25/50] [Batch 48/300] [D loss: 0.752506] [G loss: 0.500747] time: 0:37:34.310772\n",
      "0.9390719\n",
      "[Epoch 25/50] [Batch 49/300] [D loss: 0.752506] [G loss: 0.535533] time: 0:37:34.610788\n",
      "0.8812206\n",
      "[Epoch 25/50] [Batch 50/300] [D loss: 0.752496] [G loss: 0.532607] time: 0:37:34.921147\n",
      "0.9315445\n",
      "[Epoch 25/50] [Batch 51/300] [D loss: 0.752492] [G loss: 0.505757] time: 0:37:35.230282\n",
      "0.87269187\n",
      "[Epoch 25/50] [Batch 52/300] [D loss: 0.752493] [G loss: 0.538420] time: 0:37:35.518015\n",
      "0.9484455\n",
      "[Epoch 25/50] [Batch 53/300] [D loss: 0.752500] [G loss: 0.488232] time: 0:37:35.812049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94323605\n",
      "[Epoch 25/50] [Batch 54/300] [D loss: 0.752508] [G loss: 0.508313] time: 0:37:36.105633\n",
      "0.8951485\n",
      "[Epoch 25/50] [Batch 55/300] [D loss: 0.752493] [G loss: 0.523618] time: 0:37:36.405083\n",
      "0.88913506\n",
      "[Epoch 25/50] [Batch 56/300] [D loss: 0.752478] [G loss: 0.541236] time: 0:37:36.721832\n",
      "0.9172376\n",
      "[Epoch 25/50] [Batch 57/300] [D loss: 0.752501] [G loss: 0.544635] time: 0:37:37.023611\n",
      "0.93472964\n",
      "[Epoch 25/50] [Batch 58/300] [D loss: 0.752491] [G loss: 0.537458] time: 0:37:37.325675\n",
      "0.929584\n",
      "[Epoch 25/50] [Batch 59/300] [D loss: 0.752494] [G loss: 0.500158] time: 0:37:37.652280\n",
      "0.9290511\n",
      "[Epoch 25/50] [Batch 60/300] [D loss: 0.752486] [G loss: 0.495492] time: 0:37:37.952759\n",
      "0.92633176\n",
      "[Epoch 25/50] [Batch 61/300] [D loss: 0.752504] [G loss: 0.516898] time: 0:37:38.239798\n",
      "0.92689663\n",
      "[Epoch 25/50] [Batch 62/300] [D loss: 0.752486] [G loss: 0.497166] time: 0:37:38.543584\n",
      "0.94981265\n",
      "[Epoch 25/50] [Batch 63/300] [D loss: 0.752472] [G loss: 0.507497] time: 0:37:38.845930\n",
      "0.94499236\n",
      "[Epoch 25/50] [Batch 64/300] [D loss: 0.752499] [G loss: 0.514403] time: 0:37:39.142731\n",
      "0.8892874\n",
      "[Epoch 25/50] [Batch 65/300] [D loss: 0.752477] [G loss: 0.501401] time: 0:37:39.445140\n",
      "0.9197692\n",
      "[Epoch 25/50] [Batch 66/300] [D loss: 0.752502] [G loss: 0.501185] time: 0:37:39.748091\n",
      "0.9533461\n",
      "[Epoch 25/50] [Batch 67/300] [D loss: 0.752478] [G loss: 0.503565] time: 0:37:40.048533\n",
      "0.9686912\n",
      "[Epoch 25/50] [Batch 68/300] [D loss: 0.752495] [G loss: 0.489710] time: 0:37:40.357887\n",
      "0.90993756\n",
      "[Epoch 25/50] [Batch 69/300] [D loss: 0.752493] [G loss: 0.488773] time: 0:37:40.661116\n",
      "0.93183255\n",
      "[Epoch 25/50] [Batch 70/300] [D loss: 0.752488] [G loss: 0.482122] time: 0:37:40.954170\n",
      "0.9410451\n",
      "[Epoch 25/50] [Batch 71/300] [D loss: 0.752495] [G loss: 0.519554] time: 0:37:41.251894\n",
      "0.90846056\n",
      "[Epoch 25/50] [Batch 72/300] [D loss: 0.752485] [G loss: 0.519916] time: 0:37:41.541915\n",
      "0.9279224\n",
      "[Epoch 25/50] [Batch 73/300] [D loss: 0.752484] [G loss: 0.501501] time: 0:37:41.838155\n",
      "0.9163139\n",
      "[Epoch 25/50] [Batch 74/300] [D loss: 0.752493] [G loss: 0.530824] time: 0:37:42.138899\n",
      "0.9158723\n",
      "[Epoch 25/50] [Batch 75/300] [D loss: 0.752505] [G loss: 0.507402] time: 0:37:42.437966\n",
      "0.9300723\n",
      "[Epoch 25/50] [Batch 76/300] [D loss: 0.752482] [G loss: 0.501919] time: 0:37:42.746589\n",
      "0.9838243\n",
      "[Epoch 25/50] [Batch 77/300] [D loss: 0.752499] [G loss: 0.495428] time: 0:37:43.048287\n",
      "0.953479\n",
      "[Epoch 25/50] [Batch 78/300] [D loss: 0.752506] [G loss: 0.523275] time: 0:37:43.348287\n",
      "0.900255\n",
      "[Epoch 25/50] [Batch 79/300] [D loss: 0.752509] [G loss: 0.492177] time: 0:37:43.644578\n",
      "0.94830495\n",
      "[Epoch 25/50] [Batch 80/300] [D loss: 0.752477] [G loss: 0.489426] time: 0:37:43.944099\n",
      "0.94367695\n",
      "[Epoch 25/50] [Batch 81/300] [D loss: 0.752492] [G loss: 0.491837] time: 0:37:44.251803\n",
      "0.9716793\n",
      "[Epoch 25/50] [Batch 82/300] [D loss: 0.752504] [G loss: 0.513044] time: 0:37:44.538381\n",
      "0.9392635\n",
      "[Epoch 25/50] [Batch 83/300] [D loss: 0.752510] [G loss: 0.498528] time: 0:37:44.835816\n",
      "0.8842855\n",
      "[Epoch 25/50] [Batch 84/300] [D loss: 0.752484] [G loss: 0.503227] time: 0:37:45.138525\n",
      "0.91095\n",
      "[Epoch 25/50] [Batch 85/300] [D loss: 0.752506] [G loss: 0.505843] time: 0:37:45.431860\n",
      "0.9155932\n",
      "[Epoch 25/50] [Batch 86/300] [D loss: 0.752488] [G loss: 0.507900] time: 0:37:45.731800\n",
      "0.9354698\n",
      "[Epoch 25/50] [Batch 87/300] [D loss: 0.752489] [G loss: 0.521496] time: 0:37:46.028379\n",
      "0.9346733\n",
      "[Epoch 25/50] [Batch 88/300] [D loss: 0.752483] [G loss: 0.487591] time: 0:37:46.299955\n",
      "0.94338375\n",
      "[Epoch 25/50] [Batch 89/300] [D loss: 0.752511] [G loss: 0.522051] time: 0:37:46.603111\n",
      "0.91668624\n",
      "[Epoch 25/50] [Batch 90/300] [D loss: 0.752487] [G loss: 0.493002] time: 0:37:46.907538\n",
      "0.9247434\n",
      "[Epoch 25/50] [Batch 91/300] [D loss: 0.752487] [G loss: 0.495941] time: 0:37:47.210540\n",
      "0.9028565\n",
      "[Epoch 25/50] [Batch 92/300] [D loss: 0.752487] [G loss: 0.502315] time: 0:37:47.514787\n",
      "0.91229826\n",
      "[Epoch 25/50] [Batch 93/300] [D loss: 0.752496] [G loss: 0.497675] time: 0:37:47.812543\n",
      "0.9089977\n",
      "[Epoch 25/50] [Batch 94/300] [D loss: 0.752492] [G loss: 0.550618] time: 0:37:48.112814\n",
      "0.9228491\n",
      "[Epoch 25/50] [Batch 95/300] [D loss: 0.752502] [G loss: 0.497619] time: 0:37:48.419451\n",
      "0.9044488\n",
      "[Epoch 25/50] [Batch 96/300] [D loss: 0.752484] [G loss: 0.490669] time: 0:37:48.729408\n",
      "0.9137571\n",
      "[Epoch 25/50] [Batch 97/300] [D loss: 0.752508] [G loss: 0.497127] time: 0:37:49.051961\n",
      "0.9234298\n",
      "[Epoch 25/50] [Batch 98/300] [D loss: 0.752510] [G loss: 0.486255] time: 0:37:49.337810\n",
      "0.8744025\n",
      "[Epoch 25/50] [Batch 99/300] [D loss: 0.752498] [G loss: 0.491344] time: 0:37:49.631672\n",
      "0.89035565\n",
      "[Epoch 25/50] [Batch 100/300] [D loss: 0.752489] [G loss: 0.501778] time: 0:37:49.926959\n",
      "0.9040043\n",
      "[Epoch 25/50] [Batch 101/300] [D loss: 0.752487] [G loss: 0.499113] time: 0:37:50.239212\n",
      "0.9459284\n",
      "[Epoch 25/50] [Batch 102/300] [D loss: 0.752507] [G loss: 0.517060] time: 0:37:50.540727\n",
      "0.9360636\n",
      "[Epoch 25/50] [Batch 103/300] [D loss: 0.752482] [G loss: 0.517561] time: 0:37:50.828842\n",
      "0.9384666\n",
      "[Epoch 25/50] [Batch 104/300] [D loss: 0.752521] [G loss: 0.520388] time: 0:37:51.100921\n",
      "0.94010526\n",
      "[Epoch 25/50] [Batch 105/300] [D loss: 0.752487] [G loss: 0.500487] time: 0:37:51.380662\n",
      "0.9211095\n",
      "[Epoch 25/50] [Batch 106/300] [D loss: 0.752469] [G loss: 0.503994] time: 0:37:51.689087\n",
      "0.9002425\n",
      "[Epoch 25/50] [Batch 107/300] [D loss: 0.752479] [G loss: 0.513553] time: 0:37:51.983509\n",
      "0.89525896\n",
      "[Epoch 25/50] [Batch 108/300] [D loss: 0.752513] [G loss: 0.513777] time: 0:37:52.264348\n",
      "0.95888615\n",
      "[Epoch 25/50] [Batch 109/300] [D loss: 0.752485] [G loss: 0.517849] time: 0:37:52.564042\n",
      "0.8926737\n",
      "[Epoch 25/50] [Batch 110/300] [D loss: 0.752500] [G loss: 0.513209] time: 0:37:52.856107\n",
      "0.9059484\n",
      "[Epoch 25/50] [Batch 111/300] [D loss: 0.752491] [G loss: 0.490917] time: 0:37:53.161130\n",
      "0.9247568\n",
      "[Epoch 25/50] [Batch 112/300] [D loss: 0.752483] [G loss: 0.501741] time: 0:37:53.464905\n",
      "0.9601471\n",
      "[Epoch 25/50] [Batch 113/300] [D loss: 0.752491] [G loss: 0.488431] time: 0:37:53.764006\n",
      "0.92228556\n",
      "[Epoch 25/50] [Batch 114/300] [D loss: 0.752495] [G loss: 0.496612] time: 0:37:54.076743\n",
      "0.9218218\n",
      "[Epoch 25/50] [Batch 115/300] [D loss: 0.752489] [G loss: 0.494827] time: 0:37:54.375730\n",
      "0.92878073\n",
      "[Epoch 25/50] [Batch 116/300] [D loss: 0.752491] [G loss: 0.490483] time: 0:37:54.660286\n",
      "0.9010632\n",
      "[Epoch 25/50] [Batch 117/300] [D loss: 0.752467] [G loss: 0.490606] time: 0:37:54.951423\n",
      "0.90219307\n",
      "[Epoch 25/50] [Batch 118/300] [D loss: 0.752493] [G loss: 0.490097] time: 0:37:55.251517\n",
      "0.9818792\n",
      "[Epoch 25/50] [Batch 119/300] [D loss: 0.752475] [G loss: 0.503202] time: 0:37:55.543018\n",
      "0.9144437\n",
      "[Epoch 25/50] [Batch 120/300] [D loss: 0.752501] [G loss: 0.485850] time: 0:37:55.832276\n",
      "0.9158888\n",
      "[Epoch 25/50] [Batch 121/300] [D loss: 0.752471] [G loss: 0.515052] time: 0:37:56.149862\n",
      "0.9453747\n",
      "[Epoch 25/50] [Batch 122/300] [D loss: 0.752495] [G loss: 0.490045] time: 0:37:56.447490\n",
      "0.9587901\n",
      "[Epoch 25/50] [Batch 123/300] [D loss: 0.752501] [G loss: 0.513248] time: 0:37:56.739585\n",
      "0.93553203\n",
      "[Epoch 25/50] [Batch 124/300] [D loss: 0.752476] [G loss: 0.491786] time: 0:37:57.032457\n",
      "0.91616577\n",
      "[Epoch 25/50] [Batch 125/300] [D loss: 0.752471] [G loss: 0.486691] time: 0:37:57.347559\n",
      "0.93944556\n",
      "[Epoch 25/50] [Batch 126/300] [D loss: 0.752513] [G loss: 0.498545] time: 0:37:57.657005\n",
      "0.90466124\n",
      "[Epoch 25/50] [Batch 127/300] [D loss: 0.752479] [G loss: 0.505138] time: 0:37:57.959154\n",
      "0.909805\n",
      "[Epoch 25/50] [Batch 128/300] [D loss: 0.752490] [G loss: 0.573341] time: 0:37:58.263106\n",
      "0.934664\n",
      "[Epoch 25/50] [Batch 129/300] [D loss: 0.752474] [G loss: 0.511402] time: 0:37:58.569367\n",
      "0.94678384\n",
      "[Epoch 25/50] [Batch 130/300] [D loss: 0.752488] [G loss: 0.487177] time: 0:37:58.880452\n",
      "0.9465341\n",
      "[Epoch 25/50] [Batch 131/300] [D loss: 0.752504] [G loss: 0.523931] time: 0:37:59.188137\n",
      "0.94641095\n",
      "[Epoch 25/50] [Batch 132/300] [D loss: 0.752499] [G loss: 0.528939] time: 0:37:59.488669\n",
      "0.90539575\n",
      "[Epoch 25/50] [Batch 133/300] [D loss: 0.752473] [G loss: 0.561801] time: 0:37:59.800765\n",
      "0.94506234\n",
      "[Epoch 25/50] [Batch 134/300] [D loss: 0.752482] [G loss: 0.516770] time: 0:38:00.095353\n",
      "0.92056507\n",
      "[Epoch 25/50] [Batch 135/300] [D loss: 0.752491] [G loss: 0.515788] time: 0:38:00.389403\n",
      "0.93526125\n",
      "[Epoch 25/50] [Batch 136/300] [D loss: 0.752519] [G loss: 0.513004] time: 0:38:00.697585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926826\n",
      "[Epoch 25/50] [Batch 137/300] [D loss: 0.752490] [G loss: 0.500884] time: 0:38:00.992594\n",
      "0.89232445\n",
      "[Epoch 25/50] [Batch 138/300] [D loss: 0.752500] [G loss: 0.494990] time: 0:38:01.273914\n",
      "0.88395756\n",
      "[Epoch 25/50] [Batch 139/300] [D loss: 0.752490] [G loss: 0.496375] time: 0:38:01.578130\n",
      "0.9152536\n",
      "[Epoch 25/50] [Batch 140/300] [D loss: 0.752483] [G loss: 0.556265] time: 0:38:01.871473\n",
      "0.9276883\n",
      "[Epoch 25/50] [Batch 141/300] [D loss: 0.752523] [G loss: 0.507769] time: 0:38:02.169992\n",
      "0.914489\n",
      "[Epoch 25/50] [Batch 142/300] [D loss: 0.752486] [G loss: 0.502685] time: 0:38:02.451548\n",
      "0.89520246\n",
      "[Epoch 25/50] [Batch 143/300] [D loss: 0.752484] [G loss: 0.511703] time: 0:38:02.751993\n",
      "0.9446036\n",
      "[Epoch 25/50] [Batch 144/300] [D loss: 0.752494] [G loss: 0.493901] time: 0:38:03.049613\n",
      "0.907032\n",
      "[Epoch 25/50] [Batch 145/300] [D loss: 0.752486] [G loss: 0.544393] time: 0:38:03.349604\n",
      "0.96536016\n",
      "[Epoch 25/50] [Batch 146/300] [D loss: 0.752512] [G loss: 0.495281] time: 0:38:03.639733\n",
      "0.94297296\n",
      "[Epoch 25/50] [Batch 147/300] [D loss: 0.752506] [G loss: 0.507060] time: 0:38:03.935398\n",
      "0.8719049\n",
      "[Epoch 25/50] [Batch 148/300] [D loss: 0.752486] [G loss: 0.501101] time: 0:38:04.233154\n",
      "0.94965655\n",
      "[Epoch 25/50] [Batch 149/300] [D loss: 0.752499] [G loss: 0.506937] time: 0:38:04.526806\n",
      "0.9097474\n",
      "[Epoch 25/50] [Batch 150/300] [D loss: 0.752460] [G loss: 0.498836] time: 0:38:04.844292\n",
      "0.86928463\n",
      "[Epoch 25/50] [Batch 151/300] [D loss: 0.752469] [G loss: 0.485354] time: 0:38:05.131316\n",
      "0.9683767\n",
      "[Epoch 25/50] [Batch 152/300] [D loss: 0.752509] [G loss: 0.497306] time: 0:38:05.444006\n",
      "0.8942132\n",
      "[Epoch 25/50] [Batch 153/300] [D loss: 0.752472] [G loss: 0.498467] time: 0:38:05.744583\n",
      "0.9066538\n",
      "[Epoch 25/50] [Batch 154/300] [D loss: 0.752503] [G loss: 0.506060] time: 0:38:06.046077\n",
      "0.88924056\n",
      "[Epoch 25/50] [Batch 155/300] [D loss: 0.752499] [G loss: 0.502834] time: 0:38:06.345686\n",
      "0.9379441\n",
      "[Epoch 25/50] [Batch 156/300] [D loss: 0.752490] [G loss: 0.524652] time: 0:38:06.647591\n",
      "0.9470381\n",
      "[Epoch 25/50] [Batch 157/300] [D loss: 0.752489] [G loss: 0.488293] time: 0:38:06.949253\n",
      "0.93199855\n",
      "[Epoch 25/50] [Batch 158/300] [D loss: 0.752493] [G loss: 0.519345] time: 0:38:07.234515\n",
      "0.88442665\n",
      "[Epoch 25/50] [Batch 159/300] [D loss: 0.752486] [G loss: 0.490055] time: 0:38:07.527984\n",
      "0.89537007\n",
      "[Epoch 25/50] [Batch 160/300] [D loss: 0.752480] [G loss: 0.498123] time: 0:38:07.832740\n",
      "0.9005468\n",
      "[Epoch 25/50] [Batch 161/300] [D loss: 0.752489] [G loss: 0.502801] time: 0:38:08.133210\n",
      "0.93079144\n",
      "[Epoch 25/50] [Batch 162/300] [D loss: 0.752500] [G loss: 0.498553] time: 0:38:08.425018\n",
      "0.95891935\n",
      "[Epoch 25/50] [Batch 163/300] [D loss: 0.752483] [G loss: 0.491124] time: 0:38:08.741616\n",
      "0.9028225\n",
      "[Epoch 25/50] [Batch 164/300] [D loss: 0.752467] [G loss: 0.488855] time: 0:38:09.042372\n",
      "0.94600064\n",
      "[Epoch 25/50] [Batch 165/300] [D loss: 0.752473] [G loss: 0.503541] time: 0:38:09.338071\n",
      "0.92289513\n",
      "[Epoch 25/50] [Batch 166/300] [D loss: 0.752486] [G loss: 0.504258] time: 0:38:09.636579\n",
      "0.9693983\n",
      "[Epoch 25/50] [Batch 167/300] [D loss: 0.752483] [G loss: 0.487125] time: 0:38:09.941921\n",
      "0.9304308\n",
      "[Epoch 25/50] [Batch 168/300] [D loss: 0.752482] [G loss: 0.525123] time: 0:38:10.233869\n",
      "0.9326296\n",
      "[Epoch 25/50] [Batch 169/300] [D loss: 0.752489] [G loss: 0.512049] time: 0:38:10.549735\n",
      "0.9422447\n",
      "[Epoch 25/50] [Batch 170/300] [D loss: 0.752502] [G loss: 0.505352] time: 0:38:10.846515\n",
      "0.8769038\n",
      "[Epoch 25/50] [Batch 171/300] [D loss: 0.752457] [G loss: 0.509074] time: 0:38:11.152284\n",
      "0.96106845\n",
      "[Epoch 25/50] [Batch 172/300] [D loss: 0.752499] [G loss: 0.508918] time: 0:38:11.442707\n",
      "0.9314887\n",
      "[Epoch 25/50] [Batch 173/300] [D loss: 0.752470] [G loss: 0.514603] time: 0:38:11.733408\n",
      "0.87077165\n",
      "[Epoch 25/50] [Batch 174/300] [D loss: 0.752476] [G loss: 0.497725] time: 0:38:12.022370\n",
      "0.91399956\n",
      "[Epoch 25/50] [Batch 175/300] [D loss: 0.752496] [G loss: 0.502453] time: 0:38:12.323130\n",
      "0.95519763\n",
      "[Epoch 25/50] [Batch 176/300] [D loss: 0.752475] [G loss: 0.521110] time: 0:38:12.631223\n",
      "0.9063429\n",
      "[Epoch 25/50] [Batch 177/300] [D loss: 0.752502] [G loss: 0.517750] time: 0:38:12.926988\n",
      "0.91388345\n",
      "[Epoch 25/50] [Batch 178/300] [D loss: 0.752482] [G loss: 0.491869] time: 0:38:13.222531\n",
      "0.90564823\n",
      "[Epoch 25/50] [Batch 179/300] [D loss: 0.752487] [G loss: 0.505964] time: 0:38:13.509427\n",
      "0.9036193\n",
      "[Epoch 25/50] [Batch 180/300] [D loss: 0.752494] [G loss: 0.515428] time: 0:38:13.804850\n",
      "0.8941021\n",
      "[Epoch 25/50] [Batch 181/300] [D loss: 0.752504] [G loss: 0.500112] time: 0:38:14.109637\n",
      "0.8677861\n",
      "[Epoch 25/50] [Batch 182/300] [D loss: 0.752493] [G loss: 0.496443] time: 0:38:14.421281\n",
      "0.92505854\n",
      "[Epoch 25/50] [Batch 183/300] [D loss: 0.752481] [G loss: 0.496496] time: 0:38:14.711312\n",
      "0.94599795\n",
      "[Epoch 25/50] [Batch 184/300] [D loss: 0.752481] [G loss: 0.532869] time: 0:38:14.987972\n",
      "0.91202736\n",
      "[Epoch 25/50] [Batch 185/300] [D loss: 0.752481] [G loss: 0.502217] time: 0:38:15.289179\n",
      "0.9434218\n",
      "[Epoch 25/50] [Batch 186/300] [D loss: 0.752456] [G loss: 0.486991] time: 0:38:15.592271\n",
      "0.8891079\n",
      "[Epoch 25/50] [Batch 187/300] [D loss: 0.752486] [G loss: 0.494642] time: 0:38:15.893618\n",
      "0.94938254\n",
      "[Epoch 25/50] [Batch 188/300] [D loss: 0.752475] [G loss: 0.495148] time: 0:38:16.200806\n",
      "0.9029054\n",
      "[Epoch 25/50] [Batch 189/300] [D loss: 0.752481] [G loss: 0.491435] time: 0:38:16.516730\n",
      "0.91137177\n",
      "[Epoch 25/50] [Batch 190/300] [D loss: 0.752482] [G loss: 0.489504] time: 0:38:16.811425\n",
      "0.9106268\n",
      "[Epoch 25/50] [Batch 191/300] [D loss: 0.752494] [G loss: 0.515718] time: 0:38:17.105158\n",
      "0.90501934\n",
      "[Epoch 25/50] [Batch 192/300] [D loss: 0.752501] [G loss: 0.488892] time: 0:38:17.408257\n",
      "0.90839845\n",
      "[Epoch 25/50] [Batch 193/300] [D loss: 0.752492] [G loss: 0.495204] time: 0:38:17.711267\n",
      "0.9564841\n",
      "[Epoch 25/50] [Batch 194/300] [D loss: 0.752482] [G loss: 0.488320] time: 0:38:18.013568\n",
      "0.93051726\n",
      "[Epoch 25/50] [Batch 195/300] [D loss: 0.752485] [G loss: 0.535472] time: 0:38:18.306973\n",
      "0.93069714\n",
      "[Epoch 25/50] [Batch 196/300] [D loss: 0.752474] [G loss: 0.501293] time: 0:38:18.614676\n",
      "0.9067342\n",
      "[Epoch 25/50] [Batch 197/300] [D loss: 0.752505] [G loss: 0.501661] time: 0:38:18.919476\n",
      "0.9242504\n",
      "[Epoch 25/50] [Batch 198/300] [D loss: 0.752492] [G loss: 0.497203] time: 0:38:19.219189\n",
      "0.9336014\n",
      "[Epoch 25/50] [Batch 199/300] [D loss: 0.752471] [G loss: 0.530034] time: 0:38:19.511517\n",
      "0.95924354\n",
      "[Epoch 25/50] [Batch 200/300] [D loss: 0.752516] [G loss: 0.524014] time: 0:38:19.817149\n",
      "0.92902786\n",
      "[Epoch 25/50] [Batch 201/300] [D loss: 0.752463] [G loss: 0.501331] time: 0:38:20.110394\n",
      "0.94786143\n",
      "[Epoch 25/50] [Batch 202/300] [D loss: 0.752481] [G loss: 0.503617] time: 0:38:20.410248\n",
      "0.9397132\n",
      "[Epoch 25/50] [Batch 203/300] [D loss: 0.752497] [G loss: 0.490089] time: 0:38:20.714534\n",
      "0.87007314\n",
      "[Epoch 25/50] [Batch 204/300] [D loss: 0.752474] [G loss: 0.498911] time: 0:38:21.002172\n",
      "0.9588081\n",
      "[Epoch 25/50] [Batch 205/300] [D loss: 0.752475] [G loss: 0.522585] time: 0:38:21.299284\n",
      "0.97575045\n",
      "[Epoch 25/50] [Batch 206/300] [D loss: 0.752501] [G loss: 0.513057] time: 0:38:21.599699\n",
      "0.9602931\n",
      "[Epoch 25/50] [Batch 207/300] [D loss: 0.752482] [G loss: 0.509584] time: 0:38:21.896081\n",
      "0.91494083\n",
      "[Epoch 25/50] [Batch 208/300] [D loss: 0.752481] [G loss: 0.517679] time: 0:38:22.194297\n",
      "0.94507295\n",
      "[Epoch 25/50] [Batch 209/300] [D loss: 0.752468] [G loss: 0.497271] time: 0:38:22.490604\n",
      "0.9469692\n",
      "[Epoch 25/50] [Batch 210/300] [D loss: 0.752484] [G loss: 0.500651] time: 0:38:22.796110\n",
      "0.959827\n",
      "[Epoch 25/50] [Batch 211/300] [D loss: 0.752490] [G loss: 0.491078] time: 0:38:23.086002\n",
      "0.9461303\n",
      "[Epoch 25/50] [Batch 212/300] [D loss: 0.752495] [G loss: 0.491679] time: 0:38:23.391406\n",
      "0.9237132\n",
      "[Epoch 25/50] [Batch 213/300] [D loss: 0.752491] [G loss: 0.492448] time: 0:38:23.655354\n",
      "0.8946273\n",
      "[Epoch 25/50] [Batch 214/300] [D loss: 0.752483] [G loss: 0.527058] time: 0:38:23.945570\n",
      "0.9055789\n",
      "[Epoch 25/50] [Batch 215/300] [D loss: 0.752489] [G loss: 0.527613] time: 0:38:24.254752\n",
      "0.9414544\n",
      "[Epoch 25/50] [Batch 216/300] [D loss: 0.752508] [G loss: 0.511982] time: 0:38:24.555799\n",
      "0.9024772\n",
      "[Epoch 25/50] [Batch 217/300] [D loss: 0.752455] [G loss: 0.503325] time: 0:38:24.850191\n",
      "0.9748995\n",
      "[Epoch 25/50] [Batch 218/300] [D loss: 0.752491] [G loss: 0.529533] time: 0:38:25.146965\n",
      "0.9060038\n",
      "[Epoch 25/50] [Batch 219/300] [D loss: 0.752466] [G loss: 0.495419] time: 0:38:25.445902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9290671\n",
      "[Epoch 25/50] [Batch 220/300] [D loss: 0.752476] [G loss: 0.506061] time: 0:38:25.743806\n",
      "0.9006842\n",
      "[Epoch 25/50] [Batch 221/300] [D loss: 0.752489] [G loss: 0.516908] time: 0:38:26.029587\n",
      "0.88898784\n",
      "[Epoch 25/50] [Batch 222/300] [D loss: 0.752469] [G loss: 0.497991] time: 0:38:26.314099\n",
      "0.9266403\n",
      "[Epoch 25/50] [Batch 223/300] [D loss: 0.752484] [G loss: 0.513171] time: 0:38:26.611871\n",
      "0.9600834\n",
      "[Epoch 25/50] [Batch 224/300] [D loss: 0.752487] [G loss: 0.497245] time: 0:38:26.916143\n",
      "0.87477833\n",
      "[Epoch 25/50] [Batch 225/300] [D loss: 0.752489] [G loss: 0.515383] time: 0:38:27.217267\n",
      "0.9157098\n",
      "[Epoch 25/50] [Batch 226/300] [D loss: 0.752481] [G loss: 0.513520] time: 0:38:27.534020\n",
      "0.97102356\n",
      "[Epoch 25/50] [Batch 227/300] [D loss: 0.752483] [G loss: 0.486550] time: 0:38:27.834917\n",
      "0.89541835\n",
      "[Epoch 25/50] [Batch 228/300] [D loss: 0.752486] [G loss: 0.497085] time: 0:38:28.132114\n",
      "0.9164896\n",
      "[Epoch 25/50] [Batch 229/300] [D loss: 0.752507] [G loss: 0.499001] time: 0:38:28.431855\n",
      "0.880912\n",
      "[Epoch 25/50] [Batch 230/300] [D loss: 0.752514] [G loss: 0.496208] time: 0:38:28.734077\n",
      "0.89188856\n",
      "[Epoch 25/50] [Batch 231/300] [D loss: 0.752467] [G loss: 0.516042] time: 0:38:29.026570\n",
      "0.9385154\n",
      "[Epoch 25/50] [Batch 232/300] [D loss: 0.752498] [G loss: 0.490648] time: 0:38:29.317626\n",
      "0.9375163\n",
      "[Epoch 25/50] [Batch 233/300] [D loss: 0.752488] [G loss: 0.491712] time: 0:38:29.606873\n",
      "0.9113615\n",
      "[Epoch 25/50] [Batch 234/300] [D loss: 0.752471] [G loss: 0.494512] time: 0:38:29.886545\n",
      "0.93197346\n",
      "[Epoch 25/50] [Batch 235/300] [D loss: 0.752467] [G loss: 0.521723] time: 0:38:30.171572\n",
      "0.9525735\n",
      "[Epoch 25/50] [Batch 236/300] [D loss: 0.752494] [G loss: 0.533962] time: 0:38:30.453822\n",
      "0.9139045\n",
      "[Epoch 25/50] [Batch 237/300] [D loss: 0.752495] [G loss: 0.502232] time: 0:38:30.742204\n",
      "0.9450881\n",
      "[Epoch 25/50] [Batch 238/300] [D loss: 0.752490] [G loss: 0.506049] time: 0:38:31.014253\n",
      "0.96449596\n",
      "[Epoch 25/50] [Batch 239/300] [D loss: 0.752491] [G loss: 0.501567] time: 0:38:31.308269\n",
      "0.9349043\n",
      "[Epoch 25/50] [Batch 240/300] [D loss: 0.752488] [G loss: 0.505313] time: 0:38:31.610024\n",
      "0.917998\n",
      "[Epoch 25/50] [Batch 241/300] [D loss: 0.752489] [G loss: 0.540449] time: 0:38:31.887941\n",
      "0.9254134\n",
      "[Epoch 25/50] [Batch 242/300] [D loss: 0.752462] [G loss: 0.488484] time: 0:38:32.185627\n",
      "0.95301527\n",
      "[Epoch 25/50] [Batch 243/300] [D loss: 0.752473] [G loss: 0.528565] time: 0:38:32.488337\n",
      "0.9316351\n",
      "[Epoch 25/50] [Batch 244/300] [D loss: 0.752509] [G loss: 0.513663] time: 0:38:32.789024\n",
      "0.87668246\n",
      "[Epoch 25/50] [Batch 245/300] [D loss: 0.752492] [G loss: 0.496182] time: 0:38:33.065810\n",
      "0.9161089\n",
      "[Epoch 25/50] [Batch 246/300] [D loss: 0.752470] [G loss: 0.566783] time: 0:38:33.375725\n",
      "0.9303612\n",
      "[Epoch 25/50] [Batch 247/300] [D loss: 0.752463] [G loss: 0.511786] time: 0:38:33.674249\n",
      "0.93111515\n",
      "[Epoch 25/50] [Batch 248/300] [D loss: 0.752475] [G loss: 0.489606] time: 0:38:33.980766\n",
      "0.90893865\n",
      "[Epoch 25/50] [Batch 249/300] [D loss: 0.752493] [G loss: 0.509539] time: 0:38:34.289357\n",
      "0.93278533\n",
      "[Epoch 25/50] [Batch 250/300] [D loss: 0.752475] [G loss: 0.543283] time: 0:38:34.588094\n",
      "0.9421887\n",
      "[Epoch 25/50] [Batch 251/300] [D loss: 0.752487] [G loss: 0.502832] time: 0:38:34.862380\n",
      "0.9501863\n",
      "[Epoch 25/50] [Batch 252/300] [D loss: 0.752465] [G loss: 0.488852] time: 0:38:35.144739\n",
      "0.9120035\n",
      "[Epoch 25/50] [Batch 253/300] [D loss: 0.752469] [G loss: 0.505568] time: 0:38:35.444514\n",
      "0.9334948\n",
      "[Epoch 25/50] [Batch 254/300] [D loss: 0.752507] [G loss: 0.505835] time: 0:38:35.748452\n",
      "0.9392876\n",
      "[Epoch 25/50] [Batch 255/300] [D loss: 0.752480] [G loss: 0.491916] time: 0:38:36.055325\n",
      "0.9449609\n",
      "[Epoch 25/50] [Batch 256/300] [D loss: 0.752475] [G loss: 0.510050] time: 0:38:36.348863\n",
      "0.9381955\n",
      "[Epoch 25/50] [Batch 257/300] [D loss: 0.752479] [G loss: 0.523993] time: 0:38:36.649630\n",
      "0.9139679\n",
      "[Epoch 25/50] [Batch 258/300] [D loss: 0.752476] [G loss: 0.509409] time: 0:38:36.923557\n",
      "0.92148143\n",
      "[Epoch 25/50] [Batch 259/300] [D loss: 0.752469] [G loss: 0.506841] time: 0:38:37.228603\n",
      "0.8784111\n",
      "[Epoch 25/50] [Batch 260/300] [D loss: 0.752492] [G loss: 0.524756] time: 0:38:37.529368\n",
      "0.9215811\n",
      "[Epoch 25/50] [Batch 261/300] [D loss: 0.752485] [G loss: 0.511096] time: 0:38:37.834749\n",
      "0.9084916\n",
      "[Epoch 25/50] [Batch 262/300] [D loss: 0.752469] [G loss: 0.531461] time: 0:38:38.135734\n",
      "0.9384146\n",
      "[Epoch 25/50] [Batch 263/300] [D loss: 0.752495] [G loss: 0.517447] time: 0:38:38.430092\n",
      "0.90591\n",
      "[Epoch 25/50] [Batch 264/300] [D loss: 0.752472] [G loss: 0.507238] time: 0:38:38.746155\n",
      "0.9158881\n",
      "[Epoch 25/50] [Batch 265/300] [D loss: 0.752478] [G loss: 0.506857] time: 0:38:39.030637\n",
      "0.8916204\n",
      "[Epoch 25/50] [Batch 266/300] [D loss: 0.752462] [G loss: 0.501518] time: 0:38:39.351538\n",
      "0.8997608\n",
      "[Epoch 25/50] [Batch 267/300] [D loss: 0.752488] [G loss: 0.518849] time: 0:38:39.643267\n",
      "0.9178293\n",
      "[Epoch 25/50] [Batch 268/300] [D loss: 0.752502] [G loss: 0.510211] time: 0:38:39.929291\n",
      "0.9081061\n",
      "[Epoch 25/50] [Batch 269/300] [D loss: 0.752464] [G loss: 0.494054] time: 0:38:40.225446\n",
      "0.91293067\n",
      "[Epoch 25/50] [Batch 270/300] [D loss: 0.752479] [G loss: 0.491863] time: 0:38:40.546154\n",
      "0.9428754\n",
      "[Epoch 25/50] [Batch 271/300] [D loss: 0.752477] [G loss: 0.530273] time: 0:38:40.855725\n",
      "0.931583\n",
      "[Epoch 25/50] [Batch 272/300] [D loss: 0.752491] [G loss: 0.498445] time: 0:38:41.143218\n",
      "0.9004772\n",
      "[Epoch 25/50] [Batch 273/300] [D loss: 0.752467] [G loss: 0.550934] time: 0:38:41.437237\n",
      "0.9259229\n",
      "[Epoch 25/50] [Batch 274/300] [D loss: 0.752477] [G loss: 0.497040] time: 0:38:41.736214\n",
      "0.885344\n",
      "[Epoch 25/50] [Batch 275/300] [D loss: 0.752470] [G loss: 0.510393] time: 0:38:42.060292\n",
      "0.9579852\n",
      "[Epoch 25/50] [Batch 276/300] [D loss: 0.752464] [G loss: 0.514334] time: 0:38:42.338684\n",
      "0.8962272\n",
      "[Epoch 25/50] [Batch 277/300] [D loss: 0.752495] [G loss: 0.497545] time: 0:38:42.630401\n",
      "0.8901803\n",
      "[Epoch 25/50] [Batch 278/300] [D loss: 0.752480] [G loss: 0.517546] time: 0:38:42.913390\n",
      "0.9451676\n",
      "[Epoch 25/50] [Batch 279/300] [D loss: 0.752493] [G loss: 0.518463] time: 0:38:43.217791\n",
      "0.9384809\n",
      "[Epoch 25/50] [Batch 280/300] [D loss: 0.752466] [G loss: 0.557066] time: 0:38:43.523134\n",
      "0.9058415\n",
      "[Epoch 25/50] [Batch 281/300] [D loss: 0.752501] [G loss: 0.504631] time: 0:38:43.834373\n",
      "0.9241257\n",
      "[Epoch 25/50] [Batch 282/300] [D loss: 0.752484] [G loss: 0.533889] time: 0:38:44.131597\n",
      "0.9120479\n",
      "[Epoch 25/50] [Batch 283/300] [D loss: 0.752480] [G loss: 0.502053] time: 0:38:44.426701\n",
      "0.9151551\n",
      "[Epoch 25/50] [Batch 284/300] [D loss: 0.752499] [G loss: 0.512634] time: 0:38:44.716393\n",
      "0.9381921\n",
      "[Epoch 25/50] [Batch 285/300] [D loss: 0.752465] [G loss: 0.503398] time: 0:38:45.019628\n",
      "0.91423374\n",
      "[Epoch 25/50] [Batch 286/300] [D loss: 0.752468] [G loss: 0.490454] time: 0:38:45.319953\n",
      "0.8914854\n",
      "[Epoch 25/50] [Batch 287/300] [D loss: 0.752473] [G loss: 0.497255] time: 0:38:45.631524\n",
      "0.91363\n",
      "[Epoch 25/50] [Batch 288/300] [D loss: 0.752487] [G loss: 0.520577] time: 0:38:45.926880\n",
      "0.88218284\n",
      "[Epoch 25/50] [Batch 289/300] [D loss: 0.752498] [G loss: 0.527074] time: 0:38:46.212717\n",
      "0.91024214\n",
      "[Epoch 25/50] [Batch 290/300] [D loss: 0.752465] [G loss: 0.518260] time: 0:38:46.517316\n",
      "0.9836395\n",
      "[Epoch 25/50] [Batch 291/300] [D loss: 0.752477] [G loss: 0.513377] time: 0:38:46.827918\n",
      "0.9068956\n",
      "[Epoch 25/50] [Batch 292/300] [D loss: 0.752468] [G loss: 0.502336] time: 0:38:47.112555\n",
      "0.94064665\n",
      "[Epoch 25/50] [Batch 293/300] [D loss: 0.752497] [G loss: 0.496817] time: 0:38:47.410723\n",
      "0.9556106\n",
      "[Epoch 25/50] [Batch 294/300] [D loss: 0.752479] [G loss: 0.508636] time: 0:38:47.711992\n",
      "0.8861678\n",
      "[Epoch 25/50] [Batch 295/300] [D loss: 0.752470] [G loss: 0.507092] time: 0:38:48.004694\n",
      "0.93269944\n",
      "[Epoch 25/50] [Batch 296/300] [D loss: 0.752484] [G loss: 0.531077] time: 0:38:48.312670\n",
      "0.88707066\n",
      "[Epoch 25/50] [Batch 297/300] [D loss: 0.752489] [G loss: 0.498245] time: 0:38:48.614940\n",
      "0.9289248\n",
      "[Epoch 25/50] [Batch 298/300] [D loss: 0.752475] [G loss: 0.505685] time: 0:38:48.915989\n",
      "0.87169623\n",
      "[Epoch 25/50] [Batch 299/300] [D loss: 0.752470] [G loss: 0.492516] time: 0:38:49.208892\n",
      "0.95334226\n",
      "[Epoch 26/50] [Batch 0/300] [D loss: 0.752481] [G loss: 0.538792] time: 0:38:49.503783\n",
      "0.9435994\n",
      "[Epoch 26/50] [Batch 1/300] [D loss: 0.752502] [G loss: 0.501112] time: 0:38:49.808711\n",
      "0.9479239\n",
      "[Epoch 26/50] [Batch 2/300] [D loss: 0.752475] [G loss: 0.536493] time: 0:38:50.100063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91467214\n",
      "[Epoch 26/50] [Batch 3/300] [D loss: 0.752477] [G loss: 0.502238] time: 0:38:50.401563\n",
      "0.9225762\n",
      "[Epoch 26/50] [Batch 4/300] [D loss: 0.752457] [G loss: 0.500434] time: 0:38:50.718628\n",
      "0.9534982\n",
      "[Epoch 26/50] [Batch 5/300] [D loss: 0.752466] [G loss: 0.525322] time: 0:38:51.010715\n",
      "0.9453947\n",
      "[Epoch 26/50] [Batch 6/300] [D loss: 0.752463] [G loss: 0.493671] time: 0:38:51.294283\n",
      "0.9216416\n",
      "[Epoch 26/50] [Batch 7/300] [D loss: 0.752478] [G loss: 0.484823] time: 0:38:51.600564\n",
      "0.97091895\n",
      "[Epoch 26/50] [Batch 8/300] [D loss: 0.752500] [G loss: 0.531709] time: 0:38:51.906937\n",
      "0.9397711\n",
      "[Epoch 26/50] [Batch 9/300] [D loss: 0.752489] [G loss: 0.501220] time: 0:38:52.207484\n",
      "0.9334642\n",
      "[Epoch 26/50] [Batch 10/300] [D loss: 0.752481] [G loss: 0.516080] time: 0:38:52.510504\n",
      "0.97443646\n",
      "[Epoch 26/50] [Batch 11/300] [D loss: 0.752474] [G loss: 0.508013] time: 0:38:52.804972\n",
      "0.88420385\n",
      "[Epoch 26/50] [Batch 12/300] [D loss: 0.752483] [G loss: 0.513109] time: 0:38:53.113870\n",
      "0.9256174\n",
      "[Epoch 26/50] [Batch 13/300] [D loss: 0.752473] [G loss: 0.499662] time: 0:38:53.422518\n",
      "0.97600913\n",
      "[Epoch 26/50] [Batch 14/300] [D loss: 0.752476] [G loss: 0.495927] time: 0:38:53.718924\n",
      "0.94878054\n",
      "[Epoch 26/50] [Batch 15/300] [D loss: 0.752480] [G loss: 0.520963] time: 0:38:54.013563\n",
      "0.9329977\n",
      "[Epoch 26/50] [Batch 16/300] [D loss: 0.752494] [G loss: 0.510206] time: 0:38:54.322593\n",
      "0.9533062\n",
      "[Epoch 26/50] [Batch 17/300] [D loss: 0.752484] [G loss: 0.501245] time: 0:38:54.605742\n",
      "0.9125092\n",
      "[Epoch 26/50] [Batch 18/300] [D loss: 0.752499] [G loss: 0.516786] time: 0:38:54.905116\n",
      "0.9054413\n",
      "[Epoch 26/50] [Batch 19/300] [D loss: 0.752481] [G loss: 0.514875] time: 0:38:55.201671\n",
      "0.97324413\n",
      "[Epoch 26/50] [Batch 20/300] [D loss: 0.752486] [G loss: 0.540678] time: 0:38:55.493653\n",
      "0.9009474\n",
      "[Epoch 26/50] [Batch 21/300] [D loss: 0.752477] [G loss: 0.497517] time: 0:38:55.775501\n",
      "0.9216768\n",
      "[Epoch 26/50] [Batch 22/300] [D loss: 0.752486] [G loss: 0.504019] time: 0:38:56.061263\n",
      "0.9055378\n",
      "[Epoch 26/50] [Batch 23/300] [D loss: 0.752475] [G loss: 0.492442] time: 0:38:56.351198\n",
      "0.9059245\n",
      "[Epoch 26/50] [Batch 24/300] [D loss: 0.752471] [G loss: 0.495008] time: 0:38:56.629146\n",
      "0.9352974\n",
      "[Epoch 26/50] [Batch 26/300] [D loss: 0.752498] [G loss: 0.495341] time: 0:38:56.914608\n",
      "0.91196686\n",
      "[Epoch 26/50] [Batch 27/300] [D loss: 0.752467] [G loss: 0.485093] time: 0:38:57.235976\n",
      "0.9451139\n",
      "[Epoch 26/50] [Batch 28/300] [D loss: 0.752475] [G loss: 0.493822] time: 0:38:57.521437\n",
      "0.9411471\n",
      "[Epoch 26/50] [Batch 29/300] [D loss: 0.752468] [G loss: 0.482176] time: 0:38:57.818632\n",
      "0.94618446\n",
      "[Epoch 26/50] [Batch 30/300] [D loss: 0.752480] [G loss: 0.509023] time: 0:38:58.125399\n",
      "0.97309923\n",
      "[Epoch 26/50] [Batch 31/300] [D loss: 0.752496] [G loss: 0.502666] time: 0:38:58.430929\n",
      "0.87875825\n",
      "[Epoch 26/50] [Batch 32/300] [D loss: 0.752493] [G loss: 0.496002] time: 0:38:58.726564\n",
      "0.8791649\n",
      "[Epoch 26/50] [Batch 33/300] [D loss: 0.752473] [G loss: 0.513687] time: 0:38:59.031725\n",
      "0.91157484\n",
      "[Epoch 26/50] [Batch 34/300] [D loss: 0.752461] [G loss: 0.494624] time: 0:38:59.324953\n",
      "0.93186444\n",
      "[Epoch 26/50] [Batch 35/300] [D loss: 0.752449] [G loss: 0.523867] time: 0:38:59.617468\n",
      "0.923163\n",
      "[Epoch 26/50] [Batch 36/300] [D loss: 0.752472] [G loss: 0.502533] time: 0:38:59.928447\n",
      "0.9000116\n",
      "[Epoch 26/50] [Batch 37/300] [D loss: 0.752483] [G loss: 0.527207] time: 0:39:00.212599\n",
      "0.93366605\n",
      "[Epoch 26/50] [Batch 38/300] [D loss: 0.752463] [G loss: 0.508443] time: 0:39:00.503683\n",
      "0.85280746\n",
      "[Epoch 26/50] [Batch 39/300] [D loss: 0.752462] [G loss: 0.513937] time: 0:39:00.809627\n",
      "0.95584446\n",
      "[Epoch 26/50] [Batch 40/300] [D loss: 0.752477] [G loss: 0.529165] time: 0:39:01.109368\n",
      "0.9314423\n",
      "[Epoch 26/50] [Batch 41/300] [D loss: 0.752474] [G loss: 0.485504] time: 0:39:01.405302\n",
      "0.9267602\n",
      "[Epoch 26/50] [Batch 42/300] [D loss: 0.752476] [G loss: 0.498120] time: 0:39:01.694224\n",
      "0.8976967\n",
      "[Epoch 26/50] [Batch 43/300] [D loss: 0.752452] [G loss: 0.503303] time: 0:39:01.996241\n",
      "0.9268017\n",
      "[Epoch 26/50] [Batch 44/300] [D loss: 0.752483] [G loss: 0.495836] time: 0:39:02.292606\n",
      "0.93666553\n",
      "[Epoch 26/50] [Batch 45/300] [D loss: 0.752484] [G loss: 0.497630] time: 0:39:02.572002\n",
      "0.908406\n",
      "[Epoch 26/50] [Batch 46/300] [D loss: 0.752471] [G loss: 0.486367] time: 0:39:02.845952\n",
      "0.87634844\n",
      "[Epoch 26/50] [Batch 47/300] [D loss: 0.752485] [G loss: 0.497969] time: 0:39:03.151117\n",
      "0.9320968\n",
      "[Epoch 26/50] [Batch 48/300] [D loss: 0.752488] [G loss: 0.518183] time: 0:39:03.445612\n",
      "0.94878465\n",
      "[Epoch 26/50] [Batch 49/300] [D loss: 0.752478] [G loss: 0.487410] time: 0:39:03.741559\n",
      "0.9589238\n",
      "[Epoch 26/50] [Batch 50/300] [D loss: 0.752472] [G loss: 0.544834] time: 0:39:04.039460\n",
      "0.9036786\n",
      "[Epoch 26/50] [Batch 51/300] [D loss: 0.752483] [G loss: 0.514889] time: 0:39:04.346698\n",
      "0.9320076\n",
      "[Epoch 26/50] [Batch 52/300] [D loss: 0.752489] [G loss: 0.507034] time: 0:39:04.656783\n",
      "0.93145925\n",
      "[Epoch 26/50] [Batch 53/300] [D loss: 0.752507] [G loss: 0.499564] time: 0:39:04.956188\n",
      "0.9492987\n",
      "[Epoch 26/50] [Batch 54/300] [D loss: 0.752476] [G loss: 0.491270] time: 0:39:05.268887\n",
      "0.9020819\n",
      "[Epoch 26/50] [Batch 55/300] [D loss: 0.752484] [G loss: 0.480719] time: 0:39:05.560207\n",
      "0.8838048\n",
      "[Epoch 26/50] [Batch 56/300] [D loss: 0.752484] [G loss: 0.499982] time: 0:39:05.871060\n",
      "0.9579811\n",
      "[Epoch 26/50] [Batch 57/300] [D loss: 0.752485] [G loss: 0.491805] time: 0:39:06.169294\n",
      "0.9305381\n",
      "[Epoch 26/50] [Batch 58/300] [D loss: 0.752473] [G loss: 0.526287] time: 0:39:06.462577\n",
      "0.86892396\n",
      "[Epoch 26/50] [Batch 59/300] [D loss: 0.752477] [G loss: 0.512351] time: 0:39:06.764279\n",
      "0.9111538\n",
      "[Epoch 26/50] [Batch 60/300] [D loss: 0.752477] [G loss: 0.491801] time: 0:39:07.065548\n",
      "0.9332536\n",
      "[Epoch 26/50] [Batch 61/300] [D loss: 0.752506] [G loss: 0.483777] time: 0:39:07.378716\n",
      "0.85899717\n",
      "[Epoch 26/50] [Batch 62/300] [D loss: 0.752471] [G loss: 0.531814] time: 0:39:07.660756\n",
      "0.93669385\n",
      "[Epoch 26/50] [Batch 63/300] [D loss: 0.752461] [G loss: 0.512922] time: 0:39:07.964078\n",
      "0.92667633\n",
      "[Epoch 26/50] [Batch 64/300] [D loss: 0.752502] [G loss: 0.495079] time: 0:39:08.262459\n",
      "0.88534594\n",
      "[Epoch 26/50] [Batch 65/300] [D loss: 0.752461] [G loss: 0.506156] time: 0:39:08.552671\n",
      "0.8950045\n",
      "[Epoch 26/50] [Batch 66/300] [D loss: 0.752474] [G loss: 0.501405] time: 0:39:08.840833\n",
      "0.935337\n",
      "[Epoch 26/50] [Batch 67/300] [D loss: 0.752485] [G loss: 0.498017] time: 0:39:09.138400\n",
      "0.9447461\n",
      "[Epoch 26/50] [Batch 68/300] [D loss: 0.752477] [G loss: 0.524127] time: 0:39:09.450409\n",
      "0.9081354\n",
      "[Epoch 26/50] [Batch 69/300] [D loss: 0.752486] [G loss: 0.485278] time: 0:39:09.740182\n",
      "0.9439501\n",
      "[Epoch 26/50] [Batch 70/300] [D loss: 0.752482] [G loss: 0.495602] time: 0:39:10.038873\n",
      "0.95311266\n",
      "[Epoch 26/50] [Batch 71/300] [D loss: 0.752473] [G loss: 0.486565] time: 0:39:10.342959\n",
      "0.8961363\n",
      "[Epoch 26/50] [Batch 72/300] [D loss: 0.752485] [G loss: 0.490678] time: 0:39:10.654892\n",
      "0.9300175\n",
      "[Epoch 26/50] [Batch 73/300] [D loss: 0.752474] [G loss: 0.513672] time: 0:39:10.942892\n",
      "0.9154108\n",
      "[Epoch 26/50] [Batch 74/300] [D loss: 0.752461] [G loss: 0.506430] time: 0:39:11.229573\n",
      "0.9252543\n",
      "[Epoch 26/50] [Batch 75/300] [D loss: 0.752483] [G loss: 0.524983] time: 0:39:11.540828\n",
      "0.95244974\n",
      "[Epoch 26/50] [Batch 76/300] [D loss: 0.752460] [G loss: 0.493118] time: 0:39:11.846742\n",
      "0.94044185\n",
      "[Epoch 26/50] [Batch 77/300] [D loss: 0.752468] [G loss: 0.530713] time: 0:39:12.141582\n",
      "0.92994285\n",
      "[Epoch 26/50] [Batch 78/300] [D loss: 0.752470] [G loss: 0.489036] time: 0:39:12.449376\n",
      "0.93573785\n",
      "[Epoch 26/50] [Batch 79/300] [D loss: 0.752469] [G loss: 0.506436] time: 0:39:12.747060\n",
      "0.90617365\n",
      "[Epoch 26/50] [Batch 80/300] [D loss: 0.752477] [G loss: 0.503530] time: 0:39:13.036196\n",
      "0.9461871\n",
      "[Epoch 26/50] [Batch 81/300] [D loss: 0.752469] [G loss: 0.517114] time: 0:39:13.341923\n",
      "0.9388743\n",
      "[Epoch 26/50] [Batch 82/300] [D loss: 0.752472] [G loss: 0.505786] time: 0:39:13.639126\n",
      "0.9527402\n",
      "[Epoch 26/50] [Batch 83/300] [D loss: 0.752473] [G loss: 0.499176] time: 0:39:13.945461\n",
      "0.9563804\n",
      "[Epoch 26/50] [Batch 84/300] [D loss: 0.752461] [G loss: 0.518541] time: 0:39:14.230622\n",
      "0.9136607\n",
      "[Epoch 26/50] [Batch 85/300] [D loss: 0.752472] [G loss: 0.498366] time: 0:39:14.531139\n",
      "0.9082741\n",
      "[Epoch 26/50] [Batch 86/300] [D loss: 0.752471] [G loss: 0.505009] time: 0:39:14.833702\n",
      "0.9290139\n",
      "[Epoch 26/50] [Batch 87/300] [D loss: 0.752482] [G loss: 0.488926] time: 0:39:15.147675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9419077\n",
      "[Epoch 26/50] [Batch 88/300] [D loss: 0.752488] [G loss: 0.499895] time: 0:39:15.459073\n",
      "0.9222958\n",
      "[Epoch 26/50] [Batch 89/300] [D loss: 0.752493] [G loss: 0.498184] time: 0:39:15.760923\n",
      "0.91786045\n",
      "[Epoch 26/50] [Batch 90/300] [D loss: 0.752464] [G loss: 0.493850] time: 0:39:16.058173\n",
      "0.9751664\n",
      "[Epoch 26/50] [Batch 91/300] [D loss: 0.752488] [G loss: 0.501580] time: 0:39:16.363981\n",
      "0.90474945\n",
      "[Epoch 26/50] [Batch 92/300] [D loss: 0.752478] [G loss: 0.492581] time: 0:39:16.662258\n",
      "0.9449682\n",
      "[Epoch 26/50] [Batch 93/300] [D loss: 0.752460] [G loss: 0.491701] time: 0:39:16.965571\n",
      "0.8946093\n",
      "[Epoch 26/50] [Batch 94/300] [D loss: 0.752463] [G loss: 0.521374] time: 0:39:17.262120\n",
      "0.9341605\n",
      "[Epoch 26/50] [Batch 95/300] [D loss: 0.752458] [G loss: 0.498075] time: 0:39:17.558911\n",
      "0.91672474\n",
      "[Epoch 26/50] [Batch 96/300] [D loss: 0.752485] [G loss: 0.499249] time: 0:39:17.867349\n",
      "0.95983034\n",
      "[Epoch 26/50] [Batch 97/300] [D loss: 0.752447] [G loss: 0.526084] time: 0:39:18.169151\n",
      "0.8892346\n",
      "[Epoch 26/50] [Batch 98/300] [D loss: 0.752462] [G loss: 0.501326] time: 0:39:18.462645\n",
      "0.90695864\n",
      "[Epoch 26/50] [Batch 99/300] [D loss: 0.752476] [G loss: 0.490748] time: 0:39:18.759239\n",
      "0.89350456\n",
      "[Epoch 26/50] [Batch 100/300] [D loss: 0.752481] [G loss: 0.491881] time: 0:39:19.048663\n",
      "0.95296335\n",
      "[Epoch 26/50] [Batch 101/300] [D loss: 0.752479] [G loss: 0.484895] time: 0:39:19.344086\n",
      "0.9187817\n",
      "[Epoch 26/50] [Batch 102/300] [D loss: 0.752465] [G loss: 0.486593] time: 0:39:19.645166\n",
      "0.8942426\n",
      "[Epoch 26/50] [Batch 103/300] [D loss: 0.752491] [G loss: 0.482637] time: 0:39:19.950059\n",
      "0.89920896\n",
      "[Epoch 26/50] [Batch 104/300] [D loss: 0.752470] [G loss: 0.513229] time: 0:39:20.252548\n",
      "0.9319692\n",
      "[Epoch 26/50] [Batch 105/300] [D loss: 0.752487] [G loss: 0.493818] time: 0:39:20.546468\n",
      "0.9138542\n",
      "[Epoch 26/50] [Batch 106/300] [D loss: 0.752467] [G loss: 0.492042] time: 0:39:20.839964\n",
      "0.9009332\n",
      "[Epoch 26/50] [Batch 107/300] [D loss: 0.752466] [G loss: 0.482073] time: 0:39:21.149665\n",
      "0.8933318\n",
      "[Epoch 26/50] [Batch 108/300] [D loss: 0.752493] [G loss: 0.488855] time: 0:39:21.431053\n",
      "0.941292\n",
      "[Epoch 26/50] [Batch 109/300] [D loss: 0.752475] [G loss: 0.501188] time: 0:39:21.712609\n",
      "0.91542655\n",
      "[Epoch 26/50] [Batch 110/300] [D loss: 0.752472] [G loss: 0.496443] time: 0:39:22.031093\n",
      "0.8837175\n",
      "[Epoch 26/50] [Batch 111/300] [D loss: 0.752491] [G loss: 0.477973] time: 0:39:22.330593\n",
      "0.87143344\n",
      "[Epoch 26/50] [Batch 112/300] [D loss: 0.752466] [G loss: 0.509588] time: 0:39:22.653291\n",
      "0.91093796\n",
      "[Epoch 26/50] [Batch 113/300] [D loss: 0.752480] [G loss: 0.509509] time: 0:39:22.957997\n",
      "0.9563675\n",
      "[Epoch 26/50] [Batch 114/300] [D loss: 0.752466] [G loss: 0.494910] time: 0:39:23.270170\n",
      "0.9306956\n",
      "[Epoch 26/50] [Batch 115/300] [D loss: 0.752453] [G loss: 0.515458] time: 0:39:23.570241\n",
      "0.959455\n",
      "[Epoch 26/50] [Batch 116/300] [D loss: 0.752474] [G loss: 0.498043] time: 0:39:23.872808\n",
      "0.91644555\n",
      "[Epoch 26/50] [Batch 117/300] [D loss: 0.752464] [G loss: 0.500905] time: 0:39:24.182048\n",
      "0.9390333\n",
      "[Epoch 26/50] [Batch 118/300] [D loss: 0.752468] [G loss: 0.496222] time: 0:39:24.474984\n",
      "0.93141747\n",
      "[Epoch 26/50] [Batch 119/300] [D loss: 0.752464] [G loss: 0.515543] time: 0:39:24.768187\n",
      "0.9496042\n",
      "[Epoch 26/50] [Batch 120/300] [D loss: 0.752449] [G loss: 0.499737] time: 0:39:25.067949\n",
      "0.9200805\n",
      "[Epoch 26/50] [Batch 121/300] [D loss: 0.752472] [G loss: 0.523781] time: 0:39:25.354742\n",
      "0.9079681\n",
      "[Epoch 26/50] [Batch 122/300] [D loss: 0.752478] [G loss: 0.495953] time: 0:39:25.643661\n",
      "0.9198449\n",
      "[Epoch 26/50] [Batch 123/300] [D loss: 0.752478] [G loss: 0.505277] time: 0:39:25.931319\n",
      "0.90642804\n",
      "[Epoch 26/50] [Batch 124/300] [D loss: 0.752451] [G loss: 0.505074] time: 0:39:26.211925\n",
      "0.8807022\n",
      "[Epoch 26/50] [Batch 125/300] [D loss: 0.752457] [G loss: 0.492384] time: 0:39:26.515144\n",
      "0.90562195\n",
      "[Epoch 26/50] [Batch 126/300] [D loss: 0.752445] [G loss: 0.486788] time: 0:39:26.807075\n",
      "0.92185754\n",
      "[Epoch 26/50] [Batch 127/300] [D loss: 0.752461] [G loss: 0.524025] time: 0:39:27.111596\n",
      "0.9592472\n",
      "[Epoch 26/50] [Batch 128/300] [D loss: 0.752482] [G loss: 0.495354] time: 0:39:27.403888\n",
      "0.93290585\n",
      "[Epoch 26/50] [Batch 129/300] [D loss: 0.752461] [G loss: 0.501045] time: 0:39:27.704939\n",
      "0.89495426\n",
      "[Epoch 26/50] [Batch 130/300] [D loss: 0.752443] [G loss: 0.487384] time: 0:39:27.998082\n",
      "0.9053469\n",
      "[Epoch 26/50] [Batch 131/300] [D loss: 0.752476] [G loss: 0.533366] time: 0:39:28.304130\n",
      "0.9323323\n",
      "[Epoch 26/50] [Batch 132/300] [D loss: 0.752460] [G loss: 0.488473] time: 0:39:28.619266\n",
      "0.93306226\n",
      "[Epoch 26/50] [Batch 133/300] [D loss: 0.752473] [G loss: 0.519602] time: 0:39:28.915796\n",
      "0.9269646\n",
      "[Epoch 26/50] [Batch 134/300] [D loss: 0.752483] [G loss: 0.494330] time: 0:39:29.210518\n",
      "0.9108236\n",
      "[Epoch 26/50] [Batch 135/300] [D loss: 0.752473] [G loss: 0.499967] time: 0:39:29.513921\n",
      "0.90364796\n",
      "[Epoch 26/50] [Batch 136/300] [D loss: 0.752467] [G loss: 0.499006] time: 0:39:29.811525\n",
      "0.8849063\n",
      "[Epoch 26/50] [Batch 137/300] [D loss: 0.752455] [G loss: 0.499208] time: 0:39:30.121370\n",
      "0.8993966\n",
      "[Epoch 26/50] [Batch 138/300] [D loss: 0.752461] [G loss: 0.494957] time: 0:39:30.410134\n",
      "0.88931686\n",
      "[Epoch 26/50] [Batch 139/300] [D loss: 0.752461] [G loss: 0.508848] time: 0:39:30.708310\n",
      "0.9243769\n",
      "[Epoch 26/50] [Batch 140/300] [D loss: 0.752457] [G loss: 0.489024] time: 0:39:31.007952\n",
      "0.8991268\n",
      "[Epoch 26/50] [Batch 141/300] [D loss: 0.752466] [G loss: 0.501146] time: 0:39:31.308349\n",
      "0.9292968\n",
      "[Epoch 26/50] [Batch 142/300] [D loss: 0.752478] [G loss: 0.489518] time: 0:39:31.621591\n",
      "0.94241714\n",
      "[Epoch 26/50] [Batch 143/300] [D loss: 0.752442] [G loss: 0.510032] time: 0:39:31.933752\n",
      "0.8941243\n",
      "[Epoch 26/50] [Batch 144/300] [D loss: 0.752464] [G loss: 0.504111] time: 0:39:32.227071\n",
      "0.9159875\n",
      "[Epoch 26/50] [Batch 145/300] [D loss: 0.752481] [G loss: 0.507400] time: 0:39:32.528840\n",
      "0.9106328\n",
      "[Epoch 26/50] [Batch 146/300] [D loss: 0.752475] [G loss: 0.507953] time: 0:39:32.822145\n",
      "0.9100447\n",
      "[Epoch 26/50] [Batch 147/300] [D loss: 0.752458] [G loss: 0.496634] time: 0:39:33.118032\n",
      "0.97616345\n",
      "[Epoch 26/50] [Batch 148/300] [D loss: 0.752475] [G loss: 0.499478] time: 0:39:33.428153\n",
      "0.95335597\n",
      "[Epoch 26/50] [Batch 149/300] [D loss: 0.752458] [G loss: 0.496760] time: 0:39:33.718325\n",
      "0.95557266\n",
      "[Epoch 26/50] [Batch 150/300] [D loss: 0.752458] [G loss: 0.496136] time: 0:39:34.027910\n",
      "0.90848297\n",
      "[Epoch 26/50] [Batch 151/300] [D loss: 0.752457] [G loss: 0.501224] time: 0:39:34.322595\n",
      "0.98407227\n",
      "[Epoch 26/50] [Batch 152/300] [D loss: 0.752471] [G loss: 0.496657] time: 0:39:34.612660\n",
      "0.91608334\n",
      "[Epoch 26/50] [Batch 153/300] [D loss: 0.752492] [G loss: 0.512865] time: 0:39:34.902853\n",
      "0.9151313\n",
      "[Epoch 26/50] [Batch 154/300] [D loss: 0.752453] [G loss: 0.491441] time: 0:39:35.206129\n",
      "0.9174101\n",
      "[Epoch 26/50] [Batch 155/300] [D loss: 0.752456] [G loss: 0.503317] time: 0:39:35.506039\n",
      "0.92012024\n",
      "[Epoch 26/50] [Batch 156/300] [D loss: 0.752466] [G loss: 0.502378] time: 0:39:35.812747\n",
      "0.9292535\n",
      "[Epoch 26/50] [Batch 157/300] [D loss: 0.752446] [G loss: 0.504872] time: 0:39:36.117169\n",
      "0.9331569\n",
      "[Epoch 26/50] [Batch 158/300] [D loss: 0.752474] [G loss: 0.506390] time: 0:39:36.412343\n",
      "0.8938071\n",
      "[Epoch 26/50] [Batch 159/300] [D loss: 0.752479] [G loss: 0.507955] time: 0:39:36.717207\n",
      "0.9024506\n",
      "[Epoch 26/50] [Batch 160/300] [D loss: 0.752470] [G loss: 0.516584] time: 0:39:37.020271\n",
      "0.9223048\n",
      "[Epoch 26/50] [Batch 161/300] [D loss: 0.752463] [G loss: 0.497436] time: 0:39:37.302386\n",
      "0.9270797\n",
      "[Epoch 26/50] [Batch 162/300] [D loss: 0.752449] [G loss: 0.490061] time: 0:39:37.618512\n",
      "0.9350936\n",
      "[Epoch 26/50] [Batch 163/300] [D loss: 0.752454] [G loss: 0.496900] time: 0:39:37.924566\n",
      "0.93769664\n",
      "[Epoch 26/50] [Batch 164/300] [D loss: 0.752482] [G loss: 0.510358] time: 0:39:38.227402\n",
      "0.9125595\n",
      "[Epoch 26/50] [Batch 165/300] [D loss: 0.752455] [G loss: 0.530371] time: 0:39:38.542561\n",
      "0.9078966\n",
      "[Epoch 26/50] [Batch 166/300] [D loss: 0.752465] [G loss: 0.483840] time: 0:39:38.849609\n",
      "0.932888\n",
      "[Epoch 26/50] [Batch 167/300] [D loss: 0.752459] [G loss: 0.495654] time: 0:39:39.143501\n",
      "0.935946\n",
      "[Epoch 26/50] [Batch 168/300] [D loss: 0.752461] [G loss: 0.532636] time: 0:39:39.448858\n",
      "0.91632557\n",
      "[Epoch 26/50] [Batch 169/300] [D loss: 0.752448] [G loss: 0.506672] time: 0:39:39.760734\n",
      "0.89441377\n",
      "[Epoch 26/50] [Batch 170/300] [D loss: 0.752460] [G loss: 0.504958] time: 0:39:40.062414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9462838\n",
      "[Epoch 26/50] [Batch 171/300] [D loss: 0.752465] [G loss: 0.555145] time: 0:39:40.372044\n",
      "0.91734153\n",
      "[Epoch 26/50] [Batch 172/300] [D loss: 0.752478] [G loss: 0.499607] time: 0:39:40.657445\n",
      "0.9380323\n",
      "[Epoch 26/50] [Batch 173/300] [D loss: 0.752490] [G loss: 0.509531] time: 0:39:40.953491\n",
      "0.9086182\n",
      "[Epoch 26/50] [Batch 174/300] [D loss: 0.752466] [G loss: 0.484233] time: 0:39:41.245794\n",
      "0.9039924\n",
      "[Epoch 26/50] [Batch 175/300] [D loss: 0.752454] [G loss: 0.496811] time: 0:39:41.566979\n",
      "0.9093744\n",
      "[Epoch 26/50] [Batch 176/300] [D loss: 0.752465] [G loss: 0.514680] time: 0:39:41.861035\n",
      "0.9212658\n",
      "[Epoch 26/50] [Batch 177/300] [D loss: 0.752484] [G loss: 0.520634] time: 0:39:42.143601\n",
      "0.9172609\n",
      "[Epoch 26/50] [Batch 178/300] [D loss: 0.752457] [G loss: 0.508353] time: 0:39:42.439088\n",
      "0.96961564\n",
      "[Epoch 26/50] [Batch 179/300] [D loss: 0.752487] [G loss: 0.510269] time: 0:39:42.757338\n",
      "0.9355829\n",
      "[Epoch 26/50] [Batch 180/300] [D loss: 0.752449] [G loss: 0.523299] time: 0:39:43.045283\n",
      "0.92118376\n",
      "[Epoch 26/50] [Batch 181/300] [D loss: 0.752474] [G loss: 0.480508] time: 0:39:43.344801\n",
      "0.90550417\n",
      "[Epoch 26/50] [Batch 182/300] [D loss: 0.752486] [G loss: 0.486542] time: 0:39:43.650955\n",
      "0.89300793\n",
      "[Epoch 26/50] [Batch 183/300] [D loss: 0.752493] [G loss: 0.498644] time: 0:39:43.927693\n",
      "0.9489036\n",
      "[Epoch 26/50] [Batch 184/300] [D loss: 0.752467] [G loss: 0.498309] time: 0:39:44.217989\n",
      "0.91194946\n",
      "[Epoch 26/50] [Batch 185/300] [D loss: 0.752464] [G loss: 0.493208] time: 0:39:44.518504\n",
      "0.9316671\n",
      "[Epoch 26/50] [Batch 186/300] [D loss: 0.752469] [G loss: 0.494776] time: 0:39:44.814621\n",
      "0.8906695\n",
      "[Epoch 26/50] [Batch 187/300] [D loss: 0.752473] [G loss: 0.506678] time: 0:39:45.108183\n",
      "0.91637117\n",
      "[Epoch 26/50] [Batch 188/300] [D loss: 0.752449] [G loss: 0.498721] time: 0:39:45.406401\n",
      "0.8845275\n",
      "[Epoch 26/50] [Batch 189/300] [D loss: 0.752459] [G loss: 0.542431] time: 0:39:45.691398\n",
      "0.9119982\n",
      "[Epoch 26/50] [Batch 190/300] [D loss: 0.752457] [G loss: 0.491761] time: 0:39:45.996679\n",
      "0.9313295\n",
      "[Epoch 26/50] [Batch 191/300] [D loss: 0.752466] [G loss: 0.494763] time: 0:39:46.301079\n",
      "0.95263463\n",
      "[Epoch 26/50] [Batch 192/300] [D loss: 0.752459] [G loss: 0.493915] time: 0:39:46.614647\n",
      "0.8768263\n",
      "[Epoch 26/50] [Batch 193/300] [D loss: 0.752453] [G loss: 0.485437] time: 0:39:46.916069\n",
      "0.8915246\n",
      "[Epoch 26/50] [Batch 194/300] [D loss: 0.752448] [G loss: 0.487668] time: 0:39:47.217716\n",
      "0.8944263\n",
      "[Epoch 26/50] [Batch 195/300] [D loss: 0.752462] [G loss: 0.504934] time: 0:39:47.511592\n",
      "0.96033883\n",
      "[Epoch 26/50] [Batch 196/300] [D loss: 0.752459] [G loss: 0.488767] time: 0:39:47.814435\n",
      "0.9319678\n",
      "[Epoch 26/50] [Batch 197/300] [D loss: 0.752464] [G loss: 0.495456] time: 0:39:48.091725\n",
      "0.97535205\n",
      "[Epoch 26/50] [Batch 198/300] [D loss: 0.752475] [G loss: 0.481331] time: 0:39:48.393868\n",
      "0.9773848\n",
      "[Epoch 26/50] [Batch 199/300] [D loss: 0.752459] [G loss: 0.523129] time: 0:39:48.689593\n",
      "0.8733161\n",
      "[Epoch 26/50] [Batch 200/300] [D loss: 0.752462] [G loss: 0.520297] time: 0:39:48.984773\n",
      "0.9392107\n",
      "[Epoch 26/50] [Batch 201/300] [D loss: 0.752469] [G loss: 0.483537] time: 0:39:49.296604\n",
      "0.88726187\n",
      "[Epoch 26/50] [Batch 202/300] [D loss: 0.752437] [G loss: 0.525521] time: 0:39:49.596202\n",
      "0.97162956\n",
      "[Epoch 26/50] [Batch 203/300] [D loss: 0.752488] [G loss: 0.493121] time: 0:39:49.905350\n",
      "0.9604001\n",
      "[Epoch 26/50] [Batch 204/300] [D loss: 0.752448] [G loss: 0.499619] time: 0:39:50.200859\n",
      "0.9833221\n",
      "[Epoch 26/50] [Batch 205/300] [D loss: 0.752482] [G loss: 0.487674] time: 0:39:50.506448\n",
      "0.9310899\n",
      "[Epoch 26/50] [Batch 206/300] [D loss: 0.752463] [G loss: 0.512534] time: 0:39:50.791384\n",
      "0.9051817\n",
      "[Epoch 26/50] [Batch 207/300] [D loss: 0.752461] [G loss: 0.489878] time: 0:39:51.087801\n",
      "0.91856766\n",
      "[Epoch 26/50] [Batch 208/300] [D loss: 0.752451] [G loss: 0.492349] time: 0:39:51.383307\n",
      "0.9101093\n",
      "[Epoch 26/50] [Batch 209/300] [D loss: 0.752464] [G loss: 0.511266] time: 0:39:51.665624\n",
      "0.8926096\n",
      "[Epoch 26/50] [Batch 210/300] [D loss: 0.752445] [G loss: 0.526034] time: 0:39:51.947462\n",
      "0.9172067\n",
      "[Epoch 26/50] [Batch 211/300] [D loss: 0.752474] [G loss: 0.504933] time: 0:39:52.237187\n",
      "0.9272048\n",
      "[Epoch 26/50] [Batch 212/300] [D loss: 0.752494] [G loss: 0.493055] time: 0:39:52.536246\n",
      "0.91707826\n",
      "[Epoch 26/50] [Batch 213/300] [D loss: 0.752465] [G loss: 0.486421] time: 0:39:52.834646\n",
      "0.9217484\n",
      "[Epoch 26/50] [Batch 214/300] [D loss: 0.752471] [G loss: 0.483901] time: 0:39:53.126328\n",
      "0.9247125\n",
      "[Epoch 26/50] [Batch 215/300] [D loss: 0.752457] [G loss: 0.525154] time: 0:39:53.420961\n",
      "0.949549\n",
      "[Epoch 26/50] [Batch 216/300] [D loss: 0.752461] [G loss: 0.522965] time: 0:39:53.719117\n",
      "0.8993461\n",
      "[Epoch 26/50] [Batch 217/300] [D loss: 0.752455] [G loss: 0.497340] time: 0:39:54.015984\n",
      "0.97065836\n",
      "[Epoch 26/50] [Batch 218/300] [D loss: 0.752484] [G loss: 0.484328] time: 0:39:54.320220\n",
      "0.94651335\n",
      "[Epoch 26/50] [Batch 219/300] [D loss: 0.752474] [G loss: 0.493811] time: 0:39:54.613945\n",
      "0.92894197\n",
      "[Epoch 26/50] [Batch 220/300] [D loss: 0.752460] [G loss: 0.498749] time: 0:39:54.910936\n",
      "0.94406503\n",
      "[Epoch 26/50] [Batch 221/300] [D loss: 0.752449] [G loss: 0.520199] time: 0:39:55.198361\n",
      "0.9033303\n",
      "[Epoch 26/50] [Batch 222/300] [D loss: 0.752463] [G loss: 0.524342] time: 0:39:55.488627\n",
      "0.9549462\n",
      "[Epoch 26/50] [Batch 223/300] [D loss: 0.752478] [G loss: 0.485565] time: 0:39:55.784453\n",
      "0.9106379\n",
      "[Epoch 26/50] [Batch 224/300] [D loss: 0.752461] [G loss: 0.505947] time: 0:39:56.082138\n",
      "0.8891316\n",
      "[Epoch 26/50] [Batch 225/300] [D loss: 0.752488] [G loss: 0.500280] time: 0:39:56.366386\n",
      "0.93453175\n",
      "[Epoch 26/50] [Batch 226/300] [D loss: 0.752459] [G loss: 0.495323] time: 0:39:56.669693\n",
      "0.9398461\n",
      "[Epoch 26/50] [Batch 227/300] [D loss: 0.752449] [G loss: 0.483455] time: 0:39:56.983522\n",
      "0.9310527\n",
      "[Epoch 26/50] [Batch 228/300] [D loss: 0.752488] [G loss: 0.482140] time: 0:39:57.304503\n",
      "0.90853024\n",
      "[Epoch 26/50] [Batch 229/300] [D loss: 0.752468] [G loss: 0.504544] time: 0:39:57.626833\n",
      "0.97178006\n",
      "[Epoch 26/50] [Batch 230/300] [D loss: 0.752470] [G loss: 0.520677] time: 0:39:57.921451\n",
      "0.9198691\n",
      "[Epoch 26/50] [Batch 231/300] [D loss: 0.752460] [G loss: 0.504578] time: 0:39:58.200115\n",
      "0.95319253\n",
      "[Epoch 26/50] [Batch 232/300] [D loss: 0.752465] [G loss: 0.519992] time: 0:39:58.488075\n",
      "0.9055996\n",
      "[Epoch 26/50] [Batch 233/300] [D loss: 0.752457] [G loss: 0.489506] time: 0:39:58.787444\n",
      "0.8754632\n",
      "[Epoch 26/50] [Batch 234/300] [D loss: 0.752458] [G loss: 0.491256] time: 0:39:59.089083\n",
      "0.93358225\n",
      "[Epoch 26/50] [Batch 235/300] [D loss: 0.752465] [G loss: 0.507673] time: 0:39:59.378551\n",
      "0.9389734\n",
      "[Epoch 26/50] [Batch 236/300] [D loss: 0.752469] [G loss: 0.547885] time: 0:39:59.666887\n",
      "0.905643\n",
      "[Epoch 26/50] [Batch 237/300] [D loss: 0.752451] [G loss: 0.499754] time: 0:39:59.973682\n",
      "0.88593197\n",
      "[Epoch 26/50] [Batch 238/300] [D loss: 0.752430] [G loss: 0.511246] time: 0:40:00.283300\n",
      "0.9340827\n",
      "[Epoch 26/50] [Batch 239/300] [D loss: 0.752448] [G loss: 0.485159] time: 0:40:00.587485\n",
      "0.9226236\n",
      "[Epoch 26/50] [Batch 240/300] [D loss: 0.752458] [G loss: 0.503958] time: 0:40:00.881615\n",
      "0.9443331\n",
      "[Epoch 26/50] [Batch 241/300] [D loss: 0.752458] [G loss: 0.512958] time: 0:40:01.197062\n",
      "0.93374515\n",
      "[Epoch 26/50] [Batch 242/300] [D loss: 0.752491] [G loss: 0.496848] time: 0:40:01.503112\n",
      "0.84749836\n",
      "[Epoch 26/50] [Batch 243/300] [D loss: 0.752448] [G loss: 0.514028] time: 0:40:01.812985\n",
      "0.90811324\n",
      "[Epoch 26/50] [Batch 244/300] [D loss: 0.752465] [G loss: 0.510179] time: 0:40:02.137894\n",
      "0.9168291\n",
      "[Epoch 26/50] [Batch 245/300] [D loss: 0.752447] [G loss: 0.508374] time: 0:40:02.449601\n",
      "0.8947664\n",
      "[Epoch 26/50] [Batch 246/300] [D loss: 0.752469] [G loss: 0.541719] time: 0:40:02.766328\n",
      "0.9664202\n",
      "[Epoch 26/50] [Batch 247/300] [D loss: 0.752463] [G loss: 0.495602] time: 0:40:03.082591\n",
      "0.91379076\n",
      "[Epoch 26/50] [Batch 248/300] [D loss: 0.752442] [G loss: 0.538823] time: 0:40:03.377561\n",
      "0.95897514\n",
      "[Epoch 26/50] [Batch 249/300] [D loss: 0.752492] [G loss: 0.500783] time: 0:40:03.687215\n",
      "0.9051942\n",
      "[Epoch 26/50] [Batch 250/300] [D loss: 0.752444] [G loss: 0.507076] time: 0:40:03.992331\n",
      "0.88988495\n",
      "[Epoch 26/50] [Batch 251/300] [D loss: 0.752464] [G loss: 0.511930] time: 0:40:04.289467\n",
      "0.8821554\n",
      "[Epoch 26/50] [Batch 252/300] [D loss: 0.752434] [G loss: 0.516215] time: 0:40:04.601741\n",
      "0.92115974\n",
      "[Epoch 26/50] [Batch 253/300] [D loss: 0.752448] [G loss: 0.513388] time: 0:40:04.894093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9457229\n",
      "[Epoch 26/50] [Batch 254/300] [D loss: 0.752440] [G loss: 0.522816] time: 0:40:05.197805\n",
      "0.9533067\n",
      "[Epoch 26/50] [Batch 255/300] [D loss: 0.752459] [G loss: 0.488632] time: 0:40:05.479807\n",
      "0.96307135\n",
      "[Epoch 26/50] [Batch 256/300] [D loss: 0.752461] [G loss: 0.508552] time: 0:40:05.789636\n",
      "0.89056563\n",
      "[Epoch 26/50] [Batch 257/300] [D loss: 0.752449] [G loss: 0.499470] time: 0:40:06.111728\n",
      "0.93430585\n",
      "[Epoch 26/50] [Batch 258/300] [D loss: 0.752476] [G loss: 0.487196] time: 0:40:06.384273\n",
      "0.94207567\n",
      "[Epoch 26/50] [Batch 259/300] [D loss: 0.752468] [G loss: 0.508182] time: 0:40:06.681803\n",
      "0.93239206\n",
      "[Epoch 26/50] [Batch 260/300] [D loss: 0.752471] [G loss: 0.506753] time: 0:40:06.956505\n",
      "0.94284064\n",
      "[Epoch 26/50] [Batch 261/300] [D loss: 0.752479] [G loss: 0.515853] time: 0:40:07.259528\n",
      "0.88699347\n",
      "[Epoch 26/50] [Batch 262/300] [D loss: 0.752438] [G loss: 0.506559] time: 0:40:07.542236\n",
      "0.9308202\n",
      "[Epoch 26/50] [Batch 263/300] [D loss: 0.752443] [G loss: 0.502422] time: 0:40:07.845717\n",
      "0.9507111\n",
      "[Epoch 26/50] [Batch 264/300] [D loss: 0.752450] [G loss: 0.516253] time: 0:40:08.150176\n",
      "0.8998191\n",
      "[Epoch 26/50] [Batch 265/300] [D loss: 0.752456] [G loss: 0.492965] time: 0:40:08.443545\n",
      "0.9198492\n",
      "[Epoch 26/50] [Batch 266/300] [D loss: 0.752470] [G loss: 0.500785] time: 0:40:08.743129\n",
      "0.90718025\n",
      "[Epoch 26/50] [Batch 267/300] [D loss: 0.752457] [G loss: 0.517470] time: 0:40:09.036575\n",
      "0.9286876\n",
      "[Epoch 26/50] [Batch 268/300] [D loss: 0.752458] [G loss: 0.491686] time: 0:40:09.327587\n",
      "0.8666809\n",
      "[Epoch 26/50] [Batch 269/300] [D loss: 0.752445] [G loss: 0.503383] time: 0:40:09.624669\n",
      "0.94363505\n",
      "[Epoch 26/50] [Batch 270/300] [D loss: 0.752460] [G loss: 0.502900] time: 0:40:09.922982\n",
      "0.9212699\n",
      "[Epoch 26/50] [Batch 271/300] [D loss: 0.752464] [G loss: 0.526587] time: 0:40:10.237772\n",
      "0.9467979\n",
      "[Epoch 26/50] [Batch 272/300] [D loss: 0.752428] [G loss: 0.519122] time: 0:40:10.534795\n",
      "0.8837827\n",
      "[Epoch 26/50] [Batch 273/300] [D loss: 0.752442] [G loss: 0.532206] time: 0:40:10.838047\n",
      "0.9115326\n",
      "[Epoch 26/50] [Batch 274/300] [D loss: 0.752455] [G loss: 0.525912] time: 0:40:11.133708\n",
      "0.9353629\n",
      "[Epoch 26/50] [Batch 275/300] [D loss: 0.752455] [G loss: 0.510235] time: 0:40:11.434332\n",
      "0.9701695\n",
      "[Epoch 26/50] [Batch 276/300] [D loss: 0.752467] [G loss: 0.522802] time: 0:40:11.725274\n",
      "0.9086402\n",
      "[Epoch 26/50] [Batch 277/300] [D loss: 0.752434] [G loss: 0.496373] time: 0:40:11.991958\n",
      "0.92944056\n",
      "[Epoch 26/50] [Batch 278/300] [D loss: 0.752445] [G loss: 0.498085] time: 0:40:12.290901\n",
      "0.9507685\n",
      "[Epoch 26/50] [Batch 279/300] [D loss: 0.752475] [G loss: 0.505045] time: 0:40:12.594803\n",
      "0.91269\n",
      "[Epoch 26/50] [Batch 280/300] [D loss: 0.752460] [G loss: 0.485711] time: 0:40:12.888014\n",
      "0.9412002\n",
      "[Epoch 26/50] [Batch 281/300] [D loss: 0.752466] [G loss: 0.498285] time: 0:40:13.179069\n",
      "0.9019387\n",
      "[Epoch 26/50] [Batch 282/300] [D loss: 0.752453] [G loss: 0.494106] time: 0:40:13.456085\n",
      "0.90038604\n",
      "[Epoch 26/50] [Batch 283/300] [D loss: 0.752458] [G loss: 0.494528] time: 0:40:13.754129\n",
      "0.91082066\n",
      "[Epoch 26/50] [Batch 284/300] [D loss: 0.752455] [G loss: 0.496529] time: 0:40:14.033033\n",
      "0.90776825\n",
      "[Epoch 26/50] [Batch 285/300] [D loss: 0.752460] [G loss: 0.502228] time: 0:40:14.323610\n",
      "0.9064\n",
      "[Epoch 26/50] [Batch 286/300] [D loss: 0.752466] [G loss: 0.500116] time: 0:40:14.619914\n",
      "0.9405117\n",
      "[Epoch 26/50] [Batch 287/300] [D loss: 0.752457] [G loss: 0.484481] time: 0:40:14.903411\n",
      "0.88826627\n",
      "[Epoch 26/50] [Batch 288/300] [D loss: 0.752462] [G loss: 0.492939] time: 0:40:15.188109\n",
      "0.9423971\n",
      "[Epoch 26/50] [Batch 289/300] [D loss: 0.752476] [G loss: 0.527261] time: 0:40:15.484300\n",
      "0.944592\n",
      "[Epoch 26/50] [Batch 290/300] [D loss: 0.752475] [G loss: 0.502807] time: 0:40:15.786049\n",
      "0.9617944\n",
      "[Epoch 26/50] [Batch 291/300] [D loss: 0.752441] [G loss: 0.529475] time: 0:40:16.092457\n",
      "0.94577974\n",
      "[Epoch 26/50] [Batch 292/300] [D loss: 0.752469] [G loss: 0.496086] time: 0:40:16.397245\n",
      "0.9301254\n",
      "[Epoch 26/50] [Batch 293/300] [D loss: 0.752442] [G loss: 0.534782] time: 0:40:16.714243\n",
      "0.90940523\n",
      "[Epoch 26/50] [Batch 294/300] [D loss: 0.752439] [G loss: 0.497137] time: 0:40:17.024119\n",
      "0.92399937\n",
      "[Epoch 26/50] [Batch 295/300] [D loss: 0.752459] [G loss: 0.489298] time: 0:40:17.333951\n",
      "0.89911985\n",
      "[Epoch 26/50] [Batch 296/300] [D loss: 0.752453] [G loss: 0.500195] time: 0:40:17.636921\n",
      "0.9453852\n",
      "[Epoch 26/50] [Batch 297/300] [D loss: 0.752462] [G loss: 0.488348] time: 0:40:17.937955\n",
      "0.932368\n",
      "[Epoch 26/50] [Batch 298/300] [D loss: 0.752468] [G loss: 0.510155] time: 0:40:18.225557\n",
      "0.91527575\n",
      "[Epoch 26/50] [Batch 299/300] [D loss: 0.752442] [G loss: 0.519599] time: 0:40:18.526428\n",
      "0.92807096\n",
      "[Epoch 27/50] [Batch 0/300] [D loss: 0.752459] [G loss: 0.495420] time: 0:40:18.809882\n",
      "0.9169154\n",
      "[Epoch 27/50] [Batch 1/300] [D loss: 0.752477] [G loss: 0.492956] time: 0:40:19.100395\n",
      "0.91671777\n",
      "[Epoch 27/50] [Batch 2/300] [D loss: 0.752454] [G loss: 0.491480] time: 0:40:19.405443\n",
      "0.9417627\n",
      "[Epoch 27/50] [Batch 3/300] [D loss: 0.752445] [G loss: 0.497732] time: 0:40:19.684919\n",
      "0.88750666\n",
      "[Epoch 27/50] [Batch 4/300] [D loss: 0.752456] [G loss: 0.495239] time: 0:40:19.986433\n",
      "0.8995127\n",
      "[Epoch 27/50] [Batch 5/300] [D loss: 0.752476] [G loss: 0.500879] time: 0:40:20.289934\n",
      "0.92447066\n",
      "[Epoch 27/50] [Batch 6/300] [D loss: 0.752478] [G loss: 0.485860] time: 0:40:20.576530\n",
      "0.97543985\n",
      "[Epoch 27/50] [Batch 7/300] [D loss: 0.752454] [G loss: 0.508224] time: 0:40:20.883709\n",
      "0.9243774\n",
      "[Epoch 27/50] [Batch 8/300] [D loss: 0.752440] [G loss: 0.497439] time: 0:40:21.188841\n",
      "0.90789205\n",
      "[Epoch 27/50] [Batch 9/300] [D loss: 0.752444] [G loss: 0.500354] time: 0:40:21.487997\n",
      "0.91558933\n",
      "[Epoch 27/50] [Batch 10/300] [D loss: 0.752447] [G loss: 0.530496] time: 0:40:21.784636\n",
      "0.9354504\n",
      "[Epoch 27/50] [Batch 11/300] [D loss: 0.752441] [G loss: 0.508696] time: 0:40:22.080891\n",
      "0.9130495\n",
      "[Epoch 27/50] [Batch 12/300] [D loss: 0.752458] [G loss: 0.509640] time: 0:40:22.388237\n",
      "0.8681472\n",
      "[Epoch 27/50] [Batch 13/300] [D loss: 0.752457] [G loss: 0.497118] time: 0:40:22.670345\n",
      "0.9207332\n",
      "[Epoch 27/50] [Batch 14/300] [D loss: 0.752449] [G loss: 0.503676] time: 0:40:22.973135\n",
      "0.9415563\n",
      "[Epoch 27/50] [Batch 15/300] [D loss: 0.752466] [G loss: 0.512288] time: 0:40:23.284421\n",
      "0.9199186\n",
      "[Epoch 27/50] [Batch 16/300] [D loss: 0.752443] [G loss: 0.510002] time: 0:40:23.555856\n",
      "0.93928957\n",
      "[Epoch 27/50] [Batch 17/300] [D loss: 0.752441] [G loss: 0.500167] time: 0:40:23.842926\n",
      "0.92499495\n",
      "[Epoch 27/50] [Batch 18/300] [D loss: 0.752432] [G loss: 0.573480] time: 0:40:24.136106\n",
      "0.9215289\n",
      "[Epoch 27/50] [Batch 19/300] [D loss: 0.752475] [G loss: 0.512255] time: 0:40:24.424072\n",
      "0.90538996\n",
      "[Epoch 27/50] [Batch 20/300] [D loss: 0.752445] [G loss: 0.513867] time: 0:40:24.722179\n",
      "0.9135785\n",
      "[Epoch 27/50] [Batch 21/300] [D loss: 0.752462] [G loss: 0.494534] time: 0:40:25.030087\n",
      "0.9285574\n",
      "[Epoch 27/50] [Batch 22/300] [D loss: 0.752462] [G loss: 0.500217] time: 0:40:25.328866\n",
      "0.9329149\n",
      "[Epoch 27/50] [Batch 23/300] [D loss: 0.752455] [G loss: 0.498922] time: 0:40:25.618320\n",
      "0.9304957\n",
      "[Epoch 27/50] [Batch 24/300] [D loss: 0.752452] [G loss: 0.535044] time: 0:40:25.928794\n",
      "0.9411528\n",
      "[Epoch 27/50] [Batch 25/300] [D loss: 0.752441] [G loss: 0.514834] time: 0:40:26.225226\n",
      "0.9115843\n",
      "[Epoch 27/50] [Batch 27/300] [D loss: 0.752472] [G loss: 0.490683] time: 0:40:26.552418\n",
      "0.9132883\n",
      "[Epoch 27/50] [Batch 28/300] [D loss: 0.752461] [G loss: 0.495297] time: 0:40:26.852289\n",
      "0.95343894\n",
      "[Epoch 27/50] [Batch 29/300] [D loss: 0.752445] [G loss: 0.499831] time: 0:40:27.141831\n",
      "0.92311937\n",
      "[Epoch 27/50] [Batch 30/300] [D loss: 0.752461] [G loss: 0.489035] time: 0:40:27.432115\n",
      "0.8882024\n",
      "[Epoch 27/50] [Batch 31/300] [D loss: 0.752467] [G loss: 0.479048] time: 0:40:27.718364\n",
      "0.8952894\n",
      "[Epoch 27/50] [Batch 32/300] [D loss: 0.752442] [G loss: 0.487409] time: 0:40:28.012055\n",
      "0.94095373\n",
      "[Epoch 27/50] [Batch 33/300] [D loss: 0.752448] [G loss: 0.491105] time: 0:40:28.305372\n",
      "0.97742313\n",
      "[Epoch 27/50] [Batch 34/300] [D loss: 0.752450] [G loss: 0.499923] time: 0:40:28.607950\n",
      "0.93968993\n",
      "[Epoch 27/50] [Batch 35/300] [D loss: 0.752468] [G loss: 0.509539] time: 0:40:28.907722\n",
      "0.91179514\n",
      "[Epoch 27/50] [Batch 36/300] [D loss: 0.752436] [G loss: 0.489203] time: 0:40:29.216134\n",
      "0.9046479\n",
      "[Epoch 27/50] [Batch 37/300] [D loss: 0.752449] [G loss: 0.500895] time: 0:40:29.522863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9578276\n",
      "[Epoch 27/50] [Batch 38/300] [D loss: 0.752463] [G loss: 0.496765] time: 0:40:29.834609\n",
      "0.9055348\n",
      "[Epoch 27/50] [Batch 39/300] [D loss: 0.752451] [G loss: 0.488736] time: 0:40:30.111765\n",
      "0.9425092\n",
      "[Epoch 27/50] [Batch 40/300] [D loss: 0.752462] [G loss: 0.508582] time: 0:40:30.400954\n",
      "0.9521726\n",
      "[Epoch 27/50] [Batch 41/300] [D loss: 0.752456] [G loss: 0.497759] time: 0:40:30.703682\n",
      "0.91204983\n",
      "[Epoch 27/50] [Batch 42/300] [D loss: 0.752437] [G loss: 0.491853] time: 0:40:30.987774\n",
      "0.9464386\n",
      "[Epoch 27/50] [Batch 43/300] [D loss: 0.752447] [G loss: 0.503239] time: 0:40:31.273762\n",
      "0.96151024\n",
      "[Epoch 27/50] [Batch 44/300] [D loss: 0.752460] [G loss: 0.484267] time: 0:40:31.571664\n",
      "0.9836057\n",
      "[Epoch 27/50] [Batch 45/300] [D loss: 0.752483] [G loss: 0.482532] time: 0:40:31.863841\n",
      "0.9532139\n",
      "[Epoch 27/50] [Batch 46/300] [D loss: 0.752460] [G loss: 0.493947] time: 0:40:32.165617\n",
      "0.88813287\n",
      "[Epoch 27/50] [Batch 47/300] [D loss: 0.752454] [G loss: 0.484332] time: 0:40:32.446281\n",
      "0.9402778\n",
      "[Epoch 27/50] [Batch 48/300] [D loss: 0.752455] [G loss: 0.506071] time: 0:40:32.753546\n",
      "0.9201445\n",
      "[Epoch 27/50] [Batch 49/300] [D loss: 0.752476] [G loss: 0.499293] time: 0:40:33.047854\n",
      "0.94251615\n",
      "[Epoch 27/50] [Batch 50/300] [D loss: 0.752459] [G loss: 0.491855] time: 0:40:33.352607\n",
      "0.9194038\n",
      "[Epoch 27/50] [Batch 51/300] [D loss: 0.752465] [G loss: 0.479360] time: 0:40:33.663937\n",
      "0.93330795\n",
      "[Epoch 27/50] [Batch 52/300] [D loss: 0.752484] [G loss: 0.532174] time: 0:40:33.977838\n",
      "0.8906881\n",
      "[Epoch 27/50] [Batch 53/300] [D loss: 0.752445] [G loss: 0.495316] time: 0:40:34.268265\n",
      "0.9062546\n",
      "[Epoch 27/50] [Batch 54/300] [D loss: 0.752451] [G loss: 0.524523] time: 0:40:34.561915\n",
      "0.93326086\n",
      "[Epoch 27/50] [Batch 55/300] [D loss: 0.752449] [G loss: 0.490365] time: 0:40:34.858538\n",
      "0.93395376\n",
      "[Epoch 27/50] [Batch 56/300] [D loss: 0.752466] [G loss: 0.493362] time: 0:40:35.141457\n",
      "0.9157371\n",
      "[Epoch 27/50] [Batch 57/300] [D loss: 0.752467] [G loss: 0.493951] time: 0:40:35.455128\n",
      "0.90387774\n",
      "[Epoch 27/50] [Batch 58/300] [D loss: 0.752452] [G loss: 0.517112] time: 0:40:35.756009\n",
      "0.91996866\n",
      "[Epoch 27/50] [Batch 59/300] [D loss: 0.752450] [G loss: 0.497507] time: 0:40:36.057119\n",
      "0.93805456\n",
      "[Epoch 27/50] [Batch 60/300] [D loss: 0.752446] [G loss: 0.498396] time: 0:40:36.360309\n",
      "0.8898352\n",
      "[Epoch 27/50] [Batch 61/300] [D loss: 0.752448] [G loss: 0.493271] time: 0:40:36.671558\n",
      "0.9087453\n",
      "[Epoch 27/50] [Batch 62/300] [D loss: 0.752452] [G loss: 0.517903] time: 0:40:36.969103\n",
      "0.93960255\n",
      "[Epoch 27/50] [Batch 63/300] [D loss: 0.752447] [G loss: 0.515776] time: 0:40:37.270736\n",
      "0.9616081\n",
      "[Epoch 27/50] [Batch 64/300] [D loss: 0.752458] [G loss: 0.513886] time: 0:40:37.597608\n",
      "0.9268592\n",
      "[Epoch 27/50] [Batch 65/300] [D loss: 0.752476] [G loss: 0.502038] time: 0:40:37.883478\n",
      "0.9743057\n",
      "[Epoch 27/50] [Batch 66/300] [D loss: 0.752451] [G loss: 0.509019] time: 0:40:38.161703\n",
      "0.8867124\n",
      "[Epoch 27/50] [Batch 67/300] [D loss: 0.752433] [G loss: 0.500164] time: 0:40:38.452604\n",
      "0.9311998\n",
      "[Epoch 27/50] [Batch 68/300] [D loss: 0.752446] [G loss: 0.501095] time: 0:40:38.765357\n",
      "0.8997286\n",
      "[Epoch 27/50] [Batch 69/300] [D loss: 0.752448] [G loss: 0.495419] time: 0:40:39.059498\n",
      "0.9385559\n",
      "[Epoch 27/50] [Batch 70/300] [D loss: 0.752446] [G loss: 0.527481] time: 0:40:39.344643\n",
      "0.9130278\n",
      "[Epoch 27/50] [Batch 71/300] [D loss: 0.752453] [G loss: 0.497459] time: 0:40:39.645430\n",
      "0.93094873\n",
      "[Epoch 27/50] [Batch 72/300] [D loss: 0.752455] [G loss: 0.527613] time: 0:40:39.937384\n",
      "0.9076414\n",
      "[Epoch 27/50] [Batch 73/300] [D loss: 0.752453] [G loss: 0.523500] time: 0:40:40.247723\n",
      "0.94332\n",
      "[Epoch 27/50] [Batch 74/300] [D loss: 0.752451] [G loss: 0.496294] time: 0:40:40.544598\n",
      "0.95807487\n",
      "[Epoch 27/50] [Batch 75/300] [D loss: 0.752444] [G loss: 0.495678] time: 0:40:40.858152\n",
      "0.9076419\n",
      "[Epoch 27/50] [Batch 76/300] [D loss: 0.752423] [G loss: 0.497686] time: 0:40:41.153609\n",
      "0.92241\n",
      "[Epoch 27/50] [Batch 77/300] [D loss: 0.752455] [G loss: 0.507472] time: 0:40:41.463300\n",
      "0.9701648\n",
      "[Epoch 27/50] [Batch 78/300] [D loss: 0.752459] [G loss: 0.497718] time: 0:40:41.774473\n",
      "0.8986284\n",
      "[Epoch 27/50] [Batch 79/300] [D loss: 0.752462] [G loss: 0.493125] time: 0:40:42.065256\n",
      "0.9399937\n",
      "[Epoch 27/50] [Batch 80/300] [D loss: 0.752446] [G loss: 0.504222] time: 0:40:42.328469\n",
      "0.9154405\n",
      "[Epoch 27/50] [Batch 81/300] [D loss: 0.752426] [G loss: 0.508031] time: 0:40:42.622572\n",
      "0.9328251\n",
      "[Epoch 27/50] [Batch 82/300] [D loss: 0.752456] [G loss: 0.538797] time: 0:40:42.926192\n",
      "0.9085498\n",
      "[Epoch 27/50] [Batch 83/300] [D loss: 0.752450] [G loss: 0.496662] time: 0:40:43.230065\n",
      "0.93993956\n",
      "[Epoch 27/50] [Batch 84/300] [D loss: 0.752438] [G loss: 0.503143] time: 0:40:43.530363\n",
      "0.93063706\n",
      "[Epoch 27/50] [Batch 85/300] [D loss: 0.752450] [G loss: 0.480341] time: 0:40:43.822440\n",
      "0.8905527\n",
      "[Epoch 27/50] [Batch 86/300] [D loss: 0.752450] [G loss: 0.493447] time: 0:40:44.122166\n",
      "0.93253297\n",
      "[Epoch 27/50] [Batch 87/300] [D loss: 0.752447] [G loss: 0.484704] time: 0:40:44.421166\n",
      "0.9089167\n",
      "[Epoch 27/50] [Batch 88/300] [D loss: 0.752452] [G loss: 0.526940] time: 0:40:44.723380\n",
      "0.89504725\n",
      "[Epoch 27/50] [Batch 89/300] [D loss: 0.752454] [G loss: 0.491645] time: 0:40:45.026065\n",
      "0.94270056\n",
      "[Epoch 27/50] [Batch 90/300] [D loss: 0.752441] [G loss: 0.543402] time: 0:40:45.320175\n",
      "0.85215396\n",
      "[Epoch 27/50] [Batch 91/300] [D loss: 0.752465] [G loss: 0.508285] time: 0:40:45.613081\n",
      "0.91724116\n",
      "[Epoch 27/50] [Batch 92/300] [D loss: 0.752443] [G loss: 0.506195] time: 0:40:45.937526\n",
      "0.9274652\n",
      "[Epoch 27/50] [Batch 93/300] [D loss: 0.752449] [G loss: 0.507074] time: 0:40:46.245115\n",
      "0.91814303\n",
      "[Epoch 27/50] [Batch 94/300] [D loss: 0.752442] [G loss: 0.512798] time: 0:40:46.543790\n",
      "0.91599196\n",
      "[Epoch 27/50] [Batch 95/300] [D loss: 0.752453] [G loss: 0.489438] time: 0:40:46.852908\n",
      "0.94224024\n",
      "[Epoch 27/50] [Batch 96/300] [D loss: 0.752442] [G loss: 0.507354] time: 0:40:47.144243\n",
      "0.9836351\n",
      "[Epoch 27/50] [Batch 97/300] [D loss: 0.752447] [G loss: 0.492755] time: 0:40:47.453737\n",
      "0.8964202\n",
      "[Epoch 27/50] [Batch 98/300] [D loss: 0.752442] [G loss: 0.498676] time: 0:40:47.752349\n",
      "0.8942094\n",
      "[Epoch 27/50] [Batch 99/300] [D loss: 0.752466] [G loss: 0.491115] time: 0:40:48.036349\n",
      "0.9505084\n",
      "[Epoch 27/50] [Batch 100/300] [D loss: 0.752449] [G loss: 0.504681] time: 0:40:48.332915\n",
      "0.9281325\n",
      "[Epoch 27/50] [Batch 101/300] [D loss: 0.752450] [G loss: 0.488922] time: 0:40:48.633189\n",
      "0.91694784\n",
      "[Epoch 27/50] [Batch 102/300] [D loss: 0.752438] [G loss: 0.499504] time: 0:40:48.928630\n",
      "0.9330502\n",
      "[Epoch 27/50] [Batch 103/300] [D loss: 0.752444] [G loss: 0.502290] time: 0:40:49.231613\n",
      "0.8870793\n",
      "[Epoch 27/50] [Batch 104/300] [D loss: 0.752445] [G loss: 0.493333] time: 0:40:49.531180\n",
      "0.95390743\n",
      "[Epoch 27/50] [Batch 105/300] [D loss: 0.752431] [G loss: 0.485094] time: 0:40:49.829171\n",
      "0.9520669\n",
      "[Epoch 27/50] [Batch 106/300] [D loss: 0.752437] [G loss: 0.486387] time: 0:40:50.123068\n",
      "0.9055615\n",
      "[Epoch 27/50] [Batch 107/300] [D loss: 0.752444] [G loss: 0.494727] time: 0:40:50.414215\n",
      "0.9306774\n",
      "[Epoch 27/50] [Batch 108/300] [D loss: 0.752447] [G loss: 0.489794] time: 0:40:50.718077\n",
      "0.95037085\n",
      "[Epoch 27/50] [Batch 109/300] [D loss: 0.752442] [G loss: 0.496995] time: 0:40:51.015936\n",
      "0.937269\n",
      "[Epoch 27/50] [Batch 110/300] [D loss: 0.752474] [G loss: 0.500682] time: 0:40:51.305655\n",
      "0.8952446\n",
      "[Epoch 27/50] [Batch 111/300] [D loss: 0.752439] [G loss: 0.504985] time: 0:40:51.612447\n",
      "0.95347357\n",
      "[Epoch 27/50] [Batch 112/300] [D loss: 0.752438] [G loss: 0.498572] time: 0:40:51.911543\n",
      "0.9331696\n",
      "[Epoch 27/50] [Batch 113/300] [D loss: 0.752437] [G loss: 0.481637] time: 0:40:52.208650\n",
      "0.9214029\n",
      "[Epoch 27/50] [Batch 114/300] [D loss: 0.752467] [G loss: 0.478446] time: 0:40:52.486646\n",
      "0.95515984\n",
      "[Epoch 27/50] [Batch 115/300] [D loss: 0.752467] [G loss: 0.482824] time: 0:40:52.792616\n",
      "0.89907867\n",
      "[Epoch 27/50] [Batch 116/300] [D loss: 0.752439] [G loss: 0.498224] time: 0:40:53.096479\n",
      "0.9333732\n",
      "[Epoch 27/50] [Batch 117/300] [D loss: 0.752472] [G loss: 0.506203] time: 0:40:53.399110\n",
      "0.9176801\n",
      "[Epoch 27/50] [Batch 118/300] [D loss: 0.752435] [G loss: 0.512026] time: 0:40:53.671729\n",
      "0.927746\n",
      "[Epoch 27/50] [Batch 119/300] [D loss: 0.752432] [G loss: 0.512815] time: 0:40:53.949964\n",
      "0.9120205\n",
      "[Epoch 27/50] [Batch 120/300] [D loss: 0.752440] [G loss: 0.498755] time: 0:40:54.246206\n",
      "0.9435094\n",
      "[Epoch 27/50] [Batch 121/300] [D loss: 0.752451] [G loss: 0.495936] time: 0:40:54.569487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9458165\n",
      "[Epoch 27/50] [Batch 122/300] [D loss: 0.752462] [G loss: 0.518253] time: 0:40:54.879167\n",
      "0.9284143\n",
      "[Epoch 27/50] [Batch 123/300] [D loss: 0.752448] [G loss: 0.496078] time: 0:40:55.184789\n",
      "0.8790154\n",
      "[Epoch 27/50] [Batch 124/300] [D loss: 0.752431] [G loss: 0.507232] time: 0:40:55.483026\n",
      "0.93684036\n",
      "[Epoch 27/50] [Batch 125/300] [D loss: 0.752453] [G loss: 0.485475] time: 0:40:55.789486\n",
      "0.87869006\n",
      "[Epoch 27/50] [Batch 126/300] [D loss: 0.752448] [G loss: 0.503802] time: 0:40:56.076570\n",
      "0.9627862\n",
      "[Epoch 27/50] [Batch 127/300] [D loss: 0.752442] [G loss: 0.492147] time: 0:40:56.383328\n",
      "0.9283216\n",
      "[Epoch 27/50] [Batch 128/300] [D loss: 0.752463] [G loss: 0.482584] time: 0:40:56.665747\n",
      "0.9217523\n",
      "[Epoch 27/50] [Batch 129/300] [D loss: 0.752446] [G loss: 0.495735] time: 0:40:56.961358\n",
      "0.8848855\n",
      "[Epoch 27/50] [Batch 130/300] [D loss: 0.752441] [G loss: 0.504754] time: 0:40:57.259310\n",
      "0.92901105\n",
      "[Epoch 27/50] [Batch 131/300] [D loss: 0.752437] [G loss: 0.499126] time: 0:40:57.569936\n",
      "0.9318807\n",
      "[Epoch 27/50] [Batch 132/300] [D loss: 0.752450] [G loss: 0.500601] time: 0:40:57.866092\n",
      "0.9202686\n",
      "[Epoch 27/50] [Batch 133/300] [D loss: 0.752433] [G loss: 0.484812] time: 0:40:58.148721\n",
      "0.9587516\n",
      "[Epoch 27/50] [Batch 134/300] [D loss: 0.752452] [G loss: 0.485858] time: 0:40:58.442651\n",
      "0.94050914\n",
      "[Epoch 27/50] [Batch 135/300] [D loss: 0.752458] [G loss: 0.499823] time: 0:40:58.749520\n",
      "0.90593296\n",
      "[Epoch 27/50] [Batch 136/300] [D loss: 0.752449] [G loss: 0.529229] time: 0:40:59.043927\n",
      "0.9532981\n",
      "[Epoch 27/50] [Batch 137/300] [D loss: 0.752452] [G loss: 0.481671] time: 0:40:59.336760\n",
      "0.9071531\n",
      "[Epoch 27/50] [Batch 138/300] [D loss: 0.752436] [G loss: 0.532029] time: 0:40:59.636783\n",
      "0.955848\n",
      "[Epoch 27/50] [Batch 139/300] [D loss: 0.752451] [G loss: 0.497307] time: 0:40:59.953332\n",
      "0.9194036\n",
      "[Epoch 27/50] [Batch 140/300] [D loss: 0.752458] [G loss: 0.489446] time: 0:41:00.253074\n",
      "0.938591\n",
      "[Epoch 27/50] [Batch 141/300] [D loss: 0.752459] [G loss: 0.483960] time: 0:41:00.546438\n",
      "0.94979244\n",
      "[Epoch 27/50] [Batch 142/300] [D loss: 0.752456] [G loss: 0.504204] time: 0:41:00.846478\n",
      "0.9554832\n",
      "[Epoch 27/50] [Batch 143/300] [D loss: 0.752451] [G loss: 0.487880] time: 0:41:01.153014\n",
      "0.88522696\n",
      "[Epoch 27/50] [Batch 144/300] [D loss: 0.752449] [G loss: 0.509500] time: 0:41:01.451549\n",
      "0.92079276\n",
      "[Epoch 27/50] [Batch 145/300] [D loss: 0.752443] [G loss: 0.493865] time: 0:41:01.754146\n",
      "0.93626183\n",
      "[Epoch 27/50] [Batch 146/300] [D loss: 0.752459] [G loss: 0.513352] time: 0:41:02.055384\n",
      "0.946163\n",
      "[Epoch 27/50] [Batch 147/300] [D loss: 0.752459] [G loss: 0.480984] time: 0:41:02.362108\n",
      "0.97010165\n",
      "[Epoch 27/50] [Batch 148/300] [D loss: 0.752457] [G loss: 0.517776] time: 0:41:02.654231\n",
      "0.91408116\n",
      "[Epoch 27/50] [Batch 149/300] [D loss: 0.752447] [G loss: 0.518388] time: 0:41:02.946232\n",
      "0.9756856\n",
      "[Epoch 27/50] [Batch 150/300] [D loss: 0.752437] [G loss: 0.498100] time: 0:41:03.251611\n",
      "0.9166779\n",
      "[Epoch 27/50] [Batch 151/300] [D loss: 0.752442] [G loss: 0.512497] time: 0:41:03.551601\n",
      "0.90393734\n",
      "[Epoch 27/50] [Batch 152/300] [D loss: 0.752446] [G loss: 0.497576] time: 0:41:03.848865\n",
      "0.88612324\n",
      "[Epoch 27/50] [Batch 153/300] [D loss: 0.752432] [G loss: 0.515703] time: 0:41:04.159753\n",
      "0.93958855\n",
      "[Epoch 27/50] [Batch 154/300] [D loss: 0.752452] [G loss: 0.507377] time: 0:41:04.448789\n",
      "0.9524252\n",
      "[Epoch 27/50] [Batch 155/300] [D loss: 0.752453] [G loss: 0.481892] time: 0:41:04.742009\n",
      "0.90820026\n",
      "[Epoch 27/50] [Batch 156/300] [D loss: 0.752460] [G loss: 0.509189] time: 0:41:05.047639\n",
      "0.93812746\n",
      "[Epoch 27/50] [Batch 157/300] [D loss: 0.752445] [G loss: 0.497521] time: 0:41:05.342879\n",
      "0.9365346\n",
      "[Epoch 27/50] [Batch 158/300] [D loss: 0.752452] [G loss: 0.505177] time: 0:41:05.645621\n",
      "0.91385746\n",
      "[Epoch 27/50] [Batch 159/300] [D loss: 0.752460] [G loss: 0.496091] time: 0:41:05.934299\n",
      "0.89541054\n",
      "[Epoch 27/50] [Batch 160/300] [D loss: 0.752448] [G loss: 0.492523] time: 0:41:06.238523\n",
      "0.90848213\n",
      "[Epoch 27/50] [Batch 161/300] [D loss: 0.752424] [G loss: 0.503348] time: 0:41:06.533025\n",
      "0.8807016\n",
      "[Epoch 27/50] [Batch 162/300] [D loss: 0.752447] [G loss: 0.525352] time: 0:41:06.837767\n",
      "0.9473898\n",
      "[Epoch 27/50] [Batch 163/300] [D loss: 0.752442] [G loss: 0.504743] time: 0:41:07.150552\n",
      "0.9359796\n",
      "[Epoch 27/50] [Batch 164/300] [D loss: 0.752460] [G loss: 0.495361] time: 0:41:07.464255\n",
      "0.91396374\n",
      "[Epoch 27/50] [Batch 165/300] [D loss: 0.752431] [G loss: 0.521965] time: 0:41:07.765420\n",
      "0.9422915\n",
      "[Epoch 27/50] [Batch 166/300] [D loss: 0.752443] [G loss: 0.512432] time: 0:41:08.071971\n",
      "0.93477154\n",
      "[Epoch 27/50] [Batch 167/300] [D loss: 0.752451] [G loss: 0.499195] time: 0:41:08.383800\n",
      "0.88702136\n",
      "[Epoch 27/50] [Batch 168/300] [D loss: 0.752454] [G loss: 0.502296] time: 0:41:08.681668\n",
      "0.88052535\n",
      "[Epoch 27/50] [Batch 169/300] [D loss: 0.752455] [G loss: 0.486271] time: 0:41:08.991153\n",
      "0.8943124\n",
      "[Epoch 27/50] [Batch 170/300] [D loss: 0.752460] [G loss: 0.511783] time: 0:41:09.291274\n",
      "0.9495275\n",
      "[Epoch 27/50] [Batch 171/300] [D loss: 0.752468] [G loss: 0.499448] time: 0:41:09.566441\n",
      "0.92562157\n",
      "[Epoch 27/50] [Batch 172/300] [D loss: 0.752435] [G loss: 0.500853] time: 0:41:09.867329\n",
      "0.9163231\n",
      "[Epoch 27/50] [Batch 173/300] [D loss: 0.752442] [G loss: 0.495248] time: 0:41:10.174092\n",
      "0.93304235\n",
      "[Epoch 27/50] [Batch 174/300] [D loss: 0.752433] [G loss: 0.507518] time: 0:41:10.472398\n",
      "0.9392174\n",
      "[Epoch 27/50] [Batch 175/300] [D loss: 0.752430] [G loss: 0.501937] time: 0:41:10.757347\n",
      "0.9139087\n",
      "[Epoch 27/50] [Batch 176/300] [D loss: 0.752448] [G loss: 0.493068] time: 0:41:11.056832\n",
      "0.9314378\n",
      "[Epoch 27/50] [Batch 177/300] [D loss: 0.752433] [G loss: 0.496304] time: 0:41:11.373558\n",
      "0.8813029\n",
      "[Epoch 27/50] [Batch 178/300] [D loss: 0.752436] [G loss: 0.534936] time: 0:41:11.673833\n",
      "0.90459234\n",
      "[Epoch 27/50] [Batch 179/300] [D loss: 0.752444] [G loss: 0.498108] time: 0:41:11.975766\n",
      "0.9022147\n",
      "[Epoch 27/50] [Batch 180/300] [D loss: 0.752445] [G loss: 0.488641] time: 0:41:12.269816\n",
      "0.9286507\n",
      "[Epoch 27/50] [Batch 181/300] [D loss: 0.752432] [G loss: 0.484345] time: 0:41:12.575367\n",
      "0.89893407\n",
      "[Epoch 27/50] [Batch 182/300] [D loss: 0.752446] [G loss: 0.488672] time: 0:41:12.876464\n",
      "0.9130301\n",
      "[Epoch 27/50] [Batch 183/300] [D loss: 0.752453] [G loss: 0.487995] time: 0:41:13.195193\n",
      "0.94764656\n",
      "[Epoch 27/50] [Batch 184/300] [D loss: 0.752427] [G loss: 0.495600] time: 0:41:13.505297\n",
      "0.9206168\n",
      "[Epoch 27/50] [Batch 185/300] [D loss: 0.752453] [G loss: 0.491576] time: 0:41:13.789593\n",
      "0.8742346\n",
      "[Epoch 27/50] [Batch 186/300] [D loss: 0.752443] [G loss: 0.498212] time: 0:41:14.093364\n",
      "0.9215812\n",
      "[Epoch 27/50] [Batch 187/300] [D loss: 0.752450] [G loss: 0.495371] time: 0:41:14.392563\n",
      "0.90741676\n",
      "[Epoch 27/50] [Batch 188/300] [D loss: 0.752454] [G loss: 0.517975] time: 0:41:14.704222\n",
      "0.9372538\n",
      "[Epoch 27/50] [Batch 189/300] [D loss: 0.752453] [G loss: 0.481845] time: 0:41:14.999436\n",
      "0.8896308\n",
      "[Epoch 27/50] [Batch 190/300] [D loss: 0.752446] [G loss: 0.528176] time: 0:41:15.307699\n",
      "0.9071603\n",
      "[Epoch 27/50] [Batch 191/300] [D loss: 0.752446] [G loss: 0.595716] time: 0:41:15.607778\n",
      "0.9259766\n",
      "[Epoch 27/50] [Batch 192/300] [D loss: 0.752443] [G loss: 0.502216] time: 0:41:15.899853\n",
      "0.87642854\n",
      "[Epoch 27/50] [Batch 193/300] [D loss: 0.752440] [G loss: 0.523834] time: 0:41:16.190366\n",
      "0.9355049\n",
      "[Epoch 27/50] [Batch 194/300] [D loss: 0.752467] [G loss: 0.482321] time: 0:41:16.486838\n",
      "0.89598995\n",
      "[Epoch 27/50] [Batch 195/300] [D loss: 0.752444] [G loss: 0.498614] time: 0:41:16.789065\n",
      "0.888766\n",
      "[Epoch 27/50] [Batch 196/300] [D loss: 0.752436] [G loss: 0.505633] time: 0:41:17.079763\n",
      "0.9062157\n",
      "[Epoch 27/50] [Batch 197/300] [D loss: 0.752430] [G loss: 0.505253] time: 0:41:17.382151\n",
      "0.9175107\n",
      "[Epoch 27/50] [Batch 198/300] [D loss: 0.752442] [G loss: 0.499653] time: 0:41:17.686406\n",
      "0.890078\n",
      "[Epoch 27/50] [Batch 199/300] [D loss: 0.752435] [G loss: 0.513207] time: 0:41:17.986845\n",
      "0.9403088\n",
      "[Epoch 27/50] [Batch 200/300] [D loss: 0.752448] [G loss: 0.500162] time: 0:41:18.296268\n",
      "0.9348078\n",
      "[Epoch 27/50] [Batch 201/300] [D loss: 0.752442] [G loss: 0.522231] time: 0:41:18.606138\n",
      "0.9280324\n",
      "[Epoch 27/50] [Batch 202/300] [D loss: 0.752441] [G loss: 0.484334] time: 0:41:18.908081\n",
      "0.93448997\n",
      "[Epoch 27/50] [Batch 203/300] [D loss: 0.752465] [G loss: 0.507846] time: 0:41:19.200143\n",
      "0.9383108\n",
      "[Epoch 27/50] [Batch 204/300] [D loss: 0.752426] [G loss: 0.488075] time: 0:41:19.489810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88600177\n",
      "[Epoch 27/50] [Batch 205/300] [D loss: 0.752443] [G loss: 0.515432] time: 0:41:19.792750\n",
      "0.94720465\n",
      "[Epoch 27/50] [Batch 206/300] [D loss: 0.752457] [G loss: 0.516318] time: 0:41:20.097090\n",
      "0.9360525\n",
      "[Epoch 27/50] [Batch 207/300] [D loss: 0.752442] [G loss: 0.495017] time: 0:41:20.395506\n",
      "0.9404933\n",
      "[Epoch 27/50] [Batch 208/300] [D loss: 0.752447] [G loss: 0.520620] time: 0:41:20.688747\n",
      "0.93141764\n",
      "[Epoch 27/50] [Batch 209/300] [D loss: 0.752461] [G loss: 0.484229] time: 0:41:20.993756\n",
      "0.93089944\n",
      "[Epoch 27/50] [Batch 210/300] [D loss: 0.752458] [G loss: 0.498956] time: 0:41:21.297184\n",
      "0.97685975\n",
      "[Epoch 27/50] [Batch 211/300] [D loss: 0.752447] [G loss: 0.495144] time: 0:41:21.600594\n",
      "0.98341376\n",
      "[Epoch 27/50] [Batch 212/300] [D loss: 0.752436] [G loss: 0.483465] time: 0:41:21.917143\n",
      "0.8745251\n",
      "[Epoch 27/50] [Batch 213/300] [D loss: 0.752442] [G loss: 0.489840] time: 0:41:22.207367\n",
      "0.953376\n",
      "[Epoch 27/50] [Batch 214/300] [D loss: 0.752464] [G loss: 0.501079] time: 0:41:22.512662\n",
      "0.92853355\n",
      "[Epoch 27/50] [Batch 215/300] [D loss: 0.752447] [G loss: 0.478703] time: 0:41:22.821360\n",
      "0.9253871\n",
      "[Epoch 27/50] [Batch 216/300] [D loss: 0.752433] [G loss: 0.482072] time: 0:41:23.117282\n",
      "0.96869236\n",
      "[Epoch 27/50] [Batch 217/300] [D loss: 0.752451] [G loss: 0.491638] time: 0:41:23.393269\n",
      "0.922867\n",
      "[Epoch 27/50] [Batch 218/300] [D loss: 0.752419] [G loss: 0.514049] time: 0:41:23.669103\n",
      "0.92226344\n",
      "[Epoch 27/50] [Batch 219/300] [D loss: 0.752422] [G loss: 0.513867] time: 0:41:23.927000\n",
      "0.9034539\n",
      "[Epoch 27/50] [Batch 220/300] [D loss: 0.752430] [G loss: 0.525185] time: 0:41:24.221954\n",
      "0.89436984\n",
      "[Epoch 27/50] [Batch 221/300] [D loss: 0.752430] [G loss: 0.499084] time: 0:41:24.526342\n",
      "0.9214695\n",
      "[Epoch 27/50] [Batch 222/300] [D loss: 0.752434] [G loss: 0.491141] time: 0:41:24.820714\n",
      "0.9709303\n",
      "[Epoch 27/50] [Batch 223/300] [D loss: 0.752462] [G loss: 0.510749] time: 0:41:25.112849\n",
      "0.91473174\n",
      "[Epoch 27/50] [Batch 224/300] [D loss: 0.752441] [G loss: 0.513609] time: 0:41:25.408939\n",
      "0.8983039\n",
      "[Epoch 27/50] [Batch 225/300] [D loss: 0.752439] [G loss: 0.484489] time: 0:41:25.703315\n",
      "0.908317\n",
      "[Epoch 27/50] [Batch 226/300] [D loss: 0.752449] [G loss: 0.494293] time: 0:41:25.998861\n",
      "0.9096482\n",
      "[Epoch 27/50] [Batch 227/300] [D loss: 0.752441] [G loss: 0.536777] time: 0:41:26.286004\n",
      "0.9421138\n",
      "[Epoch 27/50] [Batch 228/300] [D loss: 0.752435] [G loss: 0.507407] time: 0:41:26.597395\n",
      "0.91786534\n",
      "[Epoch 27/50] [Batch 229/300] [D loss: 0.752451] [G loss: 0.502620] time: 0:41:27.012737\n",
      "0.9775173\n",
      "[Epoch 27/50] [Batch 230/300] [D loss: 0.752456] [G loss: 0.502210] time: 0:41:27.293989\n",
      "0.8862471\n",
      "[Epoch 27/50] [Batch 231/300] [D loss: 0.752416] [G loss: 0.513522] time: 0:41:27.591931\n",
      "0.9226387\n",
      "[Epoch 27/50] [Batch 232/300] [D loss: 0.752440] [G loss: 0.487794] time: 0:41:27.880065\n",
      "0.89949036\n",
      "[Epoch 27/50] [Batch 233/300] [D loss: 0.752453] [G loss: 0.481352] time: 0:41:28.172172\n",
      "0.9381904\n",
      "[Epoch 27/50] [Batch 234/300] [D loss: 0.752449] [G loss: 0.494372] time: 0:41:28.474724\n",
      "0.9396189\n",
      "[Epoch 27/50] [Batch 235/300] [D loss: 0.752443] [G loss: 0.526527] time: 0:41:28.769423\n",
      "0.9215706\n",
      "[Epoch 27/50] [Batch 236/300] [D loss: 0.752440] [G loss: 0.495995] time: 0:41:29.072063\n",
      "0.939387\n",
      "[Epoch 27/50] [Batch 237/300] [D loss: 0.752443] [G loss: 0.513973] time: 0:41:29.350439\n",
      "0.9279256\n",
      "[Epoch 27/50] [Batch 238/300] [D loss: 0.752430] [G loss: 0.507282] time: 0:41:29.645959\n",
      "0.9358533\n",
      "[Epoch 27/50] [Batch 239/300] [D loss: 0.752447] [G loss: 0.476918] time: 0:41:29.933114\n",
      "0.92629886\n",
      "[Epoch 27/50] [Batch 240/300] [D loss: 0.752439] [G loss: 0.502295] time: 0:41:30.216265\n",
      "0.9185381\n",
      "[Epoch 27/50] [Batch 241/300] [D loss: 0.752434] [G loss: 0.510160] time: 0:41:30.500375\n",
      "0.9178977\n",
      "[Epoch 27/50] [Batch 242/300] [D loss: 0.752449] [G loss: 0.537151] time: 0:41:30.812264\n",
      "0.9194379\n",
      "[Epoch 27/50] [Batch 243/300] [D loss: 0.752431] [G loss: 0.506081] time: 0:41:31.114787\n",
      "0.9170367\n",
      "[Epoch 27/50] [Batch 244/300] [D loss: 0.752449] [G loss: 0.498305] time: 0:41:31.413287\n",
      "0.9132411\n",
      "[Epoch 27/50] [Batch 245/300] [D loss: 0.752449] [G loss: 0.493770] time: 0:41:31.735513\n",
      "0.9542119\n",
      "[Epoch 27/50] [Batch 246/300] [D loss: 0.752458] [G loss: 0.502928] time: 0:41:32.046229\n",
      "0.90628284\n",
      "[Epoch 27/50] [Batch 247/300] [D loss: 0.752448] [G loss: 0.505455] time: 0:41:32.347633\n",
      "0.9716107\n",
      "[Epoch 27/50] [Batch 248/300] [D loss: 0.752440] [G loss: 0.510435] time: 0:41:32.637703\n",
      "0.9358298\n",
      "[Epoch 27/50] [Batch 249/300] [D loss: 0.752427] [G loss: 0.483348] time: 0:41:32.937500\n",
      "0.8733577\n",
      "[Epoch 27/50] [Batch 250/300] [D loss: 0.752435] [G loss: 0.497503] time: 0:41:33.217634\n",
      "0.92153245\n",
      "[Epoch 27/50] [Batch 251/300] [D loss: 0.752448] [G loss: 0.497384] time: 0:41:33.505114\n",
      "0.9001694\n",
      "[Epoch 27/50] [Batch 252/300] [D loss: 0.752435] [G loss: 0.517129] time: 0:41:33.789016\n",
      "0.88305205\n",
      "[Epoch 27/50] [Batch 253/300] [D loss: 0.752422] [G loss: 0.509628] time: 0:41:34.073779\n",
      "0.907077\n",
      "[Epoch 27/50] [Batch 254/300] [D loss: 0.752441] [G loss: 0.535535] time: 0:41:34.369067\n",
      "0.9023125\n",
      "[Epoch 27/50] [Batch 255/300] [D loss: 0.752434] [G loss: 0.536353] time: 0:41:34.662025\n",
      "0.93685323\n",
      "[Epoch 27/50] [Batch 256/300] [D loss: 0.752434] [G loss: 0.504057] time: 0:41:34.959172\n",
      "0.9375662\n",
      "[Epoch 27/50] [Batch 257/300] [D loss: 0.752453] [G loss: 0.498230] time: 0:41:35.240230\n",
      "0.9457163\n",
      "[Epoch 27/50] [Batch 258/300] [D loss: 0.752455] [G loss: 0.508419] time: 0:41:35.542386\n",
      "0.9160233\n",
      "[Epoch 27/50] [Batch 259/300] [D loss: 0.752433] [G loss: 0.528485] time: 0:41:35.843151\n",
      "0.9318903\n",
      "[Epoch 27/50] [Batch 260/300] [D loss: 0.752436] [G loss: 0.500051] time: 0:41:36.147485\n",
      "0.9476432\n",
      "[Epoch 27/50] [Batch 261/300] [D loss: 0.752426] [G loss: 0.512687] time: 0:41:36.445834\n",
      "0.93464804\n",
      "[Epoch 27/50] [Batch 262/300] [D loss: 0.752436] [G loss: 0.488833] time: 0:41:36.744152\n",
      "0.87872386\n",
      "[Epoch 27/50] [Batch 263/300] [D loss: 0.752437] [G loss: 0.515353] time: 0:41:37.058539\n",
      "0.9163919\n",
      "[Epoch 27/50] [Batch 264/300] [D loss: 0.752447] [G loss: 0.508021] time: 0:41:37.346731\n",
      "0.93929\n",
      "[Epoch 27/50] [Batch 265/300] [D loss: 0.752436] [G loss: 0.492564] time: 0:41:37.645887\n",
      "0.9418232\n",
      "[Epoch 27/50] [Batch 266/300] [D loss: 0.752443] [G loss: 0.510416] time: 0:41:37.947002\n",
      "0.931128\n",
      "[Epoch 27/50] [Batch 267/300] [D loss: 0.752449] [G loss: 0.513706] time: 0:41:38.244129\n",
      "0.91965026\n",
      "[Epoch 27/50] [Batch 268/300] [D loss: 0.752416] [G loss: 0.512487] time: 0:41:38.542130\n",
      "0.9244862\n",
      "[Epoch 27/50] [Batch 269/300] [D loss: 0.752474] [G loss: 0.483858] time: 0:41:38.850840\n",
      "0.91738605\n",
      "[Epoch 27/50] [Batch 270/300] [D loss: 0.752429] [G loss: 0.521492] time: 0:41:39.140619\n",
      "0.95353293\n",
      "[Epoch 27/50] [Batch 271/300] [D loss: 0.752445] [G loss: 0.503023] time: 0:41:39.440976\n",
      "0.89822894\n",
      "[Epoch 27/50] [Batch 272/300] [D loss: 0.752445] [G loss: 0.505692] time: 0:41:39.745284\n",
      "0.91178244\n",
      "[Epoch 27/50] [Batch 273/300] [D loss: 0.752454] [G loss: 0.500101] time: 0:41:40.041433\n",
      "0.9169628\n",
      "[Epoch 27/50] [Batch 274/300] [D loss: 0.752465] [G loss: 0.495246] time: 0:41:40.347132\n",
      "0.9235216\n",
      "[Epoch 27/50] [Batch 275/300] [D loss: 0.752464] [G loss: 0.510965] time: 0:41:40.640525\n",
      "0.9198232\n",
      "[Epoch 27/50] [Batch 276/300] [D loss: 0.752443] [G loss: 0.515255] time: 0:41:40.938707\n",
      "0.9054194\n",
      "[Epoch 27/50] [Batch 277/300] [D loss: 0.752443] [G loss: 0.505496] time: 0:41:41.234001\n",
      "0.8682135\n",
      "[Epoch 27/50] [Batch 278/300] [D loss: 0.752425] [G loss: 0.493246] time: 0:41:41.518189\n",
      "0.959642\n",
      "[Epoch 27/50] [Batch 279/300] [D loss: 0.752431] [G loss: 0.497414] time: 0:41:41.798256\n",
      "0.8863244\n",
      "[Epoch 27/50] [Batch 280/300] [D loss: 0.752455] [G loss: 0.491260] time: 0:41:42.108053\n",
      "0.9214205\n",
      "[Epoch 27/50] [Batch 281/300] [D loss: 0.752438] [G loss: 0.495222] time: 0:41:42.415425\n",
      "0.94535494\n",
      "[Epoch 27/50] [Batch 282/300] [D loss: 0.752457] [G loss: 0.494680] time: 0:41:42.716814\n",
      "0.91691035\n",
      "[Epoch 27/50] [Batch 283/300] [D loss: 0.752436] [G loss: 0.506174] time: 0:41:43.007328\n",
      "0.9087761\n",
      "[Epoch 27/50] [Batch 284/300] [D loss: 0.752413] [G loss: 0.500199] time: 0:41:43.291371\n",
      "0.9109331\n",
      "[Epoch 27/50] [Batch 285/300] [D loss: 0.752437] [G loss: 0.514238] time: 0:41:43.600759\n",
      "0.9706667\n",
      "[Epoch 27/50] [Batch 286/300] [D loss: 0.752443] [G loss: 0.512444] time: 0:41:43.901074\n",
      "0.88515145\n",
      "[Epoch 27/50] [Batch 287/300] [D loss: 0.752447] [G loss: 0.486988] time: 0:41:44.191369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88539386\n",
      "[Epoch 27/50] [Batch 288/300] [D loss: 0.752418] [G loss: 0.497636] time: 0:41:44.469988\n",
      "0.90905315\n",
      "[Epoch 27/50] [Batch 289/300] [D loss: 0.752450] [G loss: 0.499616] time: 0:41:44.766183\n",
      "0.9600568\n",
      "[Epoch 27/50] [Batch 290/300] [D loss: 0.752445] [G loss: 0.502329] time: 0:41:45.051341\n",
      "0.9495198\n",
      "[Epoch 27/50] [Batch 291/300] [D loss: 0.752435] [G loss: 0.515049] time: 0:41:45.352984\n",
      "0.9128246\n",
      "[Epoch 27/50] [Batch 292/300] [D loss: 0.752447] [G loss: 0.501042] time: 0:41:45.643016\n",
      "0.9283454\n",
      "[Epoch 27/50] [Batch 293/300] [D loss: 0.752452] [G loss: 0.516094] time: 0:41:45.955341\n",
      "0.9333361\n",
      "[Epoch 27/50] [Batch 294/300] [D loss: 0.752427] [G loss: 0.515123] time: 0:41:46.256495\n",
      "0.9088529\n",
      "[Epoch 27/50] [Batch 295/300] [D loss: 0.752432] [G loss: 0.496509] time: 0:41:46.558139\n",
      "0.94018555\n",
      "[Epoch 27/50] [Batch 296/300] [D loss: 0.752452] [G loss: 0.497010] time: 0:41:46.837724\n",
      "0.9693701\n",
      "[Epoch 27/50] [Batch 297/300] [D loss: 0.752433] [G loss: 0.498690] time: 0:41:47.126939\n",
      "0.92784315\n",
      "[Epoch 27/50] [Batch 298/300] [D loss: 0.752444] [G loss: 0.489950] time: 0:41:47.424885\n",
      "0.90854293\n",
      "[Epoch 27/50] [Batch 299/300] [D loss: 0.752423] [G loss: 0.508228] time: 0:41:47.743219\n",
      "0.9413018\n",
      "[Epoch 28/50] [Batch 0/300] [D loss: 0.752426] [G loss: 0.499799] time: 0:41:48.039176\n",
      "0.88296825\n",
      "[Epoch 28/50] [Batch 1/300] [D loss: 0.752439] [G loss: 0.507710] time: 0:41:48.324605\n",
      "0.91675204\n",
      "[Epoch 28/50] [Batch 2/300] [D loss: 0.752429] [G loss: 0.508691] time: 0:41:48.625049\n",
      "0.90976244\n",
      "[Epoch 28/50] [Batch 3/300] [D loss: 0.752428] [G loss: 0.479701] time: 0:41:48.917583\n",
      "0.9181115\n",
      "[Epoch 28/50] [Batch 4/300] [D loss: 0.752411] [G loss: 0.487962] time: 0:41:49.214890\n",
      "0.93201536\n",
      "[Epoch 28/50] [Batch 5/300] [D loss: 0.752419] [G loss: 0.497843] time: 0:41:49.511218\n",
      "0.94167286\n",
      "[Epoch 28/50] [Batch 6/300] [D loss: 0.752440] [G loss: 0.501630] time: 0:41:49.810281\n",
      "0.94132566\n",
      "[Epoch 28/50] [Batch 7/300] [D loss: 0.752439] [G loss: 0.503826] time: 0:41:50.104108\n",
      "0.93553615\n",
      "[Epoch 28/50] [Batch 8/300] [D loss: 0.752451] [G loss: 0.488755] time: 0:41:50.400395\n",
      "0.88879234\n",
      "[Epoch 28/50] [Batch 9/300] [D loss: 0.752439] [G loss: 0.486017] time: 0:41:50.684822\n",
      "0.94215935\n",
      "[Epoch 28/50] [Batch 10/300] [D loss: 0.752426] [G loss: 0.529577] time: 0:41:50.971083\n",
      "0.9470696\n",
      "[Epoch 28/50] [Batch 11/300] [D loss: 0.752417] [G loss: 0.507607] time: 0:41:51.273163\n",
      "0.9287613\n",
      "[Epoch 28/50] [Batch 12/300] [D loss: 0.752451] [G loss: 0.545099] time: 0:41:51.552552\n",
      "0.91412354\n",
      "[Epoch 28/50] [Batch 13/300] [D loss: 0.752448] [G loss: 0.506085] time: 0:41:51.856128\n",
      "0.90356475\n",
      "[Epoch 28/50] [Batch 14/300] [D loss: 0.752470] [G loss: 0.494322] time: 0:41:52.148021\n",
      "0.91794103\n",
      "[Epoch 28/50] [Batch 15/300] [D loss: 0.752424] [G loss: 0.517829] time: 0:41:52.424665\n",
      "0.9418394\n",
      "[Epoch 28/50] [Batch 16/300] [D loss: 0.752440] [G loss: 0.512521] time: 0:41:52.722552\n",
      "0.9416656\n",
      "[Epoch 28/50] [Batch 17/300] [D loss: 0.752431] [G loss: 0.550319] time: 0:41:53.021370\n",
      "0.9112304\n",
      "[Epoch 28/50] [Batch 18/300] [D loss: 0.752417] [G loss: 0.512814] time: 0:41:53.304314\n",
      "0.9419357\n",
      "[Epoch 28/50] [Batch 19/300] [D loss: 0.752426] [G loss: 0.511715] time: 0:41:53.608032\n",
      "0.94698924\n",
      "[Epoch 28/50] [Batch 20/300] [D loss: 0.752436] [G loss: 0.493106] time: 0:41:53.900859\n",
      "0.87184477\n",
      "[Epoch 28/50] [Batch 21/300] [D loss: 0.752428] [G loss: 0.561709] time: 0:41:54.205022\n",
      "0.89940125\n",
      "[Epoch 28/50] [Batch 22/300] [D loss: 0.752448] [G loss: 0.505288] time: 0:41:54.508124\n",
      "0.9068699\n",
      "[Epoch 28/50] [Batch 23/300] [D loss: 0.752441] [G loss: 0.510455] time: 0:41:54.793727\n",
      "0.9091329\n",
      "[Epoch 28/50] [Batch 24/300] [D loss: 0.752442] [G loss: 0.534246] time: 0:41:55.102874\n",
      "0.93925375\n",
      "[Epoch 28/50] [Batch 25/300] [D loss: 0.752462] [G loss: 0.508981] time: 0:41:55.407451\n",
      "0.9834485\n",
      "[Epoch 28/50] [Batch 26/300] [D loss: 0.752456] [G loss: 0.494106] time: 0:41:55.699246\n",
      "0.9165314\n",
      "[Epoch 28/50] [Batch 28/300] [D loss: 0.752446] [G loss: 0.488989] time: 0:41:56.003683\n",
      "0.9593831\n",
      "[Epoch 28/50] [Batch 29/300] [D loss: 0.752423] [G loss: 0.495681] time: 0:41:56.309548\n",
      "0.9242405\n",
      "[Epoch 28/50] [Batch 30/300] [D loss: 0.752414] [G loss: 0.498394] time: 0:41:56.609954\n",
      "0.90087557\n",
      "[Epoch 28/50] [Batch 31/300] [D loss: 0.752454] [G loss: 0.489223] time: 0:41:56.908687\n",
      "0.95231986\n",
      "[Epoch 28/50] [Batch 32/300] [D loss: 0.752438] [G loss: 0.506410] time: 0:41:57.225276\n",
      "0.89287\n",
      "[Epoch 28/50] [Batch 33/300] [D loss: 0.752436] [G loss: 0.498170] time: 0:41:57.517010\n",
      "0.89577216\n",
      "[Epoch 28/50] [Batch 34/300] [D loss: 0.752433] [G loss: 0.478775] time: 0:41:57.822588\n",
      "0.9276188\n",
      "[Epoch 28/50] [Batch 35/300] [D loss: 0.752424] [G loss: 0.493139] time: 0:41:58.121623\n",
      "0.91209525\n",
      "[Epoch 28/50] [Batch 36/300] [D loss: 0.752469] [G loss: 0.488475] time: 0:41:58.418966\n",
      "0.93109447\n",
      "[Epoch 28/50] [Batch 37/300] [D loss: 0.752435] [G loss: 0.512515] time: 0:41:58.715762\n",
      "0.91285545\n",
      "[Epoch 28/50] [Batch 38/300] [D loss: 0.752425] [G loss: 0.494190] time: 0:41:59.014437\n",
      "0.90533704\n",
      "[Epoch 28/50] [Batch 39/300] [D loss: 0.752433] [G loss: 0.508446] time: 0:41:59.329496\n",
      "0.9096468\n",
      "[Epoch 28/50] [Batch 40/300] [D loss: 0.752442] [G loss: 0.481758] time: 0:41:59.642413\n",
      "0.92331296\n",
      "[Epoch 28/50] [Batch 41/300] [D loss: 0.752432] [G loss: 0.481846] time: 0:41:59.942087\n",
      "0.9274297\n",
      "[Epoch 28/50] [Batch 42/300] [D loss: 0.752447] [G loss: 0.487664] time: 0:42:00.236255\n",
      "0.9449749\n",
      "[Epoch 28/50] [Batch 43/300] [D loss: 0.752443] [G loss: 0.487400] time: 0:42:00.532992\n",
      "0.91463447\n",
      "[Epoch 28/50] [Batch 44/300] [D loss: 0.752417] [G loss: 0.498253] time: 0:42:00.834660\n",
      "0.9068635\n",
      "[Epoch 28/50] [Batch 45/300] [D loss: 0.752425] [G loss: 0.505837] time: 0:42:01.140011\n",
      "0.94129425\n",
      "[Epoch 28/50] [Batch 46/300] [D loss: 0.752432] [G loss: 0.495435] time: 0:42:01.448166\n",
      "0.8917362\n",
      "[Epoch 28/50] [Batch 47/300] [D loss: 0.752429] [G loss: 0.481140] time: 0:42:01.734001\n",
      "0.88104105\n",
      "[Epoch 28/50] [Batch 48/300] [D loss: 0.752436] [G loss: 0.500513] time: 0:42:02.033540\n",
      "0.9346876\n",
      "[Epoch 28/50] [Batch 49/300] [D loss: 0.752438] [G loss: 0.490601] time: 0:42:02.298893\n",
      "0.867847\n",
      "[Epoch 28/50] [Batch 50/300] [D loss: 0.752430] [G loss: 0.496232] time: 0:42:02.603603\n",
      "0.90079784\n",
      "[Epoch 28/50] [Batch 51/300] [D loss: 0.752446] [G loss: 0.500263] time: 0:42:02.905115\n",
      "0.94357747\n",
      "[Epoch 28/50] [Batch 52/300] [D loss: 0.752426] [G loss: 0.489052] time: 0:42:03.211486\n",
      "0.9286399\n",
      "[Epoch 28/50] [Batch 53/300] [D loss: 0.752449] [G loss: 0.497683] time: 0:42:03.508528\n",
      "0.93189454\n",
      "[Epoch 28/50] [Batch 54/300] [D loss: 0.752437] [G loss: 0.489300] time: 0:42:03.813921\n",
      "0.95366865\n",
      "[Epoch 28/50] [Batch 55/300] [D loss: 0.752426] [G loss: 0.478356] time: 0:42:04.103124\n",
      "0.8886234\n",
      "[Epoch 28/50] [Batch 56/300] [D loss: 0.752445] [G loss: 0.491736] time: 0:42:04.398252\n",
      "0.90495807\n",
      "[Epoch 28/50] [Batch 57/300] [D loss: 0.752425] [G loss: 0.497442] time: 0:42:04.683953\n",
      "0.905277\n",
      "[Epoch 28/50] [Batch 58/300] [D loss: 0.752445] [G loss: 0.524693] time: 0:42:04.990844\n",
      "0.9841878\n",
      "[Epoch 28/50] [Batch 59/300] [D loss: 0.752444] [G loss: 0.524019] time: 0:42:05.278053\n",
      "0.9170108\n",
      "[Epoch 28/50] [Batch 60/300] [D loss: 0.752437] [G loss: 0.504437] time: 0:42:05.581234\n",
      "0.8954573\n",
      "[Epoch 28/50] [Batch 61/300] [D loss: 0.752424] [G loss: 0.498303] time: 0:42:05.851187\n",
      "0.88184315\n",
      "[Epoch 28/50] [Batch 62/300] [D loss: 0.752441] [G loss: 0.494102] time: 0:42:06.116065\n",
      "0.9546879\n",
      "[Epoch 28/50] [Batch 63/300] [D loss: 0.752433] [G loss: 0.482051] time: 0:42:06.404426\n",
      "0.89458513\n",
      "[Epoch 28/50] [Batch 64/300] [D loss: 0.752460] [G loss: 0.503038] time: 0:42:06.703561\n",
      "0.9535084\n",
      "[Epoch 28/50] [Batch 65/300] [D loss: 0.752443] [G loss: 0.500592] time: 0:42:07.014983\n",
      "0.9229274\n",
      "[Epoch 28/50] [Batch 66/300] [D loss: 0.752444] [G loss: 0.496323] time: 0:42:07.311053\n",
      "0.93680096\n",
      "[Epoch 28/50] [Batch 67/300] [D loss: 0.752425] [G loss: 0.491089] time: 0:42:07.600301\n",
      "0.91608363\n",
      "[Epoch 28/50] [Batch 68/300] [D loss: 0.752425] [G loss: 0.500542] time: 0:42:07.895812\n",
      "0.8929643\n",
      "[Epoch 28/50] [Batch 69/300] [D loss: 0.752438] [G loss: 0.490044] time: 0:42:08.194908\n",
      "0.90594935\n",
      "[Epoch 28/50] [Batch 70/300] [D loss: 0.752448] [G loss: 0.498447] time: 0:42:08.499833\n",
      "0.9435623\n",
      "[Epoch 28/50] [Batch 71/300] [D loss: 0.752447] [G loss: 0.503236] time: 0:42:08.794986\n",
      "0.9456125\n",
      "[Epoch 28/50] [Batch 72/300] [D loss: 0.752430] [G loss: 0.474110] time: 0:42:09.095701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168539\n",
      "[Epoch 28/50] [Batch 73/300] [D loss: 0.752422] [G loss: 0.506911] time: 0:42:09.401560\n",
      "0.94376945\n",
      "[Epoch 28/50] [Batch 74/300] [D loss: 0.752447] [G loss: 0.494010] time: 0:42:09.700578\n",
      "0.90680695\n",
      "[Epoch 28/50] [Batch 75/300] [D loss: 0.752429] [G loss: 0.479646] time: 0:42:10.000748\n",
      "0.9123129\n",
      "[Epoch 28/50] [Batch 76/300] [D loss: 0.752447] [G loss: 0.505069] time: 0:42:10.296266\n",
      "0.95226747\n",
      "[Epoch 28/50] [Batch 77/300] [D loss: 0.752431] [G loss: 0.503259] time: 0:42:10.595744\n",
      "0.92434007\n",
      "[Epoch 28/50] [Batch 78/300] [D loss: 0.752426] [G loss: 0.490996] time: 0:42:10.890379\n",
      "0.89297295\n",
      "[Epoch 28/50] [Batch 79/300] [D loss: 0.752441] [G loss: 0.488695] time: 0:42:11.193377\n",
      "0.90297955\n",
      "[Epoch 28/50] [Batch 80/300] [D loss: 0.752409] [G loss: 0.490957] time: 0:42:11.484559\n",
      "0.9701387\n",
      "[Epoch 28/50] [Batch 81/300] [D loss: 0.752434] [G loss: 0.493838] time: 0:42:11.798679\n",
      "0.92588615\n",
      "[Epoch 28/50] [Batch 82/300] [D loss: 0.752441] [G loss: 0.482763] time: 0:42:12.079714\n",
      "0.9660637\n",
      "[Epoch 28/50] [Batch 83/300] [D loss: 0.752446] [G loss: 0.484232] time: 0:42:12.380236\n",
      "0.91422176\n",
      "[Epoch 28/50] [Batch 84/300] [D loss: 0.752428] [G loss: 0.489701] time: 0:42:12.671020\n",
      "0.91273445\n",
      "[Epoch 28/50] [Batch 85/300] [D loss: 0.752435] [G loss: 0.513988] time: 0:42:12.967404\n",
      "0.96044\n",
      "[Epoch 28/50] [Batch 86/300] [D loss: 0.752430] [G loss: 0.508368] time: 0:42:13.249130\n",
      "0.9113427\n",
      "[Epoch 28/50] [Batch 87/300] [D loss: 0.752420] [G loss: 0.526717] time: 0:42:13.530584\n",
      "0.8838792\n",
      "[Epoch 28/50] [Batch 88/300] [D loss: 0.752412] [G loss: 0.509841] time: 0:42:13.830144\n",
      "0.9469034\n",
      "[Epoch 28/50] [Batch 89/300] [D loss: 0.752420] [G loss: 0.483252] time: 0:42:14.131405\n",
      "0.88728076\n",
      "[Epoch 28/50] [Batch 90/300] [D loss: 0.752452] [G loss: 0.518925] time: 0:42:14.431678\n",
      "0.9092381\n",
      "[Epoch 28/50] [Batch 91/300] [D loss: 0.752431] [G loss: 0.531703] time: 0:42:14.725837\n",
      "0.88119835\n",
      "[Epoch 28/50] [Batch 92/300] [D loss: 0.752445] [G loss: 0.498583] time: 0:42:15.031149\n",
      "0.9396953\n",
      "[Epoch 28/50] [Batch 93/300] [D loss: 0.752434] [G loss: 0.505815] time: 0:42:15.337193\n",
      "0.9744838\n",
      "[Epoch 28/50] [Batch 94/300] [D loss: 0.752424] [G loss: 0.495065] time: 0:42:15.640966\n",
      "0.883701\n",
      "[Epoch 28/50] [Batch 95/300] [D loss: 0.752426] [G loss: 0.502714] time: 0:42:15.946807\n",
      "0.95064497\n",
      "[Epoch 28/50] [Batch 96/300] [D loss: 0.752445] [G loss: 0.508600] time: 0:42:16.241079\n",
      "0.9200652\n",
      "[Epoch 28/50] [Batch 97/300] [D loss: 0.752436] [G loss: 0.491580] time: 0:42:16.538771\n",
      "0.9171769\n",
      "[Epoch 28/50] [Batch 98/300] [D loss: 0.752456] [G loss: 0.495989] time: 0:42:16.841281\n",
      "0.92825824\n",
      "[Epoch 28/50] [Batch 99/300] [D loss: 0.752412] [G loss: 0.488832] time: 0:42:17.114422\n",
      "0.95314294\n",
      "[Epoch 28/50] [Batch 100/300] [D loss: 0.752418] [G loss: 0.487200] time: 0:42:17.422546\n",
      "0.8856475\n",
      "[Epoch 28/50] [Batch 101/300] [D loss: 0.752434] [G loss: 0.508366] time: 0:42:17.732936\n",
      "0.9764013\n",
      "[Epoch 28/50] [Batch 102/300] [D loss: 0.752411] [G loss: 0.483582] time: 0:42:18.040296\n",
      "0.91664284\n",
      "[Epoch 28/50] [Batch 103/300] [D loss: 0.752447] [G loss: 0.480905] time: 0:42:18.310519\n",
      "0.92863184\n",
      "[Epoch 28/50] [Batch 104/300] [D loss: 0.752410] [G loss: 0.499801] time: 0:42:18.597165\n",
      "0.9328182\n",
      "[Epoch 28/50] [Batch 105/300] [D loss: 0.752430] [G loss: 0.489625] time: 0:42:18.884787\n",
      "0.8940565\n",
      "[Epoch 28/50] [Batch 106/300] [D loss: 0.752427] [G loss: 0.481978] time: 0:42:19.165926\n",
      "0.9494789\n",
      "[Epoch 28/50] [Batch 107/300] [D loss: 0.752434] [G loss: 0.496390] time: 0:42:19.438858\n",
      "0.9088122\n",
      "[Epoch 28/50] [Batch 108/300] [D loss: 0.752448] [G loss: 0.486980] time: 0:42:19.724494\n",
      "0.90060097\n",
      "[Epoch 28/50] [Batch 109/300] [D loss: 0.752426] [G loss: 0.490479] time: 0:42:20.026326\n",
      "0.9083592\n",
      "[Epoch 28/50] [Batch 110/300] [D loss: 0.752435] [G loss: 0.508756] time: 0:42:20.344063\n",
      "0.9191901\n",
      "[Epoch 28/50] [Batch 111/300] [D loss: 0.752430] [G loss: 0.522397] time: 0:42:20.633334\n",
      "0.9142978\n",
      "[Epoch 28/50] [Batch 112/300] [D loss: 0.752428] [G loss: 0.510131] time: 0:42:20.941886\n",
      "0.9327609\n",
      "[Epoch 28/50] [Batch 113/300] [D loss: 0.752426] [G loss: 0.499871] time: 0:42:21.229699\n",
      "0.9252818\n",
      "[Epoch 28/50] [Batch 114/300] [D loss: 0.752441] [G loss: 0.496851] time: 0:42:21.510152\n",
      "0.94760466\n",
      "[Epoch 28/50] [Batch 115/300] [D loss: 0.752433] [G loss: 0.495091] time: 0:42:21.815220\n",
      "0.92870027\n",
      "[Epoch 28/50] [Batch 116/300] [D loss: 0.752431] [G loss: 0.481012] time: 0:42:22.095784\n",
      "0.9163584\n",
      "[Epoch 28/50] [Batch 117/300] [D loss: 0.752413] [G loss: 0.505625] time: 0:42:22.390631\n",
      "0.9833612\n",
      "[Epoch 28/50] [Batch 118/300] [D loss: 0.752446] [G loss: 0.513536] time: 0:42:22.684496\n",
      "0.9392068\n",
      "[Epoch 28/50] [Batch 119/300] [D loss: 0.752423] [G loss: 0.488107] time: 0:42:22.965305\n",
      "0.89345294\n",
      "[Epoch 28/50] [Batch 120/300] [D loss: 0.752432] [G loss: 0.509531] time: 0:42:23.256895\n",
      "0.9159778\n",
      "[Epoch 28/50] [Batch 121/300] [D loss: 0.752419] [G loss: 0.488341] time: 0:42:23.571614\n",
      "0.9312752\n",
      "[Epoch 28/50] [Batch 122/300] [D loss: 0.752418] [G loss: 0.535400] time: 0:42:23.875433\n",
      "0.88850975\n",
      "[Epoch 28/50] [Batch 123/300] [D loss: 0.752410] [G loss: 0.483802] time: 0:42:24.163179\n",
      "0.8934966\n",
      "[Epoch 28/50] [Batch 124/300] [D loss: 0.752415] [G loss: 0.512770] time: 0:42:24.468726\n",
      "0.9229428\n",
      "[Epoch 28/50] [Batch 125/300] [D loss: 0.752422] [G loss: 0.489619] time: 0:42:24.779070\n",
      "0.91752404\n",
      "[Epoch 28/50] [Batch 126/300] [D loss: 0.752409] [G loss: 0.501716] time: 0:42:25.071769\n",
      "0.95684737\n",
      "[Epoch 28/50] [Batch 127/300] [D loss: 0.752446] [G loss: 0.501491] time: 0:42:25.358988\n",
      "0.9009039\n",
      "[Epoch 28/50] [Batch 128/300] [D loss: 0.752442] [G loss: 0.480446] time: 0:42:25.649595\n",
      "0.94789\n",
      "[Epoch 28/50] [Batch 129/300] [D loss: 0.752420] [G loss: 0.510981] time: 0:42:25.948797\n",
      "0.9419672\n",
      "[Epoch 28/50] [Batch 130/300] [D loss: 0.752424] [G loss: 0.489723] time: 0:42:26.237931\n",
      "0.9383119\n",
      "[Epoch 28/50] [Batch 131/300] [D loss: 0.752441] [G loss: 0.486643] time: 0:42:26.541913\n",
      "0.8883918\n",
      "[Epoch 28/50] [Batch 132/300] [D loss: 0.752446] [G loss: 0.492656] time: 0:42:26.832429\n",
      "0.95246357\n",
      "[Epoch 28/50] [Batch 133/300] [D loss: 0.752439] [G loss: 0.545592] time: 0:42:27.126704\n",
      "0.9077006\n",
      "[Epoch 28/50] [Batch 134/300] [D loss: 0.752440] [G loss: 0.497032] time: 0:42:27.431993\n",
      "0.9305296\n",
      "[Epoch 28/50] [Batch 135/300] [D loss: 0.752429] [G loss: 0.501505] time: 0:42:27.737250\n",
      "0.93551165\n",
      "[Epoch 28/50] [Batch 136/300] [D loss: 0.752401] [G loss: 0.518543] time: 0:42:28.033945\n",
      "0.8782315\n",
      "[Epoch 28/50] [Batch 137/300] [D loss: 0.752439] [G loss: 0.560308] time: 0:42:28.350801\n",
      "0.91375977\n",
      "[Epoch 28/50] [Batch 138/300] [D loss: 0.752415] [G loss: 0.495019] time: 0:42:28.654081\n",
      "0.9313331\n",
      "[Epoch 28/50] [Batch 139/300] [D loss: 0.752425] [G loss: 0.526468] time: 0:42:28.960457\n",
      "0.8955609\n",
      "[Epoch 28/50] [Batch 140/300] [D loss: 0.752408] [G loss: 0.509907] time: 0:42:29.262321\n",
      "0.90634656\n",
      "[Epoch 28/50] [Batch 141/300] [D loss: 0.752424] [G loss: 0.510409] time: 0:42:29.580344\n",
      "0.93471235\n",
      "[Epoch 28/50] [Batch 142/300] [D loss: 0.752416] [G loss: 0.490739] time: 0:42:29.882138\n",
      "0.92566204\n",
      "[Epoch 28/50] [Batch 143/300] [D loss: 0.752431] [G loss: 0.487682] time: 0:42:30.187320\n",
      "0.9049333\n",
      "[Epoch 28/50] [Batch 144/300] [D loss: 0.752417] [G loss: 0.490582] time: 0:42:30.491368\n",
      "0.9600027\n",
      "[Epoch 28/50] [Batch 145/300] [D loss: 0.752425] [G loss: 0.481028] time: 0:42:30.780760\n",
      "0.94464844\n",
      "[Epoch 28/50] [Batch 146/300] [D loss: 0.752406] [G loss: 0.514605] time: 0:42:31.086551\n",
      "0.9482274\n",
      "[Epoch 28/50] [Batch 147/300] [D loss: 0.752416] [G loss: 0.503295] time: 0:42:31.371980\n",
      "0.8720803\n",
      "[Epoch 28/50] [Batch 148/300] [D loss: 0.752435] [G loss: 0.490185] time: 0:42:31.682344\n",
      "0.9533245\n",
      "[Epoch 28/50] [Batch 149/300] [D loss: 0.752434] [G loss: 0.501552] time: 0:42:31.984784\n",
      "0.9328697\n",
      "[Epoch 28/50] [Batch 150/300] [D loss: 0.752449] [G loss: 0.521631] time: 0:42:32.307413\n",
      "0.9468105\n",
      "[Epoch 28/50] [Batch 151/300] [D loss: 0.752426] [G loss: 0.491959] time: 0:42:32.570395\n",
      "0.93187857\n",
      "[Epoch 28/50] [Batch 152/300] [D loss: 0.752429] [G loss: 0.523564] time: 0:42:32.853114\n",
      "0.9083974\n",
      "[Epoch 28/50] [Batch 153/300] [D loss: 0.752431] [G loss: 0.502704] time: 0:42:33.159150\n",
      "0.92637634\n",
      "[Epoch 28/50] [Batch 154/300] [D loss: 0.752424] [G loss: 0.489907] time: 0:42:33.447461\n",
      "0.92058086\n",
      "[Epoch 28/50] [Batch 155/300] [D loss: 0.752447] [G loss: 0.501738] time: 0:42:33.749035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8919289\n",
      "[Epoch 28/50] [Batch 156/300] [D loss: 0.752434] [G loss: 0.498131] time: 0:42:34.031587\n",
      "0.9466602\n",
      "[Epoch 28/50] [Batch 157/300] [D loss: 0.752431] [G loss: 0.516945] time: 0:42:34.325346\n",
      "0.9138449\n",
      "[Epoch 28/50] [Batch 158/300] [D loss: 0.752413] [G loss: 0.479910] time: 0:42:34.619784\n",
      "0.9373951\n",
      "[Epoch 28/50] [Batch 159/300] [D loss: 0.752426] [G loss: 0.498175] time: 0:42:34.908321\n",
      "0.9151518\n",
      "[Epoch 28/50] [Batch 160/300] [D loss: 0.752430] [G loss: 0.504395] time: 0:42:35.202955\n",
      "0.91407424\n",
      "[Epoch 28/50] [Batch 161/300] [D loss: 0.752434] [G loss: 0.494476] time: 0:42:35.492741\n",
      "0.96390504\n",
      "[Epoch 28/50] [Batch 162/300] [D loss: 0.752423] [G loss: 0.512680] time: 0:42:35.770235\n",
      "0.89488786\n",
      "[Epoch 28/50] [Batch 163/300] [D loss: 0.752412] [G loss: 0.489529] time: 0:42:36.057171\n",
      "0.9458952\n",
      "[Epoch 28/50] [Batch 164/300] [D loss: 0.752441] [G loss: 0.493239] time: 0:42:36.360128\n",
      "0.8817189\n",
      "[Epoch 28/50] [Batch 165/300] [D loss: 0.752421] [G loss: 0.496450] time: 0:42:36.662152\n",
      "0.9407099\n",
      "[Epoch 28/50] [Batch 166/300] [D loss: 0.752440] [G loss: 0.520439] time: 0:42:36.964105\n",
      "0.9414529\n",
      "[Epoch 28/50] [Batch 167/300] [D loss: 0.752427] [G loss: 0.484091] time: 0:42:37.260506\n",
      "0.9074829\n",
      "[Epoch 28/50] [Batch 168/300] [D loss: 0.752411] [G loss: 0.500496] time: 0:42:37.555490\n",
      "0.9083121\n",
      "[Epoch 28/50] [Batch 169/300] [D loss: 0.752420] [G loss: 0.513969] time: 0:42:37.853610\n",
      "0.8901728\n",
      "[Epoch 28/50] [Batch 170/300] [D loss: 0.752415] [G loss: 0.513516] time: 0:42:38.156060\n",
      "0.9453383\n",
      "[Epoch 28/50] [Batch 171/300] [D loss: 0.752448] [G loss: 0.486074] time: 0:42:38.445662\n",
      "0.92104894\n",
      "[Epoch 28/50] [Batch 172/300] [D loss: 0.752422] [G loss: 0.496671] time: 0:42:38.747118\n",
      "0.9141305\n",
      "[Epoch 28/50] [Batch 173/300] [D loss: 0.752452] [G loss: 0.486672] time: 0:42:39.056748\n",
      "0.9054768\n",
      "[Epoch 28/50] [Batch 174/300] [D loss: 0.752419] [G loss: 0.504352] time: 0:42:39.347735\n",
      "0.90906185\n",
      "[Epoch 28/50] [Batch 175/300] [D loss: 0.752436] [G loss: 0.521825] time: 0:42:39.634345\n",
      "0.9524085\n",
      "[Epoch 28/50] [Batch 176/300] [D loss: 0.752440] [G loss: 0.483205] time: 0:42:39.934620\n",
      "0.93595797\n",
      "[Epoch 28/50] [Batch 177/300] [D loss: 0.752436] [G loss: 0.495423] time: 0:42:40.232197\n",
      "0.9315471\n",
      "[Epoch 28/50] [Batch 178/300] [D loss: 0.752442] [G loss: 0.503565] time: 0:42:40.531197\n",
      "0.983933\n",
      "[Epoch 28/50] [Batch 179/300] [D loss: 0.752433] [G loss: 0.494270] time: 0:42:40.844356\n",
      "0.8829836\n",
      "[Epoch 28/50] [Batch 180/300] [D loss: 0.752440] [G loss: 0.517168] time: 0:42:41.139985\n",
      "0.9707511\n",
      "[Epoch 28/50] [Batch 181/300] [D loss: 0.752440] [G loss: 0.494667] time: 0:42:41.454627\n",
      "0.9051902\n",
      "[Epoch 28/50] [Batch 182/300] [D loss: 0.752432] [G loss: 0.500104] time: 0:42:41.750268\n",
      "0.8943134\n",
      "[Epoch 28/50] [Batch 183/300] [D loss: 0.752432] [G loss: 0.502687] time: 0:42:42.056383\n",
      "0.94861096\n",
      "[Epoch 28/50] [Batch 184/300] [D loss: 0.752448] [G loss: 0.481082] time: 0:42:42.361646\n",
      "0.8723659\n",
      "[Epoch 28/50] [Batch 185/300] [D loss: 0.752428] [G loss: 0.499171] time: 0:42:42.653816\n",
      "0.9470313\n",
      "[Epoch 28/50] [Batch 186/300] [D loss: 0.752435] [G loss: 0.491963] time: 0:42:42.954541\n",
      "0.9354759\n",
      "[Epoch 28/50] [Batch 187/300] [D loss: 0.752428] [G loss: 0.491650] time: 0:42:43.250856\n",
      "0.910161\n",
      "[Epoch 28/50] [Batch 188/300] [D loss: 0.752418] [G loss: 0.489789] time: 0:42:43.540098\n",
      "0.88101715\n",
      "[Epoch 28/50] [Batch 189/300] [D loss: 0.752435] [G loss: 0.489041] time: 0:42:43.848031\n",
      "0.9447903\n",
      "[Epoch 28/50] [Batch 190/300] [D loss: 0.752422] [G loss: 0.487150] time: 0:42:44.130912\n",
      "0.9057923\n",
      "[Epoch 28/50] [Batch 191/300] [D loss: 0.752423] [G loss: 0.510889] time: 0:42:44.425532\n",
      "0.9148558\n",
      "[Epoch 28/50] [Batch 192/300] [D loss: 0.752423] [G loss: 0.496530] time: 0:42:44.720426\n",
      "0.91032535\n",
      "[Epoch 28/50] [Batch 193/300] [D loss: 0.752417] [G loss: 0.505528] time: 0:42:45.011825\n",
      "0.9334183\n",
      "[Epoch 28/50] [Batch 194/300] [D loss: 0.752428] [G loss: 0.485457] time: 0:42:45.296726\n",
      "0.89196473\n",
      "[Epoch 28/50] [Batch 195/300] [D loss: 0.752401] [G loss: 0.506493] time: 0:42:45.594863\n",
      "0.9317291\n",
      "[Epoch 28/50] [Batch 196/300] [D loss: 0.752399] [G loss: 0.499087] time: 0:42:45.890565\n",
      "0.90920764\n",
      "[Epoch 28/50] [Batch 197/300] [D loss: 0.752435] [G loss: 0.489416] time: 0:42:46.179241\n",
      "0.9591164\n",
      "[Epoch 28/50] [Batch 198/300] [D loss: 0.752454] [G loss: 0.483919] time: 0:42:46.466472\n",
      "0.9182649\n",
      "[Epoch 28/50] [Batch 199/300] [D loss: 0.752410] [G loss: 0.539520] time: 0:42:46.758452\n",
      "0.9068961\n",
      "[Epoch 28/50] [Batch 200/300] [D loss: 0.752424] [G loss: 0.484815] time: 0:42:47.058743\n",
      "0.8487895\n",
      "[Epoch 28/50] [Batch 201/300] [D loss: 0.752428] [G loss: 0.535349] time: 0:42:47.340642\n",
      "0.9065862\n",
      "[Epoch 28/50] [Batch 202/300] [D loss: 0.752429] [G loss: 0.492653] time: 0:42:47.636109\n",
      "0.9095133\n",
      "[Epoch 28/50] [Batch 203/300] [D loss: 0.752418] [G loss: 0.488649] time: 0:42:47.954263\n",
      "0.8954461\n",
      "[Epoch 28/50] [Batch 204/300] [D loss: 0.752409] [G loss: 0.493557] time: 0:42:48.250809\n",
      "0.93373793\n",
      "[Epoch 28/50] [Batch 205/300] [D loss: 0.752430] [G loss: 0.503574] time: 0:42:48.563072\n",
      "0.90576595\n",
      "[Epoch 28/50] [Batch 206/300] [D loss: 0.752431] [G loss: 0.506343] time: 0:42:48.863237\n",
      "0.93805104\n",
      "[Epoch 28/50] [Batch 207/300] [D loss: 0.752418] [G loss: 0.489030] time: 0:42:49.180630\n",
      "0.8897918\n",
      "[Epoch 28/50] [Batch 208/300] [D loss: 0.752429] [G loss: 0.523906] time: 0:42:49.488009\n",
      "0.9135775\n",
      "[Epoch 28/50] [Batch 209/300] [D loss: 0.752427] [G loss: 0.506451] time: 0:42:49.802536\n",
      "0.9061586\n",
      "[Epoch 28/50] [Batch 210/300] [D loss: 0.752433] [G loss: 0.500624] time: 0:42:50.097494\n",
      "0.9760731\n",
      "[Epoch 28/50] [Batch 211/300] [D loss: 0.752427] [G loss: 0.500588] time: 0:42:50.377381\n",
      "0.92533225\n",
      "[Epoch 28/50] [Batch 212/300] [D loss: 0.752423] [G loss: 0.481493] time: 0:42:50.680647\n",
      "0.9480172\n",
      "[Epoch 28/50] [Batch 213/300] [D loss: 0.752410] [G loss: 0.481354] time: 0:42:50.978243\n",
      "0.936855\n",
      "[Epoch 28/50] [Batch 214/300] [D loss: 0.752425] [G loss: 0.507627] time: 0:42:51.260013\n",
      "0.9339215\n",
      "[Epoch 28/50] [Batch 215/300] [D loss: 0.752459] [G loss: 0.507777] time: 0:42:51.560515\n",
      "0.9047294\n",
      "[Epoch 28/50] [Batch 216/300] [D loss: 0.752434] [G loss: 0.526215] time: 0:42:51.860787\n",
      "0.9471728\n",
      "[Epoch 28/50] [Batch 217/300] [D loss: 0.752423] [G loss: 0.503819] time: 0:42:52.155688\n",
      "0.9203711\n",
      "[Epoch 28/50] [Batch 218/300] [D loss: 0.752442] [G loss: 0.529857] time: 0:42:52.465767\n",
      "0.92886645\n",
      "[Epoch 28/50] [Batch 219/300] [D loss: 0.752421] [G loss: 0.503386] time: 0:42:52.779270\n",
      "0.9139162\n",
      "[Epoch 28/50] [Batch 220/300] [D loss: 0.752425] [G loss: 0.482888] time: 0:42:53.056384\n",
      "0.9471422\n",
      "[Epoch 28/50] [Batch 221/300] [D loss: 0.752429] [G loss: 0.488823] time: 0:42:53.349995\n",
      "0.8766367\n",
      "[Epoch 28/50] [Batch 222/300] [D loss: 0.752430] [G loss: 0.531586] time: 0:42:53.652948\n",
      "0.94565064\n",
      "[Epoch 28/50] [Batch 223/300] [D loss: 0.752433] [G loss: 0.513246] time: 0:42:53.971039\n",
      "0.9478056\n",
      "[Epoch 28/50] [Batch 224/300] [D loss: 0.752420] [G loss: 0.518599] time: 0:42:54.281243\n",
      "0.89951557\n",
      "[Epoch 28/50] [Batch 225/300] [D loss: 0.752401] [G loss: 0.502569] time: 0:42:54.573494\n",
      "0.92783093\n",
      "[Epoch 28/50] [Batch 226/300] [D loss: 0.752418] [G loss: 0.497640] time: 0:42:54.882056\n",
      "0.891485\n",
      "[Epoch 28/50] [Batch 227/300] [D loss: 0.752444] [G loss: 0.498630] time: 0:42:55.177824\n",
      "0.92706513\n",
      "[Epoch 28/50] [Batch 228/300] [D loss: 0.752422] [G loss: 0.512988] time: 0:42:55.490282\n",
      "0.89495826\n",
      "[Epoch 28/50] [Batch 229/300] [D loss: 0.752419] [G loss: 0.515768] time: 0:42:55.801321\n",
      "0.9122823\n",
      "[Epoch 28/50] [Batch 230/300] [D loss: 0.752417] [G loss: 0.520489] time: 0:42:56.094186\n",
      "0.8994115\n",
      "[Epoch 28/50] [Batch 231/300] [D loss: 0.752420] [G loss: 0.493185] time: 0:42:56.401226\n",
      "0.9668064\n",
      "[Epoch 28/50] [Batch 232/300] [D loss: 0.752427] [G loss: 0.490960] time: 0:42:56.703637\n",
      "0.9703339\n",
      "[Epoch 28/50] [Batch 233/300] [D loss: 0.752429] [G loss: 0.502178] time: 0:42:57.008642\n",
      "0.95126486\n",
      "[Epoch 28/50] [Batch 234/300] [D loss: 0.752407] [G loss: 0.487075] time: 0:42:57.300094\n",
      "0.90455675\n",
      "[Epoch 28/50] [Batch 235/300] [D loss: 0.752428] [G loss: 0.523385] time: 0:42:57.599637\n",
      "0.9142702\n",
      "[Epoch 28/50] [Batch 236/300] [D loss: 0.752423] [G loss: 0.497979] time: 0:42:57.895701\n",
      "0.93863624\n",
      "[Epoch 28/50] [Batch 237/300] [D loss: 0.752422] [G loss: 0.501998] time: 0:42:58.196201\n",
      "0.96235126\n",
      "[Epoch 28/50] [Batch 238/300] [D loss: 0.752413] [G loss: 0.486102] time: 0:42:58.493525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641282\n",
      "[Epoch 28/50] [Batch 239/300] [D loss: 0.752430] [G loss: 0.513765] time: 0:42:58.790297\n",
      "0.9217623\n",
      "[Epoch 28/50] [Batch 240/300] [D loss: 0.752427] [G loss: 0.500376] time: 0:42:59.084029\n",
      "0.8849105\n",
      "[Epoch 28/50] [Batch 241/300] [D loss: 0.752419] [G loss: 0.492381] time: 0:42:59.381977\n",
      "0.88732934\n",
      "[Epoch 28/50] [Batch 242/300] [D loss: 0.752402] [G loss: 0.487960] time: 0:42:59.673662\n",
      "0.9659993\n",
      "[Epoch 28/50] [Batch 243/300] [D loss: 0.752420] [G loss: 0.480380] time: 0:42:59.970064\n",
      "0.8822256\n",
      "[Epoch 28/50] [Batch 244/300] [D loss: 0.752418] [G loss: 0.490346] time: 0:43:00.269799\n",
      "0.9669376\n",
      "[Epoch 28/50] [Batch 245/300] [D loss: 0.752430] [G loss: 0.486407] time: 0:43:00.573935\n",
      "0.88483053\n",
      "[Epoch 28/50] [Batch 246/300] [D loss: 0.752436] [G loss: 0.488567] time: 0:43:00.874085\n",
      "0.9108086\n",
      "[Epoch 28/50] [Batch 247/300] [D loss: 0.752420] [G loss: 0.495833] time: 0:43:01.162668\n",
      "0.9280412\n",
      "[Epoch 28/50] [Batch 248/300] [D loss: 0.752417] [G loss: 0.478645] time: 0:43:01.480750\n",
      "0.9309869\n",
      "[Epoch 28/50] [Batch 249/300] [D loss: 0.752432] [G loss: 0.480934] time: 0:43:01.776865\n",
      "0.9363478\n",
      "[Epoch 28/50] [Batch 250/300] [D loss: 0.752428] [G loss: 0.498571] time: 0:43:02.068768\n",
      "0.88935095\n",
      "[Epoch 28/50] [Batch 251/300] [D loss: 0.752429] [G loss: 0.494058] time: 0:43:02.346355\n",
      "0.89865255\n",
      "[Epoch 28/50] [Batch 252/300] [D loss: 0.752405] [G loss: 0.485591] time: 0:43:02.655471\n",
      "0.9578478\n",
      "[Epoch 28/50] [Batch 253/300] [D loss: 0.752460] [G loss: 0.489933] time: 0:43:02.967600\n",
      "0.97008866\n",
      "[Epoch 28/50] [Batch 254/300] [D loss: 0.752416] [G loss: 0.520686] time: 0:43:03.270200\n",
      "0.921536\n",
      "[Epoch 28/50] [Batch 255/300] [D loss: 0.752414] [G loss: 0.498958] time: 0:43:03.557769\n",
      "0.9558236\n",
      "[Epoch 28/50] [Batch 256/300] [D loss: 0.752419] [G loss: 0.504682] time: 0:43:03.830337\n",
      "0.9437442\n",
      "[Epoch 28/50] [Batch 257/300] [D loss: 0.752448] [G loss: 0.492782] time: 0:43:04.147693\n",
      "0.9588173\n",
      "[Epoch 28/50] [Batch 258/300] [D loss: 0.752427] [G loss: 0.526138] time: 0:43:04.461346\n",
      "0.8815585\n",
      "[Epoch 28/50] [Batch 259/300] [D loss: 0.752422] [G loss: 0.497591] time: 0:43:04.737181\n",
      "0.89479655\n",
      "[Epoch 28/50] [Batch 260/300] [D loss: 0.752397] [G loss: 0.504563] time: 0:43:05.031435\n",
      "0.87182504\n",
      "[Epoch 28/50] [Batch 261/300] [D loss: 0.752404] [G loss: 0.485178] time: 0:43:05.311999\n",
      "0.8863656\n",
      "[Epoch 28/50] [Batch 262/300] [D loss: 0.752416] [G loss: 0.514123] time: 0:43:05.609844\n",
      "0.9528384\n",
      "[Epoch 28/50] [Batch 263/300] [D loss: 0.752412] [G loss: 0.514140] time: 0:43:05.902309\n",
      "0.9397966\n",
      "[Epoch 28/50] [Batch 264/300] [D loss: 0.752402] [G loss: 0.491285] time: 0:43:06.193362\n",
      "0.9714458\n",
      "[Epoch 28/50] [Batch 265/300] [D loss: 0.752407] [G loss: 0.501528] time: 0:43:06.497194\n",
      "0.9002306\n",
      "[Epoch 28/50] [Batch 266/300] [D loss: 0.752419] [G loss: 0.494891] time: 0:43:06.785136\n",
      "0.91645366\n",
      "[Epoch 28/50] [Batch 267/300] [D loss: 0.752419] [G loss: 0.510361] time: 0:43:07.100351\n",
      "0.9127138\n",
      "[Epoch 28/50] [Batch 268/300] [D loss: 0.752423] [G loss: 0.499580] time: 0:43:07.401971\n",
      "0.9597695\n",
      "[Epoch 28/50] [Batch 269/300] [D loss: 0.752471] [G loss: 0.489982] time: 0:43:07.697806\n",
      "0.91658545\n",
      "[Epoch 28/50] [Batch 270/300] [D loss: 0.752414] [G loss: 0.511408] time: 0:43:07.999262\n",
      "0.89223367\n",
      "[Epoch 28/50] [Batch 271/300] [D loss: 0.752444] [G loss: 0.483687] time: 0:43:08.292593\n",
      "0.93459296\n",
      "[Epoch 28/50] [Batch 272/300] [D loss: 0.752437] [G loss: 0.498195] time: 0:43:08.586734\n",
      "0.8976753\n",
      "[Epoch 28/50] [Batch 273/300] [D loss: 0.752455] [G loss: 0.500929] time: 0:43:08.887813\n",
      "0.88395166\n",
      "[Epoch 28/50] [Batch 274/300] [D loss: 0.752421] [G loss: 0.507237] time: 0:43:09.180475\n",
      "0.9423866\n",
      "[Epoch 28/50] [Batch 275/300] [D loss: 0.752429] [G loss: 0.507720] time: 0:43:09.503430\n",
      "0.9397158\n",
      "[Epoch 28/50] [Batch 276/300] [D loss: 0.752418] [G loss: 0.537342] time: 0:43:09.785261\n",
      "0.9271049\n",
      "[Epoch 28/50] [Batch 277/300] [D loss: 0.752420] [G loss: 0.501568] time: 0:43:10.089492\n",
      "0.9539957\n",
      "[Epoch 28/50] [Batch 278/300] [D loss: 0.752401] [G loss: 0.510203] time: 0:43:10.386211\n",
      "0.92212987\n",
      "[Epoch 28/50] [Batch 279/300] [D loss: 0.752410] [G loss: 0.508388] time: 0:43:10.684140\n",
      "0.88865024\n",
      "[Epoch 28/50] [Batch 280/300] [D loss: 0.752428] [G loss: 0.482231] time: 0:43:11.117901\n",
      "0.9278464\n",
      "[Epoch 28/50] [Batch 281/300] [D loss: 0.752407] [G loss: 0.492317] time: 0:43:11.421179\n",
      "0.9275842\n",
      "[Epoch 28/50] [Batch 282/300] [D loss: 0.752397] [G loss: 0.557808] time: 0:43:11.732319\n",
      "0.9488859\n",
      "[Epoch 28/50] [Batch 283/300] [D loss: 0.752414] [G loss: 0.489815] time: 0:43:12.033059\n",
      "0.91081625\n",
      "[Epoch 28/50] [Batch 284/300] [D loss: 0.752420] [G loss: 0.518249] time: 0:43:12.310562\n",
      "0.87211114\n",
      "[Epoch 28/50] [Batch 285/300] [D loss: 0.752418] [G loss: 0.480760] time: 0:43:12.630052\n",
      "0.9530194\n",
      "[Epoch 28/50] [Batch 286/300] [D loss: 0.752414] [G loss: 0.495549] time: 0:43:12.936918\n",
      "0.88176894\n",
      "[Epoch 28/50] [Batch 287/300] [D loss: 0.752418] [G loss: 0.493795] time: 0:43:13.251821\n",
      "0.93352777\n",
      "[Epoch 28/50] [Batch 288/300] [D loss: 0.752424] [G loss: 0.511801] time: 0:43:13.549298\n",
      "0.94727415\n",
      "[Epoch 28/50] [Batch 289/300] [D loss: 0.752413] [G loss: 0.493809] time: 0:43:13.852886\n",
      "0.88870305\n",
      "[Epoch 28/50] [Batch 290/300] [D loss: 0.752438] [G loss: 0.489576] time: 0:43:14.156662\n",
      "0.9145979\n",
      "[Epoch 28/50] [Batch 291/300] [D loss: 0.752415] [G loss: 0.502666] time: 0:43:14.468726\n",
      "0.91185457\n",
      "[Epoch 28/50] [Batch 292/300] [D loss: 0.752416] [G loss: 0.509502] time: 0:43:14.771089\n",
      "0.88398665\n",
      "[Epoch 28/50] [Batch 293/300] [D loss: 0.752412] [G loss: 0.506421] time: 0:43:15.071932\n",
      "0.93465203\n",
      "[Epoch 28/50] [Batch 294/300] [D loss: 0.752438] [G loss: 0.543000] time: 0:43:15.394549\n",
      "0.9133076\n",
      "[Epoch 28/50] [Batch 295/300] [D loss: 0.752425] [G loss: 0.511178] time: 0:43:15.710006\n",
      "0.9143248\n",
      "[Epoch 28/50] [Batch 296/300] [D loss: 0.752406] [G loss: 0.521661] time: 0:43:16.012949\n",
      "0.8996339\n",
      "[Epoch 28/50] [Batch 297/300] [D loss: 0.752411] [G loss: 0.491030] time: 0:43:16.307872\n",
      "0.9279001\n",
      "[Epoch 28/50] [Batch 298/300] [D loss: 0.752413] [G loss: 0.504184] time: 0:43:16.586485\n",
      "0.92879754\n",
      "[Epoch 28/50] [Batch 299/300] [D loss: 0.752408] [G loss: 0.483863] time: 0:43:16.888390\n",
      "0.9340389\n",
      "[Epoch 29/50] [Batch 0/300] [D loss: 0.752412] [G loss: 0.494924] time: 0:43:17.198940\n",
      "0.9374749\n",
      "[Epoch 29/50] [Batch 1/300] [D loss: 0.752402] [G loss: 0.515029] time: 0:43:17.503784\n",
      "0.9317916\n",
      "[Epoch 29/50] [Batch 2/300] [D loss: 0.752422] [G loss: 0.497369] time: 0:43:17.788804\n",
      "0.9373455\n",
      "[Epoch 29/50] [Batch 3/300] [D loss: 0.752440] [G loss: 0.506424] time: 0:43:18.079925\n",
      "0.9029746\n",
      "[Epoch 29/50] [Batch 4/300] [D loss: 0.752432] [G loss: 0.502639] time: 0:43:18.380165\n",
      "0.9300914\n",
      "[Epoch 29/50] [Batch 5/300] [D loss: 0.752421] [G loss: 0.490867] time: 0:43:18.664019\n",
      "0.93938065\n",
      "[Epoch 29/50] [Batch 6/300] [D loss: 0.752434] [G loss: 0.539739] time: 0:43:18.958769\n",
      "0.9357416\n",
      "[Epoch 29/50] [Batch 7/300] [D loss: 0.752433] [G loss: 0.499441] time: 0:43:19.257845\n",
      "0.9450454\n",
      "[Epoch 29/50] [Batch 8/300] [D loss: 0.752422] [G loss: 0.513137] time: 0:43:19.550619\n",
      "0.90233976\n",
      "[Epoch 29/50] [Batch 9/300] [D loss: 0.752418] [G loss: 0.528965] time: 0:43:19.852354\n",
      "0.8995769\n",
      "[Epoch 29/50] [Batch 10/300] [D loss: 0.752433] [G loss: 0.482405] time: 0:43:20.155638\n",
      "0.94515395\n",
      "[Epoch 29/50] [Batch 11/300] [D loss: 0.752401] [G loss: 0.487000] time: 0:43:20.453641\n",
      "0.9601876\n",
      "[Epoch 29/50] [Batch 12/300] [D loss: 0.752400] [G loss: 0.510558] time: 0:43:20.761334\n",
      "0.9649341\n",
      "[Epoch 29/50] [Batch 13/300] [D loss: 0.752423] [G loss: 0.492695] time: 0:43:21.062042\n",
      "0.9339704\n",
      "[Epoch 29/50] [Batch 14/300] [D loss: 0.752418] [G loss: 0.510069] time: 0:43:21.364232\n",
      "0.902713\n",
      "[Epoch 29/50] [Batch 15/300] [D loss: 0.752404] [G loss: 0.550400] time: 0:43:21.649080\n",
      "0.9108076\n",
      "[Epoch 29/50] [Batch 16/300] [D loss: 0.752434] [G loss: 0.505450] time: 0:43:21.954292\n",
      "0.8812615\n",
      "[Epoch 29/50] [Batch 17/300] [D loss: 0.752416] [G loss: 0.491830] time: 0:43:22.255304\n",
      "0.87803775\n",
      "[Epoch 29/50] [Batch 18/300] [D loss: 0.752435] [G loss: 0.480278] time: 0:43:22.566896\n",
      "0.9095099\n",
      "[Epoch 29/50] [Batch 19/300] [D loss: 0.752435] [G loss: 0.514830] time: 0:43:22.870850\n",
      "0.87801814\n",
      "[Epoch 29/50] [Batch 20/300] [D loss: 0.752405] [G loss: 0.505702] time: 0:43:23.172529\n",
      "0.9331376\n",
      "[Epoch 29/50] [Batch 21/300] [D loss: 0.752435] [G loss: 0.487290] time: 0:43:23.472748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9038005\n",
      "[Epoch 29/50] [Batch 22/300] [D loss: 0.752395] [G loss: 0.483250] time: 0:43:23.777846\n",
      "0.94277006\n",
      "[Epoch 29/50] [Batch 23/300] [D loss: 0.752411] [G loss: 0.482800] time: 0:43:24.078041\n",
      "0.95787543\n",
      "[Epoch 29/50] [Batch 24/300] [D loss: 0.752419] [G loss: 0.507407] time: 0:43:24.384762\n",
      "0.9180066\n",
      "[Epoch 29/50] [Batch 25/300] [D loss: 0.752413] [G loss: 0.518816] time: 0:43:24.680573\n",
      "0.9532375\n",
      "[Epoch 29/50] [Batch 26/300] [D loss: 0.752427] [G loss: 0.502743] time: 0:43:24.980062\n",
      "0.9556629\n",
      "[Epoch 29/50] [Batch 27/300] [D loss: 0.752420] [G loss: 0.490760] time: 0:43:25.279036\n",
      "0.94028586\n",
      "[Epoch 29/50] [Batch 29/300] [D loss: 0.752400] [G loss: 0.489546] time: 0:43:25.584731\n",
      "0.92913705\n",
      "[Epoch 29/50] [Batch 30/300] [D loss: 0.752409] [G loss: 0.493384] time: 0:43:25.887766\n",
      "0.9391001\n",
      "[Epoch 29/50] [Batch 31/300] [D loss: 0.752425] [G loss: 0.489152] time: 0:43:26.186993\n",
      "0.9342349\n",
      "[Epoch 29/50] [Batch 32/300] [D loss: 0.752407] [G loss: 0.501699] time: 0:43:26.481075\n",
      "0.9646449\n",
      "[Epoch 29/50] [Batch 33/300] [D loss: 0.752411] [G loss: 0.493488] time: 0:43:26.775110\n",
      "0.8692911\n",
      "[Epoch 29/50] [Batch 34/300] [D loss: 0.752425] [G loss: 0.484807] time: 0:43:27.073170\n",
      "0.8815755\n",
      "[Epoch 29/50] [Batch 35/300] [D loss: 0.752416] [G loss: 0.491955] time: 0:43:27.373678\n",
      "0.9561913\n",
      "[Epoch 29/50] [Batch 36/300] [D loss: 0.752437] [G loss: 0.491900] time: 0:43:27.669977\n",
      "0.9086995\n",
      "[Epoch 29/50] [Batch 37/300] [D loss: 0.752397] [G loss: 0.484165] time: 0:43:27.951228\n",
      "0.89944786\n",
      "[Epoch 29/50] [Batch 38/300] [D loss: 0.752431] [G loss: 0.488176] time: 0:43:28.238478\n",
      "0.924103\n",
      "[Epoch 29/50] [Batch 39/300] [D loss: 0.752436] [G loss: 0.502624] time: 0:43:28.532771\n",
      "0.91662025\n",
      "[Epoch 29/50] [Batch 40/300] [D loss: 0.752418] [G loss: 0.498712] time: 0:43:28.849536\n",
      "0.91190505\n",
      "[Epoch 29/50] [Batch 41/300] [D loss: 0.752405] [G loss: 0.503173] time: 0:43:29.143664\n",
      "0.93176293\n",
      "[Epoch 29/50] [Batch 42/300] [D loss: 0.752410] [G loss: 0.497215] time: 0:43:29.414929\n",
      "0.94556713\n",
      "[Epoch 29/50] [Batch 43/300] [D loss: 0.752404] [G loss: 0.491798] time: 0:43:29.716458\n",
      "0.8802287\n",
      "[Epoch 29/50] [Batch 44/300] [D loss: 0.752414] [G loss: 0.516911] time: 0:43:30.004341\n",
      "0.9743438\n",
      "[Epoch 29/50] [Batch 45/300] [D loss: 0.752409] [G loss: 0.525174] time: 0:43:30.306039\n",
      "0.9252865\n",
      "[Epoch 29/50] [Batch 46/300] [D loss: 0.752415] [G loss: 0.498873] time: 0:43:30.607673\n",
      "0.9505518\n",
      "[Epoch 29/50] [Batch 47/300] [D loss: 0.752420] [G loss: 0.486538] time: 0:43:30.906913\n",
      "0.94519836\n",
      "[Epoch 29/50] [Batch 48/300] [D loss: 0.752422] [G loss: 0.481397] time: 0:43:31.203030\n",
      "0.90423805\n",
      "[Epoch 29/50] [Batch 49/300] [D loss: 0.752426] [G loss: 0.496650] time: 0:43:31.501301\n",
      "0.9322753\n",
      "[Epoch 29/50] [Batch 50/300] [D loss: 0.752427] [G loss: 0.499930] time: 0:43:31.805442\n",
      "0.92688054\n",
      "[Epoch 29/50] [Batch 51/300] [D loss: 0.752429] [G loss: 0.498900] time: 0:43:32.103983\n",
      "0.9523806\n",
      "[Epoch 29/50] [Batch 52/300] [D loss: 0.752422] [G loss: 0.491480] time: 0:43:32.389965\n",
      "0.9198367\n",
      "[Epoch 29/50] [Batch 53/300] [D loss: 0.752393] [G loss: 0.506227] time: 0:43:32.686376\n",
      "0.88659906\n",
      "[Epoch 29/50] [Batch 54/300] [D loss: 0.752418] [G loss: 0.515688] time: 0:43:32.988351\n",
      "0.96339434\n",
      "[Epoch 29/50] [Batch 55/300] [D loss: 0.752402] [G loss: 0.493603] time: 0:43:33.284270\n",
      "0.94526404\n",
      "[Epoch 29/50] [Batch 56/300] [D loss: 0.752441] [G loss: 0.492259] time: 0:43:33.574109\n",
      "0.8963674\n",
      "[Epoch 29/50] [Batch 57/300] [D loss: 0.752406] [G loss: 0.493888] time: 0:43:33.876146\n",
      "0.9081786\n",
      "[Epoch 29/50] [Batch 58/300] [D loss: 0.752409] [G loss: 0.490584] time: 0:43:34.160692\n",
      "0.9707691\n",
      "[Epoch 29/50] [Batch 59/300] [D loss: 0.752417] [G loss: 0.495580] time: 0:43:34.468927\n",
      "0.9136339\n",
      "[Epoch 29/50] [Batch 60/300] [D loss: 0.752402] [G loss: 0.475485] time: 0:43:34.768562\n",
      "0.88222665\n",
      "[Epoch 29/50] [Batch 61/300] [D loss: 0.752420] [G loss: 0.489505] time: 0:43:35.067943\n",
      "0.8945059\n",
      "[Epoch 29/50] [Batch 62/300] [D loss: 0.752411] [G loss: 0.489451] time: 0:43:35.359003\n",
      "0.9290616\n",
      "[Epoch 29/50] [Batch 63/300] [D loss: 0.752394] [G loss: 0.499602] time: 0:43:35.670217\n",
      "0.90759534\n",
      "[Epoch 29/50] [Batch 64/300] [D loss: 0.752398] [G loss: 0.484288] time: 0:43:35.968475\n",
      "0.884969\n",
      "[Epoch 29/50] [Batch 65/300] [D loss: 0.752390] [G loss: 0.490439] time: 0:43:36.271111\n",
      "0.941854\n",
      "[Epoch 29/50] [Batch 66/300] [D loss: 0.752417] [G loss: 0.535112] time: 0:43:36.584232\n",
      "0.9419808\n",
      "[Epoch 29/50] [Batch 67/300] [D loss: 0.752410] [G loss: 0.481175] time: 0:43:36.868287\n",
      "0.90654105\n",
      "[Epoch 29/50] [Batch 68/300] [D loss: 0.752411] [G loss: 0.487071] time: 0:43:37.191945\n",
      "0.8995557\n",
      "[Epoch 29/50] [Batch 69/300] [D loss: 0.752413] [G loss: 0.490166] time: 0:43:37.499161\n",
      "0.9348755\n",
      "[Epoch 29/50] [Batch 70/300] [D loss: 0.752410] [G loss: 0.504279] time: 0:43:37.796333\n",
      "0.9326795\n",
      "[Epoch 29/50] [Batch 71/300] [D loss: 0.752420] [G loss: 0.493454] time: 0:43:38.071912\n",
      "0.9330437\n",
      "[Epoch 29/50] [Batch 72/300] [D loss: 0.752422] [G loss: 0.498521] time: 0:43:38.368070\n",
      "0.9166212\n",
      "[Epoch 29/50] [Batch 73/300] [D loss: 0.752419] [G loss: 0.508171] time: 0:43:38.666126\n",
      "0.9500908\n",
      "[Epoch 29/50] [Batch 74/300] [D loss: 0.752414] [G loss: 0.526109] time: 0:43:38.952984\n",
      "0.9054511\n",
      "[Epoch 29/50] [Batch 75/300] [D loss: 0.752414] [G loss: 0.476257] time: 0:43:39.257827\n",
      "0.94309396\n",
      "[Epoch 29/50] [Batch 76/300] [D loss: 0.752436] [G loss: 0.482292] time: 0:43:39.569588\n",
      "0.8960213\n",
      "[Epoch 29/50] [Batch 77/300] [D loss: 0.752410] [G loss: 0.521092] time: 0:43:39.850407\n",
      "0.9306739\n",
      "[Epoch 29/50] [Batch 78/300] [D loss: 0.752411] [G loss: 0.491989] time: 0:43:40.144226\n",
      "0.9065008\n",
      "[Epoch 29/50] [Batch 79/300] [D loss: 0.752416] [G loss: 0.482453] time: 0:43:40.465881\n",
      "0.90273166\n",
      "[Epoch 29/50] [Batch 80/300] [D loss: 0.752418] [G loss: 0.490331] time: 0:43:40.771468\n",
      "0.9395564\n",
      "[Epoch 29/50] [Batch 81/300] [D loss: 0.752412] [G loss: 0.483439] time: 0:43:41.066046\n",
      "0.9270995\n",
      "[Epoch 29/50] [Batch 82/300] [D loss: 0.752407] [G loss: 0.481460] time: 0:43:41.346041\n",
      "0.8991119\n",
      "[Epoch 29/50] [Batch 83/300] [D loss: 0.752417] [G loss: 0.490568] time: 0:43:41.644560\n",
      "0.94147927\n",
      "[Epoch 29/50] [Batch 84/300] [D loss: 0.752403] [G loss: 0.487756] time: 0:43:41.941877\n",
      "0.9287651\n",
      "[Epoch 29/50] [Batch 85/300] [D loss: 0.752415] [G loss: 0.493545] time: 0:43:42.237842\n",
      "0.91186196\n",
      "[Epoch 29/50] [Batch 86/300] [D loss: 0.752425] [G loss: 0.503660] time: 0:43:42.560874\n",
      "0.9063766\n",
      "[Epoch 29/50] [Batch 87/300] [D loss: 0.752422] [G loss: 0.503466] time: 0:43:42.850961\n",
      "0.94255525\n",
      "[Epoch 29/50] [Batch 88/300] [D loss: 0.752408] [G loss: 0.507900] time: 0:43:43.143126\n",
      "0.9187862\n",
      "[Epoch 29/50] [Batch 89/300] [D loss: 0.752399] [G loss: 0.491367] time: 0:43:43.437519\n",
      "0.93297106\n",
      "[Epoch 29/50] [Batch 90/300] [D loss: 0.752415] [G loss: 0.480784] time: 0:43:43.733537\n",
      "0.9383444\n",
      "[Epoch 29/50] [Batch 91/300] [D loss: 0.752412] [G loss: 0.490792] time: 0:43:44.052274\n",
      "0.9038505\n",
      "[Epoch 29/50] [Batch 92/300] [D loss: 0.752403] [G loss: 0.505783] time: 0:43:44.372660\n",
      "0.93038315\n",
      "[Epoch 29/50] [Batch 93/300] [D loss: 0.752430] [G loss: 0.509379] time: 0:43:44.668415\n",
      "0.91755956\n",
      "[Epoch 29/50] [Batch 94/300] [D loss: 0.752416] [G loss: 0.486037] time: 0:43:44.963627\n",
      "0.9524643\n",
      "[Epoch 29/50] [Batch 95/300] [D loss: 0.752415] [G loss: 0.496174] time: 0:43:45.259994\n",
      "0.9070441\n",
      "[Epoch 29/50] [Batch 96/300] [D loss: 0.752424] [G loss: 0.523301] time: 0:43:45.543450\n",
      "0.91125005\n",
      "[Epoch 29/50] [Batch 97/300] [D loss: 0.752418] [G loss: 0.490468] time: 0:43:45.820027\n",
      "0.9004027\n",
      "[Epoch 29/50] [Batch 98/300] [D loss: 0.752404] [G loss: 0.494915] time: 0:43:46.133315\n",
      "0.8880808\n",
      "[Epoch 29/50] [Batch 99/300] [D loss: 0.752404] [G loss: 0.500890] time: 0:43:46.407759\n",
      "0.9087975\n",
      "[Epoch 29/50] [Batch 100/300] [D loss: 0.752422] [G loss: 0.487312] time: 0:43:46.702004\n",
      "0.9425352\n",
      "[Epoch 29/50] [Batch 101/300] [D loss: 0.752425] [G loss: 0.552673] time: 0:43:47.016025\n",
      "0.9343009\n",
      "[Epoch 29/50] [Batch 102/300] [D loss: 0.752405] [G loss: 0.489497] time: 0:43:47.305827\n",
      "0.8998993\n",
      "[Epoch 29/50] [Batch 103/300] [D loss: 0.752433] [G loss: 0.501873] time: 0:43:47.610620\n",
      "0.9157558\n",
      "[Epoch 29/50] [Batch 104/300] [D loss: 0.752429] [G loss: 0.501709] time: 0:43:47.888090\n",
      "0.95528245\n",
      "[Epoch 29/50] [Batch 105/300] [D loss: 0.752426] [G loss: 0.501812] time: 0:43:48.201353\n",
      "0.9274128\n",
      "[Epoch 29/50] [Batch 106/300] [D loss: 0.752410] [G loss: 0.527371] time: 0:43:48.482682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380767\n",
      "[Epoch 29/50] [Batch 107/300] [D loss: 0.752413] [G loss: 0.513162] time: 0:43:48.774246\n",
      "0.8875602\n",
      "[Epoch 29/50] [Batch 108/300] [D loss: 0.752417] [G loss: 0.504761] time: 0:43:49.066595\n",
      "0.9717396\n",
      "[Epoch 29/50] [Batch 109/300] [D loss: 0.752392] [G loss: 0.487862] time: 0:43:49.377746\n",
      "0.89961594\n",
      "[Epoch 29/50] [Batch 110/300] [D loss: 0.752404] [G loss: 0.488410] time: 0:43:49.671389\n",
      "0.9581799\n",
      "[Epoch 29/50] [Batch 111/300] [D loss: 0.752433] [G loss: 0.497538] time: 0:43:49.975076\n",
      "0.9114972\n",
      "[Epoch 29/50] [Batch 112/300] [D loss: 0.752406] [G loss: 0.504773] time: 0:43:50.278393\n",
      "0.9550901\n",
      "[Epoch 29/50] [Batch 113/300] [D loss: 0.752396] [G loss: 0.507821] time: 0:43:50.580652\n",
      "0.9622436\n",
      "[Epoch 29/50] [Batch 114/300] [D loss: 0.752421] [G loss: 0.509545] time: 0:43:50.869911\n",
      "0.97058564\n",
      "[Epoch 29/50] [Batch 115/300] [D loss: 0.752422] [G loss: 0.480453] time: 0:43:51.157942\n",
      "0.92727137\n",
      "[Epoch 29/50] [Batch 116/300] [D loss: 0.752414] [G loss: 0.482216] time: 0:43:51.463803\n",
      "0.9459157\n",
      "[Epoch 29/50] [Batch 117/300] [D loss: 0.752435] [G loss: 0.496270] time: 0:43:51.760039\n",
      "0.9194898\n",
      "[Epoch 29/50] [Batch 118/300] [D loss: 0.752401] [G loss: 0.493712] time: 0:43:52.054179\n",
      "0.9196546\n",
      "[Epoch 29/50] [Batch 119/300] [D loss: 0.752409] [G loss: 0.514945] time: 0:43:52.354960\n",
      "0.93921137\n",
      "[Epoch 29/50] [Batch 120/300] [D loss: 0.752416] [G loss: 0.485638] time: 0:43:52.652621\n",
      "0.9676357\n",
      "[Epoch 29/50] [Batch 121/300] [D loss: 0.752405] [G loss: 0.484992] time: 0:43:52.968370\n",
      "0.9077499\n",
      "[Epoch 29/50] [Batch 122/300] [D loss: 0.752405] [G loss: 0.531137] time: 0:43:53.269538\n",
      "0.91678953\n",
      "[Epoch 29/50] [Batch 123/300] [D loss: 0.752425] [G loss: 0.517219] time: 0:43:53.561971\n",
      "0.9754843\n",
      "[Epoch 29/50] [Batch 124/300] [D loss: 0.752418] [G loss: 0.519380] time: 0:43:53.859955\n",
      "0.90570045\n",
      "[Epoch 29/50] [Batch 125/300] [D loss: 0.752398] [G loss: 0.483681] time: 0:43:54.155566\n",
      "0.9375813\n",
      "[Epoch 29/50] [Batch 126/300] [D loss: 0.752433] [G loss: 0.514875] time: 0:43:54.466878\n",
      "0.9452052\n",
      "[Epoch 29/50] [Batch 127/300] [D loss: 0.752419] [G loss: 0.483659] time: 0:43:54.762272\n",
      "0.91366524\n",
      "[Epoch 29/50] [Batch 128/300] [D loss: 0.752406] [G loss: 0.513967] time: 0:43:55.054476\n",
      "0.91237646\n",
      "[Epoch 29/50] [Batch 129/300] [D loss: 0.752431] [G loss: 0.491964] time: 0:43:55.351156\n",
      "0.8530204\n",
      "[Epoch 29/50] [Batch 130/300] [D loss: 0.752431] [G loss: 0.516132] time: 0:43:55.646229\n",
      "0.9422407\n",
      "[Epoch 29/50] [Batch 131/300] [D loss: 0.752444] [G loss: 0.507167] time: 0:43:55.949793\n",
      "0.93083423\n",
      "[Epoch 29/50] [Batch 132/300] [D loss: 0.752406] [G loss: 0.507173] time: 0:43:56.244027\n",
      "0.96935827\n",
      "[Epoch 29/50] [Batch 133/300] [D loss: 0.752406] [G loss: 0.500113] time: 0:43:56.549816\n",
      "0.8904932\n",
      "[Epoch 29/50] [Batch 134/300] [D loss: 0.752418] [G loss: 0.514090] time: 0:43:56.858472\n",
      "0.89957625\n",
      "[Epoch 29/50] [Batch 135/300] [D loss: 0.752411] [G loss: 0.492955] time: 0:43:57.145783\n",
      "0.9331004\n",
      "[Epoch 29/50] [Batch 136/300] [D loss: 0.752402] [G loss: 0.489039] time: 0:43:57.454160\n",
      "0.9332776\n",
      "[Epoch 29/50] [Batch 137/300] [D loss: 0.752430] [G loss: 0.494448] time: 0:43:57.749036\n",
      "0.88169694\n",
      "[Epoch 29/50] [Batch 138/300] [D loss: 0.752404] [G loss: 0.486386] time: 0:43:58.051378\n",
      "0.9194458\n",
      "[Epoch 29/50] [Batch 139/300] [D loss: 0.752406] [G loss: 0.496504] time: 0:43:58.353959\n",
      "0.91543674\n",
      "[Epoch 29/50] [Batch 140/300] [D loss: 0.752417] [G loss: 0.483867] time: 0:43:58.660873\n",
      "0.95699483\n",
      "[Epoch 29/50] [Batch 141/300] [D loss: 0.752407] [G loss: 0.510256] time: 0:43:58.961050\n",
      "0.91002256\n",
      "[Epoch 29/50] [Batch 142/300] [D loss: 0.752394] [G loss: 0.498243] time: 0:43:59.267050\n",
      "0.88463014\n",
      "[Epoch 29/50] [Batch 143/300] [D loss: 0.752409] [G loss: 0.514573] time: 0:43:59.562079\n",
      "0.95302373\n",
      "[Epoch 29/50] [Batch 144/300] [D loss: 0.752401] [G loss: 0.518037] time: 0:43:59.859892\n",
      "0.912864\n",
      "[Epoch 29/50] [Batch 145/300] [D loss: 0.752420] [G loss: 0.499539] time: 0:44:00.156763\n",
      "0.90738386\n",
      "[Epoch 29/50] [Batch 146/300] [D loss: 0.752426] [G loss: 0.487149] time: 0:44:00.456213\n",
      "0.94277495\n",
      "[Epoch 29/50] [Batch 147/300] [D loss: 0.752399] [G loss: 0.501897] time: 0:44:00.761071\n",
      "0.92827296\n",
      "[Epoch 29/50] [Batch 148/300] [D loss: 0.752405] [G loss: 0.505335] time: 0:44:01.072665\n",
      "0.9211412\n",
      "[Epoch 29/50] [Batch 149/300] [D loss: 0.752397] [G loss: 0.514102] time: 0:44:01.369204\n",
      "0.9219982\n",
      "[Epoch 29/50] [Batch 150/300] [D loss: 0.752418] [G loss: 0.487294] time: 0:44:01.658441\n",
      "0.8760336\n",
      "[Epoch 29/50] [Batch 151/300] [D loss: 0.752409] [G loss: 0.481102] time: 0:44:01.963787\n",
      "0.90523857\n",
      "[Epoch 29/50] [Batch 152/300] [D loss: 0.752403] [G loss: 0.490695] time: 0:44:02.272221\n",
      "0.916537\n",
      "[Epoch 29/50] [Batch 153/300] [D loss: 0.752378] [G loss: 0.497949] time: 0:44:02.583757\n",
      "0.9530547\n",
      "[Epoch 29/50] [Batch 154/300] [D loss: 0.752409] [G loss: 0.489220] time: 0:44:02.891235\n",
      "0.937017\n",
      "[Epoch 29/50] [Batch 155/300] [D loss: 0.752408] [G loss: 0.496092] time: 0:44:03.202600\n",
      "0.94524175\n",
      "[Epoch 29/50] [Batch 156/300] [D loss: 0.752423] [G loss: 0.515163] time: 0:44:03.511976\n",
      "0.93948394\n",
      "[Epoch 29/50] [Batch 157/300] [D loss: 0.752418] [G loss: 0.502574] time: 0:44:03.798076\n",
      "0.930296\n",
      "[Epoch 29/50] [Batch 158/300] [D loss: 0.752394] [G loss: 0.497866] time: 0:44:04.091309\n",
      "0.9760844\n",
      "[Epoch 29/50] [Batch 159/300] [D loss: 0.752407] [G loss: 0.492496] time: 0:44:04.409279\n",
      "0.93709254\n",
      "[Epoch 29/50] [Batch 160/300] [D loss: 0.752402] [G loss: 0.477585] time: 0:44:04.702180\n",
      "0.9714427\n",
      "[Epoch 29/50] [Batch 161/300] [D loss: 0.752414] [G loss: 0.482103] time: 0:44:05.011236\n",
      "0.9193776\n",
      "[Epoch 29/50] [Batch 162/300] [D loss: 0.752400] [G loss: 0.500165] time: 0:44:05.303480\n",
      "0.9249089\n",
      "[Epoch 29/50] [Batch 163/300] [D loss: 0.752414] [G loss: 0.492288] time: 0:44:05.607291\n",
      "0.8815239\n",
      "[Epoch 29/50] [Batch 164/300] [D loss: 0.752419] [G loss: 0.500895] time: 0:44:05.907591\n",
      "0.9211301\n",
      "[Epoch 29/50] [Batch 165/300] [D loss: 0.752409] [G loss: 0.509666] time: 0:44:06.197906\n",
      "0.9477027\n",
      "[Epoch 29/50] [Batch 166/300] [D loss: 0.752406] [G loss: 0.494628] time: 0:44:06.493445\n",
      "0.9065829\n",
      "[Epoch 29/50] [Batch 167/300] [D loss: 0.752411] [G loss: 0.510911] time: 0:44:06.803201\n",
      "0.9123891\n",
      "[Epoch 29/50] [Batch 168/300] [D loss: 0.752400] [G loss: 0.486387] time: 0:44:07.108578\n",
      "0.9113384\n",
      "[Epoch 29/50] [Batch 169/300] [D loss: 0.752408] [G loss: 0.514263] time: 0:44:07.397812\n",
      "0.89899206\n",
      "[Epoch 29/50] [Batch 170/300] [D loss: 0.752416] [G loss: 0.503740] time: 0:44:07.678075\n",
      "0.909422\n",
      "[Epoch 29/50] [Batch 171/300] [D loss: 0.752421] [G loss: 0.515319] time: 0:44:07.991609\n",
      "0.95877486\n",
      "[Epoch 29/50] [Batch 172/300] [D loss: 0.752407] [G loss: 0.492185] time: 0:44:08.275365\n",
      "0.8918373\n",
      "[Epoch 29/50] [Batch 173/300] [D loss: 0.752415] [G loss: 0.506174] time: 0:44:08.579915\n",
      "0.9370334\n",
      "[Epoch 29/50] [Batch 174/300] [D loss: 0.752402] [G loss: 0.497006] time: 0:44:08.865302\n",
      "0.9699914\n",
      "[Epoch 29/50] [Batch 175/300] [D loss: 0.752410] [G loss: 0.497140] time: 0:44:09.156749\n",
      "0.9086768\n",
      "[Epoch 29/50] [Batch 176/300] [D loss: 0.752404] [G loss: 0.520928] time: 0:44:09.456089\n",
      "0.88808745\n",
      "[Epoch 29/50] [Batch 177/300] [D loss: 0.752397] [G loss: 0.525588] time: 0:44:09.741735\n",
      "0.9063162\n",
      "[Epoch 29/50] [Batch 178/300] [D loss: 0.752420] [G loss: 0.502206] time: 0:44:10.038953\n",
      "0.89495116\n",
      "[Epoch 29/50] [Batch 179/300] [D loss: 0.752410] [G loss: 0.525147] time: 0:44:10.330920\n",
      "0.88895863\n",
      "[Epoch 29/50] [Batch 180/300] [D loss: 0.752419] [G loss: 0.483588] time: 0:44:10.624219\n",
      "0.94181126\n",
      "[Epoch 29/50] [Batch 181/300] [D loss: 0.752399] [G loss: 0.494855] time: 0:44:10.946898\n",
      "0.9111536\n",
      "[Epoch 29/50] [Batch 182/300] [D loss: 0.752411] [G loss: 0.489039] time: 0:44:11.223204\n",
      "0.9349075\n",
      "[Epoch 29/50] [Batch 183/300] [D loss: 0.752417] [G loss: 0.495326] time: 0:44:11.508654\n",
      "0.9372914\n",
      "[Epoch 29/50] [Batch 184/300] [D loss: 0.752413] [G loss: 0.519347] time: 0:44:11.809325\n",
      "0.9270477\n",
      "[Epoch 29/50] [Batch 185/300] [D loss: 0.752403] [G loss: 0.521787] time: 0:44:12.098885\n",
      "0.92716765\n",
      "[Epoch 29/50] [Batch 186/300] [D loss: 0.752402] [G loss: 0.499656] time: 0:44:12.414676\n",
      "0.8882832\n",
      "[Epoch 29/50] [Batch 187/300] [D loss: 0.752408] [G loss: 0.512163] time: 0:44:12.735630\n",
      "0.9796848\n",
      "[Epoch 29/50] [Batch 188/300] [D loss: 0.752399] [G loss: 0.499815] time: 0:44:13.033859\n",
      "0.9206762\n",
      "[Epoch 29/50] [Batch 189/300] [D loss: 0.752409] [G loss: 0.482850] time: 0:44:13.330316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9391017\n",
      "[Epoch 29/50] [Batch 190/300] [D loss: 0.752413] [G loss: 0.495763] time: 0:44:13.627672\n",
      "0.91184735\n",
      "[Epoch 29/50] [Batch 191/300] [D loss: 0.752416] [G loss: 0.520820] time: 0:44:13.933055\n",
      "0.94142884\n",
      "[Epoch 29/50] [Batch 192/300] [D loss: 0.752420] [G loss: 0.496248] time: 0:44:14.228070\n",
      "0.96835715\n",
      "[Epoch 29/50] [Batch 193/300] [D loss: 0.752407] [G loss: 0.500172] time: 0:44:14.512892\n",
      "0.9064379\n",
      "[Epoch 29/50] [Batch 194/300] [D loss: 0.752398] [G loss: 0.486953] time: 0:44:14.808722\n",
      "0.8840854\n",
      "[Epoch 29/50] [Batch 195/300] [D loss: 0.752417] [G loss: 0.516937] time: 0:44:15.111606\n",
      "0.908616\n",
      "[Epoch 29/50] [Batch 196/300] [D loss: 0.752407] [G loss: 0.500552] time: 0:44:15.403711\n",
      "0.8815333\n",
      "[Epoch 29/50] [Batch 197/300] [D loss: 0.752398] [G loss: 0.517842] time: 0:44:15.702663\n",
      "0.9009288\n",
      "[Epoch 29/50] [Batch 198/300] [D loss: 0.752416] [G loss: 0.498444] time: 0:44:15.995477\n",
      "0.90137976\n",
      "[Epoch 29/50] [Batch 199/300] [D loss: 0.752400] [G loss: 0.520636] time: 0:44:16.299027\n",
      "0.9566095\n",
      "[Epoch 29/50] [Batch 200/300] [D loss: 0.752425] [G loss: 0.482805] time: 0:44:16.585744\n",
      "0.93335944\n",
      "[Epoch 29/50] [Batch 201/300] [D loss: 0.752385] [G loss: 0.498535] time: 0:44:16.889369\n",
      "0.90726423\n",
      "[Epoch 29/50] [Batch 202/300] [D loss: 0.752433] [G loss: 0.510092] time: 0:44:17.189977\n",
      "0.92085916\n",
      "[Epoch 29/50] [Batch 203/300] [D loss: 0.752396] [G loss: 0.544909] time: 0:44:17.482599\n",
      "0.9515071\n",
      "[Epoch 29/50] [Batch 204/300] [D loss: 0.752420] [G loss: 0.522307] time: 0:44:17.786757\n",
      "0.8933756\n",
      "[Epoch 29/50] [Batch 205/300] [D loss: 0.752401] [G loss: 0.534357] time: 0:44:18.108404\n",
      "0.9074073\n",
      "[Epoch 29/50] [Batch 206/300] [D loss: 0.752420] [G loss: 0.496353] time: 0:44:18.401029\n",
      "0.89033675\n",
      "[Epoch 29/50] [Batch 207/300] [D loss: 0.752388] [G loss: 0.513452] time: 0:44:18.707172\n",
      "0.93307376\n",
      "[Epoch 29/50] [Batch 208/300] [D loss: 0.752422] [G loss: 0.501686] time: 0:44:19.013446\n",
      "0.91446465\n",
      "[Epoch 29/50] [Batch 209/300] [D loss: 0.752430] [G loss: 0.491610] time: 0:44:19.317904\n",
      "0.97627425\n",
      "[Epoch 29/50] [Batch 210/300] [D loss: 0.752409] [G loss: 0.486558] time: 0:44:19.613567\n",
      "0.9420331\n",
      "[Epoch 29/50] [Batch 211/300] [D loss: 0.752415] [G loss: 0.488465] time: 0:44:19.913079\n",
      "0.91797894\n",
      "[Epoch 29/50] [Batch 212/300] [D loss: 0.752416] [G loss: 0.500797] time: 0:44:20.204729\n",
      "0.89922357\n",
      "[Epoch 29/50] [Batch 213/300] [D loss: 0.752406] [G loss: 0.501268] time: 0:44:20.490442\n",
      "0.8848476\n",
      "[Epoch 29/50] [Batch 214/300] [D loss: 0.752402] [G loss: 0.518060] time: 0:44:20.812366\n",
      "0.8830075\n",
      "[Epoch 29/50] [Batch 215/300] [D loss: 0.752429] [G loss: 0.516891] time: 0:44:21.112475\n",
      "0.969758\n",
      "[Epoch 29/50] [Batch 216/300] [D loss: 0.752396] [G loss: 0.494953] time: 0:44:21.396667\n",
      "0.8915708\n",
      "[Epoch 29/50] [Batch 217/300] [D loss: 0.752425] [G loss: 0.492170] time: 0:44:21.673387\n",
      "0.94819015\n",
      "[Epoch 29/50] [Batch 218/300] [D loss: 0.752397] [G loss: 0.512116] time: 0:44:21.960122\n",
      "0.907656\n",
      "[Epoch 29/50] [Batch 219/300] [D loss: 0.752416] [G loss: 0.482132] time: 0:44:22.260818\n",
      "0.89916855\n",
      "[Epoch 29/50] [Batch 220/300] [D loss: 0.752390] [G loss: 0.493298] time: 0:44:22.550946\n",
      "0.91416353\n",
      "[Epoch 29/50] [Batch 221/300] [D loss: 0.752413] [G loss: 0.493883] time: 0:44:22.851454\n",
      "0.94100004\n",
      "[Epoch 29/50] [Batch 222/300] [D loss: 0.752426] [G loss: 0.484168] time: 0:44:23.147858\n",
      "0.8917064\n",
      "[Epoch 29/50] [Batch 223/300] [D loss: 0.752394] [G loss: 0.494480] time: 0:44:23.427326\n",
      "0.9687056\n",
      "[Epoch 29/50] [Batch 224/300] [D loss: 0.752402] [G loss: 0.502442] time: 0:44:23.736778\n",
      "0.91666037\n",
      "[Epoch 29/50] [Batch 225/300] [D loss: 0.752418] [G loss: 0.493218] time: 0:44:24.044406\n",
      "0.95144224\n",
      "[Epoch 29/50] [Batch 226/300] [D loss: 0.752403] [G loss: 0.483221] time: 0:44:24.350179\n",
      "0.9457824\n",
      "[Epoch 29/50] [Batch 227/300] [D loss: 0.752423] [G loss: 0.481672] time: 0:44:24.645682\n",
      "0.917232\n",
      "[Epoch 29/50] [Batch 228/300] [D loss: 0.752419] [G loss: 0.494551] time: 0:44:24.947505\n",
      "0.9493111\n",
      "[Epoch 29/50] [Batch 229/300] [D loss: 0.752399] [G loss: 0.514992] time: 0:44:25.248709\n",
      "0.90712214\n",
      "[Epoch 29/50] [Batch 230/300] [D loss: 0.752400] [G loss: 0.489498] time: 0:44:25.533001\n",
      "0.9140721\n",
      "[Epoch 29/50] [Batch 231/300] [D loss: 0.752407] [G loss: 0.489063] time: 0:44:25.830402\n",
      "0.9306033\n",
      "[Epoch 29/50] [Batch 232/300] [D loss: 0.752396] [G loss: 0.494437] time: 0:44:26.113282\n",
      "0.9507897\n",
      "[Epoch 29/50] [Batch 233/300] [D loss: 0.752402] [G loss: 0.481736] time: 0:44:26.416602\n",
      "0.9049952\n",
      "[Epoch 29/50] [Batch 234/300] [D loss: 0.752403] [G loss: 0.488185] time: 0:44:26.726184\n",
      "0.89211565\n",
      "[Epoch 29/50] [Batch 235/300] [D loss: 0.752412] [G loss: 0.490097] time: 0:44:27.029407\n",
      "0.90960807\n",
      "[Epoch 29/50] [Batch 236/300] [D loss: 0.752410] [G loss: 0.483254] time: 0:44:27.322378\n",
      "0.93758583\n",
      "[Epoch 29/50] [Batch 237/300] [D loss: 0.752406] [G loss: 0.530419] time: 0:44:27.609116\n",
      "0.90579486\n",
      "[Epoch 29/50] [Batch 238/300] [D loss: 0.752401] [G loss: 0.489931] time: 0:44:27.919687\n",
      "0.9822786\n",
      "[Epoch 29/50] [Batch 239/300] [D loss: 0.752400] [G loss: 0.516673] time: 0:44:28.217912\n",
      "0.9294935\n",
      "[Epoch 29/50] [Batch 240/300] [D loss: 0.752413] [G loss: 0.483225] time: 0:44:28.515757\n",
      "0.9421902\n",
      "[Epoch 29/50] [Batch 241/300] [D loss: 0.752426] [G loss: 0.494752] time: 0:44:28.828789\n",
      "0.9397976\n",
      "[Epoch 29/50] [Batch 242/300] [D loss: 0.752403] [G loss: 0.497067] time: 0:44:29.125925\n",
      "0.9452222\n",
      "[Epoch 29/50] [Batch 243/300] [D loss: 0.752432] [G loss: 0.500642] time: 0:44:29.420712\n",
      "0.9540617\n",
      "[Epoch 29/50] [Batch 244/300] [D loss: 0.752394] [G loss: 0.513754] time: 0:44:29.730866\n",
      "0.89887136\n",
      "[Epoch 29/50] [Batch 245/300] [D loss: 0.752407] [G loss: 0.491993] time: 0:44:30.032301\n",
      "0.92479444\n",
      "[Epoch 29/50] [Batch 246/300] [D loss: 0.752407] [G loss: 0.515274] time: 0:44:30.338520\n",
      "0.91029173\n",
      "[Epoch 29/50] [Batch 247/300] [D loss: 0.752408] [G loss: 0.504695] time: 0:44:30.637329\n",
      "0.93968534\n",
      "[Epoch 29/50] [Batch 248/300] [D loss: 0.752415] [G loss: 0.495043] time: 0:44:30.934726\n",
      "0.92878026\n",
      "[Epoch 29/50] [Batch 249/300] [D loss: 0.752402] [G loss: 0.511345] time: 0:44:31.231989\n",
      "0.88019806\n",
      "[Epoch 29/50] [Batch 250/300] [D loss: 0.752411] [G loss: 0.491398] time: 0:44:31.541378\n",
      "0.97134787\n",
      "[Epoch 29/50] [Batch 251/300] [D loss: 0.752424] [G loss: 0.490942] time: 0:44:31.831773\n",
      "0.9468711\n",
      "[Epoch 29/50] [Batch 252/300] [D loss: 0.752399] [G loss: 0.489589] time: 0:44:32.130301\n",
      "0.9177885\n",
      "[Epoch 29/50] [Batch 253/300] [D loss: 0.752403] [G loss: 0.495522] time: 0:44:32.414773\n",
      "0.97120315\n",
      "[Epoch 29/50] [Batch 254/300] [D loss: 0.752381] [G loss: 0.476943] time: 0:44:32.719168\n",
      "0.8760371\n",
      "[Epoch 29/50] [Batch 255/300] [D loss: 0.752411] [G loss: 0.499645] time: 0:44:33.020390\n",
      "0.92588305\n",
      "[Epoch 29/50] [Batch 256/300] [D loss: 0.752414] [G loss: 0.488709] time: 0:44:33.335754\n",
      "0.87191516\n",
      "[Epoch 29/50] [Batch 257/300] [D loss: 0.752422] [G loss: 0.485434] time: 0:44:33.629070\n",
      "0.95224595\n",
      "[Epoch 29/50] [Batch 258/300] [D loss: 0.752403] [G loss: 0.485560] time: 0:44:33.932830\n",
      "0.93002933\n",
      "[Epoch 29/50] [Batch 259/300] [D loss: 0.752398] [G loss: 0.481271] time: 0:44:34.241798\n",
      "0.97548294\n",
      "[Epoch 29/50] [Batch 260/300] [D loss: 0.752401] [G loss: 0.516965] time: 0:44:34.558989\n",
      "0.9499107\n",
      "[Epoch 29/50] [Batch 261/300] [D loss: 0.752434] [G loss: 0.482711] time: 0:44:34.866925\n",
      "0.91311115\n",
      "[Epoch 29/50] [Batch 262/300] [D loss: 0.752422] [G loss: 0.503399] time: 0:44:35.139852\n",
      "0.9644971\n",
      "[Epoch 29/50] [Batch 263/300] [D loss: 0.752399] [G loss: 0.494143] time: 0:44:35.435190\n",
      "0.9058957\n",
      "[Epoch 29/50] [Batch 264/300] [D loss: 0.752421] [G loss: 0.476220] time: 0:44:35.719989\n",
      "0.9530712\n",
      "[Epoch 29/50] [Batch 265/300] [D loss: 0.752419] [G loss: 0.490615] time: 0:44:35.993922\n",
      "0.9004747\n",
      "[Epoch 29/50] [Batch 266/300] [D loss: 0.752388] [G loss: 0.485377] time: 0:44:36.292587\n",
      "0.9073426\n",
      "[Epoch 29/50] [Batch 267/300] [D loss: 0.752404] [G loss: 0.518930] time: 0:44:36.597588\n",
      "0.91140026\n",
      "[Epoch 29/50] [Batch 268/300] [D loss: 0.752406] [G loss: 0.491055] time: 0:44:36.880479\n",
      "0.9643255\n",
      "[Epoch 29/50] [Batch 269/300] [D loss: 0.752392] [G loss: 0.490815] time: 0:44:37.194587\n",
      "0.92348003\n",
      "[Epoch 29/50] [Batch 270/300] [D loss: 0.752411] [G loss: 0.481417] time: 0:44:37.492227\n",
      "0.9091547\n",
      "[Epoch 29/50] [Batch 271/300] [D loss: 0.752418] [G loss: 0.506646] time: 0:44:37.795750\n",
      "0.96844417\n",
      "[Epoch 29/50] [Batch 272/300] [D loss: 0.752401] [G loss: 0.493290] time: 0:44:38.079140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9232507\n",
      "[Epoch 29/50] [Batch 273/300] [D loss: 0.752404] [G loss: 0.508733] time: 0:44:38.367807\n",
      "0.8854704\n",
      "[Epoch 29/50] [Batch 274/300] [D loss: 0.752414] [G loss: 0.491640] time: 0:44:38.666380\n",
      "0.91234684\n",
      "[Epoch 29/50] [Batch 275/300] [D loss: 0.752393] [G loss: 0.521124] time: 0:44:38.975063\n",
      "0.8990147\n",
      "[Epoch 29/50] [Batch 276/300] [D loss: 0.752403] [G loss: 0.491026] time: 0:44:39.285196\n",
      "0.9233136\n",
      "[Epoch 29/50] [Batch 277/300] [D loss: 0.752406] [G loss: 0.514466] time: 0:44:39.597031\n",
      "0.88566345\n",
      "[Epoch 29/50] [Batch 278/300] [D loss: 0.752415] [G loss: 0.492782] time: 0:44:39.891110\n",
      "0.8679063\n",
      "[Epoch 29/50] [Batch 279/300] [D loss: 0.752401] [G loss: 0.507190] time: 0:44:40.195089\n",
      "0.9009188\n",
      "[Epoch 29/50] [Batch 280/300] [D loss: 0.752399] [G loss: 0.500871] time: 0:44:40.497472\n",
      "0.916321\n",
      "[Epoch 29/50] [Batch 281/300] [D loss: 0.752410] [G loss: 0.482629] time: 0:44:40.801258\n",
      "0.94974375\n",
      "[Epoch 29/50] [Batch 282/300] [D loss: 0.752416] [G loss: 0.483761] time: 0:44:41.102958\n",
      "0.9150219\n",
      "[Epoch 29/50] [Batch 283/300] [D loss: 0.752409] [G loss: 0.500808] time: 0:44:41.403451\n",
      "0.9234815\n",
      "[Epoch 29/50] [Batch 284/300] [D loss: 0.752427] [G loss: 0.494503] time: 0:44:41.708938\n",
      "0.89712256\n",
      "[Epoch 29/50] [Batch 285/300] [D loss: 0.752404] [G loss: 0.488735] time: 0:44:42.024251\n",
      "0.9161417\n",
      "[Epoch 29/50] [Batch 286/300] [D loss: 0.752411] [G loss: 0.489220] time: 0:44:42.334650\n",
      "0.89118236\n",
      "[Epoch 29/50] [Batch 287/300] [D loss: 0.752394] [G loss: 0.491976] time: 0:44:42.632237\n",
      "0.95331043\n",
      "[Epoch 29/50] [Batch 288/300] [D loss: 0.752397] [G loss: 0.495521] time: 0:44:42.917693\n",
      "0.9062185\n",
      "[Epoch 29/50] [Batch 289/300] [D loss: 0.752418] [G loss: 0.486382] time: 0:44:43.234172\n",
      "0.8873696\n",
      "[Epoch 29/50] [Batch 290/300] [D loss: 0.752414] [G loss: 0.508921] time: 0:44:43.547964\n",
      "0.8885506\n",
      "[Epoch 29/50] [Batch 291/300] [D loss: 0.752400] [G loss: 0.496456] time: 0:44:43.853258\n",
      "0.89349437\n",
      "[Epoch 29/50] [Batch 292/300] [D loss: 0.752399] [G loss: 0.493086] time: 0:44:44.147789\n",
      "0.8887159\n",
      "[Epoch 29/50] [Batch 293/300] [D loss: 0.752396] [G loss: 0.508358] time: 0:44:44.429719\n",
      "0.8859965\n",
      "[Epoch 29/50] [Batch 294/300] [D loss: 0.752385] [G loss: 0.502132] time: 0:44:44.714024\n",
      "0.9532402\n",
      "[Epoch 29/50] [Batch 295/300] [D loss: 0.752401] [G loss: 0.498573] time: 0:44:45.012134\n",
      "0.91691345\n",
      "[Epoch 29/50] [Batch 296/300] [D loss: 0.752420] [G loss: 0.484073] time: 0:44:45.288990\n",
      "0.9455867\n",
      "[Epoch 29/50] [Batch 297/300] [D loss: 0.752387] [G loss: 0.530928] time: 0:44:45.579278\n",
      "0.9268243\n",
      "[Epoch 29/50] [Batch 298/300] [D loss: 0.752401] [G loss: 0.489935] time: 0:44:45.878865\n",
      "0.97654885\n",
      "[Epoch 29/50] [Batch 299/300] [D loss: 0.752391] [G loss: 0.508492] time: 0:44:46.183620\n",
      "0.9470196\n",
      "[Epoch 30/50] [Batch 0/300] [D loss: 0.752404] [G loss: 0.506576] time: 0:44:46.477504\n",
      "0.9600256\n",
      "[Epoch 30/50] [Batch 1/300] [D loss: 0.752434] [G loss: 0.494792] time: 0:44:46.765328\n",
      "0.9398671\n",
      "[Epoch 30/50] [Batch 2/300] [D loss: 0.752407] [G loss: 0.497132] time: 0:44:47.065589\n",
      "0.8674788\n",
      "[Epoch 30/50] [Batch 3/300] [D loss: 0.752394] [G loss: 0.477624] time: 0:44:47.359868\n",
      "0.94459385\n",
      "[Epoch 30/50] [Batch 4/300] [D loss: 0.752401] [G loss: 0.482914] time: 0:44:47.641078\n",
      "0.93326133\n",
      "[Epoch 30/50] [Batch 5/300] [D loss: 0.752402] [G loss: 0.486558] time: 0:44:47.942961\n",
      "0.9331372\n",
      "[Epoch 30/50] [Batch 6/300] [D loss: 0.752412] [G loss: 0.487917] time: 0:44:48.249398\n",
      "0.9056506\n",
      "[Epoch 30/50] [Batch 7/300] [D loss: 0.752391] [G loss: 0.494832] time: 0:44:48.546217\n",
      "0.98382896\n",
      "[Epoch 30/50] [Batch 8/300] [D loss: 0.752417] [G loss: 0.476078] time: 0:44:48.845226\n",
      "0.92713356\n",
      "[Epoch 30/50] [Batch 9/300] [D loss: 0.752400] [G loss: 0.501480] time: 0:44:49.149116\n",
      "0.92936355\n",
      "[Epoch 30/50] [Batch 10/300] [D loss: 0.752391] [G loss: 0.499905] time: 0:44:49.459964\n",
      "0.9529917\n",
      "[Epoch 30/50] [Batch 11/300] [D loss: 0.752401] [G loss: 0.487627] time: 0:44:49.752607\n",
      "0.9146089\n",
      "[Epoch 30/50] [Batch 12/300] [D loss: 0.752392] [G loss: 0.487926] time: 0:44:50.049246\n",
      "0.91209054\n",
      "[Epoch 30/50] [Batch 13/300] [D loss: 0.752396] [G loss: 0.499736] time: 0:44:50.339262\n",
      "0.9387746\n",
      "[Epoch 30/50] [Batch 14/300] [D loss: 0.752394] [G loss: 0.498938] time: 0:44:50.638782\n",
      "0.893696\n",
      "[Epoch 30/50] [Batch 15/300] [D loss: 0.752394] [G loss: 0.491140] time: 0:44:50.938897\n",
      "0.90832025\n",
      "[Epoch 30/50] [Batch 16/300] [D loss: 0.752406] [G loss: 0.498142] time: 0:44:51.252617\n",
      "0.9141767\n",
      "[Epoch 30/50] [Batch 17/300] [D loss: 0.752414] [G loss: 0.477038] time: 0:44:51.548318\n",
      "0.8903556\n",
      "[Epoch 30/50] [Batch 18/300] [D loss: 0.752412] [G loss: 0.493177] time: 0:44:51.836525\n",
      "0.9196596\n",
      "[Epoch 30/50] [Batch 19/300] [D loss: 0.752404] [G loss: 0.500968] time: 0:44:52.140829\n",
      "0.93590856\n",
      "[Epoch 30/50] [Batch 20/300] [D loss: 0.752415] [G loss: 0.485757] time: 0:44:52.451244\n",
      "0.93748635\n",
      "[Epoch 30/50] [Batch 21/300] [D loss: 0.752400] [G loss: 0.492839] time: 0:44:52.766389\n",
      "0.94692326\n",
      "[Epoch 30/50] [Batch 22/300] [D loss: 0.752406] [G loss: 0.480762] time: 0:44:53.057781\n",
      "0.90852386\n",
      "[Epoch 30/50] [Batch 23/300] [D loss: 0.752384] [G loss: 0.535364] time: 0:44:53.354524\n",
      "0.93313247\n",
      "[Epoch 30/50] [Batch 24/300] [D loss: 0.752396] [G loss: 0.490063] time: 0:44:53.656401\n",
      "0.9077766\n",
      "[Epoch 30/50] [Batch 25/300] [D loss: 0.752395] [G loss: 0.504641] time: 0:44:53.947035\n",
      "0.93862176\n",
      "[Epoch 30/50] [Batch 26/300] [D loss: 0.752388] [G loss: 0.494478] time: 0:44:54.262556\n",
      "0.9406383\n",
      "[Epoch 30/50] [Batch 27/300] [D loss: 0.752381] [G loss: 0.519073] time: 0:44:54.568647\n",
      "0.94659585\n",
      "[Epoch 30/50] [Batch 28/300] [D loss: 0.752416] [G loss: 0.501269] time: 0:44:54.855545\n",
      "0.9299872\n",
      "[Epoch 30/50] [Batch 30/300] [D loss: 0.752384] [G loss: 0.490669] time: 0:44:55.172723\n",
      "0.88945556\n",
      "[Epoch 30/50] [Batch 31/300] [D loss: 0.752407] [G loss: 0.493907] time: 0:44:55.468474\n",
      "0.9176369\n",
      "[Epoch 30/50] [Batch 32/300] [D loss: 0.752406] [G loss: 0.482311] time: 0:44:55.768982\n",
      "0.9657411\n",
      "[Epoch 30/50] [Batch 33/300] [D loss: 0.752400] [G loss: 0.498627] time: 0:44:56.054805\n",
      "0.93838406\n",
      "[Epoch 30/50] [Batch 34/300] [D loss: 0.752384] [G loss: 0.497981] time: 0:44:56.332195\n",
      "0.88906884\n",
      "[Epoch 30/50] [Batch 35/300] [D loss: 0.752387] [G loss: 0.508781] time: 0:44:56.605821\n",
      "0.9336827\n",
      "[Epoch 30/50] [Batch 36/300] [D loss: 0.752432] [G loss: 0.473820] time: 0:44:56.903735\n",
      "0.8919113\n",
      "[Epoch 30/50] [Batch 37/300] [D loss: 0.752401] [G loss: 0.494335] time: 0:44:57.340235\n",
      "0.90683335\n",
      "[Epoch 30/50] [Batch 38/300] [D loss: 0.752397] [G loss: 0.497267] time: 0:44:57.665979\n",
      "0.9098995\n",
      "[Epoch 30/50] [Batch 39/300] [D loss: 0.752417] [G loss: 0.488465] time: 0:44:57.956356\n",
      "0.85225886\n",
      "[Epoch 30/50] [Batch 40/300] [D loss: 0.752412] [G loss: 0.490791] time: 0:44:58.243041\n",
      "0.889103\n",
      "[Epoch 30/50] [Batch 41/300] [D loss: 0.752387] [G loss: 0.498592] time: 0:44:58.541168\n",
      "0.94640094\n",
      "[Epoch 30/50] [Batch 42/300] [D loss: 0.752414] [G loss: 0.494163] time: 0:44:58.847957\n",
      "0.8862621\n",
      "[Epoch 30/50] [Batch 43/300] [D loss: 0.752395] [G loss: 0.504396] time: 0:44:59.137090\n",
      "0.899142\n",
      "[Epoch 30/50] [Batch 44/300] [D loss: 0.752399] [G loss: 0.513149] time: 0:44:59.439103\n",
      "0.910247\n",
      "[Epoch 30/50] [Batch 45/300] [D loss: 0.752401] [G loss: 0.486540] time: 0:44:59.726175\n",
      "0.9331591\n",
      "[Epoch 30/50] [Batch 46/300] [D loss: 0.752382] [G loss: 0.497635] time: 0:45:00.017089\n",
      "0.91244143\n",
      "[Epoch 30/50] [Batch 47/300] [D loss: 0.752408] [G loss: 0.479128] time: 0:45:00.325305\n",
      "0.88807017\n",
      "[Epoch 30/50] [Batch 48/300] [D loss: 0.752396] [G loss: 0.501359] time: 0:45:00.629141\n",
      "0.92809725\n",
      "[Epoch 30/50] [Batch 49/300] [D loss: 0.752400] [G loss: 0.478701] time: 0:45:00.930431\n",
      "0.90985656\n",
      "[Epoch 30/50] [Batch 50/300] [D loss: 0.752418] [G loss: 0.479472] time: 0:45:01.237151\n",
      "0.94446516\n",
      "[Epoch 30/50] [Batch 51/300] [D loss: 0.752408] [G loss: 0.486077] time: 0:45:01.533144\n",
      "0.9476468\n",
      "[Epoch 30/50] [Batch 52/300] [D loss: 0.752385] [G loss: 0.510989] time: 0:45:01.849340\n",
      "0.95152754\n",
      "[Epoch 30/50] [Batch 53/300] [D loss: 0.752402] [G loss: 0.481357] time: 0:45:02.134828\n",
      "0.9193986\n",
      "[Epoch 30/50] [Batch 54/300] [D loss: 0.752404] [G loss: 0.487391] time: 0:45:02.424058\n",
      "0.9475835\n",
      "[Epoch 30/50] [Batch 55/300] [D loss: 0.752398] [G loss: 0.491181] time: 0:45:02.724291\n",
      "0.91506624\n",
      "[Epoch 30/50] [Batch 56/300] [D loss: 0.752403] [G loss: 0.499126] time: 0:45:03.016783\n",
      "0.9237328\n",
      "[Epoch 30/50] [Batch 57/300] [D loss: 0.752401] [G loss: 0.479142] time: 0:45:03.330128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89527893\n",
      "[Epoch 30/50] [Batch 58/300] [D loss: 0.752408] [G loss: 0.502843] time: 0:45:03.620655\n",
      "0.8783453\n",
      "[Epoch 30/50] [Batch 59/300] [D loss: 0.752408] [G loss: 0.494897] time: 0:45:03.913966\n",
      "0.93075347\n",
      "[Epoch 30/50] [Batch 60/300] [D loss: 0.752406] [G loss: 0.483214] time: 0:45:04.219526\n",
      "0.92309713\n",
      "[Epoch 30/50] [Batch 61/300] [D loss: 0.752425] [G loss: 0.490390] time: 0:45:04.514659\n",
      "0.8840995\n",
      "[Epoch 30/50] [Batch 62/300] [D loss: 0.752406] [G loss: 0.509322] time: 0:45:04.802245\n",
      "0.9087551\n",
      "[Epoch 30/50] [Batch 63/300] [D loss: 0.752408] [G loss: 0.511514] time: 0:45:05.097173\n",
      "0.9611192\n",
      "[Epoch 30/50] [Batch 64/300] [D loss: 0.752393] [G loss: 0.499780] time: 0:45:05.384780\n",
      "0.9323047\n",
      "[Epoch 30/50] [Batch 65/300] [D loss: 0.752402] [G loss: 0.475721] time: 0:45:05.668470\n",
      "0.9177502\n",
      "[Epoch 30/50] [Batch 66/300] [D loss: 0.752387] [G loss: 0.486750] time: 0:45:05.966299\n",
      "0.91750795\n",
      "[Epoch 30/50] [Batch 67/300] [D loss: 0.752419] [G loss: 0.494659] time: 0:45:06.255297\n",
      "0.94694996\n",
      "[Epoch 30/50] [Batch 68/300] [D loss: 0.752392] [G loss: 0.488480] time: 0:45:06.530922\n",
      "0.9087577\n",
      "[Epoch 30/50] [Batch 69/300] [D loss: 0.752396] [G loss: 0.493552] time: 0:45:06.835405\n",
      "0.9825595\n",
      "[Epoch 30/50] [Batch 70/300] [D loss: 0.752404] [G loss: 0.482462] time: 0:45:07.136252\n",
      "0.9119951\n",
      "[Epoch 30/50] [Batch 71/300] [D loss: 0.752409] [G loss: 0.513861] time: 0:45:07.439012\n",
      "0.85436195\n",
      "[Epoch 30/50] [Batch 72/300] [D loss: 0.752403] [G loss: 0.492255] time: 0:45:07.747391\n",
      "0.92815596\n",
      "[Epoch 30/50] [Batch 73/300] [D loss: 0.752418] [G loss: 0.523301] time: 0:45:08.064291\n",
      "0.9354798\n",
      "[Epoch 30/50] [Batch 74/300] [D loss: 0.752406] [G loss: 0.494347] time: 0:45:08.377392\n",
      "0.9396549\n",
      "[Epoch 30/50] [Batch 75/300] [D loss: 0.752404] [G loss: 0.486411] time: 0:45:08.681385\n",
      "0.92235225\n",
      "[Epoch 30/50] [Batch 76/300] [D loss: 0.752379] [G loss: 0.501555] time: 0:45:08.984002\n",
      "0.9292474\n",
      "[Epoch 30/50] [Batch 77/300] [D loss: 0.752413] [G loss: 0.509131] time: 0:45:09.296697\n",
      "0.91296077\n",
      "[Epoch 30/50] [Batch 78/300] [D loss: 0.752383] [G loss: 0.516604] time: 0:45:09.599176\n",
      "0.93754023\n",
      "[Epoch 30/50] [Batch 79/300] [D loss: 0.752418] [G loss: 0.480746] time: 0:45:09.904266\n",
      "0.9589022\n",
      "[Epoch 30/50] [Batch 80/300] [D loss: 0.752392] [G loss: 0.487583] time: 0:45:10.195830\n",
      "0.93308467\n",
      "[Epoch 30/50] [Batch 81/300] [D loss: 0.752406] [G loss: 0.503407] time: 0:45:10.494568\n",
      "0.9460321\n",
      "[Epoch 30/50] [Batch 82/300] [D loss: 0.752383] [G loss: 0.520073] time: 0:45:10.787279\n",
      "0.8903492\n",
      "[Epoch 30/50] [Batch 83/300] [D loss: 0.752390] [G loss: 0.497721] time: 0:45:11.087594\n",
      "0.9175422\n",
      "[Epoch 30/50] [Batch 84/300] [D loss: 0.752390] [G loss: 0.489478] time: 0:45:11.393665\n",
      "0.8950693\n",
      "[Epoch 30/50] [Batch 85/300] [D loss: 0.752392] [G loss: 0.484560] time: 0:45:11.693928\n",
      "0.9250627\n",
      "[Epoch 30/50] [Batch 86/300] [D loss: 0.752396] [G loss: 0.492238] time: 0:45:12.006519\n",
      "0.88413644\n",
      "[Epoch 30/50] [Batch 87/300] [D loss: 0.752384] [G loss: 0.504863] time: 0:45:12.309027\n",
      "0.90902644\n",
      "[Epoch 30/50] [Batch 88/300] [D loss: 0.752391] [G loss: 0.492637] time: 0:45:12.601294\n",
      "0.8906951\n",
      "[Epoch 30/50] [Batch 89/300] [D loss: 0.752393] [G loss: 0.491132] time: 0:45:12.919749\n",
      "0.91049165\n",
      "[Epoch 30/50] [Batch 90/300] [D loss: 0.752404] [G loss: 0.483620] time: 0:45:13.211404\n",
      "0.9342911\n",
      "[Epoch 30/50] [Batch 91/300] [D loss: 0.752403] [G loss: 0.494001] time: 0:45:13.513399\n",
      "0.90539694\n",
      "[Epoch 30/50] [Batch 92/300] [D loss: 0.752389] [G loss: 0.499782] time: 0:45:13.823398\n",
      "0.9497364\n",
      "[Epoch 30/50] [Batch 93/300] [D loss: 0.752409] [G loss: 0.488165] time: 0:45:14.126232\n",
      "0.9166917\n",
      "[Epoch 30/50] [Batch 94/300] [D loss: 0.752396] [G loss: 0.484697] time: 0:45:14.430223\n",
      "0.93554276\n",
      "[Epoch 30/50] [Batch 95/300] [D loss: 0.752382] [G loss: 0.512469] time: 0:45:14.735274\n",
      "0.9271414\n",
      "[Epoch 30/50] [Batch 96/300] [D loss: 0.752397] [G loss: 0.484664] time: 0:45:15.054931\n",
      "0.9423704\n",
      "[Epoch 30/50] [Batch 97/300] [D loss: 0.752396] [G loss: 0.488039] time: 0:45:15.345652\n",
      "0.9533596\n",
      "[Epoch 30/50] [Batch 98/300] [D loss: 0.752403] [G loss: 0.492794] time: 0:45:15.651550\n",
      "0.9576943\n",
      "[Epoch 30/50] [Batch 99/300] [D loss: 0.752399] [G loss: 0.489826] time: 0:45:15.939922\n",
      "0.9123772\n",
      "[Epoch 30/50] [Batch 100/300] [D loss: 0.752400] [G loss: 0.498917] time: 0:45:16.227591\n",
      "0.91551924\n",
      "[Epoch 30/50] [Batch 101/300] [D loss: 0.752399] [G loss: 0.501282] time: 0:45:16.532613\n",
      "0.94113654\n",
      "[Epoch 30/50] [Batch 102/300] [D loss: 0.752393] [G loss: 0.493382] time: 0:45:16.831543\n",
      "0.8931661\n",
      "[Epoch 30/50] [Batch 103/300] [D loss: 0.752409] [G loss: 0.495790] time: 0:45:17.121966\n",
      "0.97717994\n",
      "[Epoch 30/50] [Batch 104/300] [D loss: 0.752377] [G loss: 0.512541] time: 0:45:17.436663\n",
      "0.9455581\n",
      "[Epoch 30/50] [Batch 105/300] [D loss: 0.752394] [G loss: 0.489142] time: 0:45:17.745538\n",
      "0.90882605\n",
      "[Epoch 30/50] [Batch 106/300] [D loss: 0.752402] [G loss: 0.510318] time: 0:45:18.065679\n",
      "0.90583795\n",
      "[Epoch 30/50] [Batch 107/300] [D loss: 0.752383] [G loss: 0.499622] time: 0:45:18.374894\n",
      "0.94609815\n",
      "[Epoch 30/50] [Batch 108/300] [D loss: 0.752389] [G loss: 0.507821] time: 0:45:18.672445\n",
      "0.9268756\n",
      "[Epoch 30/50] [Batch 109/300] [D loss: 0.752420] [G loss: 0.490412] time: 0:45:18.972700\n",
      "0.93739253\n",
      "[Epoch 30/50] [Batch 110/300] [D loss: 0.752377] [G loss: 0.499934] time: 0:45:19.270276\n",
      "0.89070696\n",
      "[Epoch 30/50] [Batch 111/300] [D loss: 0.752417] [G loss: 0.481966] time: 0:45:19.557831\n",
      "0.88105893\n",
      "[Epoch 30/50] [Batch 112/300] [D loss: 0.752397] [G loss: 0.484367] time: 0:45:19.860745\n",
      "0.97117025\n",
      "[Epoch 30/50] [Batch 113/300] [D loss: 0.752404] [G loss: 0.493349] time: 0:45:20.174617\n",
      "0.9433372\n",
      "[Epoch 30/50] [Batch 114/300] [D loss: 0.752393] [G loss: 0.480910] time: 0:45:20.475836\n",
      "0.8908789\n",
      "[Epoch 30/50] [Batch 115/300] [D loss: 0.752390] [G loss: 0.486120] time: 0:45:20.782691\n",
      "0.92068243\n",
      "[Epoch 30/50] [Batch 116/300] [D loss: 0.752395] [G loss: 0.503126] time: 0:45:21.080357\n",
      "0.93710876\n",
      "[Epoch 30/50] [Batch 117/300] [D loss: 0.752400] [G loss: 0.481320] time: 0:45:21.353950\n",
      "0.9124806\n",
      "[Epoch 30/50] [Batch 118/300] [D loss: 0.752394] [G loss: 0.485504] time: 0:45:21.642552\n",
      "0.8989753\n",
      "[Epoch 30/50] [Batch 119/300] [D loss: 0.752398] [G loss: 0.485923] time: 0:45:21.934728\n",
      "0.93029237\n",
      "[Epoch 30/50] [Batch 120/300] [D loss: 0.752388] [G loss: 0.494368] time: 0:45:22.218695\n",
      "0.9334524\n",
      "[Epoch 30/50] [Batch 121/300] [D loss: 0.752412] [G loss: 0.508092] time: 0:45:22.520904\n",
      "0.94716144\n",
      "[Epoch 30/50] [Batch 122/300] [D loss: 0.752405] [G loss: 0.480184] time: 0:45:22.804300\n",
      "0.9817195\n",
      "[Epoch 30/50] [Batch 123/300] [D loss: 0.752406] [G loss: 0.480670] time: 0:45:23.103337\n",
      "0.97557837\n",
      "[Epoch 30/50] [Batch 124/300] [D loss: 0.752388] [G loss: 0.506591] time: 0:45:23.403536\n",
      "0.91907626\n",
      "[Epoch 30/50] [Batch 125/300] [D loss: 0.752386] [G loss: 0.483182] time: 0:45:23.689054\n",
      "0.933276\n",
      "[Epoch 30/50] [Batch 126/300] [D loss: 0.752373] [G loss: 0.479840] time: 0:45:23.971152\n",
      "0.94698733\n",
      "[Epoch 30/50] [Batch 127/300] [D loss: 0.752390] [G loss: 0.478387] time: 0:45:24.244563\n",
      "0.95573646\n",
      "[Epoch 30/50] [Batch 128/300] [D loss: 0.752397] [G loss: 0.493282] time: 0:45:24.541569\n",
      "0.93470097\n",
      "[Epoch 30/50] [Batch 129/300] [D loss: 0.752403] [G loss: 0.503657] time: 0:45:24.848149\n",
      "0.8703571\n",
      "[Epoch 30/50] [Batch 130/300] [D loss: 0.752387] [G loss: 0.489675] time: 0:45:25.146151\n",
      "0.9122723\n",
      "[Epoch 30/50] [Batch 131/300] [D loss: 0.752388] [G loss: 0.511560] time: 0:45:25.472732\n",
      "0.90857697\n",
      "[Epoch 30/50] [Batch 132/300] [D loss: 0.752402] [G loss: 0.488295] time: 0:45:25.780343\n",
      "0.9248197\n",
      "[Epoch 30/50] [Batch 133/300] [D loss: 0.752380] [G loss: 0.498505] time: 0:45:26.072367\n",
      "0.948926\n",
      "[Epoch 30/50] [Batch 134/300] [D loss: 0.752401] [G loss: 0.507560] time: 0:45:26.361181\n",
      "0.93159443\n",
      "[Epoch 30/50] [Batch 135/300] [D loss: 0.752380] [G loss: 0.526263] time: 0:45:26.640456\n",
      "0.9473407\n",
      "[Epoch 30/50] [Batch 136/300] [D loss: 0.752400] [G loss: 0.489843] time: 0:45:26.934124\n",
      "0.88464373\n",
      "[Epoch 30/50] [Batch 137/300] [D loss: 0.752417] [G loss: 0.487704] time: 0:45:27.240649\n",
      "0.93335295\n",
      "[Epoch 30/50] [Batch 138/300] [D loss: 0.752389] [G loss: 0.481128] time: 0:45:27.533528\n",
      "0.9290254\n",
      "[Epoch 30/50] [Batch 139/300] [D loss: 0.752376] [G loss: 0.496668] time: 0:45:27.836541\n",
      "0.9059739\n",
      "[Epoch 30/50] [Batch 140/300] [D loss: 0.752392] [G loss: 0.500608] time: 0:45:28.149324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9130241\n",
      "[Epoch 30/50] [Batch 141/300] [D loss: 0.752399] [G loss: 0.490106] time: 0:45:28.448058\n",
      "0.90906787\n",
      "[Epoch 30/50] [Batch 142/300] [D loss: 0.752391] [G loss: 0.506707] time: 0:45:28.735581\n",
      "0.9383171\n",
      "[Epoch 30/50] [Batch 143/300] [D loss: 0.752392] [G loss: 0.509847] time: 0:45:29.042307\n",
      "0.9761746\n",
      "[Epoch 30/50] [Batch 144/300] [D loss: 0.752392] [G loss: 0.506261] time: 0:45:29.347529\n",
      "0.93048024\n",
      "[Epoch 30/50] [Batch 145/300] [D loss: 0.752384] [G loss: 0.494768] time: 0:45:29.650788\n",
      "0.91010064\n",
      "[Epoch 30/50] [Batch 146/300] [D loss: 0.752411] [G loss: 0.494389] time: 0:45:29.944098\n",
      "0.9054379\n",
      "[Epoch 30/50] [Batch 147/300] [D loss: 0.752396] [G loss: 0.478084] time: 0:45:30.257822\n",
      "0.939511\n",
      "[Epoch 30/50] [Batch 148/300] [D loss: 0.752386] [G loss: 0.506334] time: 0:45:30.566363\n",
      "0.89431095\n",
      "[Epoch 30/50] [Batch 149/300] [D loss: 0.752384] [G loss: 0.480196] time: 0:45:30.859151\n",
      "0.93394756\n",
      "[Epoch 30/50] [Batch 150/300] [D loss: 0.752387] [G loss: 0.492883] time: 0:45:31.165839\n",
      "0.88379306\n",
      "[Epoch 30/50] [Batch 151/300] [D loss: 0.752399] [G loss: 0.495017] time: 0:45:31.465543\n",
      "0.9158724\n",
      "[Epoch 30/50] [Batch 152/300] [D loss: 0.752410] [G loss: 0.476514] time: 0:45:31.768694\n",
      "0.9346633\n",
      "[Epoch 30/50] [Batch 153/300] [D loss: 0.752387] [G loss: 0.476669] time: 0:45:32.060910\n",
      "0.9068219\n",
      "[Epoch 30/50] [Batch 154/300] [D loss: 0.752421] [G loss: 0.486997] time: 0:45:32.368084\n",
      "0.945895\n",
      "[Epoch 30/50] [Batch 155/300] [D loss: 0.752403] [G loss: 0.505604] time: 0:45:32.665857\n",
      "0.95313627\n",
      "[Epoch 30/50] [Batch 156/300] [D loss: 0.752408] [G loss: 0.507566] time: 0:45:32.957201\n",
      "0.9360822\n",
      "[Epoch 30/50] [Batch 157/300] [D loss: 0.752385] [G loss: 0.500732] time: 0:45:33.247272\n",
      "0.9283659\n",
      "[Epoch 30/50] [Batch 158/300] [D loss: 0.752396] [G loss: 0.485122] time: 0:45:33.550600\n",
      "0.913343\n",
      "[Epoch 30/50] [Batch 159/300] [D loss: 0.752391] [G loss: 0.498134] time: 0:45:33.859299\n",
      "0.9342913\n",
      "[Epoch 30/50] [Batch 160/300] [D loss: 0.752407] [G loss: 0.499783] time: 0:45:34.153830\n",
      "0.899179\n",
      "[Epoch 30/50] [Batch 161/300] [D loss: 0.752381] [G loss: 0.483963] time: 0:45:34.453100\n",
      "0.95236826\n",
      "[Epoch 30/50] [Batch 162/300] [D loss: 0.752404] [G loss: 0.487369] time: 0:45:34.752703\n",
      "0.8914802\n",
      "[Epoch 30/50] [Batch 163/300] [D loss: 0.752395] [G loss: 0.497882] time: 0:45:35.065444\n",
      "0.9038911\n",
      "[Epoch 30/50] [Batch 164/300] [D loss: 0.752388] [G loss: 0.498189] time: 0:45:35.357820\n",
      "0.9314472\n",
      "[Epoch 30/50] [Batch 165/300] [D loss: 0.752379] [G loss: 0.527524] time: 0:45:35.634002\n",
      "0.9056086\n",
      "[Epoch 30/50] [Batch 166/300] [D loss: 0.752399] [G loss: 0.487380] time: 0:45:35.938058\n",
      "0.8720713\n",
      "[Epoch 30/50] [Batch 167/300] [D loss: 0.752411] [G loss: 0.486161] time: 0:45:36.241126\n",
      "0.9454601\n",
      "[Epoch 30/50] [Batch 168/300] [D loss: 0.752399] [G loss: 0.490642] time: 0:45:36.565919\n",
      "0.9404146\n",
      "[Epoch 30/50] [Batch 169/300] [D loss: 0.752421] [G loss: 0.495887] time: 0:45:36.857831\n",
      "0.93821126\n",
      "[Epoch 30/50] [Batch 170/300] [D loss: 0.752406] [G loss: 0.499568] time: 0:45:37.157395\n",
      "0.89058137\n",
      "[Epoch 30/50] [Batch 171/300] [D loss: 0.752394] [G loss: 0.492885] time: 0:45:37.462033\n",
      "0.981628\n",
      "[Epoch 30/50] [Batch 172/300] [D loss: 0.752397] [G loss: 0.493169] time: 0:45:37.763734\n",
      "0.92613965\n",
      "[Epoch 30/50] [Batch 173/300] [D loss: 0.752391] [G loss: 0.486976] time: 0:45:38.070855\n",
      "0.8999281\n",
      "[Epoch 30/50] [Batch 174/300] [D loss: 0.752385] [G loss: 0.514620] time: 0:45:38.360545\n",
      "0.95252436\n",
      "[Epoch 30/50] [Batch 175/300] [D loss: 0.752401] [G loss: 0.484822] time: 0:45:38.663454\n",
      "0.9169655\n",
      "[Epoch 30/50] [Batch 176/300] [D loss: 0.752374] [G loss: 0.495332] time: 0:45:38.970459\n",
      "0.93320465\n",
      "[Epoch 30/50] [Batch 177/300] [D loss: 0.752375] [G loss: 0.480352] time: 0:45:39.278735\n",
      "0.90708464\n",
      "[Epoch 30/50] [Batch 178/300] [D loss: 0.752389] [G loss: 0.495057] time: 0:45:39.587354\n",
      "0.9083782\n",
      "[Epoch 30/50] [Batch 179/300] [D loss: 0.752424] [G loss: 0.479237] time: 0:45:39.879094\n",
      "0.8834655\n",
      "[Epoch 30/50] [Batch 180/300] [D loss: 0.752393] [G loss: 0.479950] time: 0:45:40.205608\n",
      "0.9568855\n",
      "[Epoch 30/50] [Batch 181/300] [D loss: 0.752375] [G loss: 0.535797] time: 0:45:40.507951\n",
      "0.89897555\n",
      "[Epoch 30/50] [Batch 182/300] [D loss: 0.752402] [G loss: 0.498658] time: 0:45:40.823196\n",
      "0.95664376\n",
      "[Epoch 30/50] [Batch 183/300] [D loss: 0.752394] [G loss: 0.494490] time: 0:45:41.132691\n",
      "0.9021836\n",
      "[Epoch 30/50] [Batch 184/300] [D loss: 0.752400] [G loss: 0.524434] time: 0:45:41.427117\n",
      "0.9081259\n",
      "[Epoch 30/50] [Batch 185/300] [D loss: 0.752407] [G loss: 0.486712] time: 0:45:41.737457\n",
      "0.91166687\n",
      "[Epoch 30/50] [Batch 186/300] [D loss: 0.752403] [G loss: 0.494260] time: 0:45:42.036505\n",
      "0.93465966\n",
      "[Epoch 30/50] [Batch 187/300] [D loss: 0.752387] [G loss: 0.488940] time: 0:45:42.340825\n",
      "0.91379863\n",
      "[Epoch 30/50] [Batch 188/300] [D loss: 0.752398] [G loss: 0.487879] time: 0:45:42.641583\n",
      "0.88068646\n",
      "[Epoch 30/50] [Batch 189/300] [D loss: 0.752386] [G loss: 0.481706] time: 0:45:42.946428\n",
      "0.9240089\n",
      "[Epoch 30/50] [Batch 190/300] [D loss: 0.752378] [G loss: 0.475406] time: 0:45:43.263932\n",
      "0.9330749\n",
      "[Epoch 30/50] [Batch 191/300] [D loss: 0.752414] [G loss: 0.513819] time: 0:45:43.587876\n",
      "0.90742296\n",
      "[Epoch 30/50] [Batch 192/300] [D loss: 0.752401] [G loss: 0.488259] time: 0:45:43.878554\n",
      "0.9078099\n",
      "[Epoch 30/50] [Batch 193/300] [D loss: 0.752393] [G loss: 0.473803] time: 0:45:44.175715\n",
      "0.9620838\n",
      "[Epoch 30/50] [Batch 194/300] [D loss: 0.752389] [G loss: 0.481088] time: 0:45:44.469735\n",
      "0.926994\n",
      "[Epoch 30/50] [Batch 195/300] [D loss: 0.752385] [G loss: 0.507471] time: 0:45:44.770500\n",
      "0.93890256\n",
      "[Epoch 30/50] [Batch 196/300] [D loss: 0.752392] [G loss: 0.509499] time: 0:45:45.074453\n",
      "0.97138643\n",
      "[Epoch 30/50] [Batch 197/300] [D loss: 0.752394] [G loss: 0.506263] time: 0:45:45.368980\n",
      "0.868069\n",
      "[Epoch 30/50] [Batch 198/300] [D loss: 0.752400] [G loss: 0.480020] time: 0:45:45.657426\n",
      "0.9042755\n",
      "[Epoch 30/50] [Batch 199/300] [D loss: 0.752390] [G loss: 0.517084] time: 0:45:45.960949\n",
      "0.94326806\n",
      "[Epoch 30/50] [Batch 200/300] [D loss: 0.752393] [G loss: 0.497213] time: 0:45:46.243703\n",
      "0.916029\n",
      "[Epoch 30/50] [Batch 201/300] [D loss: 0.752384] [G loss: 0.485029] time: 0:45:46.545376\n",
      "0.91323924\n",
      "[Epoch 30/50] [Batch 202/300] [D loss: 0.752417] [G loss: 0.489900] time: 0:45:46.839693\n",
      "0.945076\n",
      "[Epoch 30/50] [Batch 203/300] [D loss: 0.752396] [G loss: 0.490279] time: 0:45:47.129194\n",
      "0.95375395\n",
      "[Epoch 30/50] [Batch 204/300] [D loss: 0.752383] [G loss: 0.501284] time: 0:45:47.435781\n",
      "0.88055396\n",
      "[Epoch 30/50] [Batch 205/300] [D loss: 0.752388] [G loss: 0.477753] time: 0:45:47.753037\n",
      "0.931994\n",
      "[Epoch 30/50] [Batch 206/300] [D loss: 0.752400] [G loss: 0.481227] time: 0:45:48.040309\n",
      "0.9039695\n",
      "[Epoch 30/50] [Batch 207/300] [D loss: 0.752403] [G loss: 0.501835] time: 0:45:48.350292\n",
      "0.9459567\n",
      "[Epoch 30/50] [Batch 208/300] [D loss: 0.752396] [G loss: 0.496233] time: 0:45:48.645417\n",
      "0.9192676\n",
      "[Epoch 30/50] [Batch 209/300] [D loss: 0.752410] [G loss: 0.499597] time: 0:45:48.951910\n",
      "0.9075145\n",
      "[Epoch 30/50] [Batch 210/300] [D loss: 0.752370] [G loss: 0.481877] time: 0:45:49.254233\n",
      "0.94532245\n",
      "[Epoch 30/50] [Batch 211/300] [D loss: 0.752401] [G loss: 0.479861] time: 0:45:49.558121\n",
      "0.9139338\n",
      "[Epoch 30/50] [Batch 212/300] [D loss: 0.752390] [G loss: 0.490012] time: 0:45:49.871256\n",
      "0.8741257\n",
      "[Epoch 30/50] [Batch 213/300] [D loss: 0.752393] [G loss: 0.496554] time: 0:45:50.167591\n",
      "0.94582415\n",
      "[Epoch 30/50] [Batch 214/300] [D loss: 0.752360] [G loss: 0.508643] time: 0:45:50.481878\n",
      "0.9465053\n",
      "[Epoch 30/50] [Batch 215/300] [D loss: 0.752383] [G loss: 0.478487] time: 0:45:50.767689\n",
      "0.8806577\n",
      "[Epoch 30/50] [Batch 216/300] [D loss: 0.752381] [G loss: 0.509495] time: 0:45:51.063558\n",
      "0.93470716\n",
      "[Epoch 30/50] [Batch 217/300] [D loss: 0.752380] [G loss: 0.496816] time: 0:45:51.361000\n",
      "0.91576934\n",
      "[Epoch 30/50] [Batch 218/300] [D loss: 0.752384] [G loss: 0.496357] time: 0:45:51.668482\n",
      "0.9476285\n",
      "[Epoch 30/50] [Batch 219/300] [D loss: 0.752388] [G loss: 0.485321] time: 0:45:51.958904\n",
      "0.93344754\n",
      "[Epoch 30/50] [Batch 220/300] [D loss: 0.752388] [G loss: 0.476628] time: 0:45:52.264611\n",
      "0.90767556\n",
      "[Epoch 30/50] [Batch 221/300] [D loss: 0.752392] [G loss: 0.524428] time: 0:45:52.551090\n",
      "0.9141179\n",
      "[Epoch 30/50] [Batch 222/300] [D loss: 0.752391] [G loss: 0.499868] time: 0:45:52.858810\n",
      "0.86962\n",
      "[Epoch 30/50] [Batch 223/300] [D loss: 0.752384] [G loss: 0.513851] time: 0:45:53.155717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93214434\n",
      "[Epoch 30/50] [Batch 224/300] [D loss: 0.752392] [G loss: 0.503581] time: 0:45:53.457869\n",
      "0.9709628\n",
      "[Epoch 30/50] [Batch 225/300] [D loss: 0.752380] [G loss: 0.485234] time: 0:45:53.743199\n",
      "0.9108328\n",
      "[Epoch 30/50] [Batch 226/300] [D loss: 0.752400] [G loss: 0.477317] time: 0:45:54.040208\n",
      "0.93311733\n",
      "[Epoch 30/50] [Batch 227/300] [D loss: 0.752388] [G loss: 0.480576] time: 0:45:54.326310\n",
      "0.9266651\n",
      "[Epoch 30/50] [Batch 228/300] [D loss: 0.752387] [G loss: 0.498344] time: 0:45:54.624084\n",
      "0.9022177\n",
      "[Epoch 30/50] [Batch 229/300] [D loss: 0.752372] [G loss: 0.479265] time: 0:45:54.929661\n",
      "0.9169933\n",
      "[Epoch 30/50] [Batch 230/300] [D loss: 0.752374] [G loss: 0.515501] time: 0:45:55.223320\n",
      "0.8962247\n",
      "[Epoch 30/50] [Batch 231/300] [D loss: 0.752387] [G loss: 0.481316] time: 0:45:55.522161\n",
      "0.9454685\n",
      "[Epoch 30/50] [Batch 232/300] [D loss: 0.752388] [G loss: 0.497544] time: 0:45:55.831012\n",
      "0.9535282\n",
      "[Epoch 30/50] [Batch 233/300] [D loss: 0.752383] [G loss: 0.485272] time: 0:45:56.139101\n",
      "0.88710374\n",
      "[Epoch 30/50] [Batch 234/300] [D loss: 0.752382] [G loss: 0.511670] time: 0:45:56.449479\n",
      "0.9378366\n",
      "[Epoch 30/50] [Batch 235/300] [D loss: 0.752389] [G loss: 0.480490] time: 0:45:56.762010\n",
      "0.9431998\n",
      "[Epoch 30/50] [Batch 236/300] [D loss: 0.752416] [G loss: 0.486050] time: 0:45:57.058461\n",
      "0.95337003\n",
      "[Epoch 30/50] [Batch 237/300] [D loss: 0.752393] [G loss: 0.523159] time: 0:45:57.350486\n",
      "0.91662985\n",
      "[Epoch 30/50] [Batch 238/300] [D loss: 0.752399] [G loss: 0.485707] time: 0:45:57.640619\n",
      "0.9308463\n",
      "[Epoch 30/50] [Batch 239/300] [D loss: 0.752394] [G loss: 0.507620] time: 0:45:57.932499\n",
      "0.9085309\n",
      "[Epoch 30/50] [Batch 240/300] [D loss: 0.752394] [G loss: 0.493279] time: 0:45:58.264533\n",
      "0.93757755\n",
      "[Epoch 30/50] [Batch 241/300] [D loss: 0.752392] [G loss: 0.495344] time: 0:45:58.572661\n",
      "0.95211047\n",
      "[Epoch 30/50] [Batch 242/300] [D loss: 0.752385] [G loss: 0.480955] time: 0:45:58.859337\n",
      "0.90879947\n",
      "[Epoch 30/50] [Batch 243/300] [D loss: 0.752389] [G loss: 0.500719] time: 0:45:59.161102\n",
      "0.93313545\n",
      "[Epoch 30/50] [Batch 244/300] [D loss: 0.752400] [G loss: 0.491339] time: 0:45:59.465534\n",
      "0.94850177\n",
      "[Epoch 30/50] [Batch 245/300] [D loss: 0.752390] [G loss: 0.477784] time: 0:45:59.763964\n",
      "0.95304275\n",
      "[Epoch 30/50] [Batch 246/300] [D loss: 0.752413] [G loss: 0.544998] time: 0:46:00.058564\n",
      "0.94005245\n",
      "[Epoch 30/50] [Batch 247/300] [D loss: 0.752373] [G loss: 0.504586] time: 0:46:00.360679\n",
      "0.89565486\n",
      "[Epoch 30/50] [Batch 248/300] [D loss: 0.752407] [G loss: 0.491160] time: 0:46:00.655285\n",
      "0.9260578\n",
      "[Epoch 30/50] [Batch 249/300] [D loss: 0.752376] [G loss: 0.507098] time: 0:46:00.963962\n",
      "0.9397319\n",
      "[Epoch 30/50] [Batch 250/300] [D loss: 0.752379] [G loss: 0.500051] time: 0:46:01.265249\n",
      "0.9094431\n",
      "[Epoch 30/50] [Batch 251/300] [D loss: 0.752377] [G loss: 0.500460] time: 0:46:01.568710\n",
      "0.930922\n",
      "[Epoch 30/50] [Batch 252/300] [D loss: 0.752392] [G loss: 0.485834] time: 0:46:01.867787\n",
      "0.9169449\n",
      "[Epoch 30/50] [Batch 253/300] [D loss: 0.752380] [G loss: 0.502715] time: 0:46:02.169743\n",
      "0.91568106\n",
      "[Epoch 30/50] [Batch 254/300] [D loss: 0.752382] [G loss: 0.485261] time: 0:46:02.485027\n",
      "0.9422938\n",
      "[Epoch 30/50] [Batch 255/300] [D loss: 0.752384] [G loss: 0.497196] time: 0:46:02.782161\n",
      "0.9369286\n",
      "[Epoch 30/50] [Batch 256/300] [D loss: 0.752384] [G loss: 0.489994] time: 0:46:03.078530\n",
      "0.9052176\n",
      "[Epoch 30/50] [Batch 257/300] [D loss: 0.752400] [G loss: 0.489938] time: 0:46:03.383457\n",
      "0.94511795\n",
      "[Epoch 30/50] [Batch 258/300] [D loss: 0.752406] [G loss: 0.497641] time: 0:46:03.667499\n",
      "0.9471591\n",
      "[Epoch 30/50] [Batch 259/300] [D loss: 0.752377] [G loss: 0.484099] time: 0:46:03.974116\n",
      "0.8703449\n",
      "[Epoch 30/50] [Batch 260/300] [D loss: 0.752399] [G loss: 0.493055] time: 0:46:04.297798\n",
      "0.94688004\n",
      "[Epoch 30/50] [Batch 261/300] [D loss: 0.752388] [G loss: 0.475886] time: 0:46:04.596519\n",
      "0.9078067\n",
      "[Epoch 30/50] [Batch 262/300] [D loss: 0.752375] [G loss: 0.499126] time: 0:46:04.907131\n",
      "0.89000946\n",
      "[Epoch 30/50] [Batch 263/300] [D loss: 0.752374] [G loss: 0.485665] time: 0:46:05.216720\n",
      "0.9283672\n",
      "[Epoch 30/50] [Batch 264/300] [D loss: 0.752388] [G loss: 0.478943] time: 0:46:05.519512\n",
      "0.88623023\n",
      "[Epoch 30/50] [Batch 265/300] [D loss: 0.752384] [G loss: 0.475442] time: 0:46:05.832212\n",
      "0.9391959\n",
      "[Epoch 30/50] [Batch 266/300] [D loss: 0.752398] [G loss: 0.483690] time: 0:46:06.135124\n",
      "0.9471729\n",
      "[Epoch 30/50] [Batch 267/300] [D loss: 0.752387] [G loss: 0.470752] time: 0:46:06.442437\n",
      "0.903826\n",
      "[Epoch 30/50] [Batch 268/300] [D loss: 0.752384] [G loss: 0.478385] time: 0:46:06.741396\n",
      "0.9384342\n",
      "[Epoch 30/50] [Batch 269/300] [D loss: 0.752371] [G loss: 0.475237] time: 0:46:07.056852\n",
      "0.9403038\n",
      "[Epoch 30/50] [Batch 270/300] [D loss: 0.752395] [G loss: 0.509924] time: 0:46:07.367145\n",
      "0.9352784\n",
      "[Epoch 30/50] [Batch 271/300] [D loss: 0.752386] [G loss: 0.482163] time: 0:46:07.675232\n",
      "0.922316\n",
      "[Epoch 30/50] [Batch 272/300] [D loss: 0.752394] [G loss: 0.481477] time: 0:46:07.967444\n",
      "0.9127678\n",
      "[Epoch 30/50] [Batch 273/300] [D loss: 0.752393] [G loss: 0.506982] time: 0:46:08.292283\n",
      "0.9390225\n",
      "[Epoch 30/50] [Batch 274/300] [D loss: 0.752375] [G loss: 0.508621] time: 0:46:08.593203\n",
      "0.9328509\n",
      "[Epoch 30/50] [Batch 275/300] [D loss: 0.752382] [G loss: 0.494990] time: 0:46:08.883848\n",
      "0.88395214\n",
      "[Epoch 30/50] [Batch 276/300] [D loss: 0.752386] [G loss: 0.505426] time: 0:46:09.186219\n",
      "0.8841476\n",
      "[Epoch 30/50] [Batch 277/300] [D loss: 0.752388] [G loss: 0.488028] time: 0:46:09.501622\n",
      "0.93009096\n",
      "[Epoch 30/50] [Batch 278/300] [D loss: 0.752391] [G loss: 0.493273] time: 0:46:09.806430\n",
      "0.95336825\n",
      "[Epoch 30/50] [Batch 279/300] [D loss: 0.752390] [G loss: 0.493172] time: 0:46:10.108774\n",
      "0.9307229\n",
      "[Epoch 30/50] [Batch 280/300] [D loss: 0.752375] [G loss: 0.493001] time: 0:46:10.409296\n",
      "0.92873317\n",
      "[Epoch 30/50] [Batch 281/300] [D loss: 0.752409] [G loss: 0.489287] time: 0:46:10.708961\n",
      "0.9163847\n",
      "[Epoch 30/50] [Batch 282/300] [D loss: 0.752385] [G loss: 0.481112] time: 0:46:11.003603\n",
      "0.93261534\n",
      "[Epoch 30/50] [Batch 283/300] [D loss: 0.752392] [G loss: 0.490799] time: 0:46:11.288008\n",
      "0.9477391\n",
      "[Epoch 30/50] [Batch 284/300] [D loss: 0.752370] [G loss: 0.504945] time: 0:46:11.589118\n",
      "0.9260641\n",
      "[Epoch 30/50] [Batch 285/300] [D loss: 0.752387] [G loss: 0.476531] time: 0:46:11.888306\n",
      "0.9086504\n",
      "[Epoch 30/50] [Batch 286/300] [D loss: 0.752375] [G loss: 0.484666] time: 0:46:12.161017\n",
      "0.88558227\n",
      "[Epoch 30/50] [Batch 287/300] [D loss: 0.752407] [G loss: 0.492312] time: 0:46:12.460425\n",
      "0.9183976\n",
      "[Epoch 30/50] [Batch 288/300] [D loss: 0.752392] [G loss: 0.502120] time: 0:46:12.762648\n",
      "0.94521266\n",
      "[Epoch 30/50] [Batch 289/300] [D loss: 0.752415] [G loss: 0.504426] time: 0:46:13.077843\n",
      "0.93374854\n",
      "[Epoch 30/50] [Batch 290/300] [D loss: 0.752391] [G loss: 0.487840] time: 0:46:13.375873\n",
      "0.94248605\n",
      "[Epoch 30/50] [Batch 291/300] [D loss: 0.752388] [G loss: 0.537042] time: 0:46:13.678155\n",
      "0.9374984\n",
      "[Epoch 30/50] [Batch 292/300] [D loss: 0.752384] [G loss: 0.517657] time: 0:46:13.987354\n",
      "0.90562797\n",
      "[Epoch 30/50] [Batch 293/300] [D loss: 0.752372] [G loss: 0.496983] time: 0:46:14.290017\n",
      "0.9408345\n",
      "[Epoch 30/50] [Batch 294/300] [D loss: 0.752389] [G loss: 0.510228] time: 0:46:14.601792\n",
      "0.9411621\n",
      "[Epoch 30/50] [Batch 295/300] [D loss: 0.752372] [G loss: 0.502480] time: 0:46:14.898204\n",
      "0.91029793\n",
      "[Epoch 30/50] [Batch 296/300] [D loss: 0.752376] [G loss: 0.499446] time: 0:46:15.203354\n",
      "0.9123768\n",
      "[Epoch 30/50] [Batch 297/300] [D loss: 0.752398] [G loss: 0.496518] time: 0:46:15.505958\n",
      "0.90842444\n",
      "[Epoch 30/50] [Batch 298/300] [D loss: 0.752387] [G loss: 0.494179] time: 0:46:15.810784\n",
      "0.93069726\n",
      "[Epoch 30/50] [Batch 299/300] [D loss: 0.752383] [G loss: 0.524133] time: 0:46:16.099914\n",
      "0.92677283\n",
      "[Epoch 31/50] [Batch 0/300] [D loss: 0.752381] [G loss: 0.488997] time: 0:46:16.399690\n",
      "0.8847156\n",
      "[Epoch 31/50] [Batch 1/300] [D loss: 0.752385] [G loss: 0.477983] time: 0:46:16.694796\n",
      "0.91079473\n",
      "[Epoch 31/50] [Batch 2/300] [D loss: 0.752379] [G loss: 0.498299] time: 0:46:17.009602\n",
      "0.9238372\n",
      "[Epoch 31/50] [Batch 3/300] [D loss: 0.752390] [G loss: 0.478742] time: 0:46:17.308543\n",
      "0.9077838\n",
      "[Epoch 31/50] [Batch 4/300] [D loss: 0.752375] [G loss: 0.480894] time: 0:46:17.613096\n",
      "0.91899806\n",
      "[Epoch 31/50] [Batch 5/300] [D loss: 0.752367] [G loss: 0.491658] time: 0:46:17.907274\n",
      "0.90805393\n",
      "[Epoch 31/50] [Batch 6/300] [D loss: 0.752388] [G loss: 0.491195] time: 0:46:18.197049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90288144\n",
      "[Epoch 31/50] [Batch 7/300] [D loss: 0.752376] [G loss: 0.491621] time: 0:46:18.476463\n",
      "0.9499085\n",
      "[Epoch 31/50] [Batch 8/300] [D loss: 0.752391] [G loss: 0.506225] time: 0:46:18.771084\n",
      "0.9535859\n",
      "[Epoch 31/50] [Batch 9/300] [D loss: 0.752391] [G loss: 0.493477] time: 0:46:19.069861\n",
      "0.9380705\n",
      "[Epoch 31/50] [Batch 10/300] [D loss: 0.752381] [G loss: 0.491388] time: 0:46:19.364674\n",
      "0.9421007\n",
      "[Epoch 31/50] [Batch 11/300] [D loss: 0.752389] [G loss: 0.479789] time: 0:46:19.673533\n",
      "0.9067548\n",
      "[Epoch 31/50] [Batch 12/300] [D loss: 0.752372] [G loss: 0.489088] time: 0:46:19.986795\n",
      "0.9532769\n",
      "[Epoch 31/50] [Batch 13/300] [D loss: 0.752383] [G loss: 0.508272] time: 0:46:20.263074\n",
      "0.9373018\n",
      "[Epoch 31/50] [Batch 14/300] [D loss: 0.752383] [G loss: 0.497590] time: 0:46:20.568451\n",
      "0.92935866\n",
      "[Epoch 31/50] [Batch 15/300] [D loss: 0.752404] [G loss: 0.488950] time: 0:46:20.866807\n",
      "0.9111612\n",
      "[Epoch 31/50] [Batch 16/300] [D loss: 0.752396] [G loss: 0.507787] time: 0:46:21.165213\n",
      "0.9152507\n",
      "[Epoch 31/50] [Batch 17/300] [D loss: 0.752371] [G loss: 0.518043] time: 0:46:21.474212\n",
      "0.8843393\n",
      "[Epoch 31/50] [Batch 18/300] [D loss: 0.752384] [G loss: 0.494954] time: 0:46:21.784718\n",
      "0.94216305\n",
      "[Epoch 31/50] [Batch 19/300] [D loss: 0.752390] [G loss: 0.473808] time: 0:46:22.094330\n",
      "0.91161585\n",
      "[Epoch 31/50] [Batch 20/300] [D loss: 0.752396] [G loss: 0.484882] time: 0:46:22.407313\n",
      "0.90800333\n",
      "[Epoch 31/50] [Batch 21/300] [D loss: 0.752394] [G loss: 0.542520] time: 0:46:22.707013\n",
      "0.913704\n",
      "[Epoch 31/50] [Batch 22/300] [D loss: 0.752387] [G loss: 0.490295] time: 0:46:22.981373\n",
      "0.8960058\n",
      "[Epoch 31/50] [Batch 23/300] [D loss: 0.752385] [G loss: 0.523054] time: 0:46:23.301951\n",
      "0.9139366\n",
      "[Epoch 31/50] [Batch 24/300] [D loss: 0.752371] [G loss: 0.495010] time: 0:46:23.621068\n",
      "0.91618985\n",
      "[Epoch 31/50] [Batch 25/300] [D loss: 0.752376] [G loss: 0.496816] time: 0:46:23.925314\n",
      "0.8665518\n",
      "[Epoch 31/50] [Batch 26/300] [D loss: 0.752372] [G loss: 0.490277] time: 0:46:24.212741\n",
      "0.90292406\n",
      "[Epoch 31/50] [Batch 27/300] [D loss: 0.752391] [G loss: 0.511801] time: 0:46:24.519989\n",
      "0.9386141\n",
      "[Epoch 31/50] [Batch 28/300] [D loss: 0.752391] [G loss: 0.474406] time: 0:46:24.825341\n",
      "0.9025662\n",
      "[Epoch 31/50] [Batch 29/300] [D loss: 0.752394] [G loss: 0.516084] time: 0:46:25.138403\n",
      "0.885825\n",
      "[Epoch 31/50] [Batch 31/300] [D loss: 0.752413] [G loss: 0.486391] time: 0:46:25.451125\n",
      "0.85297686\n",
      "[Epoch 31/50] [Batch 32/300] [D loss: 0.752385] [G loss: 0.495359] time: 0:46:25.778195\n",
      "0.86751515\n",
      "[Epoch 31/50] [Batch 33/300] [D loss: 0.752383] [G loss: 0.497911] time: 0:46:26.073100\n",
      "0.98068094\n",
      "[Epoch 31/50] [Batch 34/300] [D loss: 0.752399] [G loss: 0.508431] time: 0:46:26.373181\n",
      "0.9396221\n",
      "[Epoch 31/50] [Batch 35/300] [D loss: 0.752374] [G loss: 0.495869] time: 0:46:26.676731\n",
      "0.9564069\n",
      "[Epoch 31/50] [Batch 36/300] [D loss: 0.752397] [G loss: 0.493018] time: 0:46:26.971457\n",
      "0.9402202\n",
      "[Epoch 31/50] [Batch 37/300] [D loss: 0.752383] [G loss: 0.482327] time: 0:46:27.281567\n",
      "0.94735044\n",
      "[Epoch 31/50] [Batch 38/300] [D loss: 0.752401] [G loss: 0.478552] time: 0:46:27.579623\n",
      "0.92691684\n",
      "[Epoch 31/50] [Batch 39/300] [D loss: 0.752395] [G loss: 0.497667] time: 0:46:27.870037\n",
      "0.9138754\n",
      "[Epoch 31/50] [Batch 40/300] [D loss: 0.752399] [G loss: 0.488944] time: 0:46:28.177449\n",
      "0.8899681\n",
      "[Epoch 31/50] [Batch 41/300] [D loss: 0.752413] [G loss: 0.495166] time: 0:46:28.476544\n",
      "0.93105274\n",
      "[Epoch 31/50] [Batch 42/300] [D loss: 0.752385] [G loss: 0.524137] time: 0:46:28.795267\n",
      "0.9476468\n",
      "[Epoch 31/50] [Batch 43/300] [D loss: 0.752395] [G loss: 0.502302] time: 0:46:29.110748\n",
      "0.8840763\n",
      "[Epoch 31/50] [Batch 44/300] [D loss: 0.752379] [G loss: 0.495935] time: 0:46:29.388331\n",
      "0.88258666\n",
      "[Epoch 31/50] [Batch 45/300] [D loss: 0.752400] [G loss: 0.483169] time: 0:46:29.694661\n",
      "0.9503977\n",
      "[Epoch 31/50] [Batch 46/300] [D loss: 0.752395] [G loss: 0.488725] time: 0:46:29.981633\n",
      "0.90265375\n",
      "[Epoch 31/50] [Batch 47/300] [D loss: 0.752370] [G loss: 0.478531] time: 0:46:30.287447\n",
      "0.8527477\n",
      "[Epoch 31/50] [Batch 48/300] [D loss: 0.752376] [G loss: 0.486320] time: 0:46:30.591029\n",
      "0.9455046\n",
      "[Epoch 31/50] [Batch 49/300] [D loss: 0.752392] [G loss: 0.492511] time: 0:46:30.885166\n",
      "0.93127966\n",
      "[Epoch 31/50] [Batch 50/300] [D loss: 0.752364] [G loss: 0.472926] time: 0:46:31.169027\n",
      "0.94011\n",
      "[Epoch 31/50] [Batch 51/300] [D loss: 0.752379] [G loss: 0.502846] time: 0:46:31.474571\n",
      "0.89734226\n",
      "[Epoch 31/50] [Batch 52/300] [D loss: 0.752397] [G loss: 0.482787] time: 0:46:31.783720\n",
      "0.9125393\n",
      "[Epoch 31/50] [Batch 53/300] [D loss: 0.752380] [G loss: 0.512166] time: 0:46:32.100525\n",
      "0.913647\n",
      "[Epoch 31/50] [Batch 54/300] [D loss: 0.752379] [G loss: 0.471375] time: 0:46:32.411637\n",
      "0.9006281\n",
      "[Epoch 31/50] [Batch 55/300] [D loss: 0.752383] [G loss: 0.501668] time: 0:46:32.716751\n",
      "0.91576314\n",
      "[Epoch 31/50] [Batch 56/300] [D loss: 0.752390] [G loss: 0.497851] time: 0:46:33.009414\n",
      "0.85286313\n",
      "[Epoch 31/50] [Batch 57/300] [D loss: 0.752366] [G loss: 0.492172] time: 0:46:33.318209\n",
      "0.94199485\n",
      "[Epoch 31/50] [Batch 58/300] [D loss: 0.752392] [G loss: 0.491333] time: 0:46:33.635783\n",
      "0.9160099\n",
      "[Epoch 31/50] [Batch 59/300] [D loss: 0.752410] [G loss: 0.515997] time: 0:46:33.934069\n",
      "0.89564675\n",
      "[Epoch 31/50] [Batch 60/300] [D loss: 0.752373] [G loss: 0.502242] time: 0:46:34.224833\n",
      "0.90742445\n",
      "[Epoch 31/50] [Batch 61/300] [D loss: 0.752400] [G loss: 0.506634] time: 0:46:34.521954\n",
      "0.9107738\n",
      "[Epoch 31/50] [Batch 62/300] [D loss: 0.752389] [G loss: 0.486431] time: 0:46:34.828261\n",
      "0.9166465\n",
      "[Epoch 31/50] [Batch 63/300] [D loss: 0.752394] [G loss: 0.500881] time: 0:46:35.132331\n",
      "0.9196732\n",
      "[Epoch 31/50] [Batch 64/300] [D loss: 0.752395] [G loss: 0.480935] time: 0:46:35.426491\n",
      "0.8956993\n",
      "[Epoch 31/50] [Batch 65/300] [D loss: 0.752398] [G loss: 0.482828] time: 0:46:35.734634\n",
      "0.8875649\n",
      "[Epoch 31/50] [Batch 66/300] [D loss: 0.752363] [G loss: 0.529616] time: 0:46:36.050147\n",
      "0.93327445\n",
      "[Epoch 31/50] [Batch 67/300] [D loss: 0.752385] [G loss: 0.495355] time: 0:46:36.345969\n",
      "0.9218459\n",
      "[Epoch 31/50] [Batch 68/300] [D loss: 0.752384] [G loss: 0.477855] time: 0:46:36.643231\n",
      "0.9557225\n",
      "[Epoch 31/50] [Batch 69/300] [D loss: 0.752404] [G loss: 0.489622] time: 0:46:37.054133\n",
      "0.93157035\n",
      "[Epoch 31/50] [Batch 70/300] [D loss: 0.752383] [G loss: 0.500375] time: 0:46:37.352358\n",
      "0.9300823\n",
      "[Epoch 31/50] [Batch 71/300] [D loss: 0.752378] [G loss: 0.482659] time: 0:46:37.632653\n",
      "0.9343016\n",
      "[Epoch 31/50] [Batch 72/300] [D loss: 0.752391] [G loss: 0.493119] time: 0:46:37.937554\n",
      "0.88371223\n",
      "[Epoch 31/50] [Batch 73/300] [D loss: 0.752375] [G loss: 0.480754] time: 0:46:38.245907\n",
      "0.9457329\n",
      "[Epoch 31/50] [Batch 74/300] [D loss: 0.752372] [G loss: 0.502748] time: 0:46:38.549565\n",
      "0.93090725\n",
      "[Epoch 31/50] [Batch 75/300] [D loss: 0.752378] [G loss: 0.483083] time: 0:46:38.839559\n",
      "0.936003\n",
      "[Epoch 31/50] [Batch 76/300] [D loss: 0.752380] [G loss: 0.505105] time: 0:46:39.139168\n",
      "0.90558964\n",
      "[Epoch 31/50] [Batch 77/300] [D loss: 0.752382] [G loss: 0.496459] time: 0:46:39.428853\n",
      "0.92493016\n",
      "[Epoch 31/50] [Batch 78/300] [D loss: 0.752362] [G loss: 0.522902] time: 0:46:39.737616\n",
      "0.92955655\n",
      "[Epoch 31/50] [Batch 79/300] [D loss: 0.752411] [G loss: 0.483715] time: 0:46:40.030127\n",
      "0.95222527\n",
      "[Epoch 31/50] [Batch 80/300] [D loss: 0.752397] [G loss: 0.471296] time: 0:46:40.341632\n",
      "0.91231614\n",
      "[Epoch 31/50] [Batch 81/300] [D loss: 0.752377] [G loss: 0.485103] time: 0:46:40.631666\n",
      "0.91164917\n",
      "[Epoch 31/50] [Batch 82/300] [D loss: 0.752367] [G loss: 0.481779] time: 0:46:40.941483\n",
      "0.946161\n",
      "[Epoch 31/50] [Batch 83/300] [D loss: 0.752403] [G loss: 0.504234] time: 0:46:41.234072\n",
      "0.9250963\n",
      "[Epoch 31/50] [Batch 84/300] [D loss: 0.752386] [G loss: 0.475553] time: 0:46:41.535340\n",
      "0.91900367\n",
      "[Epoch 31/50] [Batch 85/300] [D loss: 0.752377] [G loss: 0.480289] time: 0:46:41.842374\n",
      "0.9181518\n",
      "[Epoch 31/50] [Batch 86/300] [D loss: 0.752379] [G loss: 0.499755] time: 0:46:42.145624\n",
      "0.9169939\n",
      "[Epoch 31/50] [Batch 87/300] [D loss: 0.752391] [G loss: 0.486420] time: 0:46:42.443743\n",
      "0.9483013\n",
      "[Epoch 31/50] [Batch 88/300] [D loss: 0.752382] [G loss: 0.488157] time: 0:46:42.755800\n",
      "0.90551215\n",
      "[Epoch 31/50] [Batch 89/300] [D loss: 0.752372] [G loss: 0.485573] time: 0:46:43.052805\n",
      "0.9808925\n",
      "[Epoch 31/50] [Batch 90/300] [D loss: 0.752374] [G loss: 0.490328] time: 0:46:43.349686\n",
      "0.9485921\n",
      "[Epoch 31/50] [Batch 91/300] [D loss: 0.752393] [G loss: 0.514910] time: 0:46:43.643700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764363\n",
      "[Epoch 31/50] [Batch 92/300] [D loss: 0.752378] [G loss: 0.486950] time: 0:46:43.940210\n",
      "0.9412895\n",
      "[Epoch 31/50] [Batch 93/300] [D loss: 0.752394] [G loss: 0.489045] time: 0:46:44.247140\n",
      "0.91734785\n",
      "[Epoch 31/50] [Batch 94/300] [D loss: 0.752385] [G loss: 0.483079] time: 0:46:44.548015\n",
      "0.93274134\n",
      "[Epoch 31/50] [Batch 95/300] [D loss: 0.752385] [G loss: 0.483161] time: 0:46:44.857266\n",
      "0.9403081\n",
      "[Epoch 31/50] [Batch 96/300] [D loss: 0.752373] [G loss: 0.487197] time: 0:46:45.156592\n",
      "0.9178829\n",
      "[Epoch 31/50] [Batch 97/300] [D loss: 0.752378] [G loss: 0.487390] time: 0:46:45.459926\n",
      "0.93514854\n",
      "[Epoch 31/50] [Batch 98/300] [D loss: 0.752379] [G loss: 0.474558] time: 0:46:45.758874\n",
      "0.9290027\n",
      "[Epoch 31/50] [Batch 99/300] [D loss: 0.752369] [G loss: 0.472151] time: 0:46:46.061883\n",
      "0.92919326\n",
      "[Epoch 31/50] [Batch 100/300] [D loss: 0.752370] [G loss: 0.488113] time: 0:46:46.370449\n",
      "0.8930047\n",
      "[Epoch 31/50] [Batch 101/300] [D loss: 0.752386] [G loss: 0.490960] time: 0:46:46.664153\n",
      "0.92337227\n",
      "[Epoch 31/50] [Batch 102/300] [D loss: 0.752373] [G loss: 0.496989] time: 0:46:46.974350\n",
      "0.93163896\n",
      "[Epoch 31/50] [Batch 103/300] [D loss: 0.752368] [G loss: 0.486738] time: 0:46:47.271088\n",
      "0.9080345\n",
      "[Epoch 31/50] [Batch 104/300] [D loss: 0.752369] [G loss: 0.490509] time: 0:46:47.576349\n",
      "0.93731207\n",
      "[Epoch 31/50] [Batch 105/300] [D loss: 0.752409] [G loss: 0.489942] time: 0:46:47.892969\n",
      "0.91619104\n",
      "[Epoch 31/50] [Batch 106/300] [D loss: 0.752363] [G loss: 0.480325] time: 0:46:48.189698\n",
      "0.91381097\n",
      "[Epoch 31/50] [Batch 107/300] [D loss: 0.752397] [G loss: 0.484072] time: 0:46:48.495740\n",
      "0.8961139\n",
      "[Epoch 31/50] [Batch 108/300] [D loss: 0.752377] [G loss: 0.519042] time: 0:46:48.808309\n",
      "0.93106794\n",
      "[Epoch 31/50] [Batch 109/300] [D loss: 0.752395] [G loss: 0.500560] time: 0:46:49.106290\n",
      "0.9456826\n",
      "[Epoch 31/50] [Batch 110/300] [D loss: 0.752374] [G loss: 0.479863] time: 0:46:49.416259\n",
      "0.9326947\n",
      "[Epoch 31/50] [Batch 111/300] [D loss: 0.752390] [G loss: 0.490833] time: 0:46:49.695016\n",
      "0.9521496\n",
      "[Epoch 31/50] [Batch 112/300] [D loss: 0.752382] [G loss: 0.488511] time: 0:46:49.993088\n",
      "0.93320894\n",
      "[Epoch 31/50] [Batch 113/300] [D loss: 0.752384] [G loss: 0.489932] time: 0:46:50.306868\n",
      "0.8891142\n",
      "[Epoch 31/50] [Batch 114/300] [D loss: 0.752380] [G loss: 0.496954] time: 0:46:50.588280\n",
      "0.9523185\n",
      "[Epoch 31/50] [Batch 115/300] [D loss: 0.752377] [G loss: 0.476474] time: 0:46:50.899408\n",
      "0.95549744\n",
      "[Epoch 31/50] [Batch 116/300] [D loss: 0.752362] [G loss: 0.503058] time: 0:46:51.197070\n",
      "0.9381954\n",
      "[Epoch 31/50] [Batch 117/300] [D loss: 0.752389] [G loss: 0.493051] time: 0:46:51.482756\n",
      "0.90909\n",
      "[Epoch 31/50] [Batch 118/300] [D loss: 0.752368] [G loss: 0.502625] time: 0:46:51.792208\n",
      "0.8825147\n",
      "[Epoch 31/50] [Batch 119/300] [D loss: 0.752377] [G loss: 0.478348] time: 0:46:52.079719\n",
      "0.89168864\n",
      "[Epoch 31/50] [Batch 120/300] [D loss: 0.752384] [G loss: 0.503607] time: 0:46:52.385908\n",
      "0.88736683\n",
      "[Epoch 31/50] [Batch 121/300] [D loss: 0.752385] [G loss: 0.493059] time: 0:46:52.692891\n",
      "0.94326687\n",
      "[Epoch 31/50] [Batch 122/300] [D loss: 0.752377] [G loss: 0.495463] time: 0:46:52.971563\n",
      "0.9591634\n",
      "[Epoch 31/50] [Batch 123/300] [D loss: 0.752374] [G loss: 0.477777] time: 0:46:53.264454\n",
      "0.91370255\n",
      "[Epoch 31/50] [Batch 124/300] [D loss: 0.752397] [G loss: 0.487561] time: 0:46:53.543780\n",
      "0.9534624\n",
      "[Epoch 31/50] [Batch 125/300] [D loss: 0.752361] [G loss: 0.495315] time: 0:46:53.839198\n",
      "0.928011\n",
      "[Epoch 31/50] [Batch 126/300] [D loss: 0.752374] [G loss: 0.491940] time: 0:46:54.136090\n",
      "0.9069144\n",
      "[Epoch 31/50] [Batch 127/300] [D loss: 0.752367] [G loss: 0.501809] time: 0:46:54.437899\n",
      "0.91947776\n",
      "[Epoch 31/50] [Batch 128/300] [D loss: 0.752402] [G loss: 0.478752] time: 0:46:54.753041\n",
      "0.88089085\n",
      "[Epoch 31/50] [Batch 129/300] [D loss: 0.752388] [G loss: 0.483495] time: 0:46:55.056101\n",
      "0.9280417\n",
      "[Epoch 31/50] [Batch 130/300] [D loss: 0.752373] [G loss: 0.498266] time: 0:46:55.377479\n",
      "0.9448579\n",
      "[Epoch 31/50] [Batch 131/300] [D loss: 0.752377] [G loss: 0.477026] time: 0:46:55.680951\n",
      "0.9393682\n",
      "[Epoch 31/50] [Batch 132/300] [D loss: 0.752392] [G loss: 0.482670] time: 0:46:55.978644\n",
      "0.9053593\n",
      "[Epoch 31/50] [Batch 133/300] [D loss: 0.752387] [G loss: 0.481408] time: 0:46:56.279544\n",
      "0.9296481\n",
      "[Epoch 31/50] [Batch 134/300] [D loss: 0.752361] [G loss: 0.498969] time: 0:46:56.572026\n",
      "0.91619104\n",
      "[Epoch 31/50] [Batch 135/300] [D loss: 0.752383] [G loss: 0.488799] time: 0:46:56.866349\n",
      "0.89628696\n",
      "[Epoch 31/50] [Batch 136/300] [D loss: 0.752387] [G loss: 0.485117] time: 0:46:57.168462\n",
      "0.90681416\n",
      "[Epoch 31/50] [Batch 137/300] [D loss: 0.752382] [G loss: 0.504385] time: 0:46:57.476999\n",
      "0.9214504\n",
      "[Epoch 31/50] [Batch 138/300] [D loss: 0.752373] [G loss: 0.511133] time: 0:46:57.785746\n",
      "0.916558\n",
      "[Epoch 31/50] [Batch 139/300] [D loss: 0.752387] [G loss: 0.485624] time: 0:46:58.103257\n",
      "0.87201875\n",
      "[Epoch 31/50] [Batch 140/300] [D loss: 0.752392] [G loss: 0.487560] time: 0:46:58.409258\n",
      "0.93857735\n",
      "[Epoch 31/50] [Batch 141/300] [D loss: 0.752390] [G loss: 0.501103] time: 0:46:58.713509\n",
      "0.9674945\n",
      "[Epoch 31/50] [Batch 142/300] [D loss: 0.752380] [G loss: 0.494838] time: 0:46:59.000321\n",
      "0.93944865\n",
      "[Epoch 31/50] [Batch 143/300] [D loss: 0.752372] [G loss: 0.477357] time: 0:46:59.300655\n",
      "0.96431285\n",
      "[Epoch 31/50] [Batch 144/300] [D loss: 0.752384] [G loss: 0.491765] time: 0:46:59.610554\n",
      "0.89415884\n",
      "[Epoch 31/50] [Batch 145/300] [D loss: 0.752389] [G loss: 0.473017] time: 0:46:59.901194\n",
      "0.94262624\n",
      "[Epoch 31/50] [Batch 146/300] [D loss: 0.752396] [G loss: 0.487621] time: 0:47:00.207336\n",
      "0.9151406\n",
      "[Epoch 31/50] [Batch 147/300] [D loss: 0.752379] [G loss: 0.486962] time: 0:47:00.486424\n",
      "0.9361151\n",
      "[Epoch 31/50] [Batch 148/300] [D loss: 0.752377] [G loss: 0.473294] time: 0:47:00.772803\n",
      "0.89929193\n",
      "[Epoch 31/50] [Batch 149/300] [D loss: 0.752372] [G loss: 0.487472] time: 0:47:01.075582\n",
      "0.9498944\n",
      "[Epoch 31/50] [Batch 150/300] [D loss: 0.752372] [G loss: 0.477609] time: 0:47:01.366951\n",
      "0.913558\n",
      "[Epoch 31/50] [Batch 151/300] [D loss: 0.752375] [G loss: 0.502925] time: 0:47:01.664711\n",
      "0.9144821\n",
      "[Epoch 31/50] [Batch 152/300] [D loss: 0.752387] [G loss: 0.475594] time: 0:47:01.969949\n",
      "0.9334081\n",
      "[Epoch 31/50] [Batch 153/300] [D loss: 0.752372] [G loss: 0.509675] time: 0:47:02.282070\n",
      "0.9419454\n",
      "[Epoch 31/50] [Batch 154/300] [D loss: 0.752387] [G loss: 0.495441] time: 0:47:02.596381\n",
      "0.88111067\n",
      "[Epoch 31/50] [Batch 155/300] [D loss: 0.752354] [G loss: 0.520002] time: 0:47:02.904108\n",
      "0.9502118\n",
      "[Epoch 31/50] [Batch 156/300] [D loss: 0.752372] [G loss: 0.483742] time: 0:47:03.222246\n",
      "0.9343427\n",
      "[Epoch 31/50] [Batch 157/300] [D loss: 0.752372] [G loss: 0.486431] time: 0:47:03.518024\n",
      "0.93743277\n",
      "[Epoch 31/50] [Batch 158/300] [D loss: 0.752374] [G loss: 0.497651] time: 0:47:03.842582\n",
      "0.9138977\n",
      "[Epoch 31/50] [Batch 159/300] [D loss: 0.752368] [G loss: 0.529396] time: 0:47:04.146053\n",
      "0.89983726\n",
      "[Epoch 31/50] [Batch 160/300] [D loss: 0.752370] [G loss: 0.479344] time: 0:47:04.444931\n",
      "0.9399554\n",
      "[Epoch 31/50] [Batch 161/300] [D loss: 0.752374] [G loss: 0.513342] time: 0:47:04.735540\n",
      "0.92006344\n",
      "[Epoch 31/50] [Batch 162/300] [D loss: 0.752384] [G loss: 0.533610] time: 0:47:05.030808\n",
      "0.9616463\n",
      "[Epoch 31/50] [Batch 163/300] [D loss: 0.752384] [G loss: 0.504275] time: 0:47:05.326352\n",
      "0.9457342\n",
      "[Epoch 31/50] [Batch 164/300] [D loss: 0.752380] [G loss: 0.545020] time: 0:47:05.628543\n",
      "0.96168995\n",
      "[Epoch 31/50] [Batch 165/300] [D loss: 0.752378] [G loss: 0.507862] time: 0:47:05.927518\n",
      "0.9080073\n",
      "[Epoch 31/50] [Batch 166/300] [D loss: 0.752368] [G loss: 0.482108] time: 0:47:06.241632\n",
      "0.9261062\n",
      "[Epoch 31/50] [Batch 167/300] [D loss: 0.752376] [G loss: 0.532066] time: 0:47:06.535814\n",
      "0.90297127\n",
      "[Epoch 31/50] [Batch 168/300] [D loss: 0.752358] [G loss: 0.482408] time: 0:47:06.843596\n",
      "0.9122264\n",
      "[Epoch 31/50] [Batch 169/300] [D loss: 0.752387] [G loss: 0.484782] time: 0:47:07.148910\n",
      "0.89521104\n",
      "[Epoch 31/50] [Batch 170/300] [D loss: 0.752404] [G loss: 0.513538] time: 0:47:07.454339\n",
      "0.89978725\n",
      "[Epoch 31/50] [Batch 171/300] [D loss: 0.752365] [G loss: 0.490780] time: 0:47:07.752228\n",
      "0.9534034\n",
      "[Epoch 31/50] [Batch 172/300] [D loss: 0.752376] [G loss: 0.488370] time: 0:47:08.044590\n",
      "0.9531316\n",
      "[Epoch 31/50] [Batch 173/300] [D loss: 0.752376] [G loss: 0.491740] time: 0:47:08.339784\n",
      "0.9140199\n",
      "[Epoch 31/50] [Batch 174/300] [D loss: 0.752390] [G loss: 0.473424] time: 0:47:08.641831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91915536\n",
      "[Epoch 31/50] [Batch 175/300] [D loss: 0.752368] [G loss: 0.484477] time: 0:47:08.945646\n",
      "0.93826485\n",
      "[Epoch 31/50] [Batch 176/300] [D loss: 0.752366] [G loss: 0.485013] time: 0:47:09.239678\n",
      "0.8987057\n",
      "[Epoch 31/50] [Batch 177/300] [D loss: 0.752365] [G loss: 0.505718] time: 0:47:09.534586\n",
      "0.9186163\n",
      "[Epoch 31/50] [Batch 178/300] [D loss: 0.752373] [G loss: 0.518663] time: 0:47:09.828048\n",
      "0.9306647\n",
      "[Epoch 31/50] [Batch 179/300] [D loss: 0.752366] [G loss: 0.528129] time: 0:47:10.129269\n",
      "0.9343024\n",
      "[Epoch 31/50] [Batch 180/300] [D loss: 0.752402] [G loss: 0.492542] time: 0:47:10.416650\n",
      "0.9488657\n",
      "[Epoch 31/50] [Batch 181/300] [D loss: 0.752378] [G loss: 0.501362] time: 0:47:10.721573\n",
      "0.952346\n",
      "[Epoch 31/50] [Batch 182/300] [D loss: 0.752369] [G loss: 0.495741] time: 0:47:11.006197\n",
      "0.880064\n",
      "[Epoch 31/50] [Batch 183/300] [D loss: 0.752382] [G loss: 0.513660] time: 0:47:11.309405\n",
      "0.9508157\n",
      "[Epoch 31/50] [Batch 184/300] [D loss: 0.752357] [G loss: 0.517482] time: 0:47:11.614693\n",
      "0.90464973\n",
      "[Epoch 31/50] [Batch 185/300] [D loss: 0.752389] [G loss: 0.487839] time: 0:47:11.917041\n",
      "0.90642005\n",
      "[Epoch 31/50] [Batch 186/300] [D loss: 0.752371] [G loss: 0.492312] time: 0:47:12.221997\n",
      "0.93491775\n",
      "[Epoch 31/50] [Batch 187/300] [D loss: 0.752365] [G loss: 0.487022] time: 0:47:12.529693\n",
      "0.8836239\n",
      "[Epoch 31/50] [Batch 188/300] [D loss: 0.752381] [G loss: 0.500483] time: 0:47:12.834398\n",
      "0.91740155\n",
      "[Epoch 31/50] [Batch 189/300] [D loss: 0.752391] [G loss: 0.494094] time: 0:47:13.144003\n",
      "0.87649614\n",
      "[Epoch 31/50] [Batch 190/300] [D loss: 0.752385] [G loss: 0.485618] time: 0:47:13.439875\n",
      "0.94493526\n",
      "[Epoch 31/50] [Batch 191/300] [D loss: 0.752380] [G loss: 0.481055] time: 0:47:13.744883\n",
      "0.91648644\n",
      "[Epoch 31/50] [Batch 192/300] [D loss: 0.752384] [G loss: 0.498145] time: 0:47:14.014606\n",
      "0.9199851\n",
      "[Epoch 31/50] [Batch 193/300] [D loss: 0.752359] [G loss: 0.528378] time: 0:47:14.311744\n",
      "0.94622463\n",
      "[Epoch 31/50] [Batch 194/300] [D loss: 0.752365] [G loss: 0.488185] time: 0:47:14.611324\n",
      "0.9649659\n",
      "[Epoch 31/50] [Batch 195/300] [D loss: 0.752383] [G loss: 0.500087] time: 0:47:14.905367\n",
      "0.9459813\n",
      "[Epoch 31/50] [Batch 196/300] [D loss: 0.752402] [G loss: 0.480511] time: 0:47:15.198835\n",
      "0.9391847\n",
      "[Epoch 31/50] [Batch 197/300] [D loss: 0.752377] [G loss: 0.482083] time: 0:47:15.502756\n",
      "0.95591944\n",
      "[Epoch 31/50] [Batch 198/300] [D loss: 0.752377] [G loss: 0.529930] time: 0:47:15.811249\n",
      "0.8945422\n",
      "[Epoch 31/50] [Batch 199/300] [D loss: 0.752391] [G loss: 0.477688] time: 0:47:16.109808\n",
      "0.92914504\n",
      "[Epoch 31/50] [Batch 200/300] [D loss: 0.752381] [G loss: 0.524930] time: 0:47:16.414410\n",
      "0.9480397\n",
      "[Epoch 31/50] [Batch 201/300] [D loss: 0.752376] [G loss: 0.512454] time: 0:47:16.718242\n",
      "0.9302046\n",
      "[Epoch 31/50] [Batch 202/300] [D loss: 0.752389] [G loss: 0.489646] time: 0:47:17.019704\n",
      "0.91604286\n",
      "[Epoch 31/50] [Batch 203/300] [D loss: 0.752369] [G loss: 0.483730] time: 0:47:17.328592\n",
      "0.9462428\n",
      "[Epoch 31/50] [Batch 204/300] [D loss: 0.752367] [G loss: 0.499169] time: 0:47:17.624105\n",
      "0.9330242\n",
      "[Epoch 31/50] [Batch 205/300] [D loss: 0.752397] [G loss: 0.497028] time: 0:47:17.935828\n",
      "0.92613196\n",
      "[Epoch 31/50] [Batch 206/300] [D loss: 0.752375] [G loss: 0.514830] time: 0:47:18.238625\n",
      "0.9482958\n",
      "[Epoch 31/50] [Batch 207/300] [D loss: 0.752374] [G loss: 0.480327] time: 0:47:18.537348\n",
      "0.9431193\n",
      "[Epoch 31/50] [Batch 208/300] [D loss: 0.752393] [G loss: 0.498433] time: 0:47:18.836220\n",
      "0.93107367\n",
      "[Epoch 31/50] [Batch 209/300] [D loss: 0.752382] [G loss: 0.496439] time: 0:47:19.146820\n",
      "0.94789773\n",
      "[Epoch 31/50] [Batch 210/300] [D loss: 0.752383] [G loss: 0.487911] time: 0:47:19.451662\n",
      "0.91086197\n",
      "[Epoch 31/50] [Batch 211/300] [D loss: 0.752379] [G loss: 0.498197] time: 0:47:19.741410\n",
      "0.88774896\n",
      "[Epoch 31/50] [Batch 212/300] [D loss: 0.752385] [G loss: 0.507033] time: 0:47:20.052753\n",
      "0.91277194\n",
      "[Epoch 31/50] [Batch 213/300] [D loss: 0.752370] [G loss: 0.490278] time: 0:47:20.339322\n",
      "0.96266913\n",
      "[Epoch 31/50] [Batch 214/300] [D loss: 0.752382] [G loss: 0.483035] time: 0:47:20.640760\n",
      "0.93801147\n",
      "[Epoch 31/50] [Batch 215/300] [D loss: 0.752386] [G loss: 0.478072] time: 0:47:20.945704\n",
      "0.9197337\n",
      "[Epoch 31/50] [Batch 216/300] [D loss: 0.752381] [G loss: 0.494506] time: 0:47:21.232309\n",
      "0.9314322\n",
      "[Epoch 31/50] [Batch 217/300] [D loss: 0.752387] [G loss: 0.479883] time: 0:47:21.527958\n",
      "0.9077222\n",
      "[Epoch 31/50] [Batch 218/300] [D loss: 0.752373] [G loss: 0.491040] time: 0:47:21.826774\n",
      "0.9044628\n",
      "[Epoch 31/50] [Batch 219/300] [D loss: 0.752371] [G loss: 0.493849] time: 0:47:22.125356\n",
      "0.9124271\n",
      "[Epoch 31/50] [Batch 220/300] [D loss: 0.752366] [G loss: 0.527331] time: 0:47:22.424118\n",
      "0.9411145\n",
      "[Epoch 31/50] [Batch 221/300] [D loss: 0.752403] [G loss: 0.481258] time: 0:47:22.721538\n",
      "0.9477658\n",
      "[Epoch 31/50] [Batch 222/300] [D loss: 0.752370] [G loss: 0.494895] time: 0:47:22.994101\n",
      "0.9370131\n",
      "[Epoch 31/50] [Batch 223/300] [D loss: 0.752371] [G loss: 0.502386] time: 0:47:23.293438\n",
      "0.86730343\n",
      "[Epoch 31/50] [Batch 224/300] [D loss: 0.752371] [G loss: 0.478681] time: 0:47:23.597966\n",
      "0.9264458\n",
      "[Epoch 31/50] [Batch 225/300] [D loss: 0.752387] [G loss: 0.510515] time: 0:47:23.896853\n",
      "0.9499306\n",
      "[Epoch 31/50] [Batch 226/300] [D loss: 0.752394] [G loss: 0.485730] time: 0:47:24.191556\n",
      "0.8774192\n",
      "[Epoch 31/50] [Batch 227/300] [D loss: 0.752357] [G loss: 0.511968] time: 0:47:24.478740\n",
      "0.870742\n",
      "[Epoch 31/50] [Batch 228/300] [D loss: 0.752361] [G loss: 0.511430] time: 0:47:24.782369\n",
      "0.92093134\n",
      "[Epoch 31/50] [Batch 229/300] [D loss: 0.752386] [G loss: 0.530104] time: 0:47:25.090063\n",
      "0.82091624\n",
      "[Epoch 31/50] [Batch 230/300] [D loss: 0.752379] [G loss: 0.618331] time: 0:47:25.394200\n",
      "0.957501\n",
      "[Epoch 31/50] [Batch 231/300] [D loss: 0.752375] [G loss: 0.725635] time: 0:47:25.691787\n",
      "0.94967955\n",
      "[Epoch 31/50] [Batch 232/300] [D loss: 0.752375] [G loss: 0.669388] time: 0:47:25.970854\n",
      "0.9460058\n",
      "[Epoch 31/50] [Batch 233/300] [D loss: 0.752383] [G loss: 0.572573] time: 0:47:26.252316\n",
      "0.9087496\n",
      "[Epoch 31/50] [Batch 234/300] [D loss: 0.752375] [G loss: 0.601500] time: 0:47:26.552106\n",
      "0.76946163\n",
      "[Epoch 31/50] [Batch 235/300] [D loss: 0.752406] [G loss: 0.553225] time: 0:47:26.860623\n",
      "0.9301807\n",
      "[Epoch 31/50] [Batch 236/300] [D loss: 0.752380] [G loss: 0.590030] time: 0:47:27.169019\n",
      "0.883646\n",
      "[Epoch 31/50] [Batch 237/300] [D loss: 0.752380] [G loss: 0.615367] time: 0:47:27.472636\n",
      "0.87932247\n",
      "[Epoch 31/50] [Batch 238/300] [D loss: 0.752393] [G loss: 0.583171] time: 0:47:27.781373\n",
      "0.9066205\n",
      "[Epoch 31/50] [Batch 239/300] [D loss: 0.752391] [G loss: 0.547339] time: 0:47:28.078298\n",
      "0.88466734\n",
      "[Epoch 31/50] [Batch 240/300] [D loss: 0.752386] [G loss: 0.558735] time: 0:47:28.391799\n",
      "0.92995065\n",
      "[Epoch 31/50] [Batch 241/300] [D loss: 0.752381] [G loss: 0.545769] time: 0:47:28.703491\n",
      "0.8871222\n",
      "[Epoch 31/50] [Batch 242/300] [D loss: 0.752392] [G loss: 0.548128] time: 0:47:29.002842\n",
      "0.9359599\n",
      "[Epoch 31/50] [Batch 243/300] [D loss: 0.752364] [G loss: 0.527793] time: 0:47:29.275329\n",
      "0.9350264\n",
      "[Epoch 31/50] [Batch 244/300] [D loss: 0.752380] [G loss: 0.523010] time: 0:47:29.583069\n",
      "0.9484604\n",
      "[Epoch 31/50] [Batch 245/300] [D loss: 0.752383] [G loss: 0.518613] time: 0:47:29.895891\n",
      "0.9151501\n",
      "[Epoch 31/50] [Batch 246/300] [D loss: 0.752373] [G loss: 0.538018] time: 0:47:30.190108\n",
      "0.9543259\n",
      "[Epoch 31/50] [Batch 247/300] [D loss: 0.752361] [G loss: 0.521446] time: 0:47:30.497047\n",
      "0.9220118\n",
      "[Epoch 31/50] [Batch 248/300] [D loss: 0.752374] [G loss: 0.520001] time: 0:47:30.820491\n",
      "0.94279194\n",
      "[Epoch 31/50] [Batch 249/300] [D loss: 0.752381] [G loss: 0.528190] time: 0:47:31.118183\n",
      "0.9002287\n",
      "[Epoch 31/50] [Batch 250/300] [D loss: 0.752378] [G loss: 0.540995] time: 0:47:31.432985\n",
      "0.89566255\n",
      "[Epoch 31/50] [Batch 251/300] [D loss: 0.752389] [G loss: 0.560991] time: 0:47:31.729399\n",
      "0.9131569\n",
      "[Epoch 31/50] [Batch 252/300] [D loss: 0.752375] [G loss: 0.536836] time: 0:47:32.031251\n",
      "0.92683125\n",
      "[Epoch 31/50] [Batch 253/300] [D loss: 0.752384] [G loss: 0.516142] time: 0:47:32.342437\n",
      "0.90636617\n",
      "[Epoch 31/50] [Batch 254/300] [D loss: 0.752372] [G loss: 0.516551] time: 0:47:32.638690\n",
      "0.89914364\n",
      "[Epoch 31/50] [Batch 255/300] [D loss: 0.752364] [G loss: 0.525314] time: 0:47:32.925945\n",
      "0.9314347\n",
      "[Epoch 31/50] [Batch 256/300] [D loss: 0.752374] [G loss: 0.513657] time: 0:47:33.211675\n",
      "0.94573045\n",
      "[Epoch 31/50] [Batch 257/300] [D loss: 0.752378] [G loss: 0.532704] time: 0:47:33.502575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94888896\n",
      "[Epoch 31/50] [Batch 258/300] [D loss: 0.752369] [G loss: 0.520375] time: 0:47:33.803380\n",
      "0.9250264\n",
      "[Epoch 31/50] [Batch 259/300] [D loss: 0.752373] [G loss: 0.529619] time: 0:47:34.096697\n",
      "0.9268999\n",
      "[Epoch 31/50] [Batch 260/300] [D loss: 0.752372] [G loss: 0.526468] time: 0:47:34.404298\n",
      "0.9287228\n",
      "[Epoch 31/50] [Batch 261/300] [D loss: 0.752373] [G loss: 0.494612] time: 0:47:34.706451\n",
      "0.88267994\n",
      "[Epoch 31/50] [Batch 262/300] [D loss: 0.752394] [G loss: 0.511981] time: 0:47:35.003467\n",
      "0.9177168\n",
      "[Epoch 31/50] [Batch 263/300] [D loss: 0.752369] [G loss: 0.524689] time: 0:47:35.314967\n",
      "0.9335579\n",
      "[Epoch 31/50] [Batch 264/300] [D loss: 0.752375] [G loss: 0.508241] time: 0:47:35.598489\n",
      "0.9645524\n",
      "[Epoch 31/50] [Batch 265/300] [D loss: 0.752373] [G loss: 0.513809] time: 0:47:35.906269\n",
      "0.9025442\n",
      "[Epoch 31/50] [Batch 266/300] [D loss: 0.752376] [G loss: 0.500544] time: 0:47:36.201170\n",
      "0.91596836\n",
      "[Epoch 31/50] [Batch 267/300] [D loss: 0.752367] [G loss: 0.495036] time: 0:47:36.515840\n",
      "0.9397107\n",
      "[Epoch 31/50] [Batch 268/300] [D loss: 0.752378] [G loss: 0.545845] time: 0:47:36.826653\n",
      "0.93379277\n",
      "[Epoch 31/50] [Batch 269/300] [D loss: 0.752397] [G loss: 0.520019] time: 0:47:37.134113\n",
      "0.9159475\n",
      "[Epoch 31/50] [Batch 270/300] [D loss: 0.752363] [G loss: 0.495849] time: 0:47:37.428487\n",
      "0.90544504\n",
      "[Epoch 31/50] [Batch 271/300] [D loss: 0.752363] [G loss: 0.509226] time: 0:47:37.719706\n",
      "0.9390387\n",
      "[Epoch 31/50] [Batch 272/300] [D loss: 0.752385] [G loss: 0.494588] time: 0:47:38.026044\n",
      "0.9235603\n",
      "[Epoch 31/50] [Batch 273/300] [D loss: 0.752362] [G loss: 0.491807] time: 0:47:38.323942\n",
      "0.94006234\n",
      "[Epoch 31/50] [Batch 274/300] [D loss: 0.752381] [G loss: 0.522796] time: 0:47:38.632381\n",
      "0.9534378\n",
      "[Epoch 31/50] [Batch 275/300] [D loss: 0.752376] [G loss: 0.526990] time: 0:47:38.949184\n",
      "0.93921804\n",
      "[Epoch 31/50] [Batch 276/300] [D loss: 0.752353] [G loss: 0.521631] time: 0:47:39.251331\n",
      "0.909403\n",
      "[Epoch 31/50] [Batch 277/300] [D loss: 0.752363] [G loss: 0.534175] time: 0:47:39.544210\n",
      "0.90548897\n",
      "[Epoch 31/50] [Batch 278/300] [D loss: 0.752360] [G loss: 0.521586] time: 0:47:39.846439\n",
      "0.9090178\n",
      "[Epoch 31/50] [Batch 279/300] [D loss: 0.752369] [G loss: 0.531547] time: 0:47:40.143298\n",
      "0.8794255\n",
      "[Epoch 31/50] [Batch 280/300] [D loss: 0.752373] [G loss: 0.504521] time: 0:47:40.462272\n",
      "0.93650895\n",
      "[Epoch 31/50] [Batch 281/300] [D loss: 0.752367] [G loss: 0.506223] time: 0:47:40.774293\n",
      "0.9382119\n",
      "[Epoch 31/50] [Batch 282/300] [D loss: 0.752386] [G loss: 0.526710] time: 0:47:41.065926\n",
      "0.90889335\n",
      "[Epoch 31/50] [Batch 283/300] [D loss: 0.752381] [G loss: 0.494007] time: 0:47:41.371154\n",
      "0.91464776\n",
      "[Epoch 31/50] [Batch 284/300] [D loss: 0.752384] [G loss: 0.498468] time: 0:47:41.671428\n",
      "0.90380186\n",
      "[Epoch 31/50] [Batch 285/300] [D loss: 0.752378] [G loss: 0.499183] time: 0:47:41.966221\n",
      "0.9531992\n",
      "[Epoch 31/50] [Batch 286/300] [D loss: 0.752363] [G loss: 0.502379] time: 0:47:42.263673\n",
      "0.892965\n",
      "[Epoch 31/50] [Batch 287/300] [D loss: 0.752373] [G loss: 0.481883] time: 0:47:42.564575\n",
      "0.927856\n",
      "[Epoch 31/50] [Batch 288/300] [D loss: 0.752390] [G loss: 0.522321] time: 0:47:42.869509\n",
      "0.8913935\n",
      "[Epoch 31/50] [Batch 289/300] [D loss: 0.752372] [G loss: 0.491146] time: 0:47:43.178203\n",
      "0.910644\n",
      "[Epoch 31/50] [Batch 290/300] [D loss: 0.752369] [G loss: 0.508129] time: 0:47:43.490655\n",
      "0.92954016\n",
      "[Epoch 31/50] [Batch 291/300] [D loss: 0.752372] [G loss: 0.532258] time: 0:47:43.811341\n",
      "0.8856316\n",
      "[Epoch 31/50] [Batch 292/300] [D loss: 0.752382] [G loss: 0.500039] time: 0:47:44.098257\n",
      "0.9083988\n",
      "[Epoch 31/50] [Batch 293/300] [D loss: 0.752372] [G loss: 0.517049] time: 0:47:44.404958\n",
      "0.9256611\n",
      "[Epoch 31/50] [Batch 294/300] [D loss: 0.752383] [G loss: 0.507758] time: 0:47:44.690258\n",
      "0.94338185\n",
      "[Epoch 31/50] [Batch 295/300] [D loss: 0.752363] [G loss: 0.498177] time: 0:47:44.996022\n",
      "0.9706562\n",
      "[Epoch 31/50] [Batch 296/300] [D loss: 0.752373] [G loss: 0.510061] time: 0:47:45.295827\n",
      "0.9495179\n",
      "[Epoch 31/50] [Batch 297/300] [D loss: 0.752392] [G loss: 0.506760] time: 0:47:45.582486\n",
      "0.9264736\n",
      "[Epoch 31/50] [Batch 298/300] [D loss: 0.752359] [G loss: 0.523229] time: 0:47:45.881599\n",
      "0.8821778\n",
      "[Epoch 31/50] [Batch 299/300] [D loss: 0.752355] [G loss: 0.499087] time: 0:47:46.190787\n",
      "0.9301669\n",
      "[Epoch 32/50] [Batch 0/300] [D loss: 0.752367] [G loss: 0.527708] time: 0:47:46.511505\n",
      "0.93299097\n",
      "[Epoch 32/50] [Batch 1/300] [D loss: 0.752386] [G loss: 0.498875] time: 0:47:46.802163\n",
      "0.90300703\n",
      "[Epoch 32/50] [Batch 2/300] [D loss: 0.752350] [G loss: 0.506786] time: 0:47:47.094165\n",
      "0.9169903\n",
      "[Epoch 32/50] [Batch 3/300] [D loss: 0.752367] [G loss: 0.508746] time: 0:47:47.404221\n",
      "0.9164484\n",
      "[Epoch 32/50] [Batch 4/300] [D loss: 0.752388] [G loss: 0.493552] time: 0:47:47.710330\n",
      "0.9139957\n",
      "[Epoch 32/50] [Batch 5/300] [D loss: 0.752378] [G loss: 0.495137] time: 0:47:48.000196\n",
      "0.88078094\n",
      "[Epoch 32/50] [Batch 6/300] [D loss: 0.752371] [G loss: 0.494454] time: 0:47:48.288894\n",
      "0.9025925\n",
      "[Epoch 32/50] [Batch 7/300] [D loss: 0.752356] [G loss: 0.490095] time: 0:47:48.590957\n",
      "0.9116699\n",
      "[Epoch 32/50] [Batch 8/300] [D loss: 0.752391] [G loss: 0.498429] time: 0:47:48.892171\n",
      "0.93089336\n",
      "[Epoch 32/50] [Batch 9/300] [D loss: 0.752373] [G loss: 0.491699] time: 0:47:49.195829\n",
      "0.8886811\n",
      "[Epoch 32/50] [Batch 10/300] [D loss: 0.752386] [G loss: 0.484979] time: 0:47:49.496565\n",
      "0.91614395\n",
      "[Epoch 32/50] [Batch 11/300] [D loss: 0.752379] [G loss: 0.499523] time: 0:47:49.791946\n",
      "0.8672531\n",
      "[Epoch 32/50] [Batch 12/300] [D loss: 0.752378] [G loss: 0.519734] time: 0:47:50.093183\n",
      "0.90935606\n",
      "[Epoch 32/50] [Batch 13/300] [D loss: 0.752374] [G loss: 0.492700] time: 0:47:50.393323\n",
      "0.90761465\n",
      "[Epoch 32/50] [Batch 14/300] [D loss: 0.752352] [G loss: 0.494539] time: 0:47:50.694912\n",
      "0.92116874\n",
      "[Epoch 32/50] [Batch 15/300] [D loss: 0.752364] [G loss: 0.498387] time: 0:47:50.996420\n",
      "0.88480544\n",
      "[Epoch 32/50] [Batch 16/300] [D loss: 0.752364] [G loss: 0.504407] time: 0:47:51.293638\n",
      "0.8938629\n",
      "[Epoch 32/50] [Batch 17/300] [D loss: 0.752383] [G loss: 0.497186] time: 0:47:51.599356\n",
      "0.8910019\n",
      "[Epoch 32/50] [Batch 18/300] [D loss: 0.752371] [G loss: 0.489129] time: 0:47:51.916674\n",
      "0.9374532\n",
      "[Epoch 32/50] [Batch 19/300] [D loss: 0.752384] [G loss: 0.491034] time: 0:47:52.237625\n",
      "0.9600846\n",
      "[Epoch 32/50] [Batch 20/300] [D loss: 0.752363] [G loss: 0.496645] time: 0:47:52.546350\n",
      "0.91056037\n",
      "[Epoch 32/50] [Batch 21/300] [D loss: 0.752349] [G loss: 0.492233] time: 0:47:52.848881\n",
      "0.9348836\n",
      "[Epoch 32/50] [Batch 22/300] [D loss: 0.752391] [G loss: 0.488497] time: 0:47:53.169630\n",
      "0.90748805\n",
      "[Epoch 32/50] [Batch 23/300] [D loss: 0.752385] [G loss: 0.483618] time: 0:47:53.476880\n",
      "0.90550137\n",
      "[Epoch 32/50] [Batch 24/300] [D loss: 0.752380] [G loss: 0.514372] time: 0:47:53.785456\n",
      "0.9243843\n",
      "[Epoch 32/50] [Batch 25/300] [D loss: 0.752376] [G loss: 0.477043] time: 0:47:54.088474\n",
      "0.93320155\n",
      "[Epoch 32/50] [Batch 26/300] [D loss: 0.752364] [G loss: 0.489999] time: 0:47:54.383939\n",
      "0.91534585\n",
      "[Epoch 32/50] [Batch 27/300] [D loss: 0.752399] [G loss: 0.484180] time: 0:47:54.688874\n",
      "0.92925376\n",
      "[Epoch 32/50] [Batch 28/300] [D loss: 0.752379] [G loss: 0.503492] time: 0:47:54.997733\n",
      "0.8969209\n",
      "[Epoch 32/50] [Batch 29/300] [D loss: 0.752377] [G loss: 0.513782] time: 0:47:55.307078\n",
      "0.92107743\n",
      "[Epoch 32/50] [Batch 30/300] [D loss: 0.752379] [G loss: 0.483745] time: 0:47:55.610706\n",
      "0.9141159\n",
      "[Epoch 32/50] [Batch 32/300] [D loss: 0.752372] [G loss: 0.487098] time: 0:47:55.918916\n",
      "0.90703386\n",
      "[Epoch 32/50] [Batch 33/300] [D loss: 0.752370] [G loss: 0.514378] time: 0:47:56.227634\n",
      "0.9466968\n",
      "[Epoch 32/50] [Batch 34/300] [D loss: 0.752365] [G loss: 0.490732] time: 0:47:56.533293\n",
      "0.9177974\n",
      "[Epoch 32/50] [Batch 35/300] [D loss: 0.752364] [G loss: 0.501041] time: 0:47:56.848263\n",
      "0.9464962\n",
      "[Epoch 32/50] [Batch 36/300] [D loss: 0.752376] [G loss: 0.498223] time: 0:47:57.155567\n",
      "0.94680816\n",
      "[Epoch 32/50] [Batch 37/300] [D loss: 0.752372] [G loss: 0.503917] time: 0:47:57.447225\n",
      "0.9071074\n",
      "[Epoch 32/50] [Batch 38/300] [D loss: 0.752389] [G loss: 0.484777] time: 0:47:57.762157\n",
      "0.9160397\n",
      "[Epoch 32/50] [Batch 39/300] [D loss: 0.752352] [G loss: 0.515073] time: 0:47:58.079044\n",
      "0.916115\n",
      "[Epoch 32/50] [Batch 40/300] [D loss: 0.752368] [G loss: 0.489974] time: 0:47:58.387680\n",
      "0.9141626\n",
      "[Epoch 32/50] [Batch 41/300] [D loss: 0.752372] [G loss: 0.522472] time: 0:47:58.688104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9071372\n",
      "[Epoch 32/50] [Batch 42/300] [D loss: 0.752378] [G loss: 0.486418] time: 0:47:58.978881\n",
      "0.85468274\n",
      "[Epoch 32/50] [Batch 43/300] [D loss: 0.752376] [G loss: 0.497084] time: 0:47:59.281482\n",
      "0.9300731\n",
      "[Epoch 32/50] [Batch 44/300] [D loss: 0.752365] [G loss: 0.511483] time: 0:47:59.574847\n",
      "0.9206422\n",
      "[Epoch 32/50] [Batch 45/300] [D loss: 0.752362] [G loss: 0.497126] time: 0:47:59.874796\n",
      "0.92737436\n",
      "[Epoch 32/50] [Batch 46/300] [D loss: 0.752370] [G loss: 0.491552] time: 0:48:00.183733\n",
      "0.93081474\n",
      "[Epoch 32/50] [Batch 47/300] [D loss: 0.752367] [G loss: 0.479421] time: 0:48:00.477118\n",
      "0.9133006\n",
      "[Epoch 32/50] [Batch 48/300] [D loss: 0.752362] [G loss: 0.516629] time: 0:48:00.777983\n",
      "0.94699866\n",
      "[Epoch 32/50] [Batch 49/300] [D loss: 0.752370] [G loss: 0.504376] time: 0:48:01.090672\n",
      "0.9332517\n",
      "[Epoch 32/50] [Batch 50/300] [D loss: 0.752369] [G loss: 0.475805] time: 0:48:01.404754\n",
      "0.91177994\n",
      "[Epoch 32/50] [Batch 51/300] [D loss: 0.752380] [G loss: 0.485130] time: 0:48:01.721883\n",
      "0.91314983\n",
      "[Epoch 32/50] [Batch 52/300] [D loss: 0.752386] [G loss: 0.493313] time: 0:48:02.029548\n",
      "0.8695547\n",
      "[Epoch 32/50] [Batch 53/300] [D loss: 0.752356] [G loss: 0.483154] time: 0:48:02.348191\n",
      "0.9776537\n",
      "[Epoch 32/50] [Batch 54/300] [D loss: 0.752380] [G loss: 0.477891] time: 0:48:02.635468\n",
      "0.928284\n",
      "[Epoch 32/50] [Batch 55/300] [D loss: 0.752377] [G loss: 0.513494] time: 0:48:02.938531\n",
      "0.9688678\n",
      "[Epoch 32/50] [Batch 56/300] [D loss: 0.752376] [G loss: 0.531678] time: 0:48:03.232396\n",
      "0.89457464\n",
      "[Epoch 32/50] [Batch 57/300] [D loss: 0.752381] [G loss: 0.503285] time: 0:48:03.536811\n",
      "0.95394224\n",
      "[Epoch 32/50] [Batch 58/300] [D loss: 0.752371] [G loss: 0.500984] time: 0:48:03.836064\n",
      "0.88745594\n",
      "[Epoch 32/50] [Batch 59/300] [D loss: 0.752362] [G loss: 0.490643] time: 0:48:04.142043\n",
      "0.89077425\n",
      "[Epoch 32/50] [Batch 60/300] [D loss: 0.752380] [G loss: 0.511131] time: 0:48:04.450082\n",
      "0.8929089\n",
      "[Epoch 32/50] [Batch 61/300] [D loss: 0.752377] [G loss: 0.491858] time: 0:48:04.735829\n",
      "0.9394564\n",
      "[Epoch 32/50] [Batch 62/300] [D loss: 0.752370] [G loss: 0.484302] time: 0:48:05.043512\n",
      "0.9350686\n",
      "[Epoch 32/50] [Batch 63/300] [D loss: 0.752392] [G loss: 0.494370] time: 0:48:05.369590\n",
      "0.9564161\n",
      "[Epoch 32/50] [Batch 64/300] [D loss: 0.752354] [G loss: 0.500157] time: 0:48:05.656026\n",
      "0.87639254\n",
      "[Epoch 32/50] [Batch 65/300] [D loss: 0.752387] [G loss: 0.512320] time: 0:48:05.964605\n",
      "0.8996413\n",
      "[Epoch 32/50] [Batch 66/300] [D loss: 0.752380] [G loss: 0.496348] time: 0:48:06.249489\n",
      "0.8806522\n",
      "[Epoch 32/50] [Batch 67/300] [D loss: 0.752373] [G loss: 0.509907] time: 0:48:06.545134\n",
      "0.90832585\n",
      "[Epoch 32/50] [Batch 68/300] [D loss: 0.752360] [G loss: 0.487585] time: 0:48:06.857950\n",
      "0.9138443\n",
      "[Epoch 32/50] [Batch 69/300] [D loss: 0.752372] [G loss: 0.488329] time: 0:48:07.155567\n",
      "0.9055181\n",
      "[Epoch 32/50] [Batch 70/300] [D loss: 0.752387] [G loss: 0.479661] time: 0:48:07.455670\n",
      "0.9449861\n",
      "[Epoch 32/50] [Batch 71/300] [D loss: 0.752370] [G loss: 0.489035] time: 0:48:07.744127\n",
      "0.95267624\n",
      "[Epoch 32/50] [Batch 72/300] [D loss: 0.752367] [G loss: 0.498040] time: 0:48:08.054355\n",
      "0.92325646\n",
      "[Epoch 32/50] [Batch 73/300] [D loss: 0.752378] [G loss: 0.502485] time: 0:48:08.350969\n",
      "0.9025739\n",
      "[Epoch 32/50] [Batch 74/300] [D loss: 0.752381] [G loss: 0.501849] time: 0:48:08.648653\n",
      "0.94192\n",
      "[Epoch 32/50] [Batch 75/300] [D loss: 0.752369] [G loss: 0.495898] time: 0:48:08.937335\n",
      "0.909338\n",
      "[Epoch 32/50] [Batch 76/300] [D loss: 0.752363] [G loss: 0.499808] time: 0:48:09.246208\n",
      "0.95064384\n",
      "[Epoch 32/50] [Batch 77/300] [D loss: 0.752380] [G loss: 0.503902] time: 0:48:09.551094\n",
      "0.913404\n",
      "[Epoch 32/50] [Batch 78/300] [D loss: 0.752376] [G loss: 0.502666] time: 0:48:09.846230\n",
      "0.978705\n",
      "[Epoch 32/50] [Batch 79/300] [D loss: 0.752356] [G loss: 0.500816] time: 0:48:10.153882\n",
      "0.9178546\n",
      "[Epoch 32/50] [Batch 80/300] [D loss: 0.752369] [G loss: 0.501786] time: 0:48:10.458418\n",
      "0.9280713\n",
      "[Epoch 32/50] [Batch 81/300] [D loss: 0.752363] [G loss: 0.502186] time: 0:48:10.756467\n",
      "0.9049143\n",
      "[Epoch 32/50] [Batch 82/300] [D loss: 0.752363] [G loss: 0.489698] time: 0:48:11.064753\n",
      "0.9374094\n",
      "[Epoch 32/50] [Batch 83/300] [D loss: 0.752353] [G loss: 0.490839] time: 0:48:11.374505\n",
      "0.9215532\n",
      "[Epoch 32/50] [Batch 84/300] [D loss: 0.752386] [G loss: 0.486037] time: 0:48:11.684970\n",
      "0.9100893\n",
      "[Epoch 32/50] [Batch 85/300] [D loss: 0.752357] [G loss: 0.487740] time: 0:48:11.984126\n",
      "0.9599357\n",
      "[Epoch 32/50] [Batch 86/300] [D loss: 0.752361] [G loss: 0.479085] time: 0:48:12.298149\n",
      "0.93765473\n",
      "[Epoch 32/50] [Batch 87/300] [D loss: 0.752352] [G loss: 0.476600] time: 0:48:12.611298\n",
      "0.9409273\n",
      "[Epoch 32/50] [Batch 88/300] [D loss: 0.752354] [G loss: 0.494927] time: 0:48:12.912900\n",
      "0.91189176\n",
      "[Epoch 32/50] [Batch 89/300] [D loss: 0.752373] [G loss: 0.498981] time: 0:48:13.229909\n",
      "0.9378097\n",
      "[Epoch 32/50] [Batch 90/300] [D loss: 0.752368] [G loss: 0.485267] time: 0:48:13.530050\n",
      "0.9354995\n",
      "[Epoch 32/50] [Batch 91/300] [D loss: 0.752367] [G loss: 0.480285] time: 0:48:13.838030\n",
      "0.8998235\n",
      "[Epoch 32/50] [Batch 92/300] [D loss: 0.752376] [G loss: 0.490003] time: 0:48:14.132540\n",
      "0.88142234\n",
      "[Epoch 32/50] [Batch 93/300] [D loss: 0.752394] [G loss: 0.478237] time: 0:48:14.446519\n",
      "0.8893373\n",
      "[Epoch 32/50] [Batch 94/300] [D loss: 0.752364] [G loss: 0.499377] time: 0:48:14.760635\n",
      "0.9364317\n",
      "[Epoch 32/50] [Batch 95/300] [D loss: 0.752375] [G loss: 0.493590] time: 0:48:15.063255\n",
      "0.9317396\n",
      "[Epoch 32/50] [Batch 96/300] [D loss: 0.752357] [G loss: 0.488781] time: 0:48:15.366619\n",
      "0.91325116\n",
      "[Epoch 32/50] [Batch 97/300] [D loss: 0.752383] [G loss: 0.492028] time: 0:48:15.665135\n",
      "0.94057673\n",
      "[Epoch 32/50] [Batch 98/300] [D loss: 0.752371] [G loss: 0.500654] time: 0:48:15.978700\n",
      "0.9018813\n",
      "[Epoch 32/50] [Batch 99/300] [D loss: 0.752354] [G loss: 0.496665] time: 0:48:16.283022\n",
      "0.90527105\n",
      "[Epoch 32/50] [Batch 100/300] [D loss: 0.752382] [G loss: 0.507482] time: 0:48:16.567331\n",
      "0.9210729\n",
      "[Epoch 32/50] [Batch 101/300] [D loss: 0.752372] [G loss: 0.489185] time: 0:48:16.854519\n",
      "0.90337175\n",
      "[Epoch 32/50] [Batch 102/300] [D loss: 0.752368] [G loss: 0.495532] time: 0:48:17.137744\n",
      "0.94039583\n",
      "[Epoch 32/50] [Batch 103/300] [D loss: 0.752369] [G loss: 0.497924] time: 0:48:17.446589\n",
      "0.90705466\n",
      "[Epoch 32/50] [Batch 104/300] [D loss: 0.752365] [G loss: 0.524719] time: 0:48:17.754179\n",
      "0.9008186\n",
      "[Epoch 32/50] [Batch 105/300] [D loss: 0.752364] [G loss: 0.480701] time: 0:48:18.080094\n",
      "0.9072512\n",
      "[Epoch 32/50] [Batch 106/300] [D loss: 0.752373] [G loss: 0.478162] time: 0:48:18.379130\n",
      "0.9108892\n",
      "[Epoch 32/50] [Batch 107/300] [D loss: 0.752361] [G loss: 0.475901] time: 0:48:18.674060\n",
      "0.9815411\n",
      "[Epoch 32/50] [Batch 108/300] [D loss: 0.752356] [G loss: 0.489725] time: 0:48:18.985479\n",
      "0.9402055\n",
      "[Epoch 32/50] [Batch 109/300] [D loss: 0.752385] [G loss: 0.488938] time: 0:48:19.306743\n",
      "0.9707978\n",
      "[Epoch 32/50] [Batch 110/300] [D loss: 0.752369] [G loss: 0.484247] time: 0:48:19.602250\n",
      "0.8882182\n",
      "[Epoch 32/50] [Batch 111/300] [D loss: 0.752373] [G loss: 0.487318] time: 0:48:19.901335\n",
      "0.9161094\n",
      "[Epoch 32/50] [Batch 112/300] [D loss: 0.752363] [G loss: 0.480320] time: 0:48:20.172736\n",
      "0.90871507\n",
      "[Epoch 32/50] [Batch 113/300] [D loss: 0.752356] [G loss: 0.496028] time: 0:48:20.470579\n",
      "0.92788196\n",
      "[Epoch 32/50] [Batch 114/300] [D loss: 0.752359] [G loss: 0.482865] time: 0:48:20.765134\n",
      "0.94646305\n",
      "[Epoch 32/50] [Batch 115/300] [D loss: 0.752371] [G loss: 0.488965] time: 0:48:21.206088\n",
      "0.9053114\n",
      "[Epoch 32/50] [Batch 116/300] [D loss: 0.752373] [G loss: 0.495879] time: 0:48:21.487809\n",
      "0.90356034\n",
      "[Epoch 32/50] [Batch 117/300] [D loss: 0.752359] [G loss: 0.498811] time: 0:48:21.776816\n",
      "0.8535032\n",
      "[Epoch 32/50] [Batch 118/300] [D loss: 0.752357] [G loss: 0.532417] time: 0:48:22.074917\n",
      "0.9366506\n",
      "[Epoch 32/50] [Batch 119/300] [D loss: 0.752368] [G loss: 0.485755] time: 0:48:22.373968\n",
      "0.925011\n",
      "[Epoch 32/50] [Batch 120/300] [D loss: 0.752374] [G loss: 0.494109] time: 0:48:22.673108\n",
      "0.90758276\n",
      "[Epoch 32/50] [Batch 121/300] [D loss: 0.752366] [G loss: 0.496860] time: 0:48:22.956608\n",
      "0.9418568\n",
      "[Epoch 32/50] [Batch 122/300] [D loss: 0.752351] [G loss: 0.480173] time: 0:48:23.238699\n",
      "0.91257256\n",
      "[Epoch 32/50] [Batch 123/300] [D loss: 0.752367] [G loss: 0.484990] time: 0:48:23.542274\n",
      "0.9202568\n",
      "[Epoch 32/50] [Batch 124/300] [D loss: 0.752379] [G loss: 0.493143] time: 0:48:23.839213\n",
      "0.8873531\n",
      "[Epoch 32/50] [Batch 125/300] [D loss: 0.752363] [G loss: 0.495669] time: 0:48:24.137221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95735645\n",
      "[Epoch 32/50] [Batch 126/300] [D loss: 0.752384] [G loss: 0.479418] time: 0:48:24.443608\n",
      "0.9323399\n",
      "[Epoch 32/50] [Batch 127/300] [D loss: 0.752361] [G loss: 0.485290] time: 0:48:24.750257\n",
      "0.8892083\n",
      "[Epoch 32/50] [Batch 128/300] [D loss: 0.752362] [G loss: 0.487837] time: 0:48:25.021286\n",
      "0.9377083\n",
      "[Epoch 32/50] [Batch 129/300] [D loss: 0.752364] [G loss: 0.487717] time: 0:48:25.330500\n",
      "0.93887186\n",
      "[Epoch 32/50] [Batch 130/300] [D loss: 0.752361] [G loss: 0.494929] time: 0:48:25.637309\n",
      "0.9391827\n",
      "[Epoch 32/50] [Batch 131/300] [D loss: 0.752362] [G loss: 0.488882] time: 0:48:25.926950\n",
      "0.9171855\n",
      "[Epoch 32/50] [Batch 132/300] [D loss: 0.752346] [G loss: 0.478261] time: 0:48:26.229079\n",
      "0.90389323\n",
      "[Epoch 32/50] [Batch 133/300] [D loss: 0.752369] [G loss: 0.488640] time: 0:48:26.520181\n",
      "0.91983557\n",
      "[Epoch 32/50] [Batch 134/300] [D loss: 0.752381] [G loss: 0.500005] time: 0:48:26.827054\n",
      "0.9307725\n",
      "[Epoch 32/50] [Batch 135/300] [D loss: 0.752360] [G loss: 0.485655] time: 0:48:27.122663\n",
      "0.9125301\n",
      "[Epoch 32/50] [Batch 136/300] [D loss: 0.752367] [G loss: 0.485045] time: 0:48:27.426054\n",
      "0.9522863\n",
      "[Epoch 32/50] [Batch 137/300] [D loss: 0.752370] [G loss: 0.478576] time: 0:48:27.732888\n",
      "0.93842727\n",
      "[Epoch 32/50] [Batch 138/300] [D loss: 0.752376] [G loss: 0.505718] time: 0:48:28.026444\n",
      "0.9114798\n",
      "[Epoch 32/50] [Batch 139/300] [D loss: 0.752370] [G loss: 0.489898] time: 0:48:28.334735\n",
      "0.92919636\n",
      "[Epoch 32/50] [Batch 140/300] [D loss: 0.752376] [G loss: 0.479116] time: 0:48:28.647796\n",
      "0.9089863\n",
      "[Epoch 32/50] [Batch 141/300] [D loss: 0.752351] [G loss: 0.482806] time: 0:48:28.948785\n",
      "0.9477785\n",
      "[Epoch 32/50] [Batch 142/300] [D loss: 0.752370] [G loss: 0.507645] time: 0:48:29.238747\n",
      "0.9101754\n",
      "[Epoch 32/50] [Batch 143/300] [D loss: 0.752361] [G loss: 0.491018] time: 0:48:29.543154\n",
      "0.96471006\n",
      "[Epoch 32/50] [Batch 144/300] [D loss: 0.752362] [G loss: 0.514977] time: 0:48:29.852543\n",
      "0.8813272\n",
      "[Epoch 32/50] [Batch 145/300] [D loss: 0.752375] [G loss: 0.507940] time: 0:48:30.142749\n",
      "0.9148553\n",
      "[Epoch 32/50] [Batch 146/300] [D loss: 0.752364] [G loss: 0.506824] time: 0:48:30.452732\n",
      "0.9458742\n",
      "[Epoch 32/50] [Batch 147/300] [D loss: 0.752360] [G loss: 0.499713] time: 0:48:30.746346\n",
      "0.9066816\n",
      "[Epoch 32/50] [Batch 148/300] [D loss: 0.752377] [G loss: 0.477390] time: 0:48:31.028736\n",
      "0.91808134\n",
      "[Epoch 32/50] [Batch 149/300] [D loss: 0.752370] [G loss: 0.505493] time: 0:48:31.326762\n",
      "0.94558597\n",
      "[Epoch 32/50] [Batch 150/300] [D loss: 0.752359] [G loss: 0.493759] time: 0:48:31.609661\n",
      "0.935766\n",
      "[Epoch 32/50] [Batch 151/300] [D loss: 0.752351] [G loss: 0.480193] time: 0:48:31.910275\n",
      "0.88646394\n",
      "[Epoch 32/50] [Batch 152/300] [D loss: 0.752354] [G loss: 0.501807] time: 0:48:32.216440\n",
      "0.963942\n",
      "[Epoch 32/50] [Batch 153/300] [D loss: 0.752352] [G loss: 0.488532] time: 0:48:32.524382\n",
      "0.90370196\n",
      "[Epoch 32/50] [Batch 154/300] [D loss: 0.752393] [G loss: 0.511095] time: 0:48:32.810782\n",
      "0.9423774\n",
      "[Epoch 32/50] [Batch 155/300] [D loss: 0.752355] [G loss: 0.496848] time: 0:48:33.112145\n",
      "0.9139962\n",
      "[Epoch 32/50] [Batch 156/300] [D loss: 0.752377] [G loss: 0.495643] time: 0:48:33.421579\n",
      "0.93628186\n",
      "[Epoch 32/50] [Batch 157/300] [D loss: 0.752352] [G loss: 0.508012] time: 0:48:33.711367\n",
      "0.9361363\n",
      "[Epoch 32/50] [Batch 158/300] [D loss: 0.752367] [G loss: 0.481328] time: 0:48:34.011410\n",
      "0.9059724\n",
      "[Epoch 32/50] [Batch 159/300] [D loss: 0.752379] [G loss: 0.474747] time: 0:48:34.312636\n",
      "0.9219465\n",
      "[Epoch 32/50] [Batch 160/300] [D loss: 0.752382] [G loss: 0.503847] time: 0:48:34.619102\n",
      "0.9027791\n",
      "[Epoch 32/50] [Batch 161/300] [D loss: 0.752363] [G loss: 0.481818] time: 0:48:34.908439\n",
      "0.93182904\n",
      "[Epoch 32/50] [Batch 162/300] [D loss: 0.752358] [G loss: 0.482552] time: 0:48:35.194257\n",
      "0.9144339\n",
      "[Epoch 32/50] [Batch 163/300] [D loss: 0.752354] [G loss: 0.493468] time: 0:48:35.498007\n",
      "0.9711688\n",
      "[Epoch 32/50] [Batch 164/300] [D loss: 0.752368] [G loss: 0.483647] time: 0:48:35.820129\n",
      "0.9617774\n",
      "[Epoch 32/50] [Batch 165/300] [D loss: 0.752378] [G loss: 0.484329] time: 0:48:36.116361\n",
      "0.9155863\n",
      "[Epoch 32/50] [Batch 166/300] [D loss: 0.752367] [G loss: 0.499737] time: 0:48:36.418120\n",
      "0.93557924\n",
      "[Epoch 32/50] [Batch 167/300] [D loss: 0.752382] [G loss: 0.477412] time: 0:48:36.710642\n",
      "0.9540858\n",
      "[Epoch 32/50] [Batch 168/300] [D loss: 0.752349] [G loss: 0.507362] time: 0:48:37.004137\n",
      "0.8949938\n",
      "[Epoch 32/50] [Batch 169/300] [D loss: 0.752376] [G loss: 0.483381] time: 0:48:37.297978\n",
      "0.90370923\n",
      "[Epoch 32/50] [Batch 170/300] [D loss: 0.752370] [G loss: 0.482745] time: 0:48:37.585733\n",
      "0.88053447\n",
      "[Epoch 32/50] [Batch 171/300] [D loss: 0.752365] [G loss: 0.492340] time: 0:48:37.885724\n",
      "0.938713\n",
      "[Epoch 32/50] [Batch 172/300] [D loss: 0.752360] [G loss: 0.487838] time: 0:48:38.173818\n",
      "0.95109254\n",
      "[Epoch 32/50] [Batch 173/300] [D loss: 0.752358] [G loss: 0.526435] time: 0:48:38.456506\n",
      "0.92153174\n",
      "[Epoch 32/50] [Batch 174/300] [D loss: 0.752367] [G loss: 0.498798] time: 0:48:38.745197\n",
      "0.9758021\n",
      "[Epoch 32/50] [Batch 175/300] [D loss: 0.752361] [G loss: 0.497926] time: 0:48:39.042019\n",
      "0.87684494\n",
      "[Epoch 32/50] [Batch 176/300] [D loss: 0.752363] [G loss: 0.495586] time: 0:48:39.330988\n",
      "0.90323895\n",
      "[Epoch 32/50] [Batch 177/300] [D loss: 0.752378] [G loss: 0.501324] time: 0:48:39.634673\n",
      "0.97123575\n",
      "[Epoch 32/50] [Batch 178/300] [D loss: 0.752377] [G loss: 0.485713] time: 0:48:39.933906\n",
      "0.9581461\n",
      "[Epoch 32/50] [Batch 179/300] [D loss: 0.752362] [G loss: 0.484634] time: 0:48:40.215575\n",
      "0.9000289\n",
      "[Epoch 32/50] [Batch 180/300] [D loss: 0.752364] [G loss: 0.516874] time: 0:48:40.505435\n",
      "0.91349417\n",
      "[Epoch 32/50] [Batch 181/300] [D loss: 0.752369] [G loss: 0.500686] time: 0:48:40.806833\n",
      "0.8819315\n",
      "[Epoch 32/50] [Batch 182/300] [D loss: 0.752350] [G loss: 0.484091] time: 0:48:41.085913\n",
      "0.9171211\n",
      "[Epoch 32/50] [Batch 183/300] [D loss: 0.752369] [G loss: 0.486517] time: 0:48:41.386567\n",
      "0.9462562\n",
      "[Epoch 32/50] [Batch 184/300] [D loss: 0.752371] [G loss: 0.485115] time: 0:48:41.685627\n",
      "0.943767\n",
      "[Epoch 32/50] [Batch 185/300] [D loss: 0.752374] [G loss: 0.502071] time: 0:48:41.973477\n",
      "0.9313714\n",
      "[Epoch 32/50] [Batch 186/300] [D loss: 0.752367] [G loss: 0.514333] time: 0:48:42.269697\n",
      "0.881296\n",
      "[Epoch 32/50] [Batch 187/300] [D loss: 0.752356] [G loss: 0.493445] time: 0:48:42.564373\n",
      "0.90058595\n",
      "[Epoch 32/50] [Batch 188/300] [D loss: 0.752362] [G loss: 0.481335] time: 0:48:42.870380\n",
      "0.8800144\n",
      "[Epoch 32/50] [Batch 189/300] [D loss: 0.752364] [G loss: 0.499456] time: 0:48:43.161074\n",
      "0.93180275\n",
      "[Epoch 32/50] [Batch 190/300] [D loss: 0.752376] [G loss: 0.487461] time: 0:48:43.453149\n",
      "0.94814014\n",
      "[Epoch 32/50] [Batch 191/300] [D loss: 0.752376] [G loss: 0.477078] time: 0:48:43.749576\n",
      "0.93140006\n",
      "[Epoch 32/50] [Batch 192/300] [D loss: 0.752369] [G loss: 0.491710] time: 0:48:44.045197\n",
      "0.9002932\n",
      "[Epoch 32/50] [Batch 193/300] [D loss: 0.752374] [G loss: 0.472523] time: 0:48:44.354191\n",
      "0.90591604\n",
      "[Epoch 32/50] [Batch 194/300] [D loss: 0.752359] [G loss: 0.480432] time: 0:48:44.663598\n",
      "0.94303983\n",
      "[Epoch 32/50] [Batch 195/300] [D loss: 0.752379] [G loss: 0.507472] time: 0:48:44.964167\n",
      "0.8843336\n",
      "[Epoch 32/50] [Batch 196/300] [D loss: 0.752367] [G loss: 0.496025] time: 0:48:45.269922\n",
      "0.95288223\n",
      "[Epoch 32/50] [Batch 197/300] [D loss: 0.752350] [G loss: 0.497890] time: 0:48:45.579806\n",
      "0.9426326\n",
      "[Epoch 32/50] [Batch 198/300] [D loss: 0.752357] [G loss: 0.501804] time: 0:48:45.884079\n",
      "0.9165767\n",
      "[Epoch 32/50] [Batch 199/300] [D loss: 0.752352] [G loss: 0.483124] time: 0:48:46.176047\n",
      "0.9120021\n",
      "[Epoch 32/50] [Batch 200/300] [D loss: 0.752362] [G loss: 0.478757] time: 0:48:46.467279\n",
      "0.9419227\n",
      "[Epoch 32/50] [Batch 201/300] [D loss: 0.752370] [G loss: 0.494068] time: 0:48:46.742079\n",
      "0.89966583\n",
      "[Epoch 32/50] [Batch 202/300] [D loss: 0.752379] [G loss: 0.480034] time: 0:48:47.044306\n",
      "0.9136448\n",
      "[Epoch 32/50] [Batch 203/300] [D loss: 0.752353] [G loss: 0.488638] time: 0:48:47.345996\n",
      "0.9166259\n",
      "[Epoch 32/50] [Batch 204/300] [D loss: 0.752360] [G loss: 0.504937] time: 0:48:47.637053\n",
      "0.94151276\n",
      "[Epoch 32/50] [Batch 205/300] [D loss: 0.752357] [G loss: 0.482196] time: 0:48:47.934699\n",
      "0.96472263\n",
      "[Epoch 32/50] [Batch 206/300] [D loss: 0.752363] [G loss: 0.498965] time: 0:48:48.213793\n",
      "0.9289536\n",
      "[Epoch 32/50] [Batch 207/300] [D loss: 0.752363] [G loss: 0.486985] time: 0:48:48.515756\n",
      "0.8956921\n",
      "[Epoch 32/50] [Batch 208/300] [D loss: 0.752355] [G loss: 0.486244] time: 0:48:48.813250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93024564\n",
      "[Epoch 32/50] [Batch 209/300] [D loss: 0.752370] [G loss: 0.501269] time: 0:48:49.094853\n",
      "0.9132588\n",
      "[Epoch 32/50] [Batch 210/300] [D loss: 0.752362] [G loss: 0.486763] time: 0:48:49.384690\n",
      "0.94327664\n",
      "[Epoch 32/50] [Batch 211/300] [D loss: 0.752353] [G loss: 0.492502] time: 0:48:49.685535\n",
      "0.96014327\n",
      "[Epoch 32/50] [Batch 212/300] [D loss: 0.752360] [G loss: 0.488243] time: 0:48:49.988866\n",
      "0.92146856\n",
      "[Epoch 32/50] [Batch 213/300] [D loss: 0.752348] [G loss: 0.495975] time: 0:48:50.283501\n",
      "0.9007395\n",
      "[Epoch 32/50] [Batch 214/300] [D loss: 0.752367] [G loss: 0.486493] time: 0:48:50.578963\n",
      "0.9069004\n",
      "[Epoch 32/50] [Batch 215/300] [D loss: 0.752345] [G loss: 0.484135] time: 0:48:50.882030\n",
      "0.91784674\n",
      "[Epoch 32/50] [Batch 216/300] [D loss: 0.752368] [G loss: 0.498982] time: 0:48:51.181133\n",
      "0.9281071\n",
      "[Epoch 32/50] [Batch 217/300] [D loss: 0.752360] [G loss: 0.498103] time: 0:48:51.477149\n",
      "0.94224524\n",
      "[Epoch 32/50] [Batch 218/300] [D loss: 0.752357] [G loss: 0.485671] time: 0:48:51.781647\n",
      "0.8836772\n",
      "[Epoch 32/50] [Batch 219/300] [D loss: 0.752367] [G loss: 0.479414] time: 0:48:52.073728\n",
      "0.9152884\n",
      "[Epoch 32/50] [Batch 220/300] [D loss: 0.752377] [G loss: 0.478511] time: 0:48:52.388339\n",
      "0.9204914\n",
      "[Epoch 32/50] [Batch 221/300] [D loss: 0.752351] [G loss: 0.501972] time: 0:48:52.684579\n",
      "0.9269803\n",
      "[Epoch 32/50] [Batch 222/300] [D loss: 0.752355] [G loss: 0.494350] time: 0:48:52.986877\n",
      "0.9430494\n",
      "[Epoch 32/50] [Batch 223/300] [D loss: 0.752381] [G loss: 0.500338] time: 0:48:53.284814\n",
      "0.9618365\n",
      "[Epoch 32/50] [Batch 224/300] [D loss: 0.752354] [G loss: 0.491391] time: 0:48:53.594157\n",
      "0.9139757\n",
      "[Epoch 32/50] [Batch 225/300] [D loss: 0.752378] [G loss: 0.485381] time: 0:48:53.891840\n",
      "0.90886027\n",
      "[Epoch 32/50] [Batch 226/300] [D loss: 0.752369] [G loss: 0.499636] time: 0:48:54.172781\n",
      "0.89865273\n",
      "[Epoch 32/50] [Batch 227/300] [D loss: 0.752347] [G loss: 0.489988] time: 0:48:54.459850\n",
      "0.9027136\n",
      "[Epoch 32/50] [Batch 228/300] [D loss: 0.752348] [G loss: 0.489767] time: 0:48:54.767377\n",
      "0.90686625\n",
      "[Epoch 32/50] [Batch 229/300] [D loss: 0.752361] [G loss: 0.476573] time: 0:48:55.065243\n",
      "0.9331207\n",
      "[Epoch 32/50] [Batch 230/300] [D loss: 0.752372] [G loss: 0.487845] time: 0:48:55.370186\n",
      "0.9331997\n",
      "[Epoch 32/50] [Batch 231/300] [D loss: 0.752344] [G loss: 0.495748] time: 0:48:55.664562\n",
      "0.90611154\n",
      "[Epoch 32/50] [Batch 232/300] [D loss: 0.752362] [G loss: 0.500300] time: 0:48:55.955588\n",
      "0.9215428\n",
      "[Epoch 32/50] [Batch 233/300] [D loss: 0.752378] [G loss: 0.513577] time: 0:48:56.249546\n",
      "0.9259698\n",
      "[Epoch 32/50] [Batch 234/300] [D loss: 0.752382] [G loss: 0.490910] time: 0:48:56.561387\n",
      "0.91410613\n",
      "[Epoch 32/50] [Batch 235/300] [D loss: 0.752358] [G loss: 0.481025] time: 0:48:56.857059\n",
      "0.91799265\n",
      "[Epoch 32/50] [Batch 236/300] [D loss: 0.752363] [G loss: 0.481749] time: 0:48:57.146727\n",
      "0.8832858\n",
      "[Epoch 32/50] [Batch 237/300] [D loss: 0.752377] [G loss: 0.513123] time: 0:48:57.438529\n",
      "0.9049113\n",
      "[Epoch 32/50] [Batch 238/300] [D loss: 0.752370] [G loss: 0.479690] time: 0:48:57.749141\n",
      "0.9088714\n",
      "[Epoch 32/50] [Batch 239/300] [D loss: 0.752361] [G loss: 0.509116] time: 0:48:58.039033\n",
      "0.9701066\n",
      "[Epoch 32/50] [Batch 240/300] [D loss: 0.752347] [G loss: 0.492316] time: 0:48:58.332344\n",
      "0.9249688\n",
      "[Epoch 32/50] [Batch 241/300] [D loss: 0.752346] [G loss: 0.492593] time: 0:48:58.629956\n",
      "0.91074294\n",
      "[Epoch 32/50] [Batch 242/300] [D loss: 0.752342] [G loss: 0.528370] time: 0:48:58.924115\n",
      "0.946505\n",
      "[Epoch 32/50] [Batch 243/300] [D loss: 0.752370] [G loss: 0.508806] time: 0:48:59.214392\n",
      "0.94054526\n",
      "[Epoch 32/50] [Batch 244/300] [D loss: 0.752358] [G loss: 0.493992] time: 0:48:59.512027\n",
      "0.9088157\n",
      "[Epoch 32/50] [Batch 245/300] [D loss: 0.752351] [G loss: 0.497410] time: 0:48:59.796368\n",
      "0.93968743\n",
      "[Epoch 32/50] [Batch 246/300] [D loss: 0.752382] [G loss: 0.516563] time: 0:49:00.074818\n",
      "0.9044644\n",
      "[Epoch 32/50] [Batch 247/300] [D loss: 0.752369] [G loss: 0.480930] time: 0:49:00.385191\n",
      "0.9532357\n",
      "[Epoch 32/50] [Batch 248/300] [D loss: 0.752381] [G loss: 0.489565] time: 0:49:00.687426\n",
      "0.9365738\n",
      "[Epoch 32/50] [Batch 249/300] [D loss: 0.752375] [G loss: 0.491264] time: 0:49:01.003583\n",
      "0.9153166\n",
      "[Epoch 32/50] [Batch 250/300] [D loss: 0.752367] [G loss: 0.486571] time: 0:49:01.306613\n",
      "0.9316303\n",
      "[Epoch 32/50] [Batch 251/300] [D loss: 0.752357] [G loss: 0.502283] time: 0:49:01.605866\n",
      "0.9311808\n",
      "[Epoch 32/50] [Batch 252/300] [D loss: 0.752355] [G loss: 0.510720] time: 0:49:01.905390\n",
      "0.94317174\n",
      "[Epoch 32/50] [Batch 253/300] [D loss: 0.752352] [G loss: 0.495304] time: 0:49:02.210630\n",
      "0.9165227\n",
      "[Epoch 32/50] [Batch 254/300] [D loss: 0.752360] [G loss: 0.473497] time: 0:49:02.509905\n",
      "0.90890545\n",
      "[Epoch 32/50] [Batch 255/300] [D loss: 0.752361] [G loss: 0.503827] time: 0:49:02.814893\n",
      "0.92961234\n",
      "[Epoch 32/50] [Batch 256/300] [D loss: 0.752366] [G loss: 0.499743] time: 0:49:03.131723\n",
      "0.9166417\n",
      "[Epoch 32/50] [Batch 257/300] [D loss: 0.752385] [G loss: 0.495443] time: 0:49:03.430660\n",
      "0.90521485\n",
      "[Epoch 32/50] [Batch 258/300] [D loss: 0.752354] [G loss: 0.487848] time: 0:49:03.729728\n",
      "0.95217556\n",
      "[Epoch 32/50] [Batch 259/300] [D loss: 0.752361] [G loss: 0.496777] time: 0:49:04.032685\n",
      "0.93069917\n",
      "[Epoch 32/50] [Batch 260/300] [D loss: 0.752346] [G loss: 0.498130] time: 0:49:04.329245\n",
      "0.8742029\n",
      "[Epoch 32/50] [Batch 261/300] [D loss: 0.752376] [G loss: 0.479020] time: 0:49:04.624137\n",
      "0.91673476\n",
      "[Epoch 32/50] [Batch 262/300] [D loss: 0.752350] [G loss: 0.492115] time: 0:49:04.923960\n",
      "0.9429503\n",
      "[Epoch 32/50] [Batch 263/300] [D loss: 0.752357] [G loss: 0.488891] time: 0:49:05.220731\n",
      "0.93506676\n",
      "[Epoch 32/50] [Batch 264/300] [D loss: 0.752354] [G loss: 0.482453] time: 0:49:05.536513\n",
      "0.89302045\n",
      "[Epoch 32/50] [Batch 265/300] [D loss: 0.752381] [G loss: 0.490478] time: 0:49:05.842699\n",
      "0.95670956\n",
      "[Epoch 32/50] [Batch 266/300] [D loss: 0.752376] [G loss: 0.470860] time: 0:49:06.149833\n",
      "0.9471218\n",
      "[Epoch 32/50] [Batch 267/300] [D loss: 0.752352] [G loss: 0.489238] time: 0:49:06.428677\n",
      "0.87020344\n",
      "[Epoch 32/50] [Batch 268/300] [D loss: 0.752347] [G loss: 0.488845] time: 0:49:06.726887\n",
      "0.93905\n",
      "[Epoch 32/50] [Batch 269/300] [D loss: 0.752377] [G loss: 0.483990] time: 0:49:07.010962\n",
      "0.8705546\n",
      "[Epoch 32/50] [Batch 270/300] [D loss: 0.752348] [G loss: 0.481132] time: 0:49:07.304065\n",
      "0.9107811\n",
      "[Epoch 32/50] [Batch 271/300] [D loss: 0.752363] [G loss: 0.477890] time: 0:49:07.602225\n",
      "0.92490226\n",
      "[Epoch 32/50] [Batch 272/300] [D loss: 0.752372] [G loss: 0.488367] time: 0:49:07.921665\n",
      "0.9420087\n",
      "[Epoch 32/50] [Batch 273/300] [D loss: 0.752361] [G loss: 0.488002] time: 0:49:08.216770\n",
      "0.9396942\n",
      "[Epoch 32/50] [Batch 274/300] [D loss: 0.752363] [G loss: 0.501257] time: 0:49:08.511541\n",
      "0.9318673\n",
      "[Epoch 32/50] [Batch 275/300] [D loss: 0.752342] [G loss: 0.500537] time: 0:49:08.811153\n",
      "0.8919027\n",
      "[Epoch 32/50] [Batch 276/300] [D loss: 0.752371] [G loss: 0.483835] time: 0:49:09.107060\n",
      "0.8835857\n",
      "[Epoch 32/50] [Batch 277/300] [D loss: 0.752356] [G loss: 0.489596] time: 0:49:09.402692\n",
      "0.9462841\n",
      "[Epoch 32/50] [Batch 278/300] [D loss: 0.752347] [G loss: 0.497720] time: 0:49:09.702462\n",
      "0.95307976\n",
      "[Epoch 32/50] [Batch 279/300] [D loss: 0.752369] [G loss: 0.497366] time: 0:49:10.005311\n",
      "0.90320987\n",
      "[Epoch 32/50] [Batch 280/300] [D loss: 0.752364] [G loss: 0.489656] time: 0:49:10.297698\n",
      "0.9341445\n",
      "[Epoch 32/50] [Batch 281/300] [D loss: 0.752352] [G loss: 0.481665] time: 0:49:10.592500\n",
      "0.9030064\n",
      "[Epoch 32/50] [Batch 282/300] [D loss: 0.752374] [G loss: 0.501581] time: 0:49:10.879674\n",
      "0.92793435\n",
      "[Epoch 32/50] [Batch 283/300] [D loss: 0.752358] [G loss: 0.483462] time: 0:49:11.156231\n",
      "0.86756635\n",
      "[Epoch 32/50] [Batch 284/300] [D loss: 0.752359] [G loss: 0.485892] time: 0:49:11.458608\n",
      "0.88116693\n",
      "[Epoch 32/50] [Batch 285/300] [D loss: 0.752348] [G loss: 0.482699] time: 0:49:11.758308\n",
      "0.92512107\n",
      "[Epoch 32/50] [Batch 286/300] [D loss: 0.752361] [G loss: 0.488806] time: 0:49:12.060444\n",
      "0.9716754\n",
      "[Epoch 32/50] [Batch 287/300] [D loss: 0.752376] [G loss: 0.478455] time: 0:49:12.368879\n",
      "0.9123344\n",
      "[Epoch 32/50] [Batch 288/300] [D loss: 0.752362] [G loss: 0.484532] time: 0:49:12.669526\n",
      "0.9530881\n",
      "[Epoch 32/50] [Batch 289/300] [D loss: 0.752355] [G loss: 0.484323] time: 0:49:12.959471\n",
      "0.95328814\n",
      "[Epoch 32/50] [Batch 290/300] [D loss: 0.752355] [G loss: 0.483820] time: 0:49:13.241945\n",
      "0.89292556\n",
      "[Epoch 32/50] [Batch 291/300] [D loss: 0.752362] [G loss: 0.472601] time: 0:49:13.544905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87483907\n",
      "[Epoch 32/50] [Batch 292/300] [D loss: 0.752351] [G loss: 0.511828] time: 0:49:13.845745\n",
      "0.9349155\n",
      "[Epoch 32/50] [Batch 293/300] [D loss: 0.752364] [G loss: 0.486291] time: 0:49:14.136631\n",
      "0.93861645\n",
      "[Epoch 32/50] [Batch 294/300] [D loss: 0.752365] [G loss: 0.490124] time: 0:49:14.432573\n",
      "0.8990963\n",
      "[Epoch 32/50] [Batch 295/300] [D loss: 0.752381] [G loss: 0.510450] time: 0:49:14.733291\n",
      "0.95555836\n",
      "[Epoch 32/50] [Batch 296/300] [D loss: 0.752357] [G loss: 0.501399] time: 0:49:15.037848\n",
      "0.8894754\n",
      "[Epoch 32/50] [Batch 297/300] [D loss: 0.752364] [G loss: 0.499329] time: 0:49:15.358636\n",
      "0.9395802\n",
      "[Epoch 32/50] [Batch 298/300] [D loss: 0.752367] [G loss: 0.514271] time: 0:49:15.672282\n",
      "0.90207547\n",
      "[Epoch 32/50] [Batch 299/300] [D loss: 0.752366] [G loss: 0.482187] time: 0:49:15.984220\n",
      "0.9179824\n",
      "[Epoch 33/50] [Batch 0/300] [D loss: 0.752356] [G loss: 0.492414] time: 0:49:16.274685\n",
      "0.8734519\n",
      "[Epoch 33/50] [Batch 1/300] [D loss: 0.752352] [G loss: 0.511023] time: 0:49:16.567717\n",
      "0.9193821\n",
      "[Epoch 33/50] [Batch 2/300] [D loss: 0.752356] [G loss: 0.504120] time: 0:49:16.844269\n",
      "0.91630393\n",
      "[Epoch 33/50] [Batch 3/300] [D loss: 0.752354] [G loss: 0.485791] time: 0:49:17.147201\n",
      "0.97557217\n",
      "[Epoch 33/50] [Batch 4/300] [D loss: 0.752371] [G loss: 0.488692] time: 0:49:17.449558\n",
      "0.9459526\n",
      "[Epoch 33/50] [Batch 5/300] [D loss: 0.752365] [G loss: 0.490708] time: 0:49:17.761401\n",
      "0.94189376\n",
      "[Epoch 33/50] [Batch 6/300] [D loss: 0.752343] [G loss: 0.508694] time: 0:49:18.062994\n",
      "0.8932709\n",
      "[Epoch 33/50] [Batch 7/300] [D loss: 0.752351] [G loss: 0.482663] time: 0:49:18.356189\n",
      "0.9201332\n",
      "[Epoch 33/50] [Batch 8/300] [D loss: 0.752353] [G loss: 0.511179] time: 0:49:18.644106\n",
      "0.8957179\n",
      "[Epoch 33/50] [Batch 9/300] [D loss: 0.752353] [G loss: 0.506652] time: 0:49:18.925020\n",
      "0.8853698\n",
      "[Epoch 33/50] [Batch 10/300] [D loss: 0.752346] [G loss: 0.535020] time: 0:49:19.228189\n",
      "0.90175813\n",
      "[Epoch 33/50] [Batch 11/300] [D loss: 0.752339] [G loss: 0.499143] time: 0:49:19.545038\n",
      "0.94645756\n",
      "[Epoch 33/50] [Batch 12/300] [D loss: 0.752353] [G loss: 0.490806] time: 0:49:19.820696\n",
      "0.92263556\n",
      "[Epoch 33/50] [Batch 13/300] [D loss: 0.752360] [G loss: 0.492796] time: 0:49:20.112249\n",
      "0.88771343\n",
      "[Epoch 33/50] [Batch 14/300] [D loss: 0.752351] [G loss: 0.498687] time: 0:49:20.421223\n",
      "0.93014556\n",
      "[Epoch 33/50] [Batch 15/300] [D loss: 0.752355] [G loss: 0.530269] time: 0:49:20.716797\n",
      "0.9171071\n",
      "[Epoch 33/50] [Batch 16/300] [D loss: 0.752351] [G loss: 0.479975] time: 0:49:21.010415\n",
      "0.9760477\n",
      "[Epoch 33/50] [Batch 17/300] [D loss: 0.752353] [G loss: 0.494092] time: 0:49:21.313086\n",
      "0.87657183\n",
      "[Epoch 33/50] [Batch 18/300] [D loss: 0.752358] [G loss: 0.474838] time: 0:49:21.615756\n",
      "0.91729087\n",
      "[Epoch 33/50] [Batch 19/300] [D loss: 0.752369] [G loss: 0.502871] time: 0:49:21.897549\n",
      "0.9315898\n",
      "[Epoch 33/50] [Batch 20/300] [D loss: 0.752372] [G loss: 0.481561] time: 0:49:22.203031\n",
      "0.88671285\n",
      "[Epoch 33/50] [Batch 21/300] [D loss: 0.752374] [G loss: 0.499974] time: 0:49:22.489225\n",
      "0.94124717\n",
      "[Epoch 33/50] [Batch 22/300] [D loss: 0.752381] [G loss: 0.486937] time: 0:49:22.786316\n",
      "0.9482762\n",
      "[Epoch 33/50] [Batch 23/300] [D loss: 0.752356] [G loss: 0.486147] time: 0:49:23.093227\n",
      "0.93878293\n",
      "[Epoch 33/50] [Batch 24/300] [D loss: 0.752359] [G loss: 0.480991] time: 0:49:23.404788\n",
      "0.9310868\n",
      "[Epoch 33/50] [Batch 25/300] [D loss: 0.752353] [G loss: 0.487723] time: 0:49:23.698137\n",
      "0.952601\n",
      "[Epoch 33/50] [Batch 26/300] [D loss: 0.752348] [G loss: 0.494739] time: 0:49:24.007993\n",
      "0.86794144\n",
      "[Epoch 33/50] [Batch 27/300] [D loss: 0.752368] [G loss: 0.510118] time: 0:49:24.311468\n",
      "0.8888595\n",
      "[Epoch 33/50] [Batch 28/300] [D loss: 0.752369] [G loss: 0.494167] time: 0:49:24.600372\n",
      "0.9376691\n",
      "[Epoch 33/50] [Batch 29/300] [D loss: 0.752349] [G loss: 0.495540] time: 0:49:24.908032\n",
      "0.9329286\n",
      "[Epoch 33/50] [Batch 30/300] [D loss: 0.752360] [G loss: 0.484925] time: 0:49:25.217300\n",
      "0.9413317\n",
      "[Epoch 33/50] [Batch 31/300] [D loss: 0.752355] [G loss: 0.486543] time: 0:49:25.507427\n",
      "0.8943317\n",
      "[Epoch 33/50] [Batch 33/300] [D loss: 0.752352] [G loss: 0.493325] time: 0:49:25.828450\n",
      "0.89921933\n",
      "[Epoch 33/50] [Batch 34/300] [D loss: 0.752346] [G loss: 0.506692] time: 0:49:26.138015\n",
      "0.9463117\n",
      "[Epoch 33/50] [Batch 35/300] [D loss: 0.752349] [G loss: 0.493504] time: 0:49:26.438403\n",
      "0.87649304\n",
      "[Epoch 33/50] [Batch 36/300] [D loss: 0.752375] [G loss: 0.474808] time: 0:49:26.721120\n",
      "0.9414065\n",
      "[Epoch 33/50] [Batch 37/300] [D loss: 0.752346] [G loss: 0.488882] time: 0:49:27.035932\n",
      "0.9442802\n",
      "[Epoch 33/50] [Batch 38/300] [D loss: 0.752340] [G loss: 0.476291] time: 0:49:27.337371\n",
      "0.90771174\n",
      "[Epoch 33/50] [Batch 39/300] [D loss: 0.752364] [G loss: 0.477137] time: 0:49:27.639896\n",
      "0.8823821\n",
      "[Epoch 33/50] [Batch 40/300] [D loss: 0.752370] [G loss: 0.485723] time: 0:49:27.943935\n",
      "0.9291198\n",
      "[Epoch 33/50] [Batch 41/300] [D loss: 0.752354] [G loss: 0.491519] time: 0:49:28.256051\n",
      "0.90600497\n",
      "[Epoch 33/50] [Batch 42/300] [D loss: 0.752355] [G loss: 0.491637] time: 0:49:28.545099\n",
      "0.9309435\n",
      "[Epoch 33/50] [Batch 43/300] [D loss: 0.752353] [G loss: 0.500221] time: 0:49:28.829917\n",
      "0.9173711\n",
      "[Epoch 33/50] [Batch 44/300] [D loss: 0.752364] [G loss: 0.485880] time: 0:49:29.138382\n",
      "0.9008729\n",
      "[Epoch 33/50] [Batch 45/300] [D loss: 0.752357] [G loss: 0.479891] time: 0:49:29.445186\n",
      "0.9241503\n",
      "[Epoch 33/50] [Batch 46/300] [D loss: 0.752356] [G loss: 0.498157] time: 0:49:29.726567\n",
      "0.8944239\n",
      "[Epoch 33/50] [Batch 47/300] [D loss: 0.752357] [G loss: 0.490150] time: 0:49:30.028691\n",
      "0.9524968\n",
      "[Epoch 33/50] [Batch 48/300] [D loss: 0.752388] [G loss: 0.493341] time: 0:49:30.300834\n",
      "0.9293522\n",
      "[Epoch 33/50] [Batch 49/300] [D loss: 0.752360] [G loss: 0.488144] time: 0:49:30.592193\n",
      "0.9176784\n",
      "[Epoch 33/50] [Batch 50/300] [D loss: 0.752356] [G loss: 0.488028] time: 0:49:30.891480\n",
      "0.92214507\n",
      "[Epoch 33/50] [Batch 51/300] [D loss: 0.752347] [G loss: 0.525404] time: 0:49:31.189650\n",
      "0.95275563\n",
      "[Epoch 33/50] [Batch 52/300] [D loss: 0.752343] [G loss: 0.481067] time: 0:49:31.500046\n",
      "0.9428616\n",
      "[Epoch 33/50] [Batch 53/300] [D loss: 0.752370] [G loss: 0.476161] time: 0:49:31.789665\n",
      "0.93722886\n",
      "[Epoch 33/50] [Batch 54/300] [D loss: 0.752368] [G loss: 0.481342] time: 0:49:32.096973\n",
      "0.93145543\n",
      "[Epoch 33/50] [Batch 55/300] [D loss: 0.752354] [G loss: 0.483063] time: 0:49:32.388264\n",
      "0.9504092\n",
      "[Epoch 33/50] [Batch 56/300] [D loss: 0.752350] [G loss: 0.485674] time: 0:49:32.684248\n",
      "0.9688289\n",
      "[Epoch 33/50] [Batch 57/300] [D loss: 0.752348] [G loss: 0.478127] time: 0:49:32.979732\n",
      "0.8867903\n",
      "[Epoch 33/50] [Batch 58/300] [D loss: 0.752355] [G loss: 0.488737] time: 0:49:33.288086\n",
      "0.9263995\n",
      "[Epoch 33/50] [Batch 59/300] [D loss: 0.752363] [G loss: 0.486215] time: 0:49:33.589499\n",
      "0.96193767\n",
      "[Epoch 33/50] [Batch 60/300] [D loss: 0.752347] [G loss: 0.477560] time: 0:49:33.902772\n",
      "0.93076843\n",
      "[Epoch 33/50] [Batch 61/300] [D loss: 0.752363] [G loss: 0.481156] time: 0:49:34.223442\n",
      "0.9095203\n",
      "[Epoch 33/50] [Batch 62/300] [D loss: 0.752350] [G loss: 0.487846] time: 0:49:34.532966\n",
      "0.88621587\n",
      "[Epoch 33/50] [Batch 63/300] [D loss: 0.752367] [G loss: 0.504569] time: 0:49:34.832192\n",
      "0.9095311\n",
      "[Epoch 33/50] [Batch 64/300] [D loss: 0.752354] [G loss: 0.502206] time: 0:49:35.133557\n",
      "0.9364226\n",
      "[Epoch 33/50] [Batch 65/300] [D loss: 0.752362] [G loss: 0.487055] time: 0:49:35.412245\n",
      "0.91607547\n",
      "[Epoch 33/50] [Batch 66/300] [D loss: 0.752365] [G loss: 0.492338] time: 0:49:35.711954\n",
      "0.9202204\n",
      "[Epoch 33/50] [Batch 67/300] [D loss: 0.752346] [G loss: 0.488813] time: 0:49:36.014846\n",
      "0.90930897\n",
      "[Epoch 33/50] [Batch 68/300] [D loss: 0.752361] [G loss: 0.493904] time: 0:49:36.305183\n",
      "0.9137967\n",
      "[Epoch 33/50] [Batch 69/300] [D loss: 0.752352] [G loss: 0.480187] time: 0:49:36.597832\n",
      "0.93142384\n",
      "[Epoch 33/50] [Batch 70/300] [D loss: 0.752347] [G loss: 0.478312] time: 0:49:36.893094\n",
      "0.8890615\n",
      "[Epoch 33/50] [Batch 71/300] [D loss: 0.752357] [G loss: 0.489381] time: 0:49:37.201664\n",
      "0.9111375\n",
      "[Epoch 33/50] [Batch 72/300] [D loss: 0.752373] [G loss: 0.478227] time: 0:49:37.506098\n",
      "0.9273786\n",
      "[Epoch 33/50] [Batch 73/300] [D loss: 0.752353] [G loss: 0.479176] time: 0:49:37.800246\n",
      "0.9431624\n",
      "[Epoch 33/50] [Batch 74/300] [D loss: 0.752362] [G loss: 0.484360] time: 0:49:38.090852\n",
      "0.9225483\n",
      "[Epoch 33/50] [Batch 75/300] [D loss: 0.752347] [G loss: 0.482025] time: 0:49:38.400967\n",
      "0.9496669\n",
      "[Epoch 33/50] [Batch 76/300] [D loss: 0.752347] [G loss: 0.482184] time: 0:49:38.712873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93190765\n",
      "[Epoch 33/50] [Batch 77/300] [D loss: 0.752359] [G loss: 0.482695] time: 0:49:38.984724\n",
      "0.9349912\n",
      "[Epoch 33/50] [Batch 78/300] [D loss: 0.752363] [G loss: 0.483679] time: 0:49:39.282921\n",
      "0.9052504\n",
      "[Epoch 33/50] [Batch 79/300] [D loss: 0.752358] [G loss: 0.495485] time: 0:49:39.585598\n",
      "0.9159634\n",
      "[Epoch 33/50] [Batch 80/300] [D loss: 0.752370] [G loss: 0.475693] time: 0:49:39.867517\n",
      "0.9134366\n",
      "[Epoch 33/50] [Batch 81/300] [D loss: 0.752363] [G loss: 0.476585] time: 0:49:40.168866\n",
      "0.9315646\n",
      "[Epoch 33/50] [Batch 82/300] [D loss: 0.752366] [G loss: 0.476435] time: 0:49:40.470464\n",
      "0.9280427\n",
      "[Epoch 33/50] [Batch 83/300] [D loss: 0.752346] [G loss: 0.484676] time: 0:49:40.757015\n",
      "0.87993884\n",
      "[Epoch 33/50] [Batch 84/300] [D loss: 0.752369] [G loss: 0.477793] time: 0:49:41.053269\n",
      "0.97544694\n",
      "[Epoch 33/50] [Batch 85/300] [D loss: 0.752351] [G loss: 0.516496] time: 0:49:41.364401\n",
      "0.9123065\n",
      "[Epoch 33/50] [Batch 86/300] [D loss: 0.752366] [G loss: 0.494932] time: 0:49:41.653364\n",
      "0.9462128\n",
      "[Epoch 33/50] [Batch 87/300] [D loss: 0.752376] [G loss: 0.515361] time: 0:49:41.953856\n",
      "0.9153134\n",
      "[Epoch 33/50] [Batch 88/300] [D loss: 0.752363] [G loss: 0.488091] time: 0:49:42.258631\n",
      "0.9157279\n",
      "[Epoch 33/50] [Batch 89/300] [D loss: 0.752358] [G loss: 0.489044] time: 0:49:42.558481\n",
      "0.96457577\n",
      "[Epoch 33/50] [Batch 90/300] [D loss: 0.752360] [G loss: 0.493204] time: 0:49:42.854249\n",
      "0.97606677\n",
      "[Epoch 33/50] [Batch 91/300] [D loss: 0.752352] [G loss: 0.494587] time: 0:49:43.141916\n",
      "0.8988948\n",
      "[Epoch 33/50] [Batch 92/300] [D loss: 0.752352] [G loss: 0.471414] time: 0:49:43.439334\n",
      "0.9668341\n",
      "[Epoch 33/50] [Batch 93/300] [D loss: 0.752351] [G loss: 0.503063] time: 0:49:43.744528\n",
      "0.9336532\n",
      "[Epoch 33/50] [Batch 94/300] [D loss: 0.752357] [G loss: 0.492059] time: 0:49:44.038492\n",
      "0.9374054\n",
      "[Epoch 33/50] [Batch 95/300] [D loss: 0.752353] [G loss: 0.475369] time: 0:49:44.342892\n",
      "0.9121701\n",
      "[Epoch 33/50] [Batch 96/300] [D loss: 0.752341] [G loss: 0.501383] time: 0:49:44.648719\n",
      "0.90548843\n",
      "[Epoch 33/50] [Batch 97/300] [D loss: 0.752352] [G loss: 0.480232] time: 0:49:44.949210\n",
      "0.92329407\n",
      "[Epoch 33/50] [Batch 98/300] [D loss: 0.752358] [G loss: 0.503436] time: 0:49:45.239535\n",
      "0.9270796\n",
      "[Epoch 33/50] [Batch 99/300] [D loss: 0.752348] [G loss: 0.501491] time: 0:49:45.526498\n",
      "0.9532318\n",
      "[Epoch 33/50] [Batch 100/300] [D loss: 0.752359] [G loss: 0.490043] time: 0:49:45.843260\n",
      "0.9427783\n",
      "[Epoch 33/50] [Batch 101/300] [D loss: 0.752362] [G loss: 0.471257] time: 0:49:46.128658\n",
      "0.94085294\n",
      "[Epoch 33/50] [Batch 102/300] [D loss: 0.752361] [G loss: 0.475889] time: 0:49:46.423081\n",
      "0.9171896\n",
      "[Epoch 33/50] [Batch 103/300] [D loss: 0.752354] [G loss: 0.488317] time: 0:49:46.710614\n",
      "0.8849559\n",
      "[Epoch 33/50] [Batch 104/300] [D loss: 0.752355] [G loss: 0.503966] time: 0:49:47.032770\n",
      "0.90263987\n",
      "[Epoch 33/50] [Batch 105/300] [D loss: 0.752335] [G loss: 0.489782] time: 0:49:47.352498\n",
      "0.867959\n",
      "[Epoch 33/50] [Batch 106/300] [D loss: 0.752348] [G loss: 0.512237] time: 0:49:47.648402\n",
      "0.9118448\n",
      "[Epoch 33/50] [Batch 107/300] [D loss: 0.752346] [G loss: 0.477455] time: 0:49:47.951234\n",
      "0.96018356\n",
      "[Epoch 33/50] [Batch 108/300] [D loss: 0.752358] [G loss: 0.511362] time: 0:49:48.252183\n",
      "0.893975\n",
      "[Epoch 33/50] [Batch 109/300] [D loss: 0.752351] [G loss: 0.500782] time: 0:49:48.556710\n",
      "0.93855685\n",
      "[Epoch 33/50] [Batch 110/300] [D loss: 0.752353] [G loss: 0.481226] time: 0:49:48.842777\n",
      "0.89670175\n",
      "[Epoch 33/50] [Batch 111/300] [D loss: 0.752340] [G loss: 0.487273] time: 0:49:49.152283\n",
      "0.9394047\n",
      "[Epoch 33/50] [Batch 112/300] [D loss: 0.752349] [G loss: 0.498901] time: 0:49:49.457848\n",
      "0.94613886\n",
      "[Epoch 33/50] [Batch 113/300] [D loss: 0.752364] [G loss: 0.477945] time: 0:49:49.754777\n",
      "0.9331688\n",
      "[Epoch 33/50] [Batch 114/300] [D loss: 0.752362] [G loss: 0.488457] time: 0:49:50.038441\n",
      "0.9135348\n",
      "[Epoch 33/50] [Batch 115/300] [D loss: 0.752363] [G loss: 0.472695] time: 0:49:50.341842\n",
      "0.8805677\n",
      "[Epoch 33/50] [Batch 116/300] [D loss: 0.752345] [G loss: 0.511593] time: 0:49:50.643881\n",
      "0.88231236\n",
      "[Epoch 33/50] [Batch 117/300] [D loss: 0.752336] [G loss: 0.513119] time: 0:49:50.938493\n",
      "0.8910427\n",
      "[Epoch 33/50] [Batch 118/300] [D loss: 0.752354] [G loss: 0.482326] time: 0:49:51.238528\n",
      "0.8948261\n",
      "[Epoch 33/50] [Batch 119/300] [D loss: 0.752350] [G loss: 0.483840] time: 0:49:51.540462\n",
      "0.88261056\n",
      "[Epoch 33/50] [Batch 120/300] [D loss: 0.752359] [G loss: 0.505962] time: 0:49:51.832136\n",
      "0.907069\n",
      "[Epoch 33/50] [Batch 121/300] [D loss: 0.752348] [G loss: 0.480515] time: 0:49:52.127313\n",
      "0.94692475\n",
      "[Epoch 33/50] [Batch 122/300] [D loss: 0.752356] [G loss: 0.480777] time: 0:49:52.420212\n",
      "0.9161925\n",
      "[Epoch 33/50] [Batch 123/300] [D loss: 0.752345] [G loss: 0.469556] time: 0:49:52.718982\n",
      "0.9834755\n",
      "[Epoch 33/50] [Batch 124/300] [D loss: 0.752341] [G loss: 0.475705] time: 0:49:53.002855\n",
      "0.95184165\n",
      "[Epoch 33/50] [Batch 125/300] [D loss: 0.752341] [G loss: 0.496330] time: 0:49:53.286353\n",
      "0.95749474\n",
      "[Epoch 33/50] [Batch 126/300] [D loss: 0.752344] [G loss: 0.482542] time: 0:49:53.587848\n",
      "0.9815983\n",
      "[Epoch 33/50] [Batch 127/300] [D loss: 0.752361] [G loss: 0.499049] time: 0:49:53.892705\n",
      "0.9063569\n",
      "[Epoch 33/50] [Batch 128/300] [D loss: 0.752358] [G loss: 0.488613] time: 0:49:54.188421\n",
      "0.90617234\n",
      "[Epoch 33/50] [Batch 129/300] [D loss: 0.752357] [G loss: 0.510981] time: 0:49:54.490232\n",
      "0.90892625\n",
      "[Epoch 33/50] [Batch 130/300] [D loss: 0.752350] [G loss: 0.499038] time: 0:49:54.798382\n",
      "0.90746826\n",
      "[Epoch 33/50] [Batch 131/300] [D loss: 0.752354] [G loss: 0.477344] time: 0:49:55.096412\n",
      "0.87746906\n",
      "[Epoch 33/50] [Batch 132/300] [D loss: 0.752345] [G loss: 0.504470] time: 0:49:55.388954\n",
      "0.94693583\n",
      "[Epoch 33/50] [Batch 133/300] [D loss: 0.752347] [G loss: 0.482229] time: 0:49:55.691084\n",
      "0.91005474\n",
      "[Epoch 33/50] [Batch 134/300] [D loss: 0.752348] [G loss: 0.490989] time: 0:49:56.014265\n",
      "0.8745794\n",
      "[Epoch 33/50] [Batch 135/300] [D loss: 0.752349] [G loss: 0.494367] time: 0:49:56.309431\n",
      "0.8942416\n",
      "[Epoch 33/50] [Batch 136/300] [D loss: 0.752342] [G loss: 0.494294] time: 0:49:56.611189\n",
      "0.9353909\n",
      "[Epoch 33/50] [Batch 137/300] [D loss: 0.752357] [G loss: 0.485187] time: 0:49:56.921107\n",
      "0.98191816\n",
      "[Epoch 33/50] [Batch 138/300] [D loss: 0.752346] [G loss: 0.515099] time: 0:49:57.217391\n",
      "0.97012204\n",
      "[Epoch 33/50] [Batch 139/300] [D loss: 0.752351] [G loss: 0.490152] time: 0:49:57.510324\n",
      "0.95737934\n",
      "[Epoch 33/50] [Batch 140/300] [D loss: 0.752346] [G loss: 0.480261] time: 0:49:57.808200\n",
      "0.94791657\n",
      "[Epoch 33/50] [Batch 141/300] [D loss: 0.752350] [G loss: 0.500670] time: 0:49:58.096068\n",
      "0.8887553\n",
      "[Epoch 33/50] [Batch 142/300] [D loss: 0.752336] [G loss: 0.497584] time: 0:49:58.386828\n",
      "0.92453235\n",
      "[Epoch 33/50] [Batch 143/300] [D loss: 0.752371] [G loss: 0.481962] time: 0:49:58.670596\n",
      "0.95907193\n",
      "[Epoch 33/50] [Batch 144/300] [D loss: 0.752336] [G loss: 0.481548] time: 0:49:58.960851\n",
      "0.9113988\n",
      "[Epoch 33/50] [Batch 145/300] [D loss: 0.752334] [G loss: 0.484810] time: 0:49:59.253442\n",
      "0.8522629\n",
      "[Epoch 33/50] [Batch 146/300] [D loss: 0.752345] [G loss: 0.504672] time: 0:49:59.542469\n",
      "0.95256853\n",
      "[Epoch 33/50] [Batch 147/300] [D loss: 0.752346] [G loss: 0.496773] time: 0:49:59.846324\n",
      "0.8885679\n",
      "[Epoch 33/50] [Batch 148/300] [D loss: 0.752356] [G loss: 0.477524] time: 0:50:00.138534\n",
      "0.8881807\n",
      "[Epoch 33/50] [Batch 149/300] [D loss: 0.752347] [G loss: 0.478364] time: 0:50:00.427170\n",
      "0.93847585\n",
      "[Epoch 33/50] [Batch 150/300] [D loss: 0.752365] [G loss: 0.502460] time: 0:50:00.730895\n",
      "0.9496818\n",
      "[Epoch 33/50] [Batch 151/300] [D loss: 0.752353] [G loss: 0.501268] time: 0:50:01.031144\n",
      "0.9302912\n",
      "[Epoch 33/50] [Batch 152/300] [D loss: 0.752360] [G loss: 0.480366] time: 0:50:01.328061\n",
      "0.953239\n",
      "[Epoch 33/50] [Batch 153/300] [D loss: 0.752334] [G loss: 0.481795] time: 0:50:01.630643\n",
      "0.8930395\n",
      "[Epoch 33/50] [Batch 154/300] [D loss: 0.752357] [G loss: 0.493113] time: 0:50:01.943300\n",
      "0.9285228\n",
      "[Epoch 33/50] [Batch 155/300] [D loss: 0.752347] [G loss: 0.488351] time: 0:50:02.237417\n",
      "0.89064884\n",
      "[Epoch 33/50] [Batch 156/300] [D loss: 0.752360] [G loss: 0.486376] time: 0:50:02.541651\n",
      "0.93064994\n",
      "[Epoch 33/50] [Batch 157/300] [D loss: 0.752355] [G loss: 0.481472] time: 0:50:02.825661\n",
      "0.9062743\n",
      "[Epoch 33/50] [Batch 158/300] [D loss: 0.752346] [G loss: 0.496805] time: 0:50:03.121857\n",
      "0.88098127\n",
      "[Epoch 33/50] [Batch 159/300] [D loss: 0.752348] [G loss: 0.501017] time: 0:50:03.400049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88811463\n",
      "[Epoch 33/50] [Batch 160/300] [D loss: 0.752346] [G loss: 0.501154] time: 0:50:03.693181\n",
      "0.9115448\n",
      "[Epoch 33/50] [Batch 161/300] [D loss: 0.752364] [G loss: 0.490080] time: 0:50:03.987113\n",
      "0.94573134\n",
      "[Epoch 33/50] [Batch 162/300] [D loss: 0.752357] [G loss: 0.488676] time: 0:50:04.272511\n",
      "0.9198448\n",
      "[Epoch 33/50] [Batch 163/300] [D loss: 0.752356] [G loss: 0.505230] time: 0:50:04.571386\n",
      "0.94585186\n",
      "[Epoch 33/50] [Batch 164/300] [D loss: 0.752357] [G loss: 0.509371] time: 0:50:04.877412\n",
      "0.8744145\n",
      "[Epoch 33/50] [Batch 165/300] [D loss: 0.752356] [G loss: 0.476875] time: 0:50:05.154784\n",
      "0.90693647\n",
      "[Epoch 33/50] [Batch 166/300] [D loss: 0.752357] [G loss: 0.473955] time: 0:50:05.446894\n",
      "0.8908079\n",
      "[Epoch 33/50] [Batch 167/300] [D loss: 0.752358] [G loss: 0.495230] time: 0:50:05.730498\n",
      "0.8943489\n",
      "[Epoch 33/50] [Batch 168/300] [D loss: 0.752345] [G loss: 0.514123] time: 0:50:06.034098\n",
      "0.9406553\n",
      "[Epoch 33/50] [Batch 169/300] [D loss: 0.752372] [G loss: 0.490896] time: 0:50:06.335860\n",
      "0.89124626\n",
      "[Epoch 33/50] [Batch 170/300] [D loss: 0.752348] [G loss: 0.489043] time: 0:50:06.621789\n",
      "0.87032586\n",
      "[Epoch 33/50] [Batch 171/300] [D loss: 0.752355] [G loss: 0.490153] time: 0:50:06.920021\n",
      "0.88879853\n",
      "[Epoch 33/50] [Batch 172/300] [D loss: 0.752358] [G loss: 0.486723] time: 0:50:07.207715\n",
      "0.91946846\n",
      "[Epoch 33/50] [Batch 173/300] [D loss: 0.752336] [G loss: 0.485050] time: 0:50:07.496283\n",
      "0.929691\n",
      "[Epoch 33/50] [Batch 174/300] [D loss: 0.752350] [G loss: 0.498229] time: 0:50:07.778235\n",
      "0.93556976\n",
      "[Epoch 33/50] [Batch 175/300] [D loss: 0.752345] [G loss: 0.494597] time: 0:50:08.077171\n",
      "0.9072571\n",
      "[Epoch 33/50] [Batch 176/300] [D loss: 0.752344] [G loss: 0.491010] time: 0:50:08.398984\n",
      "0.9301925\n",
      "[Epoch 33/50] [Batch 177/300] [D loss: 0.752361] [G loss: 0.512018] time: 0:50:08.697503\n",
      "0.9373496\n",
      "[Epoch 33/50] [Batch 178/300] [D loss: 0.752350] [G loss: 0.481683] time: 0:50:08.999775\n",
      "0.913542\n",
      "[Epoch 33/50] [Batch 179/300] [D loss: 0.752348] [G loss: 0.475693] time: 0:50:09.290804\n",
      "0.9743166\n",
      "[Epoch 33/50] [Batch 180/300] [D loss: 0.752348] [G loss: 0.491256] time: 0:50:09.599770\n",
      "0.8853089\n",
      "[Epoch 33/50] [Batch 181/300] [D loss: 0.752336] [G loss: 0.496470] time: 0:50:09.887676\n",
      "0.89949584\n",
      "[Epoch 33/50] [Batch 182/300] [D loss: 0.752360] [G loss: 0.472921] time: 0:50:10.189994\n",
      "0.9300089\n",
      "[Epoch 33/50] [Batch 183/300] [D loss: 0.752374] [G loss: 0.501883] time: 0:50:10.499823\n",
      "0.95789045\n",
      "[Epoch 33/50] [Batch 184/300] [D loss: 0.752351] [G loss: 0.479813] time: 0:50:10.797877\n",
      "0.90806526\n",
      "[Epoch 33/50] [Batch 185/300] [D loss: 0.752364] [G loss: 0.485788] time: 0:50:11.089448\n",
      "0.8984809\n",
      "[Epoch 33/50] [Batch 186/300] [D loss: 0.752339] [G loss: 0.485993] time: 0:50:11.381374\n",
      "0.9457123\n",
      "[Epoch 33/50] [Batch 187/300] [D loss: 0.752337] [G loss: 0.522346] time: 0:50:11.673208\n",
      "0.97607356\n",
      "[Epoch 33/50] [Batch 188/300] [D loss: 0.752348] [G loss: 0.502295] time: 0:50:11.958567\n",
      "0.9596788\n",
      "[Epoch 33/50] [Batch 189/300] [D loss: 0.752358] [G loss: 0.475798] time: 0:50:12.254244\n",
      "0.9330711\n",
      "[Epoch 33/50] [Batch 190/300] [D loss: 0.752341] [G loss: 0.479809] time: 0:50:12.540676\n",
      "0.8956186\n",
      "[Epoch 33/50] [Batch 191/300] [D loss: 0.752342] [G loss: 0.496523] time: 0:50:12.837139\n",
      "0.8525102\n",
      "[Epoch 33/50] [Batch 192/300] [D loss: 0.752349] [G loss: 0.479943] time: 0:50:13.143200\n",
      "0.9461661\n",
      "[Epoch 33/50] [Batch 193/300] [D loss: 0.752348] [G loss: 0.489033] time: 0:50:13.438763\n",
      "0.89402133\n",
      "[Epoch 33/50] [Batch 194/300] [D loss: 0.752373] [G loss: 0.480076] time: 0:50:13.737589\n",
      "0.95917374\n",
      "[Epoch 33/50] [Batch 195/300] [D loss: 0.752357] [G loss: 0.482682] time: 0:50:14.038051\n",
      "0.96862173\n",
      "[Epoch 33/50] [Batch 196/300] [D loss: 0.752372] [G loss: 0.480062] time: 0:50:14.324445\n",
      "0.90966606\n",
      "[Epoch 33/50] [Batch 197/300] [D loss: 0.752340] [G loss: 0.487575] time: 0:50:14.602047\n",
      "0.952872\n",
      "[Epoch 33/50] [Batch 198/300] [D loss: 0.752358] [G loss: 0.494757] time: 0:50:14.889284\n",
      "0.9139721\n",
      "[Epoch 33/50] [Batch 199/300] [D loss: 0.752341] [G loss: 0.491351] time: 0:50:15.190476\n",
      "0.9468537\n",
      "[Epoch 33/50] [Batch 200/300] [D loss: 0.752353] [G loss: 0.480673] time: 0:50:15.482974\n",
      "0.9374612\n",
      "[Epoch 33/50] [Batch 201/300] [D loss: 0.752345] [G loss: 0.486211] time: 0:50:15.771638\n",
      "0.89559984\n",
      "[Epoch 33/50] [Batch 202/300] [D loss: 0.752337] [G loss: 0.473255] time: 0:50:16.063292\n",
      "0.94827765\n",
      "[Epoch 33/50] [Batch 203/300] [D loss: 0.752365] [G loss: 0.481749] time: 0:50:16.371875\n",
      "0.9604945\n",
      "[Epoch 33/50] [Batch 204/300] [D loss: 0.752355] [G loss: 0.483266] time: 0:50:16.662975\n",
      "0.9398384\n",
      "[Epoch 33/50] [Batch 205/300] [D loss: 0.752350] [G loss: 0.511535] time: 0:50:16.945994\n",
      "0.97108454\n",
      "[Epoch 33/50] [Batch 206/300] [D loss: 0.752345] [G loss: 0.472585] time: 0:50:17.242403\n",
      "0.92852074\n",
      "[Epoch 33/50] [Batch 207/300] [D loss: 0.752364] [G loss: 0.479821] time: 0:50:17.536960\n",
      "0.9355485\n",
      "[Epoch 33/50] [Batch 208/300] [D loss: 0.752348] [G loss: 0.483093] time: 0:50:17.835518\n",
      "0.9398702\n",
      "[Epoch 33/50] [Batch 209/300] [D loss: 0.752342] [G loss: 0.479802] time: 0:50:18.145723\n",
      "0.92847425\n",
      "[Epoch 33/50] [Batch 210/300] [D loss: 0.752344] [G loss: 0.468477] time: 0:50:18.464725\n",
      "0.93577427\n",
      "[Epoch 33/50] [Batch 211/300] [D loss: 0.752352] [G loss: 0.486496] time: 0:50:18.757580\n",
      "0.930078\n",
      "[Epoch 33/50] [Batch 212/300] [D loss: 0.752341] [G loss: 0.479002] time: 0:50:19.059980\n",
      "0.8890092\n",
      "[Epoch 33/50] [Batch 213/300] [D loss: 0.752353] [G loss: 0.475640] time: 0:50:19.353680\n",
      "0.9282143\n",
      "[Epoch 33/50] [Batch 214/300] [D loss: 0.752344] [G loss: 0.485636] time: 0:50:19.635762\n",
      "0.8990717\n",
      "[Epoch 33/50] [Batch 215/300] [D loss: 0.752345] [G loss: 0.495293] time: 0:50:19.953059\n",
      "0.89557904\n",
      "[Epoch 33/50] [Batch 216/300] [D loss: 0.752358] [G loss: 0.478677] time: 0:50:20.245379\n",
      "0.96655273\n",
      "[Epoch 33/50] [Batch 217/300] [D loss: 0.752359] [G loss: 0.481867] time: 0:50:20.545797\n",
      "0.94149953\n",
      "[Epoch 33/50] [Batch 218/300] [D loss: 0.752347] [G loss: 0.477246] time: 0:50:20.840189\n",
      "0.903027\n",
      "[Epoch 33/50] [Batch 219/300] [D loss: 0.752355] [G loss: 0.492596] time: 0:50:21.139429\n",
      "0.91257477\n",
      "[Epoch 33/50] [Batch 220/300] [D loss: 0.752348] [G loss: 0.483153] time: 0:50:21.464171\n",
      "0.9425853\n",
      "[Epoch 33/50] [Batch 221/300] [D loss: 0.752350] [G loss: 0.487563] time: 0:50:21.761241\n",
      "0.88176423\n",
      "[Epoch 33/50] [Batch 222/300] [D loss: 0.752340] [G loss: 0.497747] time: 0:50:22.052957\n",
      "0.90287447\n",
      "[Epoch 33/50] [Batch 223/300] [D loss: 0.752343] [G loss: 0.498157] time: 0:50:22.354234\n",
      "0.9373862\n",
      "[Epoch 33/50] [Batch 224/300] [D loss: 0.752347] [G loss: 0.486486] time: 0:50:22.647092\n",
      "0.95386547\n",
      "[Epoch 33/50] [Batch 225/300] [D loss: 0.752347] [G loss: 0.480307] time: 0:50:22.945373\n",
      "0.9551943\n",
      "[Epoch 33/50] [Batch 226/300] [D loss: 0.752347] [G loss: 0.486336] time: 0:50:23.245856\n",
      "0.91893053\n",
      "[Epoch 33/50] [Batch 227/300] [D loss: 0.752340] [G loss: 0.474003] time: 0:50:23.512027\n",
      "0.94715816\n",
      "[Epoch 33/50] [Batch 228/300] [D loss: 0.752350] [G loss: 0.486386] time: 0:50:23.802214\n",
      "0.94748574\n",
      "[Epoch 33/50] [Batch 229/300] [D loss: 0.752341] [G loss: 0.493934] time: 0:50:24.080685\n",
      "0.9198068\n",
      "[Epoch 33/50] [Batch 230/300] [D loss: 0.752360] [G loss: 0.482260] time: 0:50:24.385695\n",
      "0.8917356\n",
      "[Epoch 33/50] [Batch 231/300] [D loss: 0.752348] [G loss: 0.478101] time: 0:50:24.671076\n",
      "0.8987424\n",
      "[Epoch 33/50] [Batch 232/300] [D loss: 0.752339] [G loss: 0.494571] time: 0:50:24.978234\n",
      "0.9132697\n",
      "[Epoch 33/50] [Batch 233/300] [D loss: 0.752342] [G loss: 0.503959] time: 0:50:25.284038\n",
      "0.92930764\n",
      "[Epoch 33/50] [Batch 234/300] [D loss: 0.752334] [G loss: 0.520342] time: 0:50:25.566651\n",
      "0.8980964\n",
      "[Epoch 33/50] [Batch 235/300] [D loss: 0.752353] [G loss: 0.515139] time: 0:50:25.871145\n",
      "0.93513036\n",
      "[Epoch 33/50] [Batch 236/300] [D loss: 0.752345] [G loss: 0.484308] time: 0:50:26.173853\n",
      "0.9021446\n",
      "[Epoch 33/50] [Batch 237/300] [D loss: 0.752346] [G loss: 0.496553] time: 0:50:26.470328\n",
      "0.90542984\n",
      "[Epoch 33/50] [Batch 238/300] [D loss: 0.752334] [G loss: 0.502533] time: 0:50:26.760523\n",
      "0.9070404\n",
      "[Epoch 33/50] [Batch 239/300] [D loss: 0.752346] [G loss: 0.482809] time: 0:50:27.055366\n",
      "0.87874365\n",
      "[Epoch 33/50] [Batch 240/300] [D loss: 0.752340] [G loss: 0.473140] time: 0:50:27.377689\n",
      "0.92922664\n",
      "[Epoch 33/50] [Batch 241/300] [D loss: 0.752346] [G loss: 0.487294] time: 0:50:27.691732\n",
      "0.90869063\n",
      "[Epoch 33/50] [Batch 242/300] [D loss: 0.752360] [G loss: 0.488501] time: 0:50:27.982499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9173402\n",
      "[Epoch 33/50] [Batch 243/300] [D loss: 0.752351] [G loss: 0.473109] time: 0:50:28.286813\n",
      "0.93817854\n",
      "[Epoch 33/50] [Batch 244/300] [D loss: 0.752358] [G loss: 0.494216] time: 0:50:28.585799\n",
      "0.9103391\n",
      "[Epoch 33/50] [Batch 245/300] [D loss: 0.752354] [G loss: 0.506201] time: 0:50:28.890675\n",
      "0.89979243\n",
      "[Epoch 33/50] [Batch 246/300] [D loss: 0.752357] [G loss: 0.489249] time: 0:50:29.191268\n",
      "0.9079687\n",
      "[Epoch 33/50] [Batch 247/300] [D loss: 0.752351] [G loss: 0.488734] time: 0:50:29.482273\n",
      "0.90996975\n",
      "[Epoch 33/50] [Batch 248/300] [D loss: 0.752347] [G loss: 0.496238] time: 0:50:29.787158\n",
      "0.926297\n",
      "[Epoch 33/50] [Batch 249/300] [D loss: 0.752356] [G loss: 0.504098] time: 0:50:30.065570\n",
      "0.9089329\n",
      "[Epoch 33/50] [Batch 250/300] [D loss: 0.752339] [G loss: 0.480947] time: 0:50:30.367438\n",
      "0.89866287\n",
      "[Epoch 33/50] [Batch 251/300] [D loss: 0.752354] [G loss: 0.482496] time: 0:50:30.661175\n",
      "0.9228528\n",
      "[Epoch 33/50] [Batch 252/300] [D loss: 0.752347] [G loss: 0.524659] time: 0:50:30.940131\n",
      "0.93110675\n",
      "[Epoch 33/50] [Batch 253/300] [D loss: 0.752342] [G loss: 0.479678] time: 0:50:31.233887\n",
      "0.9616301\n",
      "[Epoch 33/50] [Batch 254/300] [D loss: 0.752359] [G loss: 0.498865] time: 0:50:31.541524\n",
      "0.898653\n",
      "[Epoch 33/50] [Batch 255/300] [D loss: 0.752353] [G loss: 0.486174] time: 0:50:31.840367\n",
      "0.8759451\n",
      "[Epoch 33/50] [Batch 256/300] [D loss: 0.752351] [G loss: 0.500536] time: 0:50:32.146607\n",
      "0.9307532\n",
      "[Epoch 33/50] [Batch 257/300] [D loss: 0.752342] [G loss: 0.484027] time: 0:50:32.426932\n",
      "0.94766814\n",
      "[Epoch 33/50] [Batch 258/300] [D loss: 0.752342] [G loss: 0.488607] time: 0:50:32.730605\n",
      "0.92874527\n",
      "[Epoch 33/50] [Batch 259/300] [D loss: 0.752343] [G loss: 0.517037] time: 0:50:33.025247\n",
      "0.9325653\n",
      "[Epoch 33/50] [Batch 260/300] [D loss: 0.752349] [G loss: 0.486151] time: 0:50:33.341533\n",
      "0.9085851\n",
      "[Epoch 33/50] [Batch 261/300] [D loss: 0.752352] [G loss: 0.497606] time: 0:50:33.642097\n",
      "0.93029517\n",
      "[Epoch 33/50] [Batch 262/300] [D loss: 0.752369] [G loss: 0.507196] time: 0:50:33.950586\n",
      "0.9624621\n",
      "[Epoch 33/50] [Batch 263/300] [D loss: 0.752353] [G loss: 0.484450] time: 0:50:34.251845\n",
      "0.89067787\n",
      "[Epoch 33/50] [Batch 264/300] [D loss: 0.752342] [G loss: 0.491535] time: 0:50:34.534128\n",
      "0.94806546\n",
      "[Epoch 33/50] [Batch 265/300] [D loss: 0.752363] [G loss: 0.482690] time: 0:50:34.822912\n",
      "0.89360255\n",
      "[Epoch 33/50] [Batch 266/300] [D loss: 0.752336] [G loss: 0.479311] time: 0:50:35.115001\n",
      "0.8704534\n",
      "[Epoch 33/50] [Batch 267/300] [D loss: 0.752351] [G loss: 0.495382] time: 0:50:35.417938\n",
      "0.95574015\n",
      "[Epoch 33/50] [Batch 268/300] [D loss: 0.752342] [G loss: 0.475735] time: 0:50:35.709959\n",
      "0.9196264\n",
      "[Epoch 33/50] [Batch 269/300] [D loss: 0.752353] [G loss: 0.478265] time: 0:50:36.002101\n",
      "0.9232554\n",
      "[Epoch 33/50] [Batch 270/300] [D loss: 0.752375] [G loss: 0.484065] time: 0:50:36.296730\n",
      "0.90923995\n",
      "[Epoch 33/50] [Batch 271/300] [D loss: 0.752362] [G loss: 0.496482] time: 0:50:36.607008\n",
      "0.91136235\n",
      "[Epoch 33/50] [Batch 272/300] [D loss: 0.752344] [G loss: 0.497279] time: 0:50:36.905531\n",
      "0.96000814\n",
      "[Epoch 33/50] [Batch 273/300] [D loss: 0.752334] [G loss: 0.478888] time: 0:50:37.205745\n",
      "0.9708085\n",
      "[Epoch 33/50] [Batch 274/300] [D loss: 0.752346] [G loss: 0.505339] time: 0:50:37.505793\n",
      "0.9297913\n",
      "[Epoch 33/50] [Batch 275/300] [D loss: 0.752345] [G loss: 0.476337] time: 0:50:37.807752\n",
      "0.94504195\n",
      "[Epoch 33/50] [Batch 276/300] [D loss: 0.752360] [G loss: 0.488899] time: 0:50:38.103293\n",
      "0.94634485\n",
      "[Epoch 33/50] [Batch 277/300] [D loss: 0.752344] [G loss: 0.489187] time: 0:50:38.394117\n",
      "0.9690688\n",
      "[Epoch 33/50] [Batch 278/300] [D loss: 0.752372] [G loss: 0.479073] time: 0:50:38.705277\n",
      "0.94713616\n",
      "[Epoch 33/50] [Batch 279/300] [D loss: 0.752342] [G loss: 0.474555] time: 0:50:38.997051\n",
      "0.9378802\n",
      "[Epoch 33/50] [Batch 280/300] [D loss: 0.752340] [G loss: 0.472120] time: 0:50:39.284056\n",
      "0.903121\n",
      "[Epoch 33/50] [Batch 281/300] [D loss: 0.752348] [G loss: 0.490756] time: 0:50:39.572615\n",
      "0.92811674\n",
      "[Epoch 33/50] [Batch 282/300] [D loss: 0.752358] [G loss: 0.509590] time: 0:50:39.881569\n",
      "0.9707348\n",
      "[Epoch 33/50] [Batch 283/300] [D loss: 0.752351] [G loss: 0.492832] time: 0:50:40.185971\n",
      "0.90895206\n",
      "[Epoch 33/50] [Batch 284/300] [D loss: 0.752346] [G loss: 0.481836] time: 0:50:40.455074\n",
      "0.8998771\n",
      "[Epoch 33/50] [Batch 285/300] [D loss: 0.752333] [G loss: 0.489896] time: 0:50:40.756873\n",
      "0.9529498\n",
      "[Epoch 33/50] [Batch 286/300] [D loss: 0.752354] [G loss: 0.495245] time: 0:50:41.059196\n",
      "0.9315488\n",
      "[Epoch 33/50] [Batch 287/300] [D loss: 0.752364] [G loss: 0.478984] time: 0:50:41.356286\n",
      "0.9271986\n",
      "[Epoch 33/50] [Batch 288/300] [D loss: 0.752341] [G loss: 0.491057] time: 0:50:41.653804\n",
      "0.85272056\n",
      "[Epoch 33/50] [Batch 289/300] [D loss: 0.752351] [G loss: 0.474625] time: 0:50:41.943660\n",
      "0.87872213\n",
      "[Epoch 33/50] [Batch 290/300] [D loss: 0.752348] [G loss: 0.479360] time: 0:50:42.232849\n",
      "0.93356776\n",
      "[Epoch 33/50] [Batch 291/300] [D loss: 0.752348] [G loss: 0.477334] time: 0:50:42.544642\n",
      "0.9203398\n",
      "[Epoch 33/50] [Batch 292/300] [D loss: 0.752343] [G loss: 0.488329] time: 0:50:42.840654\n",
      "0.9066557\n",
      "[Epoch 33/50] [Batch 293/300] [D loss: 0.752359] [G loss: 0.487596] time: 0:50:43.121606\n",
      "0.90104985\n",
      "[Epoch 33/50] [Batch 294/300] [D loss: 0.752382] [G loss: 0.488122] time: 0:50:43.421832\n",
      "0.95748645\n",
      "[Epoch 33/50] [Batch 295/300] [D loss: 0.752353] [G loss: 0.488176] time: 0:50:43.709748\n",
      "0.87667805\n",
      "[Epoch 33/50] [Batch 296/300] [D loss: 0.752359] [G loss: 0.492962] time: 0:50:44.010952\n",
      "0.9140144\n",
      "[Epoch 33/50] [Batch 297/300] [D loss: 0.752358] [G loss: 0.487955] time: 0:50:44.324415\n",
      "0.9332356\n",
      "[Epoch 33/50] [Batch 298/300] [D loss: 0.752354] [G loss: 0.489465] time: 0:50:44.638277\n",
      "0.9497259\n",
      "[Epoch 33/50] [Batch 299/300] [D loss: 0.752346] [G loss: 0.508002] time: 0:50:44.925894\n",
      "0.9159481\n",
      "[Epoch 34/50] [Batch 0/300] [D loss: 0.752344] [G loss: 0.497869] time: 0:50:45.220855\n",
      "0.95252246\n",
      "[Epoch 34/50] [Batch 1/300] [D loss: 0.752347] [G loss: 0.478267] time: 0:50:45.515339\n",
      "0.96025676\n",
      "[Epoch 34/50] [Batch 2/300] [D loss: 0.752351] [G loss: 0.484997] time: 0:50:45.828339\n",
      "0.9186004\n",
      "[Epoch 34/50] [Batch 3/300] [D loss: 0.752352] [G loss: 0.476750] time: 0:50:46.126859\n",
      "0.91169983\n",
      "[Epoch 34/50] [Batch 4/300] [D loss: 0.752341] [G loss: 0.499733] time: 0:50:46.399173\n",
      "0.91569877\n",
      "[Epoch 34/50] [Batch 5/300] [D loss: 0.752347] [G loss: 0.493096] time: 0:50:46.696608\n",
      "0.91180235\n",
      "[Epoch 34/50] [Batch 6/300] [D loss: 0.752347] [G loss: 0.509711] time: 0:50:47.005047\n",
      "0.92379576\n",
      "[Epoch 34/50] [Batch 7/300] [D loss: 0.752362] [G loss: 0.489757] time: 0:50:47.312234\n",
      "0.91500264\n",
      "[Epoch 34/50] [Batch 8/300] [D loss: 0.752343] [G loss: 0.480865] time: 0:50:47.594984\n",
      "0.89731807\n",
      "[Epoch 34/50] [Batch 9/300] [D loss: 0.752353] [G loss: 0.477401] time: 0:50:47.890083\n",
      "0.93542546\n",
      "[Epoch 34/50] [Batch 10/300] [D loss: 0.752359] [G loss: 0.482180] time: 0:50:48.205874\n",
      "0.90822154\n",
      "[Epoch 34/50] [Batch 11/300] [D loss: 0.752350] [G loss: 0.488853] time: 0:50:48.505232\n",
      "0.94664985\n",
      "[Epoch 34/50] [Batch 12/300] [D loss: 0.752333] [G loss: 0.474524] time: 0:50:48.822658\n",
      "0.92936826\n",
      "[Epoch 34/50] [Batch 13/300] [D loss: 0.752337] [G loss: 0.506138] time: 0:50:49.120817\n",
      "0.90630865\n",
      "[Epoch 34/50] [Batch 14/300] [D loss: 0.752353] [G loss: 0.478607] time: 0:50:49.429864\n",
      "0.94130087\n",
      "[Epoch 34/50] [Batch 15/300] [D loss: 0.752348] [G loss: 0.497426] time: 0:50:49.744599\n",
      "0.9470288\n",
      "[Epoch 34/50] [Batch 16/300] [D loss: 0.752354] [G loss: 0.490892] time: 0:50:50.064253\n",
      "0.9107342\n",
      "[Epoch 34/50] [Batch 17/300] [D loss: 0.752348] [G loss: 0.490498] time: 0:50:50.365006\n",
      "0.925124\n",
      "[Epoch 34/50] [Batch 18/300] [D loss: 0.752331] [G loss: 0.480113] time: 0:50:50.658740\n",
      "0.92917305\n",
      "[Epoch 34/50] [Batch 19/300] [D loss: 0.752349] [G loss: 0.476706] time: 0:50:50.972089\n",
      "0.92516285\n",
      "[Epoch 34/50] [Batch 20/300] [D loss: 0.752364] [G loss: 0.511471] time: 0:50:51.263716\n",
      "0.92880017\n",
      "[Epoch 34/50] [Batch 21/300] [D loss: 0.752349] [G loss: 0.493286] time: 0:50:51.557418\n",
      "0.9187811\n",
      "[Epoch 34/50] [Batch 22/300] [D loss: 0.752339] [G loss: 0.494176] time: 0:50:51.845143\n",
      "0.94807225\n",
      "[Epoch 34/50] [Batch 23/300] [D loss: 0.752349] [G loss: 0.474459] time: 0:50:52.148957\n",
      "0.93799233\n",
      "[Epoch 34/50] [Batch 24/300] [D loss: 0.752350] [G loss: 0.502299] time: 0:50:52.447495\n",
      "0.9135681\n",
      "[Epoch 34/50] [Batch 25/300] [D loss: 0.752327] [G loss: 0.480555] time: 0:50:52.763047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9347088\n",
      "[Epoch 34/50] [Batch 26/300] [D loss: 0.752355] [G loss: 0.474341] time: 0:50:53.053037\n",
      "0.9375687\n",
      "[Epoch 34/50] [Batch 27/300] [D loss: 0.752331] [G loss: 0.473237] time: 0:50:53.345271\n",
      "0.9099896\n",
      "[Epoch 34/50] [Batch 28/300] [D loss: 0.752332] [G loss: 0.483723] time: 0:50:53.655051\n",
      "0.9465707\n",
      "[Epoch 34/50] [Batch 29/300] [D loss: 0.752338] [G loss: 0.484797] time: 0:50:53.953452\n",
      "0.93659616\n",
      "[Epoch 34/50] [Batch 30/300] [D loss: 0.752339] [G loss: 0.487039] time: 0:50:54.262392\n",
      "0.88422585\n",
      "[Epoch 34/50] [Batch 31/300] [D loss: 0.752354] [G loss: 0.496286] time: 0:50:54.548219\n",
      "0.93201727\n",
      "[Epoch 34/50] [Batch 32/300] [D loss: 0.752347] [G loss: 0.474400] time: 0:50:54.861071\n",
      "0.93016523\n",
      "[Epoch 34/50] [Batch 34/300] [D loss: 0.752336] [G loss: 0.487494] time: 0:50:55.180356\n",
      "0.90794545\n",
      "[Epoch 34/50] [Batch 35/300] [D loss: 0.752339] [G loss: 0.483450] time: 0:50:55.478073\n",
      "0.8996567\n",
      "[Epoch 34/50] [Batch 36/300] [D loss: 0.752339] [G loss: 0.481740] time: 0:50:55.759531\n",
      "0.89279836\n",
      "[Epoch 34/50] [Batch 37/300] [D loss: 0.752350] [G loss: 0.502010] time: 0:50:56.066835\n",
      "0.9170621\n",
      "[Epoch 34/50] [Batch 38/300] [D loss: 0.752339] [G loss: 0.477999] time: 0:50:56.362736\n",
      "0.90269494\n",
      "[Epoch 34/50] [Batch 39/300] [D loss: 0.752335] [G loss: 0.515574] time: 0:50:56.654354\n",
      "0.90562314\n",
      "[Epoch 34/50] [Batch 40/300] [D loss: 0.752361] [G loss: 0.508581] time: 0:50:56.957554\n",
      "0.93715906\n",
      "[Epoch 34/50] [Batch 41/300] [D loss: 0.752345] [G loss: 0.494635] time: 0:50:57.256291\n",
      "0.9382355\n",
      "[Epoch 34/50] [Batch 42/300] [D loss: 0.752353] [G loss: 0.500923] time: 0:50:57.544764\n",
      "0.90832883\n",
      "[Epoch 34/50] [Batch 43/300] [D loss: 0.752317] [G loss: 0.502145] time: 0:50:57.849574\n",
      "0.90558034\n",
      "[Epoch 34/50] [Batch 44/300] [D loss: 0.752337] [G loss: 0.478975] time: 0:50:58.162967\n",
      "0.9625427\n",
      "[Epoch 34/50] [Batch 45/300] [D loss: 0.752360] [G loss: 0.486298] time: 0:50:58.467533\n",
      "0.9139135\n",
      "[Epoch 34/50] [Batch 46/300] [D loss: 0.752343] [G loss: 0.483015] time: 0:50:58.762358\n",
      "0.9308631\n",
      "[Epoch 34/50] [Batch 47/300] [D loss: 0.752358] [G loss: 0.489270] time: 0:50:59.049373\n",
      "0.9121861\n",
      "[Epoch 34/50] [Batch 48/300] [D loss: 0.752342] [G loss: 0.485337] time: 0:50:59.312685\n",
      "0.9174617\n",
      "[Epoch 34/50] [Batch 49/300] [D loss: 0.752349] [G loss: 0.482252] time: 0:50:59.619175\n",
      "0.91683245\n",
      "[Epoch 34/50] [Batch 50/300] [D loss: 0.752332] [G loss: 0.495952] time: 0:50:59.913351\n",
      "0.9463205\n",
      "[Epoch 34/50] [Batch 51/300] [D loss: 0.752336] [G loss: 0.494365] time: 0:51:00.209337\n",
      "0.9075391\n",
      "[Epoch 34/50] [Batch 52/300] [D loss: 0.752350] [G loss: 0.485397] time: 0:51:00.509119\n",
      "0.9355331\n",
      "[Epoch 34/50] [Batch 53/300] [D loss: 0.752363] [G loss: 0.475417] time: 0:51:00.800596\n",
      "0.95273304\n",
      "[Epoch 34/50] [Batch 54/300] [D loss: 0.752349] [G loss: 0.478712] time: 0:51:01.086504\n",
      "0.8793664\n",
      "[Epoch 34/50] [Batch 55/300] [D loss: 0.752348] [G loss: 0.503043] time: 0:51:01.393075\n",
      "0.92915064\n",
      "[Epoch 34/50] [Batch 56/300] [D loss: 0.752344] [G loss: 0.482374] time: 0:51:01.685078\n",
      "0.90851706\n",
      "[Epoch 34/50] [Batch 57/300] [D loss: 0.752349] [G loss: 0.479892] time: 0:51:01.975219\n",
      "0.9331896\n",
      "[Epoch 34/50] [Batch 58/300] [D loss: 0.752360] [G loss: 0.470108] time: 0:51:02.253156\n",
      "0.8848948\n",
      "[Epoch 34/50] [Batch 59/300] [D loss: 0.752340] [G loss: 0.469708] time: 0:51:02.545748\n",
      "0.8892115\n",
      "[Epoch 34/50] [Batch 60/300] [D loss: 0.752336] [G loss: 0.477894] time: 0:51:02.847162\n",
      "0.8878576\n",
      "[Epoch 34/50] [Batch 61/300] [D loss: 0.752359] [G loss: 0.491896] time: 0:51:03.146943\n",
      "0.9284435\n",
      "[Epoch 34/50] [Batch 62/300] [D loss: 0.752333] [G loss: 0.479513] time: 0:51:03.449340\n",
      "0.9085491\n",
      "[Epoch 34/50] [Batch 63/300] [D loss: 0.752356] [G loss: 0.508267] time: 0:51:03.736106\n",
      "0.9352656\n",
      "[Epoch 34/50] [Batch 64/300] [D loss: 0.752328] [G loss: 0.473545] time: 0:51:04.017633\n",
      "0.8938094\n",
      "[Epoch 34/50] [Batch 65/300] [D loss: 0.752355] [G loss: 0.486804] time: 0:51:04.306770\n",
      "0.9271898\n",
      "[Epoch 34/50] [Batch 66/300] [D loss: 0.752369] [G loss: 0.467137] time: 0:51:04.595699\n",
      "0.93313724\n",
      "[Epoch 34/50] [Batch 67/300] [D loss: 0.752351] [G loss: 0.481661] time: 0:51:04.895046\n",
      "0.9373904\n",
      "[Epoch 34/50] [Batch 68/300] [D loss: 0.752331] [G loss: 0.484812] time: 0:51:05.186492\n",
      "0.87514186\n",
      "[Epoch 34/50] [Batch 69/300] [D loss: 0.752364] [G loss: 0.477906] time: 0:51:05.482728\n",
      "0.91730475\n",
      "[Epoch 34/50] [Batch 70/300] [D loss: 0.752350] [G loss: 0.506980] time: 0:51:05.782446\n",
      "0.9091471\n",
      "[Epoch 34/50] [Batch 71/300] [D loss: 0.752339] [G loss: 0.480157] time: 0:51:06.080979\n",
      "0.93742186\n",
      "[Epoch 34/50] [Batch 72/300] [D loss: 0.752351] [G loss: 0.472627] time: 0:51:06.375795\n",
      "0.9049781\n",
      "[Epoch 34/50] [Batch 73/300] [D loss: 0.752354] [G loss: 0.477881] time: 0:51:06.666495\n",
      "0.9130249\n",
      "[Epoch 34/50] [Batch 74/300] [D loss: 0.752334] [G loss: 0.495460] time: 0:51:06.954367\n",
      "0.90367097\n",
      "[Epoch 34/50] [Batch 75/300] [D loss: 0.752356] [G loss: 0.488499] time: 0:51:07.254392\n",
      "0.8891244\n",
      "[Epoch 34/50] [Batch 76/300] [D loss: 0.752349] [G loss: 0.517775] time: 0:51:07.571496\n",
      "0.8858225\n",
      "[Epoch 34/50] [Batch 77/300] [D loss: 0.752347] [G loss: 0.486777] time: 0:51:07.870567\n",
      "0.9524576\n",
      "[Epoch 34/50] [Batch 78/300] [D loss: 0.752354] [G loss: 0.470375] time: 0:51:08.156360\n",
      "0.95575255\n",
      "[Epoch 34/50] [Batch 79/300] [D loss: 0.752355] [G loss: 0.483204] time: 0:51:08.458002\n",
      "0.9330886\n",
      "[Epoch 34/50] [Batch 80/300] [D loss: 0.752359] [G loss: 0.477851] time: 0:51:08.755088\n",
      "0.9122753\n",
      "[Epoch 34/50] [Batch 81/300] [D loss: 0.752346] [G loss: 0.513385] time: 0:51:09.059203\n",
      "0.89453626\n",
      "[Epoch 34/50] [Batch 82/300] [D loss: 0.752341] [G loss: 0.474895] time: 0:51:09.356482\n",
      "0.9291763\n",
      "[Epoch 34/50] [Batch 83/300] [D loss: 0.752339] [G loss: 0.485312] time: 0:51:09.655362\n",
      "0.9693108\n",
      "[Epoch 34/50] [Batch 84/300] [D loss: 0.752341] [G loss: 0.481307] time: 0:51:09.934988\n",
      "0.9163697\n",
      "[Epoch 34/50] [Batch 85/300] [D loss: 0.752355] [G loss: 0.481041] time: 0:51:10.219839\n",
      "0.91893226\n",
      "[Epoch 34/50] [Batch 86/300] [D loss: 0.752328] [G loss: 0.516603] time: 0:51:10.522108\n",
      "0.9448824\n",
      "[Epoch 34/50] [Batch 87/300] [D loss: 0.752320] [G loss: 0.480795] time: 0:51:10.824281\n",
      "0.92036533\n",
      "[Epoch 34/50] [Batch 88/300] [D loss: 0.752350] [G loss: 0.499885] time: 0:51:11.123169\n",
      "0.9513281\n",
      "[Epoch 34/50] [Batch 89/300] [D loss: 0.752347] [G loss: 0.476429] time: 0:51:11.412233\n",
      "0.9232285\n",
      "[Epoch 34/50] [Batch 90/300] [D loss: 0.752330] [G loss: 0.494046] time: 0:51:11.709593\n",
      "0.89919835\n",
      "[Epoch 34/50] [Batch 91/300] [D loss: 0.752338] [G loss: 0.484401] time: 0:51:12.017087\n",
      "0.98373055\n",
      "[Epoch 34/50] [Batch 92/300] [D loss: 0.752333] [G loss: 0.499441] time: 0:51:12.321263\n",
      "0.93887264\n",
      "[Epoch 34/50] [Batch 93/300] [D loss: 0.752337] [G loss: 0.475622] time: 0:51:12.613641\n",
      "0.92602366\n",
      "[Epoch 34/50] [Batch 94/300] [D loss: 0.752344] [G loss: 0.473403] time: 0:51:12.911931\n",
      "0.9607579\n",
      "[Epoch 34/50] [Batch 95/300] [D loss: 0.752348] [G loss: 0.473636] time: 0:51:13.188305\n",
      "0.9250546\n",
      "[Epoch 34/50] [Batch 96/300] [D loss: 0.752359] [G loss: 0.483646] time: 0:51:13.490254\n",
      "0.93014604\n",
      "[Epoch 34/50] [Batch 97/300] [D loss: 0.752356] [G loss: 0.503980] time: 0:51:13.781979\n",
      "0.9182081\n",
      "[Epoch 34/50] [Batch 98/300] [D loss: 0.752357] [G loss: 0.485762] time: 0:51:14.050359\n",
      "0.9099002\n",
      "[Epoch 34/50] [Batch 99/300] [D loss: 0.752342] [G loss: 0.484160] time: 0:51:14.333134\n",
      "0.9082752\n",
      "[Epoch 34/50] [Batch 100/300] [D loss: 0.752333] [G loss: 0.494677] time: 0:51:14.626067\n",
      "0.8995633\n",
      "[Epoch 34/50] [Batch 101/300] [D loss: 0.752361] [G loss: 0.495093] time: 0:51:14.911403\n",
      "0.9479208\n",
      "[Epoch 34/50] [Batch 102/300] [D loss: 0.752350] [G loss: 0.474431] time: 0:51:15.199949\n",
      "0.90539545\n",
      "[Epoch 34/50] [Batch 103/300] [D loss: 0.752346] [G loss: 0.486166] time: 0:51:15.492287\n",
      "0.93267673\n",
      "[Epoch 34/50] [Batch 104/300] [D loss: 0.752330] [G loss: 0.481724] time: 0:51:15.795437\n",
      "0.93166023\n",
      "[Epoch 34/50] [Batch 105/300] [D loss: 0.752351] [G loss: 0.502368] time: 0:51:16.079393\n",
      "0.93509704\n",
      "[Epoch 34/50] [Batch 106/300] [D loss: 0.752355] [G loss: 0.482828] time: 0:51:16.392577\n",
      "0.87617135\n",
      "[Epoch 34/50] [Batch 107/300] [D loss: 0.752333] [G loss: 0.490523] time: 0:51:16.685519\n",
      "0.9298608\n",
      "[Epoch 34/50] [Batch 108/300] [D loss: 0.752346] [G loss: 0.500729] time: 0:51:16.991500\n",
      "0.9063172\n",
      "[Epoch 34/50] [Batch 109/300] [D loss: 0.752355] [G loss: 0.480259] time: 0:51:17.295798\n",
      "0.9753203\n",
      "[Epoch 34/50] [Batch 110/300] [D loss: 0.752336] [G loss: 0.484639] time: 0:51:17.592084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9319473\n",
      "[Epoch 34/50] [Batch 111/300] [D loss: 0.752350] [G loss: 0.496990] time: 0:51:17.886013\n",
      "0.9160225\n",
      "[Epoch 34/50] [Batch 112/300] [D loss: 0.752345] [G loss: 0.480493] time: 0:51:18.182657\n",
      "0.9483419\n",
      "[Epoch 34/50] [Batch 113/300] [D loss: 0.752327] [G loss: 0.486753] time: 0:51:18.484916\n",
      "0.9158103\n",
      "[Epoch 34/50] [Batch 114/300] [D loss: 0.752330] [G loss: 0.473634] time: 0:51:18.788053\n",
      "0.94211555\n",
      "[Epoch 34/50] [Batch 115/300] [D loss: 0.752361] [G loss: 0.473934] time: 0:51:19.072234\n",
      "0.90943736\n",
      "[Epoch 34/50] [Batch 116/300] [D loss: 0.752335] [G loss: 0.494337] time: 0:51:19.346401\n",
      "0.9532254\n",
      "[Epoch 34/50] [Batch 117/300] [D loss: 0.752349] [G loss: 0.511657] time: 0:51:19.653428\n",
      "0.8839998\n",
      "[Epoch 34/50] [Batch 118/300] [D loss: 0.752355] [G loss: 0.476252] time: 0:51:19.931929\n",
      "0.9707357\n",
      "[Epoch 34/50] [Batch 119/300] [D loss: 0.752347] [G loss: 0.493937] time: 0:51:20.229884\n",
      "0.866518\n",
      "[Epoch 34/50] [Batch 120/300] [D loss: 0.752339] [G loss: 0.480686] time: 0:51:20.537247\n",
      "0.94209665\n",
      "[Epoch 34/50] [Batch 121/300] [D loss: 0.752338] [G loss: 0.510768] time: 0:51:20.847815\n",
      "0.91905147\n",
      "[Epoch 34/50] [Batch 122/300] [D loss: 0.752333] [G loss: 0.490301] time: 0:51:21.134837\n",
      "0.9386625\n",
      "[Epoch 34/50] [Batch 123/300] [D loss: 0.752347] [G loss: 0.472306] time: 0:51:21.435449\n",
      "0.9152066\n",
      "[Epoch 34/50] [Batch 124/300] [D loss: 0.752346] [G loss: 0.482338] time: 0:51:21.735557\n",
      "0.9171281\n",
      "[Epoch 34/50] [Batch 125/300] [D loss: 0.752351] [G loss: 0.497869] time: 0:51:22.036492\n",
      "0.94615656\n",
      "[Epoch 34/50] [Batch 126/300] [D loss: 0.752347] [G loss: 0.475693] time: 0:51:22.325268\n",
      "0.90775484\n",
      "[Epoch 34/50] [Batch 127/300] [D loss: 0.752332] [G loss: 0.491649] time: 0:51:22.622585\n",
      "0.8996868\n",
      "[Epoch 34/50] [Batch 128/300] [D loss: 0.752349] [G loss: 0.478583] time: 0:51:22.926043\n",
      "0.93901294\n",
      "[Epoch 34/50] [Batch 129/300] [D loss: 0.752353] [G loss: 0.468850] time: 0:51:23.223056\n",
      "0.8850222\n",
      "[Epoch 34/50] [Batch 130/300] [D loss: 0.752336] [G loss: 0.483797] time: 0:51:23.513314\n",
      "0.89857984\n",
      "[Epoch 34/50] [Batch 131/300] [D loss: 0.752341] [G loss: 0.478347] time: 0:51:23.815822\n",
      "0.90160674\n",
      "[Epoch 34/50] [Batch 132/300] [D loss: 0.752349] [G loss: 0.484004] time: 0:51:24.102312\n",
      "0.8662421\n",
      "[Epoch 34/50] [Batch 133/300] [D loss: 0.752356] [G loss: 0.469917] time: 0:51:24.401852\n",
      "0.93715763\n",
      "[Epoch 34/50] [Batch 134/300] [D loss: 0.752351] [G loss: 0.507591] time: 0:51:24.686260\n",
      "0.917576\n",
      "[Epoch 34/50] [Batch 135/300] [D loss: 0.752355] [G loss: 0.479113] time: 0:51:24.991724\n",
      "0.8790161\n",
      "[Epoch 34/50] [Batch 136/300] [D loss: 0.752342] [G loss: 0.502013] time: 0:51:25.276243\n",
      "0.9469207\n",
      "[Epoch 34/50] [Batch 137/300] [D loss: 0.752333] [G loss: 0.485413] time: 0:51:25.575798\n",
      "0.8857899\n",
      "[Epoch 34/50] [Batch 138/300] [D loss: 0.752332] [G loss: 0.480814] time: 0:51:25.872131\n",
      "0.8994239\n",
      "[Epoch 34/50] [Batch 139/300] [D loss: 0.752331] [G loss: 0.468258] time: 0:51:26.176481\n",
      "0.96776026\n",
      "[Epoch 34/50] [Batch 140/300] [D loss: 0.752351] [G loss: 0.485057] time: 0:51:26.468309\n",
      "0.8930497\n",
      "[Epoch 34/50] [Batch 141/300] [D loss: 0.752331] [G loss: 0.474588] time: 0:51:26.769012\n",
      "0.9402523\n",
      "[Epoch 34/50] [Batch 142/300] [D loss: 0.752318] [G loss: 0.479611] time: 0:51:27.064680\n",
      "0.9711036\n",
      "[Epoch 34/50] [Batch 143/300] [D loss: 0.752345] [G loss: 0.483199] time: 0:51:27.370340\n",
      "0.93758434\n",
      "[Epoch 34/50] [Batch 144/300] [D loss: 0.752332] [G loss: 0.482657] time: 0:51:27.672207\n",
      "0.9553868\n",
      "[Epoch 34/50] [Batch 145/300] [D loss: 0.752347] [G loss: 0.483975] time: 0:51:27.959739\n",
      "0.91553205\n",
      "[Epoch 34/50] [Batch 146/300] [D loss: 0.752351] [G loss: 0.474932] time: 0:51:28.253087\n",
      "0.9057946\n",
      "[Epoch 34/50] [Batch 147/300] [D loss: 0.752330] [G loss: 0.475354] time: 0:51:28.560375\n",
      "0.96871805\n",
      "[Epoch 34/50] [Batch 148/300] [D loss: 0.752371] [G loss: 0.474989] time: 0:51:28.867469\n",
      "0.9078533\n",
      "[Epoch 34/50] [Batch 149/300] [D loss: 0.752329] [G loss: 0.490800] time: 0:51:29.149574\n",
      "0.9035861\n",
      "[Epoch 34/50] [Batch 150/300] [D loss: 0.752340] [G loss: 0.493675] time: 0:51:29.436297\n",
      "0.9279453\n",
      "[Epoch 34/50] [Batch 151/300] [D loss: 0.752337] [G loss: 0.473924] time: 0:51:29.743090\n",
      "0.95271015\n",
      "[Epoch 34/50] [Batch 152/300] [D loss: 0.752343] [G loss: 0.481028] time: 0:51:30.042651\n",
      "0.94556326\n",
      "[Epoch 34/50] [Batch 153/300] [D loss: 0.752347] [G loss: 0.510381] time: 0:51:30.330137\n",
      "0.9091746\n",
      "[Epoch 34/50] [Batch 154/300] [D loss: 0.752344] [G loss: 0.497856] time: 0:51:30.632958\n",
      "0.9379038\n",
      "[Epoch 34/50] [Batch 155/300] [D loss: 0.752331] [G loss: 0.502588] time: 0:51:30.921723\n",
      "0.9254226\n",
      "[Epoch 34/50] [Batch 156/300] [D loss: 0.752354] [G loss: 0.491253] time: 0:51:31.236496\n",
      "0.91493297\n",
      "[Epoch 34/50] [Batch 157/300] [D loss: 0.752331] [G loss: 0.475133] time: 0:51:31.537607\n",
      "0.8847311\n",
      "[Epoch 34/50] [Batch 158/300] [D loss: 0.752373] [G loss: 0.481071] time: 0:51:31.837575\n",
      "0.8790439\n",
      "[Epoch 34/50] [Batch 159/300] [D loss: 0.752336] [G loss: 0.481191] time: 0:51:32.125234\n",
      "0.91935354\n",
      "[Epoch 34/50] [Batch 160/300] [D loss: 0.752339] [G loss: 0.475026] time: 0:51:32.438216\n",
      "0.9251074\n",
      "[Epoch 34/50] [Batch 161/300] [D loss: 0.752337] [G loss: 0.470817] time: 0:51:32.741252\n",
      "0.95441127\n",
      "[Epoch 34/50] [Batch 162/300] [D loss: 0.752325] [G loss: 0.488142] time: 0:51:33.034741\n",
      "0.93824214\n",
      "[Epoch 34/50] [Batch 163/300] [D loss: 0.752339] [G loss: 0.472340] time: 0:51:33.330648\n",
      "0.9158804\n",
      "[Epoch 34/50] [Batch 164/300] [D loss: 0.752348] [G loss: 0.476852] time: 0:51:33.627993\n",
      "0.9334975\n",
      "[Epoch 34/50] [Batch 165/300] [D loss: 0.752348] [G loss: 0.487448] time: 0:51:33.923428\n",
      "0.90446585\n",
      "[Epoch 34/50] [Batch 166/300] [D loss: 0.752318] [G loss: 0.481304] time: 0:51:34.212788\n",
      "0.9215744\n",
      "[Epoch 34/50] [Batch 167/300] [D loss: 0.752324] [G loss: 0.485548] time: 0:51:34.489022\n",
      "0.9456036\n",
      "[Epoch 34/50] [Batch 168/300] [D loss: 0.752349] [G loss: 0.497841] time: 0:51:34.788759\n",
      "0.90833396\n",
      "[Epoch 34/50] [Batch 169/300] [D loss: 0.752342] [G loss: 0.500322] time: 0:51:35.092319\n",
      "0.9817627\n",
      "[Epoch 34/50] [Batch 170/300] [D loss: 0.752349] [G loss: 0.491045] time: 0:51:35.389366\n",
      "0.90835696\n",
      "[Epoch 34/50] [Batch 171/300] [D loss: 0.752327] [G loss: 0.503598] time: 0:51:35.691766\n",
      "0.94193864\n",
      "[Epoch 34/50] [Batch 172/300] [D loss: 0.752344] [G loss: 0.485348] time: 0:51:35.985900\n",
      "0.93297213\n",
      "[Epoch 34/50] [Batch 173/300] [D loss: 0.752357] [G loss: 0.490613] time: 0:51:36.281826\n",
      "0.9332072\n",
      "[Epoch 34/50] [Batch 174/300] [D loss: 0.752338] [G loss: 0.474482] time: 0:51:36.576169\n",
      "0.9212765\n",
      "[Epoch 34/50] [Batch 175/300] [D loss: 0.752339] [G loss: 0.476533] time: 0:51:36.885225\n",
      "0.9075611\n",
      "[Epoch 34/50] [Batch 176/300] [D loss: 0.752344] [G loss: 0.481982] time: 0:51:37.183431\n",
      "0.94504994\n",
      "[Epoch 34/50] [Batch 177/300] [D loss: 0.752339] [G loss: 0.486163] time: 0:51:37.456735\n",
      "0.93040293\n",
      "[Epoch 34/50] [Batch 178/300] [D loss: 0.752355] [G loss: 0.485885] time: 0:51:37.767144\n",
      "0.9058767\n",
      "[Epoch 34/50] [Batch 179/300] [D loss: 0.752339] [G loss: 0.516257] time: 0:51:38.063024\n",
      "0.93912816\n",
      "[Epoch 34/50] [Batch 180/300] [D loss: 0.752342] [G loss: 0.467883] time: 0:51:38.372291\n",
      "0.928922\n",
      "[Epoch 34/50] [Batch 181/300] [D loss: 0.752332] [G loss: 0.498840] time: 0:51:38.689603\n",
      "0.97099227\n",
      "[Epoch 34/50] [Batch 182/300] [D loss: 0.752340] [G loss: 0.491484] time: 0:51:39.003469\n",
      "0.9277876\n",
      "[Epoch 34/50] [Batch 183/300] [D loss: 0.752338] [G loss: 0.471843] time: 0:51:39.299305\n",
      "0.9761619\n",
      "[Epoch 34/50] [Batch 184/300] [D loss: 0.752340] [G loss: 0.476048] time: 0:51:39.612060\n",
      "0.9172349\n",
      "[Epoch 34/50] [Batch 185/300] [D loss: 0.752344] [G loss: 0.472074] time: 0:51:39.912973\n",
      "0.9161713\n",
      "[Epoch 34/50] [Batch 186/300] [D loss: 0.752322] [G loss: 0.475225] time: 0:51:40.197409\n",
      "0.92784756\n",
      "[Epoch 34/50] [Batch 187/300] [D loss: 0.752332] [G loss: 0.484449] time: 0:51:40.497198\n",
      "0.94444317\n",
      "[Epoch 34/50] [Batch 188/300] [D loss: 0.752342] [G loss: 0.475762] time: 0:51:40.792037\n",
      "0.9224162\n",
      "[Epoch 34/50] [Batch 189/300] [D loss: 0.752343] [G loss: 0.476110] time: 0:51:41.090209\n",
      "0.8742721\n",
      "[Epoch 34/50] [Batch 190/300] [D loss: 0.752336] [G loss: 0.484947] time: 0:51:41.380929\n",
      "0.9818906\n",
      "[Epoch 34/50] [Batch 191/300] [D loss: 0.752338] [G loss: 0.493030] time: 0:51:41.687703\n",
      "0.9408424\n",
      "[Epoch 34/50] [Batch 192/300] [D loss: 0.752344] [G loss: 0.491263] time: 0:51:41.986693\n",
      "0.91907305\n",
      "[Epoch 34/50] [Batch 193/300] [D loss: 0.752330] [G loss: 0.489135] time: 0:51:42.258335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853689\n",
      "[Epoch 34/50] [Batch 194/300] [D loss: 0.752340] [G loss: 0.506431] time: 0:51:42.547638\n",
      "0.9590227\n",
      "[Epoch 34/50] [Batch 195/300] [D loss: 0.752327] [G loss: 0.489869] time: 0:51:42.844411\n",
      "0.8875471\n",
      "[Epoch 34/50] [Batch 196/300] [D loss: 0.752331] [G loss: 0.479174] time: 0:51:43.148158\n",
      "0.8861492\n",
      "[Epoch 34/50] [Batch 197/300] [D loss: 0.752334] [G loss: 0.499019] time: 0:51:43.443775\n",
      "0.91367227\n",
      "[Epoch 34/50] [Batch 198/300] [D loss: 0.752331] [G loss: 0.476042] time: 0:51:43.736594\n",
      "0.9083263\n",
      "[Epoch 34/50] [Batch 199/300] [D loss: 0.752332] [G loss: 0.477709] time: 0:51:44.039598\n",
      "0.8961043\n",
      "[Epoch 34/50] [Batch 200/300] [D loss: 0.752328] [G loss: 0.495513] time: 0:51:44.335017\n",
      "0.87699014\n",
      "[Epoch 34/50] [Batch 201/300] [D loss: 0.752333] [G loss: 0.475742] time: 0:51:44.641454\n",
      "0.94301814\n",
      "[Epoch 34/50] [Batch 202/300] [D loss: 0.752337] [G loss: 0.492377] time: 0:51:44.925378\n",
      "0.916703\n",
      "[Epoch 34/50] [Batch 203/300] [D loss: 0.752365] [G loss: 0.485845] time: 0:51:45.237541\n",
      "0.890637\n",
      "[Epoch 34/50] [Batch 204/300] [D loss: 0.752329] [G loss: 0.482608] time: 0:51:45.531171\n",
      "0.9084049\n",
      "[Epoch 34/50] [Batch 205/300] [D loss: 0.752335] [G loss: 0.498097] time: 0:51:45.823829\n",
      "0.9470897\n",
      "[Epoch 34/50] [Batch 206/300] [D loss: 0.752334] [G loss: 0.474502] time: 0:51:46.122003\n",
      "0.91409606\n",
      "[Epoch 34/50] [Batch 207/300] [D loss: 0.752355] [G loss: 0.478286] time: 0:51:46.405559\n",
      "0.9333475\n",
      "[Epoch 34/50] [Batch 208/300] [D loss: 0.752345] [G loss: 0.499661] time: 0:51:46.701010\n",
      "0.9037613\n",
      "[Epoch 34/50] [Batch 209/300] [D loss: 0.752336] [G loss: 0.474257] time: 0:51:47.000395\n",
      "0.93789417\n",
      "[Epoch 34/50] [Batch 210/300] [D loss: 0.752326] [G loss: 0.486108] time: 0:51:47.286322\n",
      "0.9691069\n",
      "[Epoch 34/50] [Batch 211/300] [D loss: 0.752344] [G loss: 0.476179] time: 0:51:47.594211\n",
      "0.94742554\n",
      "[Epoch 34/50] [Batch 212/300] [D loss: 0.752340] [G loss: 0.487255] time: 0:51:47.899051\n",
      "0.92538637\n",
      "[Epoch 34/50] [Batch 213/300] [D loss: 0.752340] [G loss: 0.479148] time: 0:51:48.203993\n",
      "0.94469815\n",
      "[Epoch 34/50] [Batch 214/300] [D loss: 0.752337] [G loss: 0.473511] time: 0:51:48.505477\n",
      "0.90684074\n",
      "[Epoch 34/50] [Batch 215/300] [D loss: 0.752339] [G loss: 0.472088] time: 0:51:48.796959\n",
      "0.91028976\n",
      "[Epoch 34/50] [Batch 216/300] [D loss: 0.752340] [G loss: 0.480870] time: 0:51:49.091969\n",
      "0.9309589\n",
      "[Epoch 34/50] [Batch 217/300] [D loss: 0.752335] [G loss: 0.480823] time: 0:51:49.392304\n",
      "0.93068266\n",
      "[Epoch 34/50] [Batch 218/300] [D loss: 0.752334] [G loss: 0.490145] time: 0:51:49.682186\n",
      "0.9177048\n",
      "[Epoch 34/50] [Batch 219/300] [D loss: 0.752348] [G loss: 0.474878] time: 0:51:49.974412\n",
      "0.9071264\n",
      "[Epoch 34/50] [Batch 220/300] [D loss: 0.752335] [G loss: 0.487645] time: 0:51:50.258301\n",
      "0.8921442\n",
      "[Epoch 34/50] [Batch 221/300] [D loss: 0.752355] [G loss: 0.475286] time: 0:51:50.555246\n",
      "0.92224693\n",
      "[Epoch 34/50] [Batch 222/300] [D loss: 0.752337] [G loss: 0.491738] time: 0:51:50.857018\n",
      "0.9532774\n",
      "[Epoch 34/50] [Batch 223/300] [D loss: 0.752354] [G loss: 0.491761] time: 0:51:51.149524\n",
      "0.91352826\n",
      "[Epoch 34/50] [Batch 224/300] [D loss: 0.752338] [G loss: 0.484137] time: 0:51:51.451299\n",
      "0.95038843\n",
      "[Epoch 34/50] [Batch 225/300] [D loss: 0.752336] [G loss: 0.475617] time: 0:51:51.767102\n",
      "0.9124941\n",
      "[Epoch 34/50] [Batch 226/300] [D loss: 0.752340] [G loss: 0.475543] time: 0:51:52.056166\n",
      "0.9101269\n",
      "[Epoch 34/50] [Batch 227/300] [D loss: 0.752337] [G loss: 0.509640] time: 0:51:52.339697\n",
      "0.97127694\n",
      "[Epoch 34/50] [Batch 228/300] [D loss: 0.752337] [G loss: 0.487110] time: 0:51:52.639359\n",
      "0.9533916\n",
      "[Epoch 34/50] [Batch 229/300] [D loss: 0.752339] [G loss: 0.490671] time: 0:51:52.933916\n",
      "0.9194247\n",
      "[Epoch 34/50] [Batch 230/300] [D loss: 0.752329] [G loss: 0.503763] time: 0:51:53.226769\n",
      "0.91090673\n",
      "[Epoch 34/50] [Batch 231/300] [D loss: 0.752346] [G loss: 0.481007] time: 0:51:53.527991\n",
      "0.905721\n",
      "[Epoch 34/50] [Batch 232/300] [D loss: 0.752359] [G loss: 0.494615] time: 0:51:53.807827\n",
      "0.9030326\n",
      "[Epoch 34/50] [Batch 233/300] [D loss: 0.752326] [G loss: 0.499561] time: 0:51:54.097194\n",
      "0.8870383\n",
      "[Epoch 34/50] [Batch 234/300] [D loss: 0.752334] [G loss: 0.479785] time: 0:51:54.386589\n",
      "0.9615478\n",
      "[Epoch 34/50] [Batch 235/300] [D loss: 0.752342] [G loss: 0.476106] time: 0:51:54.680997\n",
      "0.88354284\n",
      "[Epoch 34/50] [Batch 236/300] [D loss: 0.752312] [G loss: 0.499470] time: 0:51:54.961085\n",
      "0.93297917\n",
      "[Epoch 34/50] [Batch 237/300] [D loss: 0.752351] [G loss: 0.477178] time: 0:51:55.260541\n",
      "0.8878456\n",
      "[Epoch 34/50] [Batch 238/300] [D loss: 0.752340] [G loss: 0.498979] time: 0:51:55.563842\n",
      "0.9417884\n",
      "[Epoch 34/50] [Batch 239/300] [D loss: 0.752339] [G loss: 0.484703] time: 0:51:55.855541\n",
      "0.9567094\n",
      "[Epoch 34/50] [Batch 240/300] [D loss: 0.752356] [G loss: 0.480526] time: 0:51:56.127838\n",
      "0.88154\n",
      "[Epoch 34/50] [Batch 241/300] [D loss: 0.752331] [G loss: 0.499599] time: 0:51:56.400763\n",
      "0.8884894\n",
      "[Epoch 34/50] [Batch 242/300] [D loss: 0.752345] [G loss: 0.492481] time: 0:51:56.681931\n",
      "0.9223695\n",
      "[Epoch 34/50] [Batch 243/300] [D loss: 0.752332] [G loss: 0.485018] time: 0:51:56.982018\n",
      "0.9319814\n",
      "[Epoch 34/50] [Batch 244/300] [D loss: 0.752340] [G loss: 0.489988] time: 0:51:57.284309\n",
      "0.93024594\n",
      "[Epoch 34/50] [Batch 245/300] [D loss: 0.752345] [G loss: 0.488485] time: 0:51:57.589666\n",
      "0.92572516\n",
      "[Epoch 34/50] [Batch 246/300] [D loss: 0.752358] [G loss: 0.483440] time: 0:51:57.894934\n",
      "0.94580156\n",
      "[Epoch 34/50] [Batch 247/300] [D loss: 0.752346] [G loss: 0.485082] time: 0:51:58.187343\n",
      "0.89894587\n",
      "[Epoch 34/50] [Batch 248/300] [D loss: 0.752330] [G loss: 0.469394] time: 0:51:58.488269\n",
      "0.9606336\n",
      "[Epoch 34/50] [Batch 249/300] [D loss: 0.752342] [G loss: 0.474644] time: 0:51:58.791092\n",
      "0.90632445\n",
      "[Epoch 34/50] [Batch 250/300] [D loss: 0.752323] [G loss: 0.492209] time: 0:51:59.080281\n",
      "0.88732415\n",
      "[Epoch 34/50] [Batch 251/300] [D loss: 0.752330] [G loss: 0.495173] time: 0:51:59.381153\n",
      "0.9287546\n",
      "[Epoch 34/50] [Batch 252/300] [D loss: 0.752341] [G loss: 0.500986] time: 0:51:59.687150\n",
      "0.9102452\n",
      "[Epoch 34/50] [Batch 253/300] [D loss: 0.752337] [G loss: 0.490860] time: 0:51:59.991114\n",
      "0.92190105\n",
      "[Epoch 34/50] [Batch 254/300] [D loss: 0.752349] [G loss: 0.478651] time: 0:52:00.268900\n",
      "0.90624946\n",
      "[Epoch 34/50] [Batch 255/300] [D loss: 0.752356] [G loss: 0.495266] time: 0:52:00.575015\n",
      "0.9282747\n",
      "[Epoch 34/50] [Batch 256/300] [D loss: 0.752334] [G loss: 0.480919] time: 0:52:00.862864\n",
      "0.93847424\n",
      "[Epoch 34/50] [Batch 257/300] [D loss: 0.752343] [G loss: 0.500289] time: 0:52:01.160322\n",
      "0.91585964\n",
      "[Epoch 34/50] [Batch 258/300] [D loss: 0.752334] [G loss: 0.485706] time: 0:52:01.463370\n",
      "0.9567557\n",
      "[Epoch 34/50] [Batch 259/300] [D loss: 0.752343] [G loss: 0.480161] time: 0:52:01.767442\n",
      "0.85267\n",
      "[Epoch 34/50] [Batch 260/300] [D loss: 0.752326] [G loss: 0.491344] time: 0:52:02.066509\n",
      "0.93135643\n",
      "[Epoch 34/50] [Batch 261/300] [D loss: 0.752344] [G loss: 0.519714] time: 0:52:02.376251\n",
      "0.89239866\n",
      "[Epoch 34/50] [Batch 262/300] [D loss: 0.752340] [G loss: 0.501190] time: 0:52:02.662730\n",
      "0.9464472\n",
      "[Epoch 34/50] [Batch 263/300] [D loss: 0.752337] [G loss: 0.500836] time: 0:52:02.954752\n",
      "0.953057\n",
      "[Epoch 34/50] [Batch 264/300] [D loss: 0.752319] [G loss: 0.496567] time: 0:52:03.263793\n",
      "0.90237826\n",
      "[Epoch 34/50] [Batch 265/300] [D loss: 0.752318] [G loss: 0.499595] time: 0:52:03.547394\n",
      "0.9116692\n",
      "[Epoch 34/50] [Batch 266/300] [D loss: 0.752334] [G loss: 0.520349] time: 0:52:03.853852\n",
      "0.97626805\n",
      "[Epoch 34/50] [Batch 267/300] [D loss: 0.752346] [G loss: 0.493497] time: 0:52:04.158386\n",
      "0.90740067\n",
      "[Epoch 34/50] [Batch 268/300] [D loss: 0.752329] [G loss: 0.488076] time: 0:52:04.466148\n",
      "0.9167382\n",
      "[Epoch 34/50] [Batch 269/300] [D loss: 0.752337] [G loss: 0.476721] time: 0:52:04.757421\n",
      "0.9569895\n",
      "[Epoch 34/50] [Batch 270/300] [D loss: 0.752337] [G loss: 0.501692] time: 0:52:05.066097\n",
      "0.9215278\n",
      "[Epoch 34/50] [Batch 271/300] [D loss: 0.752339] [G loss: 0.500893] time: 0:52:05.390117\n",
      "0.8898589\n",
      "[Epoch 34/50] [Batch 272/300] [D loss: 0.752347] [G loss: 0.491739] time: 0:52:05.685706\n",
      "0.90460044\n",
      "[Epoch 34/50] [Batch 273/300] [D loss: 0.752339] [G loss: 0.497600] time: 0:52:05.959973\n",
      "0.9083681\n",
      "[Epoch 34/50] [Batch 274/300] [D loss: 0.752333] [G loss: 0.484370] time: 0:52:06.263640\n",
      "0.95070904\n",
      "[Epoch 34/50] [Batch 275/300] [D loss: 0.752326] [G loss: 0.496035] time: 0:52:06.556958\n",
      "0.9254947\n",
      "[Epoch 34/50] [Batch 276/300] [D loss: 0.752334] [G loss: 0.480793] time: 0:52:06.843498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88883924\n",
      "[Epoch 34/50] [Batch 277/300] [D loss: 0.752324] [G loss: 0.484124] time: 0:52:07.144188\n",
      "0.9358571\n",
      "[Epoch 34/50] [Batch 278/300] [D loss: 0.752353] [G loss: 0.470494] time: 0:52:07.436019\n",
      "0.94517136\n",
      "[Epoch 34/50] [Batch 279/300] [D loss: 0.752340] [G loss: 0.480820] time: 0:52:07.740659\n",
      "0.9662326\n",
      "[Epoch 34/50] [Batch 280/300] [D loss: 0.752337] [G loss: 0.479169] time: 0:52:08.055935\n",
      "0.9530473\n",
      "[Epoch 34/50] [Batch 281/300] [D loss: 0.752334] [G loss: 0.479847] time: 0:52:08.354675\n",
      "0.92996436\n",
      "[Epoch 34/50] [Batch 282/300] [D loss: 0.752334] [G loss: 0.490877] time: 0:52:08.635723\n",
      "0.9156372\n",
      "[Epoch 34/50] [Batch 283/300] [D loss: 0.752340] [G loss: 0.492329] time: 0:52:08.905756\n",
      "0.9312558\n",
      "[Epoch 34/50] [Batch 284/300] [D loss: 0.752328] [G loss: 0.478900] time: 0:52:09.202547\n",
      "0.93890923\n",
      "[Epoch 34/50] [Batch 285/300] [D loss: 0.752353] [G loss: 0.481278] time: 0:52:09.507859\n",
      "0.92549914\n",
      "[Epoch 34/50] [Batch 286/300] [D loss: 0.752319] [G loss: 0.474477] time: 0:52:09.793096\n",
      "0.9532718\n",
      "[Epoch 34/50] [Batch 287/300] [D loss: 0.752334] [G loss: 0.486108] time: 0:52:10.097847\n",
      "0.92478895\n",
      "[Epoch 34/50] [Batch 288/300] [D loss: 0.752337] [G loss: 0.488626] time: 0:52:10.394784\n",
      "0.9464037\n",
      "[Epoch 34/50] [Batch 289/300] [D loss: 0.752336] [G loss: 0.485719] time: 0:52:10.693321\n",
      "0.9301763\n",
      "[Epoch 34/50] [Batch 290/300] [D loss: 0.752341] [G loss: 0.480698] time: 0:52:10.991048\n",
      "0.9490549\n",
      "[Epoch 34/50] [Batch 291/300] [D loss: 0.752327] [G loss: 0.476224] time: 0:52:11.292558\n",
      "0.90377396\n",
      "[Epoch 34/50] [Batch 292/300] [D loss: 0.752332] [G loss: 0.501754] time: 0:52:11.589701\n",
      "0.8846612\n",
      "[Epoch 34/50] [Batch 293/300] [D loss: 0.752331] [G loss: 0.480363] time: 0:52:11.895516\n",
      "0.91088\n",
      "[Epoch 34/50] [Batch 294/300] [D loss: 0.752325] [G loss: 0.498690] time: 0:52:12.189690\n",
      "0.8975017\n",
      "[Epoch 34/50] [Batch 295/300] [D loss: 0.752331] [G loss: 0.501120] time: 0:52:12.485831\n",
      "0.9285992\n",
      "[Epoch 34/50] [Batch 296/300] [D loss: 0.752338] [G loss: 0.491447] time: 0:52:12.764629\n",
      "0.90366906\n",
      "[Epoch 34/50] [Batch 297/300] [D loss: 0.752332] [G loss: 0.504338] time: 0:52:13.067420\n",
      "0.9557373\n",
      "[Epoch 34/50] [Batch 298/300] [D loss: 0.752338] [G loss: 0.486394] time: 0:52:13.368484\n",
      "0.9289183\n",
      "[Epoch 34/50] [Batch 299/300] [D loss: 0.752328] [G loss: 0.515217] time: 0:52:13.679460\n",
      "0.9303983\n",
      "[Epoch 35/50] [Batch 0/300] [D loss: 0.752325] [G loss: 0.492967] time: 0:52:13.946170\n",
      "0.8838761\n",
      "[Epoch 35/50] [Batch 1/300] [D loss: 0.752331] [G loss: 0.522951] time: 0:52:14.241800\n",
      "0.93472916\n",
      "[Epoch 35/50] [Batch 2/300] [D loss: 0.752339] [G loss: 0.468105] time: 0:52:14.546732\n",
      "0.8883254\n",
      "[Epoch 35/50] [Batch 3/300] [D loss: 0.752329] [G loss: 0.502681] time: 0:52:14.848119\n",
      "0.93110824\n",
      "[Epoch 35/50] [Batch 4/300] [D loss: 0.752350] [G loss: 0.491940] time: 0:52:15.140559\n",
      "0.9165804\n",
      "[Epoch 35/50] [Batch 5/300] [D loss: 0.752343] [G loss: 0.478972] time: 0:52:15.438421\n",
      "0.93400717\n",
      "[Epoch 35/50] [Batch 6/300] [D loss: 0.752319] [G loss: 0.471913] time: 0:52:15.743494\n",
      "0.91676635\n",
      "[Epoch 35/50] [Batch 7/300] [D loss: 0.752322] [G loss: 0.495512] time: 0:52:16.038246\n",
      "0.9111893\n",
      "[Epoch 35/50] [Batch 8/300] [D loss: 0.752357] [G loss: 0.484412] time: 0:52:16.340602\n",
      "0.9276776\n",
      "[Epoch 35/50] [Batch 9/300] [D loss: 0.752347] [G loss: 0.483350] time: 0:52:16.613220\n",
      "0.9355071\n",
      "[Epoch 35/50] [Batch 10/300] [D loss: 0.752325] [G loss: 0.490620] time: 0:52:16.913412\n",
      "0.9240451\n",
      "[Epoch 35/50] [Batch 11/300] [D loss: 0.752344] [G loss: 0.477855] time: 0:52:17.213158\n",
      "0.89880747\n",
      "[Epoch 35/50] [Batch 12/300] [D loss: 0.752346] [G loss: 0.493300] time: 0:52:17.512498\n",
      "0.926919\n",
      "[Epoch 35/50] [Batch 13/300] [D loss: 0.752332] [G loss: 0.512783] time: 0:52:17.803602\n",
      "0.91430527\n",
      "[Epoch 35/50] [Batch 14/300] [D loss: 0.752334] [G loss: 0.498254] time: 0:52:18.101916\n",
      "0.95247287\n",
      "[Epoch 35/50] [Batch 15/300] [D loss: 0.752320] [G loss: 0.484765] time: 0:52:18.414927\n",
      "0.9301388\n",
      "[Epoch 35/50] [Batch 16/300] [D loss: 0.752351] [G loss: 0.504517] time: 0:52:18.705767\n",
      "0.89862394\n",
      "[Epoch 35/50] [Batch 17/300] [D loss: 0.752336] [G loss: 0.495735] time: 0:52:19.003084\n",
      "0.9006493\n",
      "[Epoch 35/50] [Batch 18/300] [D loss: 0.752332] [G loss: 0.486091] time: 0:52:19.287911\n",
      "0.9374327\n",
      "[Epoch 35/50] [Batch 19/300] [D loss: 0.752328] [G loss: 0.476412] time: 0:52:19.602821\n",
      "0.9078233\n",
      "[Epoch 35/50] [Batch 20/300] [D loss: 0.752332] [G loss: 0.512906] time: 0:52:19.889331\n",
      "0.9091688\n",
      "[Epoch 35/50] [Batch 21/300] [D loss: 0.752326] [G loss: 0.480035] time: 0:52:20.170856\n",
      "0.9225831\n",
      "[Epoch 35/50] [Batch 22/300] [D loss: 0.752332] [G loss: 0.485714] time: 0:52:20.460331\n",
      "0.94598943\n",
      "[Epoch 35/50] [Batch 23/300] [D loss: 0.752333] [G loss: 0.482974] time: 0:52:20.756003\n",
      "0.9357028\n",
      "[Epoch 35/50] [Batch 24/300] [D loss: 0.752340] [G loss: 0.486814] time: 0:52:21.062022\n",
      "0.9333067\n",
      "[Epoch 35/50] [Batch 25/300] [D loss: 0.752322] [G loss: 0.487107] time: 0:52:21.344027\n",
      "0.9289711\n",
      "[Epoch 35/50] [Batch 26/300] [D loss: 0.752326] [G loss: 0.489932] time: 0:52:21.647817\n",
      "0.9233701\n",
      "[Epoch 35/50] [Batch 27/300] [D loss: 0.752331] [G loss: 0.482733] time: 0:52:21.944752\n",
      "0.94201183\n",
      "[Epoch 35/50] [Batch 28/300] [D loss: 0.752363] [G loss: 0.481091] time: 0:52:22.248268\n",
      "0.9339513\n",
      "[Epoch 35/50] [Batch 29/300] [D loss: 0.752339] [G loss: 0.479841] time: 0:52:22.547707\n",
      "0.9168897\n",
      "[Epoch 35/50] [Batch 30/300] [D loss: 0.752324] [G loss: 0.474229] time: 0:52:22.848095\n",
      "0.9246812\n",
      "[Epoch 35/50] [Batch 31/300] [D loss: 0.752347] [G loss: 0.491641] time: 0:52:23.140474\n",
      "0.935957\n",
      "[Epoch 35/50] [Batch 32/300] [D loss: 0.752331] [G loss: 0.498259] time: 0:52:23.443991\n",
      "0.913764\n",
      "[Epoch 35/50] [Batch 33/300] [D loss: 0.752338] [G loss: 0.506626] time: 0:52:23.731766\n",
      "0.9565957\n",
      "[Epoch 35/50] [Batch 35/300] [D loss: 0.752334] [G loss: 0.527513] time: 0:52:24.056787\n",
      "0.9053872\n",
      "[Epoch 35/50] [Batch 36/300] [D loss: 0.752342] [G loss: 0.480742] time: 0:52:24.358288\n",
      "0.91618055\n",
      "[Epoch 35/50] [Batch 37/300] [D loss: 0.752329] [G loss: 0.470147] time: 0:52:24.671789\n",
      "0.9160518\n",
      "[Epoch 35/50] [Batch 38/300] [D loss: 0.752328] [G loss: 0.478981] time: 0:52:24.967283\n",
      "0.9773712\n",
      "[Epoch 35/50] [Batch 39/300] [D loss: 0.752348] [G loss: 0.486560] time: 0:52:25.257917\n",
      "0.88066584\n",
      "[Epoch 35/50] [Batch 40/300] [D loss: 0.752343] [G loss: 0.490481] time: 0:52:25.557488\n",
      "0.95357937\n",
      "[Epoch 35/50] [Batch 41/300] [D loss: 0.752332] [G loss: 0.470953] time: 0:52:25.871846\n",
      "0.95320725\n",
      "[Epoch 35/50] [Batch 42/300] [D loss: 0.752336] [G loss: 0.475336] time: 0:52:26.172978\n",
      "0.91058904\n",
      "[Epoch 35/50] [Batch 43/300] [D loss: 0.752329] [G loss: 0.480206] time: 0:52:26.472265\n",
      "0.926132\n",
      "[Epoch 35/50] [Batch 44/300] [D loss: 0.752339] [G loss: 0.492568] time: 0:52:26.774597\n",
      "0.9773384\n",
      "[Epoch 35/50] [Batch 45/300] [D loss: 0.752326] [G loss: 0.489447] time: 0:52:27.075791\n",
      "0.9468902\n",
      "[Epoch 35/50] [Batch 46/300] [D loss: 0.752337] [G loss: 0.478338] time: 0:52:27.380738\n",
      "0.92157173\n",
      "[Epoch 35/50] [Batch 47/300] [D loss: 0.752338] [G loss: 0.517496] time: 0:52:27.688052\n",
      "0.9384758\n",
      "[Epoch 35/50] [Batch 48/300] [D loss: 0.752328] [G loss: 0.495402] time: 0:52:27.995072\n",
      "0.93396765\n",
      "[Epoch 35/50] [Batch 49/300] [D loss: 0.752330] [G loss: 0.492878] time: 0:52:28.297023\n",
      "0.9051333\n",
      "[Epoch 35/50] [Batch 50/300] [D loss: 0.752342] [G loss: 0.470367] time: 0:52:28.614620\n",
      "0.9394167\n",
      "[Epoch 35/50] [Batch 51/300] [D loss: 0.752333] [G loss: 0.477213] time: 0:52:28.917673\n",
      "0.91427404\n",
      "[Epoch 35/50] [Batch 52/300] [D loss: 0.752318] [G loss: 0.474014] time: 0:52:29.228080\n",
      "0.89955854\n",
      "[Epoch 35/50] [Batch 53/300] [D loss: 0.752341] [G loss: 0.480382] time: 0:52:29.550022\n",
      "0.9530447\n",
      "[Epoch 35/50] [Batch 54/300] [D loss: 0.752337] [G loss: 0.472246] time: 0:52:29.853179\n",
      "0.9446626\n",
      "[Epoch 35/50] [Batch 55/300] [D loss: 0.752328] [G loss: 0.478290] time: 0:52:30.150118\n",
      "0.90108204\n",
      "[Epoch 35/50] [Batch 56/300] [D loss: 0.752328] [G loss: 0.473138] time: 0:52:30.451618\n",
      "0.93220764\n",
      "[Epoch 35/50] [Batch 57/300] [D loss: 0.752342] [G loss: 0.482769] time: 0:52:30.750241\n",
      "0.9291161\n",
      "[Epoch 35/50] [Batch 58/300] [D loss: 0.752336] [G loss: 0.481049] time: 0:52:31.060103\n",
      "0.8914736\n",
      "[Epoch 35/50] [Batch 59/300] [D loss: 0.752329] [G loss: 0.487584] time: 0:52:31.359781\n",
      "0.96000737\n",
      "[Epoch 35/50] [Batch 60/300] [D loss: 0.752335] [G loss: 0.491716] time: 0:52:31.658292\n",
      "0.905485\n",
      "[Epoch 35/50] [Batch 61/300] [D loss: 0.752326] [G loss: 0.483897] time: 0:52:31.954936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95537466\n",
      "[Epoch 35/50] [Batch 62/300] [D loss: 0.752322] [G loss: 0.471844] time: 0:52:32.243409\n",
      "0.93720555\n",
      "[Epoch 35/50] [Batch 63/300] [D loss: 0.752323] [G loss: 0.486560] time: 0:52:32.534200\n",
      "0.9834215\n",
      "[Epoch 35/50] [Batch 64/300] [D loss: 0.752333] [G loss: 0.497621] time: 0:52:32.826850\n",
      "0.9355981\n",
      "[Epoch 35/50] [Batch 65/300] [D loss: 0.752346] [G loss: 0.477508] time: 0:52:33.126342\n",
      "0.9561854\n",
      "[Epoch 35/50] [Batch 66/300] [D loss: 0.752318] [G loss: 0.474876] time: 0:52:33.442505\n",
      "0.9307313\n",
      "[Epoch 35/50] [Batch 67/300] [D loss: 0.752337] [G loss: 0.489711] time: 0:52:33.733970\n",
      "0.913677\n",
      "[Epoch 35/50] [Batch 68/300] [D loss: 0.752340] [G loss: 0.475368] time: 0:52:34.031888\n",
      "0.87818104\n",
      "[Epoch 35/50] [Batch 69/300] [D loss: 0.752334] [G loss: 0.486674] time: 0:52:34.340052\n",
      "0.9288228\n",
      "[Epoch 35/50] [Batch 70/300] [D loss: 0.752337] [G loss: 0.496298] time: 0:52:34.651737\n",
      "0.9102952\n",
      "[Epoch 35/50] [Batch 71/300] [D loss: 0.752334] [G loss: 0.482093] time: 0:52:34.954389\n",
      "0.90676403\n",
      "[Epoch 35/50] [Batch 72/300] [D loss: 0.752328] [G loss: 0.472376] time: 0:52:35.250102\n",
      "0.8886016\n",
      "[Epoch 35/50] [Batch 73/300] [D loss: 0.752327] [G loss: 0.476216] time: 0:52:35.541505\n",
      "0.93184453\n",
      "[Epoch 35/50] [Batch 74/300] [D loss: 0.752346] [G loss: 0.473420] time: 0:52:35.827221\n",
      "0.8861556\n",
      "[Epoch 35/50] [Batch 75/300] [D loss: 0.752336] [G loss: 0.471640] time: 0:52:36.105175\n",
      "0.8738284\n",
      "[Epoch 35/50] [Batch 76/300] [D loss: 0.752328] [G loss: 0.480498] time: 0:52:36.421742\n",
      "0.9760856\n",
      "[Epoch 35/50] [Batch 77/300] [D loss: 0.752335] [G loss: 0.480194] time: 0:52:36.718979\n",
      "0.9086561\n",
      "[Epoch 35/50] [Batch 78/300] [D loss: 0.752337] [G loss: 0.486856] time: 0:52:37.027971\n",
      "0.94990796\n",
      "[Epoch 35/50] [Batch 79/300] [D loss: 0.752323] [G loss: 0.493876] time: 0:52:37.326294\n",
      "0.92550135\n",
      "[Epoch 35/50] [Batch 80/300] [D loss: 0.752324] [G loss: 0.472567] time: 0:52:37.629897\n",
      "0.90538543\n",
      "[Epoch 35/50] [Batch 81/300] [D loss: 0.752332] [G loss: 0.469913] time: 0:52:37.949375\n",
      "0.93702966\n",
      "[Epoch 35/50] [Batch 82/300] [D loss: 0.752328] [G loss: 0.490160] time: 0:52:38.243859\n",
      "0.937773\n",
      "[Epoch 35/50] [Batch 83/300] [D loss: 0.752324] [G loss: 0.485800] time: 0:52:38.524130\n",
      "0.9294016\n",
      "[Epoch 35/50] [Batch 84/300] [D loss: 0.752328] [G loss: 0.478926] time: 0:52:38.825702\n",
      "0.9115842\n",
      "[Epoch 35/50] [Batch 85/300] [D loss: 0.752343] [G loss: 0.488203] time: 0:52:39.116091\n",
      "0.8959647\n",
      "[Epoch 35/50] [Batch 86/300] [D loss: 0.752338] [G loss: 0.506416] time: 0:52:39.414478\n",
      "0.94962245\n",
      "[Epoch 35/50] [Batch 87/300] [D loss: 0.752327] [G loss: 0.487328] time: 0:52:39.735990\n",
      "0.91403675\n",
      "[Epoch 35/50] [Batch 88/300] [D loss: 0.752319] [G loss: 0.487429] time: 0:52:40.130258\n",
      "0.8885816\n",
      "[Epoch 35/50] [Batch 89/300] [D loss: 0.752328] [G loss: 0.476085] time: 0:52:40.432571\n",
      "0.895232\n",
      "[Epoch 35/50] [Batch 90/300] [D loss: 0.752317] [G loss: 0.509319] time: 0:52:40.738153\n",
      "0.95124596\n",
      "[Epoch 35/50] [Batch 91/300] [D loss: 0.752322] [G loss: 0.470999] time: 0:52:41.031332\n",
      "0.9451539\n",
      "[Epoch 35/50] [Batch 92/300] [D loss: 0.752337] [G loss: 0.484878] time: 0:52:41.330216\n",
      "0.9535089\n",
      "[Epoch 35/50] [Batch 93/300] [D loss: 0.752319] [G loss: 0.479565] time: 0:52:41.613482\n",
      "0.98357326\n",
      "[Epoch 35/50] [Batch 94/300] [D loss: 0.752333] [G loss: 0.503707] time: 0:52:41.907331\n",
      "0.89176726\n",
      "[Epoch 35/50] [Batch 95/300] [D loss: 0.752352] [G loss: 0.469378] time: 0:52:42.212691\n",
      "0.8813316\n",
      "[Epoch 35/50] [Batch 96/300] [D loss: 0.752321] [G loss: 0.474668] time: 0:52:42.510450\n",
      "0.9000314\n",
      "[Epoch 35/50] [Batch 97/300] [D loss: 0.752334] [G loss: 0.475539] time: 0:52:42.810658\n",
      "0.9067695\n",
      "[Epoch 35/50] [Batch 98/300] [D loss: 0.752324] [G loss: 0.494451] time: 0:52:43.107675\n",
      "0.9530771\n",
      "[Epoch 35/50] [Batch 99/300] [D loss: 0.752335] [G loss: 0.485198] time: 0:52:43.382884\n",
      "0.8918531\n",
      "[Epoch 35/50] [Batch 100/300] [D loss: 0.752334] [G loss: 0.485590] time: 0:52:43.673349\n",
      "0.9833851\n",
      "[Epoch 35/50] [Batch 101/300] [D loss: 0.752328] [G loss: 0.477186] time: 0:52:43.969904\n",
      "0.9322405\n",
      "[Epoch 35/50] [Batch 102/300] [D loss: 0.752322] [G loss: 0.473551] time: 0:52:44.277753\n",
      "0.9623537\n",
      "[Epoch 35/50] [Batch 103/300] [D loss: 0.752326] [G loss: 0.468726] time: 0:52:44.587499\n",
      "0.90684175\n",
      "[Epoch 35/50] [Batch 104/300] [D loss: 0.752329] [G loss: 0.472719] time: 0:52:44.889025\n",
      "0.8575575\n",
      "[Epoch 35/50] [Batch 105/300] [D loss: 0.752325] [G loss: 0.488219] time: 0:52:45.196825\n",
      "0.96079415\n",
      "[Epoch 35/50] [Batch 106/300] [D loss: 0.752335] [G loss: 0.481668] time: 0:52:45.487615\n",
      "0.9087209\n",
      "[Epoch 35/50] [Batch 107/300] [D loss: 0.752332] [G loss: 0.483800] time: 0:52:45.797904\n",
      "0.9089177\n",
      "[Epoch 35/50] [Batch 108/300] [D loss: 0.752335] [G loss: 0.489313] time: 0:52:46.109578\n",
      "0.9130165\n",
      "[Epoch 35/50] [Batch 109/300] [D loss: 0.752323] [G loss: 0.501424] time: 0:52:46.413996\n",
      "0.92688054\n",
      "[Epoch 35/50] [Batch 110/300] [D loss: 0.752324] [G loss: 0.495593] time: 0:52:46.737027\n",
      "0.91661143\n",
      "[Epoch 35/50] [Batch 111/300] [D loss: 0.752328] [G loss: 0.482570] time: 0:52:47.031581\n",
      "0.8994344\n",
      "[Epoch 35/50] [Batch 112/300] [D loss: 0.752342] [G loss: 0.480620] time: 0:52:47.334686\n",
      "0.9298675\n",
      "[Epoch 35/50] [Batch 113/300] [D loss: 0.752329] [G loss: 0.495631] time: 0:52:47.613354\n",
      "0.90947527\n",
      "[Epoch 35/50] [Batch 114/300] [D loss: 0.752330] [G loss: 0.477415] time: 0:52:47.922262\n",
      "0.932751\n",
      "[Epoch 35/50] [Batch 115/300] [D loss: 0.752322] [G loss: 0.485307] time: 0:52:48.202975\n",
      "0.90668195\n",
      "[Epoch 35/50] [Batch 116/300] [D loss: 0.752331] [G loss: 0.494376] time: 0:52:48.491533\n",
      "0.9174505\n",
      "[Epoch 35/50] [Batch 117/300] [D loss: 0.752322] [G loss: 0.484495] time: 0:52:48.789477\n",
      "0.9248807\n",
      "[Epoch 35/50] [Batch 118/300] [D loss: 0.752329] [G loss: 0.510301] time: 0:52:49.094468\n",
      "0.9159439\n",
      "[Epoch 35/50] [Batch 119/300] [D loss: 0.752343] [G loss: 0.476856] time: 0:52:49.396364\n",
      "0.9390437\n",
      "[Epoch 35/50] [Batch 120/300] [D loss: 0.752336] [G loss: 0.492878] time: 0:52:49.688523\n",
      "0.9023381\n",
      "[Epoch 35/50] [Batch 121/300] [D loss: 0.752324] [G loss: 0.475577] time: 0:52:49.977312\n",
      "0.92687637\n",
      "[Epoch 35/50] [Batch 122/300] [D loss: 0.752320] [G loss: 0.494484] time: 0:52:50.278806\n",
      "0.93684316\n",
      "[Epoch 35/50] [Batch 123/300] [D loss: 0.752323] [G loss: 0.494334] time: 0:52:50.559604\n",
      "0.9466755\n",
      "[Epoch 35/50] [Batch 124/300] [D loss: 0.752330] [G loss: 0.478904] time: 0:52:50.839180\n",
      "0.9434301\n",
      "[Epoch 35/50] [Batch 125/300] [D loss: 0.752335] [G loss: 0.477822] time: 0:52:51.124929\n",
      "0.8753255\n",
      "[Epoch 35/50] [Batch 126/300] [D loss: 0.752341] [G loss: 0.482889] time: 0:52:51.409517\n",
      "0.90843457\n",
      "[Epoch 35/50] [Batch 127/300] [D loss: 0.752327] [G loss: 0.482498] time: 0:52:51.711053\n",
      "0.94276524\n",
      "[Epoch 35/50] [Batch 128/300] [D loss: 0.752331] [G loss: 0.500650] time: 0:52:52.002857\n",
      "0.9062609\n",
      "[Epoch 35/50] [Batch 129/300] [D loss: 0.752318] [G loss: 0.475659] time: 0:52:52.296158\n",
      "0.90648156\n",
      "[Epoch 35/50] [Batch 130/300] [D loss: 0.752326] [G loss: 0.489656] time: 0:52:52.599992\n",
      "0.919647\n",
      "[Epoch 35/50] [Batch 131/300] [D loss: 0.752336] [G loss: 0.478422] time: 0:52:52.881026\n",
      "0.8682347\n",
      "[Epoch 35/50] [Batch 132/300] [D loss: 0.752341] [G loss: 0.476941] time: 0:52:53.187467\n",
      "0.9352951\n",
      "[Epoch 35/50] [Batch 133/300] [D loss: 0.752326] [G loss: 0.497085] time: 0:52:53.491723\n",
      "0.90000516\n",
      "[Epoch 35/50] [Batch 134/300] [D loss: 0.752327] [G loss: 0.476596] time: 0:52:53.792835\n",
      "0.9495678\n",
      "[Epoch 35/50] [Batch 135/300] [D loss: 0.752332] [G loss: 0.486362] time: 0:52:54.081580\n",
      "0.9346347\n",
      "[Epoch 35/50] [Batch 136/300] [D loss: 0.752324] [G loss: 0.483307] time: 0:52:54.360951\n",
      "0.946141\n",
      "[Epoch 35/50] [Batch 137/300] [D loss: 0.752322] [G loss: 0.473239] time: 0:52:54.656951\n",
      "0.93496615\n",
      "[Epoch 35/50] [Batch 138/300] [D loss: 0.752324] [G loss: 0.490606] time: 0:52:54.963870\n",
      "0.89083475\n",
      "[Epoch 35/50] [Batch 139/300] [D loss: 0.752314] [G loss: 0.493328] time: 0:52:55.252293\n",
      "0.90356493\n",
      "[Epoch 35/50] [Batch 140/300] [D loss: 0.752315] [G loss: 0.492558] time: 0:52:55.543924\n",
      "0.9169194\n",
      "[Epoch 35/50] [Batch 141/300] [D loss: 0.752320] [G loss: 0.474209] time: 0:52:55.857619\n",
      "0.91242296\n",
      "[Epoch 35/50] [Batch 142/300] [D loss: 0.752332] [G loss: 0.486373] time: 0:52:56.162613\n",
      "0.9074593\n",
      "[Epoch 35/50] [Batch 143/300] [D loss: 0.752341] [G loss: 0.487756] time: 0:52:56.460377\n",
      "0.92194575\n",
      "[Epoch 35/50] [Batch 144/300] [D loss: 0.752335] [G loss: 0.471091] time: 0:52:56.763361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90866274\n",
      "[Epoch 35/50] [Batch 145/300] [D loss: 0.752319] [G loss: 0.474671] time: 0:52:57.057057\n",
      "0.8587475\n",
      "[Epoch 35/50] [Batch 146/300] [D loss: 0.752321] [G loss: 0.496103] time: 0:52:57.364489\n",
      "0.9485844\n",
      "[Epoch 35/50] [Batch 147/300] [D loss: 0.752332] [G loss: 0.479390] time: 0:52:57.659621\n",
      "0.899107\n",
      "[Epoch 35/50] [Batch 148/300] [D loss: 0.752333] [G loss: 0.512952] time: 0:52:57.944469\n",
      "0.9125224\n",
      "[Epoch 35/50] [Batch 149/300] [D loss: 0.752324] [G loss: 0.486466] time: 0:52:58.240317\n",
      "0.93539256\n",
      "[Epoch 35/50] [Batch 150/300] [D loss: 0.752314] [G loss: 0.481149] time: 0:52:58.544505\n",
      "0.9330046\n",
      "[Epoch 35/50] [Batch 151/300] [D loss: 0.752327] [G loss: 0.478840] time: 0:52:58.852889\n",
      "0.9835592\n",
      "[Epoch 35/50] [Batch 152/300] [D loss: 0.752316] [G loss: 0.488559] time: 0:52:59.137340\n",
      "0.9000921\n",
      "[Epoch 35/50] [Batch 153/300] [D loss: 0.752324] [G loss: 0.487109] time: 0:52:59.450011\n",
      "0.95427674\n",
      "[Epoch 35/50] [Batch 154/300] [D loss: 0.752349] [G loss: 0.484912] time: 0:52:59.755949\n",
      "0.90924615\n",
      "[Epoch 35/50] [Batch 155/300] [D loss: 0.752333] [G loss: 0.488608] time: 0:53:00.055481\n",
      "0.91736764\n",
      "[Epoch 35/50] [Batch 156/300] [D loss: 0.752336] [G loss: 0.475284] time: 0:53:00.351525\n",
      "0.8987162\n",
      "[Epoch 35/50] [Batch 157/300] [D loss: 0.752338] [G loss: 0.487103] time: 0:53:00.656581\n",
      "0.93386793\n",
      "[Epoch 35/50] [Batch 158/300] [D loss: 0.752351] [G loss: 0.483668] time: 0:53:00.971514\n",
      "0.91626644\n",
      "[Epoch 35/50] [Batch 159/300] [D loss: 0.752320] [G loss: 0.480407] time: 0:53:01.265142\n",
      "0.9316625\n",
      "[Epoch 35/50] [Batch 160/300] [D loss: 0.752324] [G loss: 0.501795] time: 0:53:01.579768\n",
      "0.9245796\n",
      "[Epoch 35/50] [Batch 161/300] [D loss: 0.752312] [G loss: 0.485086] time: 0:53:01.875144\n",
      "0.922293\n",
      "[Epoch 35/50] [Batch 162/300] [D loss: 0.752328] [G loss: 0.488686] time: 0:53:02.178467\n",
      "0.9534709\n",
      "[Epoch 35/50] [Batch 163/300] [D loss: 0.752330] [G loss: 0.490822] time: 0:53:02.480786\n",
      "0.88318807\n",
      "[Epoch 35/50] [Batch 164/300] [D loss: 0.752314] [G loss: 0.484382] time: 0:53:02.773691\n",
      "0.92145187\n",
      "[Epoch 35/50] [Batch 165/300] [D loss: 0.752337] [G loss: 0.477992] time: 0:53:03.076709\n",
      "0.9422563\n",
      "[Epoch 35/50] [Batch 166/300] [D loss: 0.752346] [G loss: 0.499193] time: 0:53:03.357935\n",
      "0.934696\n",
      "[Epoch 35/50] [Batch 167/300] [D loss: 0.752324] [G loss: 0.493099] time: 0:53:03.642322\n",
      "0.94610643\n",
      "[Epoch 35/50] [Batch 168/300] [D loss: 0.752329] [G loss: 0.524678] time: 0:53:03.910397\n",
      "0.9552539\n",
      "[Epoch 35/50] [Batch 169/300] [D loss: 0.752356] [G loss: 0.497963] time: 0:53:04.196450\n",
      "0.88616323\n",
      "[Epoch 35/50] [Batch 170/300] [D loss: 0.752322] [G loss: 0.494446] time: 0:53:04.497832\n",
      "0.9248454\n",
      "[Epoch 35/50] [Batch 171/300] [D loss: 0.752327] [G loss: 0.479544] time: 0:53:04.817748\n",
      "0.9087835\n",
      "[Epoch 35/50] [Batch 172/300] [D loss: 0.752342] [G loss: 0.481219] time: 0:53:05.100096\n",
      "0.94222903\n",
      "[Epoch 35/50] [Batch 173/300] [D loss: 0.752343] [G loss: 0.506986] time: 0:53:05.409515\n",
      "0.9425567\n",
      "[Epoch 35/50] [Batch 174/300] [D loss: 0.752332] [G loss: 0.494824] time: 0:53:05.720406\n",
      "0.90711087\n",
      "[Epoch 35/50] [Batch 175/300] [D loss: 0.752321] [G loss: 0.494654] time: 0:53:06.023903\n",
      "0.91612655\n",
      "[Epoch 35/50] [Batch 176/300] [D loss: 0.752330] [G loss: 0.482137] time: 0:53:06.325671\n",
      "0.93328637\n",
      "[Epoch 35/50] [Batch 177/300] [D loss: 0.752328] [G loss: 0.491960] time: 0:53:06.625253\n",
      "0.9074374\n",
      "[Epoch 35/50] [Batch 178/300] [D loss: 0.752335] [G loss: 0.483114] time: 0:53:06.926251\n",
      "0.9336121\n",
      "[Epoch 35/50] [Batch 179/300] [D loss: 0.752335] [G loss: 0.472130] time: 0:53:07.209608\n",
      "0.9352079\n",
      "[Epoch 35/50] [Batch 180/300] [D loss: 0.752335] [G loss: 0.484187] time: 0:53:07.512615\n",
      "0.89894325\n",
      "[Epoch 35/50] [Batch 181/300] [D loss: 0.752310] [G loss: 0.477081] time: 0:53:07.822657\n",
      "0.9442992\n",
      "[Epoch 35/50] [Batch 182/300] [D loss: 0.752340] [G loss: 0.473827] time: 0:53:08.104233\n",
      "0.89588165\n",
      "[Epoch 35/50] [Batch 183/300] [D loss: 0.752326] [G loss: 0.483497] time: 0:53:08.412262\n",
      "0.9216134\n",
      "[Epoch 35/50] [Batch 184/300] [D loss: 0.752336] [G loss: 0.489101] time: 0:53:08.705419\n",
      "0.9753682\n",
      "[Epoch 35/50] [Batch 185/300] [D loss: 0.752333] [G loss: 0.482130] time: 0:53:08.989744\n",
      "0.91366506\n",
      "[Epoch 35/50] [Batch 186/300] [D loss: 0.752360] [G loss: 0.474098] time: 0:53:09.268683\n",
      "0.93473345\n",
      "[Epoch 35/50] [Batch 187/300] [D loss: 0.752331] [G loss: 0.498454] time: 0:53:09.560322\n",
      "0.93920904\n",
      "[Epoch 35/50] [Batch 188/300] [D loss: 0.752310] [G loss: 0.486877] time: 0:53:09.861871\n",
      "0.91716415\n",
      "[Epoch 35/50] [Batch 189/300] [D loss: 0.752315] [G loss: 0.483873] time: 0:53:10.166328\n",
      "0.91253215\n",
      "[Epoch 35/50] [Batch 190/300] [D loss: 0.752305] [G loss: 0.506867] time: 0:53:10.457598\n",
      "0.8874748\n",
      "[Epoch 35/50] [Batch 191/300] [D loss: 0.752334] [G loss: 0.476125] time: 0:53:10.757993\n",
      "0.9308166\n",
      "[Epoch 35/50] [Batch 192/300] [D loss: 0.752324] [G loss: 0.475435] time: 0:53:11.064086\n",
      "0.91823035\n",
      "[Epoch 35/50] [Batch 193/300] [D loss: 0.752341] [G loss: 0.485718] time: 0:53:11.351464\n",
      "0.8994999\n",
      "[Epoch 35/50] [Batch 194/300] [D loss: 0.752320] [G loss: 0.479285] time: 0:53:11.656099\n",
      "0.8876602\n",
      "[Epoch 35/50] [Batch 195/300] [D loss: 0.752331] [G loss: 0.494810] time: 0:53:11.969121\n",
      "0.93968123\n",
      "[Epoch 35/50] [Batch 196/300] [D loss: 0.752347] [G loss: 0.477925] time: 0:53:12.279821\n",
      "0.9070049\n",
      "[Epoch 35/50] [Batch 197/300] [D loss: 0.752349] [G loss: 0.480129] time: 0:53:12.586469\n",
      "0.9314613\n",
      "[Epoch 35/50] [Batch 198/300] [D loss: 0.752330] [G loss: 0.475613] time: 0:53:12.873963\n",
      "0.8994427\n",
      "[Epoch 35/50] [Batch 199/300] [D loss: 0.752333] [G loss: 0.479980] time: 0:53:13.181610\n",
      "0.9117322\n",
      "[Epoch 35/50] [Batch 200/300] [D loss: 0.752320] [G loss: 0.477651] time: 0:53:13.484666\n",
      "0.9235919\n",
      "[Epoch 35/50] [Batch 201/300] [D loss: 0.752321] [G loss: 0.498652] time: 0:53:13.789159\n",
      "0.91181564\n",
      "[Epoch 35/50] [Batch 202/300] [D loss: 0.752315] [G loss: 0.488138] time: 0:53:14.088484\n",
      "0.93299073\n",
      "[Epoch 35/50] [Batch 203/300] [D loss: 0.752345] [G loss: 0.477959] time: 0:53:14.373674\n",
      "0.924874\n",
      "[Epoch 35/50] [Batch 204/300] [D loss: 0.752325] [G loss: 0.502455] time: 0:53:14.652108\n",
      "0.9380376\n",
      "[Epoch 35/50] [Batch 205/300] [D loss: 0.752321] [G loss: 0.477503] time: 0:53:14.941540\n",
      "0.89255947\n",
      "[Epoch 35/50] [Batch 206/300] [D loss: 0.752322] [G loss: 0.483473] time: 0:53:15.226605\n",
      "0.90565085\n",
      "[Epoch 35/50] [Batch 207/300] [D loss: 0.752325] [G loss: 0.498333] time: 0:53:15.510804\n",
      "0.8778555\n",
      "[Epoch 35/50] [Batch 208/300] [D loss: 0.752325] [G loss: 0.493600] time: 0:53:15.797022\n",
      "0.8711614\n",
      "[Epoch 35/50] [Batch 209/300] [D loss: 0.752317] [G loss: 0.474193] time: 0:53:16.097008\n",
      "0.9466595\n",
      "[Epoch 35/50] [Batch 210/300] [D loss: 0.752324] [G loss: 0.487158] time: 0:53:16.388707\n",
      "0.91764736\n",
      "[Epoch 35/50] [Batch 211/300] [D loss: 0.752312] [G loss: 0.473693] time: 0:53:16.697590\n",
      "0.9336247\n",
      "[Epoch 35/50] [Batch 212/300] [D loss: 0.752333] [G loss: 0.474495] time: 0:53:17.000321\n",
      "0.95231384\n",
      "[Epoch 35/50] [Batch 213/300] [D loss: 0.752320] [G loss: 0.469672] time: 0:53:17.304300\n",
      "0.9192807\n",
      "[Epoch 35/50] [Batch 214/300] [D loss: 0.752338] [G loss: 0.480859] time: 0:53:17.597037\n",
      "0.9071153\n",
      "[Epoch 35/50] [Batch 215/300] [D loss: 0.752323] [G loss: 0.472930] time: 0:53:17.870335\n",
      "0.93642044\n",
      "[Epoch 35/50] [Batch 216/300] [D loss: 0.752320] [G loss: 0.479858] time: 0:53:18.176420\n",
      "0.9599988\n",
      "[Epoch 35/50] [Batch 217/300] [D loss: 0.752316] [G loss: 0.514161] time: 0:53:18.470864\n",
      "0.9371633\n",
      "[Epoch 35/50] [Batch 218/300] [D loss: 0.752321] [G loss: 0.488900] time: 0:53:18.777214\n",
      "0.983303\n",
      "[Epoch 35/50] [Batch 219/300] [D loss: 0.752329] [G loss: 0.471892] time: 0:53:19.078737\n",
      "0.8700549\n",
      "[Epoch 35/50] [Batch 220/300] [D loss: 0.752324] [G loss: 0.480331] time: 0:53:19.388742\n",
      "0.9380965\n",
      "[Epoch 35/50] [Batch 221/300] [D loss: 0.752335] [G loss: 0.499800] time: 0:53:19.688231\n",
      "0.95944947\n",
      "[Epoch 35/50] [Batch 222/300] [D loss: 0.752328] [G loss: 0.482992] time: 0:53:19.980160\n",
      "0.9302985\n",
      "[Epoch 35/50] [Batch 223/300] [D loss: 0.752330] [G loss: 0.494925] time: 0:53:20.279571\n",
      "0.96802217\n",
      "[Epoch 35/50] [Batch 224/300] [D loss: 0.752326] [G loss: 0.471259] time: 0:53:20.571590\n",
      "0.883159\n",
      "[Epoch 35/50] [Batch 225/300] [D loss: 0.752344] [G loss: 0.486566] time: 0:53:20.861537\n",
      "0.89588827\n",
      "[Epoch 35/50] [Batch 226/300] [D loss: 0.752344] [G loss: 0.477871] time: 0:53:21.173601\n",
      "0.9166238\n",
      "[Epoch 35/50] [Batch 227/300] [D loss: 0.752318] [G loss: 0.492042] time: 0:53:21.462147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9471393\n",
      "[Epoch 35/50] [Batch 228/300] [D loss: 0.752326] [G loss: 0.481419] time: 0:53:21.765317\n",
      "0.9329435\n",
      "[Epoch 35/50] [Batch 229/300] [D loss: 0.752317] [G loss: 0.480062] time: 0:53:22.056928\n",
      "0.9248832\n",
      "[Epoch 35/50] [Batch 230/300] [D loss: 0.752329] [G loss: 0.472765] time: 0:53:22.354645\n",
      "0.9805934\n",
      "[Epoch 35/50] [Batch 231/300] [D loss: 0.752315] [G loss: 0.486786] time: 0:53:22.629773\n",
      "0.9029598\n",
      "[Epoch 35/50] [Batch 232/300] [D loss: 0.752326] [G loss: 0.509084] time: 0:53:22.925766\n",
      "0.8836033\n",
      "[Epoch 35/50] [Batch 233/300] [D loss: 0.752338] [G loss: 0.478701] time: 0:53:23.238739\n",
      "0.95325845\n",
      "[Epoch 35/50] [Batch 234/300] [D loss: 0.752330] [G loss: 0.501591] time: 0:53:23.547541\n",
      "0.9369302\n",
      "[Epoch 35/50] [Batch 235/300] [D loss: 0.752322] [G loss: 0.488052] time: 0:53:23.836349\n",
      "0.93957454\n",
      "[Epoch 35/50] [Batch 236/300] [D loss: 0.752327] [G loss: 0.481405] time: 0:53:24.144890\n",
      "0.8887102\n",
      "[Epoch 35/50] [Batch 237/300] [D loss: 0.752325] [G loss: 0.498670] time: 0:53:24.449595\n",
      "0.95809364\n",
      "[Epoch 35/50] [Batch 238/300] [D loss: 0.752325] [G loss: 0.486426] time: 0:53:24.735835\n",
      "0.86746293\n",
      "[Epoch 35/50] [Batch 239/300] [D loss: 0.752337] [G loss: 0.474955] time: 0:53:25.034808\n",
      "0.8734798\n",
      "[Epoch 35/50] [Batch 240/300] [D loss: 0.752323] [G loss: 0.500152] time: 0:53:25.329269\n",
      "0.89088154\n",
      "[Epoch 35/50] [Batch 241/300] [D loss: 0.752322] [G loss: 0.471486] time: 0:53:25.630778\n",
      "0.8886859\n",
      "[Epoch 35/50] [Batch 242/300] [D loss: 0.752329] [G loss: 0.476702] time: 0:53:25.921668\n",
      "0.8809952\n",
      "[Epoch 35/50] [Batch 243/300] [D loss: 0.752318] [G loss: 0.483381] time: 0:53:26.222592\n",
      "0.90043646\n",
      "[Epoch 35/50] [Batch 244/300] [D loss: 0.752322] [G loss: 0.472236] time: 0:53:26.506974\n",
      "0.9080817\n",
      "[Epoch 35/50] [Batch 245/300] [D loss: 0.752318] [G loss: 0.487097] time: 0:53:26.810567\n",
      "0.89029926\n",
      "[Epoch 35/50] [Batch 246/300] [D loss: 0.752321] [G loss: 0.476932] time: 0:53:27.118060\n",
      "0.9414601\n",
      "[Epoch 35/50] [Batch 247/300] [D loss: 0.752319] [G loss: 0.480575] time: 0:53:27.422706\n",
      "0.9352233\n",
      "[Epoch 35/50] [Batch 248/300] [D loss: 0.752319] [G loss: 0.503656] time: 0:53:27.722628\n",
      "0.90530944\n",
      "[Epoch 35/50] [Batch 249/300] [D loss: 0.752320] [G loss: 0.481756] time: 0:53:28.037540\n",
      "0.92523474\n",
      "[Epoch 35/50] [Batch 250/300] [D loss: 0.752331] [G loss: 0.499713] time: 0:53:28.339565\n",
      "0.9106579\n",
      "[Epoch 35/50] [Batch 251/300] [D loss: 0.752314] [G loss: 0.471835] time: 0:53:28.633954\n",
      "0.89096004\n",
      "[Epoch 35/50] [Batch 252/300] [D loss: 0.752315] [G loss: 0.469148] time: 0:53:28.940275\n",
      "0.91559345\n",
      "[Epoch 35/50] [Batch 253/300] [D loss: 0.752328] [G loss: 0.476145] time: 0:53:29.212449\n",
      "0.9617574\n",
      "[Epoch 35/50] [Batch 254/300] [D loss: 0.752358] [G loss: 0.479292] time: 0:53:29.506348\n",
      "0.9118641\n",
      "[Epoch 35/50] [Batch 255/300] [D loss: 0.752342] [G loss: 0.481294] time: 0:53:29.780122\n",
      "0.9161722\n",
      "[Epoch 35/50] [Batch 256/300] [D loss: 0.752325] [G loss: 0.503421] time: 0:53:30.075109\n",
      "0.9107068\n",
      "[Epoch 35/50] [Batch 257/300] [D loss: 0.752328] [G loss: 0.474485] time: 0:53:30.360689\n",
      "0.8981274\n",
      "[Epoch 35/50] [Batch 258/300] [D loss: 0.752312] [G loss: 0.486017] time: 0:53:30.677472\n",
      "0.8900512\n",
      "[Epoch 35/50] [Batch 259/300] [D loss: 0.752351] [G loss: 0.491753] time: 0:53:30.981384\n",
      "0.9644096\n",
      "[Epoch 35/50] [Batch 260/300] [D loss: 0.752331] [G loss: 0.491674] time: 0:53:31.283725\n",
      "0.90286857\n",
      "[Epoch 35/50] [Batch 261/300] [D loss: 0.752339] [G loss: 0.478313] time: 0:53:31.600204\n",
      "0.90625906\n",
      "[Epoch 35/50] [Batch 262/300] [D loss: 0.752316] [G loss: 0.498224] time: 0:53:31.899367\n",
      "0.98333025\n",
      "[Epoch 35/50] [Batch 263/300] [D loss: 0.752337] [G loss: 0.487335] time: 0:53:32.192848\n",
      "0.92157406\n",
      "[Epoch 35/50] [Batch 264/300] [D loss: 0.752327] [G loss: 0.470122] time: 0:53:32.474001\n",
      "0.9103721\n",
      "[Epoch 35/50] [Batch 265/300] [D loss: 0.752346] [G loss: 0.475594] time: 0:53:32.768466\n",
      "0.91945726\n",
      "[Epoch 35/50] [Batch 266/300] [D loss: 0.752339] [G loss: 0.482309] time: 0:53:33.080772\n",
      "0.9423602\n",
      "[Epoch 35/50] [Batch 267/300] [D loss: 0.752335] [G loss: 0.491288] time: 0:53:33.379688\n",
      "0.92159766\n",
      "[Epoch 35/50] [Batch 268/300] [D loss: 0.752326] [G loss: 0.481654] time: 0:53:33.677092\n",
      "0.8762205\n",
      "[Epoch 35/50] [Batch 269/300] [D loss: 0.752340] [G loss: 0.474717] time: 0:53:33.978263\n",
      "0.9117698\n",
      "[Epoch 35/50] [Batch 270/300] [D loss: 0.752327] [G loss: 0.480107] time: 0:53:34.286373\n",
      "0.9325002\n",
      "[Epoch 35/50] [Batch 271/300] [D loss: 0.752334] [G loss: 0.477223] time: 0:53:34.565478\n",
      "0.89282626\n",
      "[Epoch 35/50] [Batch 272/300] [D loss: 0.752321] [G loss: 0.490639] time: 0:53:34.865902\n",
      "0.9608059\n",
      "[Epoch 35/50] [Batch 273/300] [D loss: 0.752325] [G loss: 0.484814] time: 0:53:35.155759\n",
      "0.96901625\n",
      "[Epoch 35/50] [Batch 274/300] [D loss: 0.752324] [G loss: 0.513248] time: 0:53:35.460802\n",
      "0.8812227\n",
      "[Epoch 35/50] [Batch 275/300] [D loss: 0.752330] [G loss: 0.480664] time: 0:53:35.741981\n",
      "0.9243789\n",
      "[Epoch 35/50] [Batch 276/300] [D loss: 0.752351] [G loss: 0.484669] time: 0:53:36.042928\n",
      "0.94213384\n",
      "[Epoch 35/50] [Batch 277/300] [D loss: 0.752334] [G loss: 0.475550] time: 0:53:36.324717\n",
      "0.98153925\n",
      "[Epoch 35/50] [Batch 278/300] [D loss: 0.752339] [G loss: 0.477551] time: 0:53:36.635928\n",
      "0.8899429\n",
      "[Epoch 35/50] [Batch 279/300] [D loss: 0.752340] [G loss: 0.479962] time: 0:53:36.931876\n",
      "0.95551753\n",
      "[Epoch 35/50] [Batch 280/300] [D loss: 0.752322] [G loss: 0.484883] time: 0:53:37.224714\n",
      "0.9252138\n",
      "[Epoch 35/50] [Batch 281/300] [D loss: 0.752332] [G loss: 0.470357] time: 0:53:37.518217\n",
      "0.95145893\n",
      "[Epoch 35/50] [Batch 282/300] [D loss: 0.752354] [G loss: 0.488518] time: 0:53:37.790700\n",
      "0.9307429\n",
      "[Epoch 35/50] [Batch 283/300] [D loss: 0.752341] [G loss: 0.474948] time: 0:53:38.100679\n",
      "0.93601084\n",
      "[Epoch 35/50] [Batch 284/300] [D loss: 0.752300] [G loss: 0.483109] time: 0:53:38.402477\n",
      "0.9297037\n",
      "[Epoch 35/50] [Batch 285/300] [D loss: 0.752340] [G loss: 0.480609] time: 0:53:38.704061\n",
      "0.95084816\n",
      "[Epoch 35/50] [Batch 286/300] [D loss: 0.752320] [G loss: 0.493637] time: 0:53:39.018548\n",
      "0.8889478\n",
      "[Epoch 35/50] [Batch 287/300] [D loss: 0.752331] [G loss: 0.508893] time: 0:53:39.305481\n",
      "0.98204595\n",
      "[Epoch 35/50] [Batch 288/300] [D loss: 0.752322] [G loss: 0.480092] time: 0:53:39.615497\n",
      "0.9103503\n",
      "[Epoch 35/50] [Batch 289/300] [D loss: 0.752327] [G loss: 0.472811] time: 0:53:39.908454\n",
      "0.9362309\n",
      "[Epoch 35/50] [Batch 290/300] [D loss: 0.752339] [G loss: 0.486718] time: 0:53:40.209884\n",
      "0.8750747\n",
      "[Epoch 35/50] [Batch 291/300] [D loss: 0.752323] [G loss: 0.490355] time: 0:53:40.510801\n",
      "0.92245644\n",
      "[Epoch 35/50] [Batch 292/300] [D loss: 0.752332] [G loss: 0.504284] time: 0:53:40.812673\n",
      "0.89145446\n",
      "[Epoch 35/50] [Batch 293/300] [D loss: 0.752317] [G loss: 0.477537] time: 0:53:41.106484\n",
      "0.9107849\n",
      "[Epoch 35/50] [Batch 294/300] [D loss: 0.752314] [G loss: 0.485823] time: 0:53:41.410481\n",
      "0.9351142\n",
      "[Epoch 35/50] [Batch 295/300] [D loss: 0.752342] [G loss: 0.496538] time: 0:53:41.720136\n",
      "0.9189488\n",
      "[Epoch 35/50] [Batch 296/300] [D loss: 0.752323] [G loss: 0.501189] time: 0:53:42.013715\n",
      "0.9217248\n",
      "[Epoch 35/50] [Batch 297/300] [D loss: 0.752330] [G loss: 0.477910] time: 0:53:42.317550\n",
      "0.95062727\n",
      "[Epoch 35/50] [Batch 298/300] [D loss: 0.752324] [G loss: 0.473531] time: 0:53:42.623957\n",
      "0.9461077\n",
      "[Epoch 35/50] [Batch 299/300] [D loss: 0.752327] [G loss: 0.483416] time: 0:53:42.913471\n",
      "0.9078383\n",
      "[Epoch 36/50] [Batch 0/300] [D loss: 0.752330] [G loss: 0.518162] time: 0:53:43.204050\n",
      "0.9074481\n",
      "[Epoch 36/50] [Batch 1/300] [D loss: 0.752334] [G loss: 0.467294] time: 0:53:43.499272\n",
      "0.91157913\n",
      "[Epoch 36/50] [Batch 2/300] [D loss: 0.752315] [G loss: 0.493749] time: 0:53:43.801055\n",
      "0.8919923\n",
      "[Epoch 36/50] [Batch 3/300] [D loss: 0.752326] [G loss: 0.483361] time: 0:53:44.104836\n",
      "0.93148494\n",
      "[Epoch 36/50] [Batch 4/300] [D loss: 0.752330] [G loss: 0.484925] time: 0:53:44.403004\n",
      "0.90520185\n",
      "[Epoch 36/50] [Batch 5/300] [D loss: 0.752332] [G loss: 0.484473] time: 0:53:44.715533\n",
      "0.9454679\n",
      "[Epoch 36/50] [Batch 6/300] [D loss: 0.752335] [G loss: 0.482206] time: 0:53:45.012997\n",
      "0.92949027\n",
      "[Epoch 36/50] [Batch 7/300] [D loss: 0.752315] [G loss: 0.490836] time: 0:53:45.304125\n",
      "0.88636494\n",
      "[Epoch 36/50] [Batch 8/300] [D loss: 0.752309] [G loss: 0.500951] time: 0:53:45.626288\n",
      "0.8958973\n",
      "[Epoch 36/50] [Batch 9/300] [D loss: 0.752325] [G loss: 0.501584] time: 0:53:45.941811\n",
      "0.94466907\n",
      "[Epoch 36/50] [Batch 10/300] [D loss: 0.752334] [G loss: 0.483713] time: 0:53:46.242034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9454586\n",
      "[Epoch 36/50] [Batch 11/300] [D loss: 0.752332] [G loss: 0.495410] time: 0:53:46.556542\n",
      "0.91262865\n",
      "[Epoch 36/50] [Batch 12/300] [D loss: 0.752339] [G loss: 0.514022] time: 0:53:46.842909\n",
      "0.9231606\n",
      "[Epoch 36/50] [Batch 13/300] [D loss: 0.752333] [G loss: 0.499822] time: 0:53:47.156519\n",
      "0.92814875\n",
      "[Epoch 36/50] [Batch 14/300] [D loss: 0.752332] [G loss: 0.490945] time: 0:53:47.452623\n",
      "0.90500814\n",
      "[Epoch 36/50] [Batch 15/300] [D loss: 0.752329] [G loss: 0.477021] time: 0:53:47.749518\n",
      "0.97126085\n",
      "[Epoch 36/50] [Batch 16/300] [D loss: 0.752330] [G loss: 0.477499] time: 0:53:48.044454\n",
      "0.9411995\n",
      "[Epoch 36/50] [Batch 17/300] [D loss: 0.752322] [G loss: 0.478660] time: 0:53:48.338627\n",
      "0.9474794\n",
      "[Epoch 36/50] [Batch 18/300] [D loss: 0.752320] [G loss: 0.486788] time: 0:53:48.631277\n",
      "0.95160866\n",
      "[Epoch 36/50] [Batch 19/300] [D loss: 0.752334] [G loss: 0.481028] time: 0:53:48.922055\n",
      "0.94283885\n",
      "[Epoch 36/50] [Batch 20/300] [D loss: 0.752319] [G loss: 0.490849] time: 0:53:49.201498\n",
      "0.894216\n",
      "[Epoch 36/50] [Batch 21/300] [D loss: 0.752322] [G loss: 0.469275] time: 0:53:49.492561\n",
      "0.9040342\n",
      "[Epoch 36/50] [Batch 22/300] [D loss: 0.752316] [G loss: 0.488193] time: 0:53:49.799855\n",
      "0.9754048\n",
      "[Epoch 36/50] [Batch 23/300] [D loss: 0.752315] [G loss: 0.483765] time: 0:53:50.108862\n",
      "0.8777062\n",
      "[Epoch 36/50] [Batch 24/300] [D loss: 0.752325] [G loss: 0.483046] time: 0:53:50.409537\n",
      "0.9292457\n",
      "[Epoch 36/50] [Batch 25/300] [D loss: 0.752313] [G loss: 0.480620] time: 0:53:50.701404\n",
      "0.9141354\n",
      "[Epoch 36/50] [Batch 26/300] [D loss: 0.752321] [G loss: 0.475901] time: 0:53:51.014046\n",
      "0.9443478\n",
      "[Epoch 36/50] [Batch 27/300] [D loss: 0.752319] [G loss: 0.503515] time: 0:53:51.315844\n",
      "0.8858556\n",
      "[Epoch 36/50] [Batch 28/300] [D loss: 0.752324] [G loss: 0.481601] time: 0:53:51.613709\n",
      "0.9157655\n",
      "[Epoch 36/50] [Batch 29/300] [D loss: 0.752324] [G loss: 0.477343] time: 0:53:51.912838\n",
      "0.94327927\n",
      "[Epoch 36/50] [Batch 30/300] [D loss: 0.752324] [G loss: 0.505029] time: 0:53:52.221846\n",
      "0.89624643\n",
      "[Epoch 36/50] [Batch 31/300] [D loss: 0.752339] [G loss: 0.485661] time: 0:53:52.522077\n",
      "0.9395163\n",
      "[Epoch 36/50] [Batch 32/300] [D loss: 0.752326] [G loss: 0.501829] time: 0:53:52.845553\n",
      "0.98144406\n",
      "[Epoch 36/50] [Batch 33/300] [D loss: 0.752357] [G loss: 0.493185] time: 0:53:53.157513\n",
      "0.93077594\n",
      "[Epoch 36/50] [Batch 34/300] [D loss: 0.752312] [G loss: 0.501079] time: 0:53:53.454735\n",
      "0.88503605\n",
      "[Epoch 36/50] [Batch 36/300] [D loss: 0.752323] [G loss: 0.481643] time: 0:53:53.771506\n",
      "0.9168298\n",
      "[Epoch 36/50] [Batch 37/300] [D loss: 0.752316] [G loss: 0.499971] time: 0:53:54.085083\n",
      "0.950131\n",
      "[Epoch 36/50] [Batch 38/300] [D loss: 0.752312] [G loss: 0.487749] time: 0:53:54.374732\n",
      "0.97291845\n",
      "[Epoch 36/50] [Batch 39/300] [D loss: 0.752342] [G loss: 0.476465] time: 0:53:54.675711\n",
      "0.9231117\n",
      "[Epoch 36/50] [Batch 40/300] [D loss: 0.752319] [G loss: 0.512936] time: 0:53:54.965340\n",
      "0.8956894\n",
      "[Epoch 36/50] [Batch 41/300] [D loss: 0.752314] [G loss: 0.486223] time: 0:53:55.266252\n",
      "0.92848635\n",
      "[Epoch 36/50] [Batch 42/300] [D loss: 0.752317] [G loss: 0.477511] time: 0:53:55.561173\n",
      "0.9330452\n",
      "[Epoch 36/50] [Batch 43/300] [D loss: 0.752346] [G loss: 0.483960] time: 0:53:55.860602\n",
      "0.93060535\n",
      "[Epoch 36/50] [Batch 44/300] [D loss: 0.752327] [G loss: 0.473929] time: 0:53:56.145768\n",
      "0.9404702\n",
      "[Epoch 36/50] [Batch 45/300] [D loss: 0.752324] [G loss: 0.489298] time: 0:53:56.437446\n",
      "0.9422741\n",
      "[Epoch 36/50] [Batch 46/300] [D loss: 0.752334] [G loss: 0.479908] time: 0:53:56.733417\n",
      "0.9150486\n",
      "[Epoch 36/50] [Batch 47/300] [D loss: 0.752321] [G loss: 0.489248] time: 0:53:57.018858\n",
      "0.9248666\n",
      "[Epoch 36/50] [Batch 48/300] [D loss: 0.752334] [G loss: 0.496950] time: 0:53:57.316183\n",
      "0.94638515\n",
      "[Epoch 36/50] [Batch 49/300] [D loss: 0.752319] [G loss: 0.472041] time: 0:53:57.609001\n",
      "0.95273095\n",
      "[Epoch 36/50] [Batch 50/300] [D loss: 0.752329] [G loss: 0.468645] time: 0:53:57.913650\n",
      "0.9735754\n",
      "[Epoch 36/50] [Batch 51/300] [D loss: 0.752326] [G loss: 0.488135] time: 0:53:58.218364\n",
      "0.9175785\n",
      "[Epoch 36/50] [Batch 52/300] [D loss: 0.752325] [G loss: 0.472138] time: 0:53:58.510169\n",
      "0.90556496\n",
      "[Epoch 36/50] [Batch 53/300] [D loss: 0.752317] [G loss: 0.477948] time: 0:53:58.804312\n",
      "0.90400416\n",
      "[Epoch 36/50] [Batch 54/300] [D loss: 0.752311] [G loss: 0.493424] time: 0:53:59.093933\n",
      "0.8884643\n",
      "[Epoch 36/50] [Batch 55/300] [D loss: 0.752327] [G loss: 0.489602] time: 0:53:59.408296\n",
      "0.895895\n",
      "[Epoch 36/50] [Batch 56/300] [D loss: 0.752326] [G loss: 0.473290] time: 0:53:59.699672\n",
      "0.91574717\n",
      "[Epoch 36/50] [Batch 57/300] [D loss: 0.752314] [G loss: 0.494963] time: 0:53:59.997341\n",
      "0.8865499\n",
      "[Epoch 36/50] [Batch 58/300] [D loss: 0.752326] [G loss: 0.475938] time: 0:54:00.299507\n",
      "0.93468046\n",
      "[Epoch 36/50] [Batch 59/300] [D loss: 0.752329] [G loss: 0.478546] time: 0:54:00.581652\n",
      "0.87795454\n",
      "[Epoch 36/50] [Batch 60/300] [D loss: 0.752345] [G loss: 0.496388] time: 0:54:00.873264\n",
      "0.857553\n",
      "[Epoch 36/50] [Batch 61/300] [D loss: 0.752329] [G loss: 0.499672] time: 0:54:01.188735\n",
      "0.9016681\n",
      "[Epoch 36/50] [Batch 62/300] [D loss: 0.752324] [G loss: 0.482512] time: 0:54:01.479202\n",
      "0.93897724\n",
      "[Epoch 36/50] [Batch 63/300] [D loss: 0.752320] [G loss: 0.487935] time: 0:54:01.791718\n",
      "0.94199395\n",
      "[Epoch 36/50] [Batch 64/300] [D loss: 0.752316] [G loss: 0.476294] time: 0:54:02.065905\n",
      "0.9270205\n",
      "[Epoch 36/50] [Batch 65/300] [D loss: 0.752320] [G loss: 0.480494] time: 0:54:02.350006\n",
      "0.94299793\n",
      "[Epoch 36/50] [Batch 66/300] [D loss: 0.752319] [G loss: 0.491236] time: 0:54:02.650126\n",
      "0.9061323\n",
      "[Epoch 36/50] [Batch 67/300] [D loss: 0.752315] [G loss: 0.485944] time: 0:54:02.946022\n",
      "0.89575416\n",
      "[Epoch 36/50] [Batch 68/300] [D loss: 0.752314] [G loss: 0.487814] time: 0:54:03.233394\n",
      "0.92839\n",
      "[Epoch 36/50] [Batch 69/300] [D loss: 0.752306] [G loss: 0.488542] time: 0:54:03.538444\n",
      "0.9396785\n",
      "[Epoch 36/50] [Batch 70/300] [D loss: 0.752309] [G loss: 0.488709] time: 0:54:03.824596\n",
      "0.883183\n",
      "[Epoch 36/50] [Batch 71/300] [D loss: 0.752340] [G loss: 0.476684] time: 0:54:04.134723\n",
      "0.9527939\n",
      "[Epoch 36/50] [Batch 72/300] [D loss: 0.752328] [G loss: 0.471739] time: 0:54:04.423923\n",
      "0.93101996\n",
      "[Epoch 36/50] [Batch 73/300] [D loss: 0.752324] [G loss: 0.470014] time: 0:54:04.735237\n",
      "0.9353094\n",
      "[Epoch 36/50] [Batch 74/300] [D loss: 0.752323] [G loss: 0.475505] time: 0:54:05.049876\n",
      "0.9337723\n",
      "[Epoch 36/50] [Batch 75/300] [D loss: 0.752316] [G loss: 0.469831] time: 0:54:05.360239\n",
      "0.93363243\n",
      "[Epoch 36/50] [Batch 76/300] [D loss: 0.752346] [G loss: 0.477686] time: 0:54:05.667820\n",
      "0.9122982\n",
      "[Epoch 36/50] [Batch 77/300] [D loss: 0.752321] [G loss: 0.492575] time: 0:54:05.970619\n",
      "0.93572927\n",
      "[Epoch 36/50] [Batch 78/300] [D loss: 0.752328] [G loss: 0.484022] time: 0:54:06.266625\n",
      "0.8994934\n",
      "[Epoch 36/50] [Batch 79/300] [D loss: 0.752322] [G loss: 0.499893] time: 0:54:06.571969\n",
      "0.91255\n",
      "[Epoch 36/50] [Batch 80/300] [D loss: 0.752316] [G loss: 0.472930] time: 0:54:06.870051\n",
      "0.92100745\n",
      "[Epoch 36/50] [Batch 81/300] [D loss: 0.752346] [G loss: 0.477663] time: 0:54:07.183567\n",
      "0.9277423\n",
      "[Epoch 36/50] [Batch 82/300] [D loss: 0.752314] [G loss: 0.496162] time: 0:54:07.515371\n",
      "0.9248342\n",
      "[Epoch 36/50] [Batch 83/300] [D loss: 0.752306] [G loss: 0.478412] time: 0:54:07.819845\n",
      "0.92326957\n",
      "[Epoch 36/50] [Batch 84/300] [D loss: 0.752314] [G loss: 0.486337] time: 0:54:08.120514\n",
      "0.90873384\n",
      "[Epoch 36/50] [Batch 85/300] [D loss: 0.752308] [G loss: 0.485272] time: 0:54:08.407199\n",
      "0.88350385\n",
      "[Epoch 36/50] [Batch 86/300] [D loss: 0.752330] [G loss: 0.491092] time: 0:54:08.704134\n",
      "0.887749\n",
      "[Epoch 36/50] [Batch 87/300] [D loss: 0.752320] [G loss: 0.479738] time: 0:54:09.018769\n",
      "0.9158948\n",
      "[Epoch 36/50] [Batch 88/300] [D loss: 0.752322] [G loss: 0.503563] time: 0:54:09.322908\n",
      "0.9753113\n",
      "[Epoch 36/50] [Batch 89/300] [D loss: 0.752316] [G loss: 0.476778] time: 0:54:09.621060\n",
      "0.87175304\n",
      "[Epoch 36/50] [Batch 90/300] [D loss: 0.752323] [G loss: 0.463287] time: 0:54:09.893910\n",
      "0.9336138\n",
      "[Epoch 36/50] [Batch 91/300] [D loss: 0.752322] [G loss: 0.470075] time: 0:54:10.197629\n",
      "0.9615845\n",
      "[Epoch 36/50] [Batch 92/300] [D loss: 0.752345] [G loss: 0.491731] time: 0:54:10.491750\n",
      "0.9399927\n",
      "[Epoch 36/50] [Batch 93/300] [D loss: 0.752333] [G loss: 0.470894] time: 0:54:10.794139\n",
      "0.9188328\n",
      "[Epoch 36/50] [Batch 94/300] [D loss: 0.752312] [G loss: 0.475885] time: 0:54:11.102172\n",
      "0.9224523\n",
      "[Epoch 36/50] [Batch 95/300] [D loss: 0.752322] [G loss: 0.477585] time: 0:54:11.405547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9152629\n",
      "[Epoch 36/50] [Batch 96/300] [D loss: 0.752326] [G loss: 0.491806] time: 0:54:11.711908\n",
      "0.88069636\n",
      "[Epoch 36/50] [Batch 97/300] [D loss: 0.752324] [G loss: 0.483055] time: 0:54:12.023211\n",
      "0.93514156\n",
      "[Epoch 36/50] [Batch 98/300] [D loss: 0.752316] [G loss: 0.470613] time: 0:54:12.333390\n",
      "0.9156441\n",
      "[Epoch 36/50] [Batch 99/300] [D loss: 0.752314] [G loss: 0.481028] time: 0:54:12.649143\n",
      "0.93333644\n",
      "[Epoch 36/50] [Batch 100/300] [D loss: 0.752331] [G loss: 0.474866] time: 0:54:12.946213\n",
      "0.94413775\n",
      "[Epoch 36/50] [Batch 101/300] [D loss: 0.752321] [G loss: 0.475044] time: 0:54:13.252952\n",
      "0.90559286\n",
      "[Epoch 36/50] [Batch 102/300] [D loss: 0.752314] [G loss: 0.470857] time: 0:54:13.557899\n",
      "0.93133926\n",
      "[Epoch 36/50] [Batch 103/300] [D loss: 0.752317] [G loss: 0.496051] time: 0:54:13.880101\n",
      "0.9529545\n",
      "[Epoch 36/50] [Batch 104/300] [D loss: 0.752314] [G loss: 0.469949] time: 0:54:14.142022\n",
      "0.94092494\n",
      "[Epoch 36/50] [Batch 105/300] [D loss: 0.752315] [G loss: 0.471303] time: 0:54:14.438628\n",
      "0.9318645\n",
      "[Epoch 36/50] [Batch 106/300] [D loss: 0.752322] [G loss: 0.482193] time: 0:54:14.723292\n",
      "0.9289896\n",
      "[Epoch 36/50] [Batch 107/300] [D loss: 0.752319] [G loss: 0.474385] time: 0:54:15.011311\n",
      "0.9082637\n",
      "[Epoch 36/50] [Batch 108/300] [D loss: 0.752311] [G loss: 0.471904] time: 0:54:15.315320\n",
      "0.92649627\n",
      "[Epoch 36/50] [Batch 109/300] [D loss: 0.752322] [G loss: 0.511415] time: 0:54:15.607671\n",
      "0.91773814\n",
      "[Epoch 36/50] [Batch 110/300] [D loss: 0.752322] [G loss: 0.494486] time: 0:54:15.910173\n",
      "0.88488525\n",
      "[Epoch 36/50] [Batch 111/300] [D loss: 0.752325] [G loss: 0.473686] time: 0:54:16.210750\n",
      "0.9099827\n",
      "[Epoch 36/50] [Batch 112/300] [D loss: 0.752318] [G loss: 0.508206] time: 0:54:16.501215\n",
      "0.9164613\n",
      "[Epoch 36/50] [Batch 113/300] [D loss: 0.752322] [G loss: 0.498604] time: 0:54:16.814249\n",
      "0.95055056\n",
      "[Epoch 36/50] [Batch 114/300] [D loss: 0.752324] [G loss: 0.475782] time: 0:54:17.117812\n",
      "0.94211864\n",
      "[Epoch 36/50] [Batch 115/300] [D loss: 0.752339] [G loss: 0.483928] time: 0:54:17.417997\n",
      "0.91415524\n",
      "[Epoch 36/50] [Batch 116/300] [D loss: 0.752303] [G loss: 0.493198] time: 0:54:17.719794\n",
      "0.9354973\n",
      "[Epoch 36/50] [Batch 117/300] [D loss: 0.752312] [G loss: 0.484958] time: 0:54:18.018382\n",
      "0.9208946\n",
      "[Epoch 36/50] [Batch 118/300] [D loss: 0.752314] [G loss: 0.487299] time: 0:54:18.319953\n",
      "0.920417\n",
      "[Epoch 36/50] [Batch 119/300] [D loss: 0.752331] [G loss: 0.475958] time: 0:54:18.627580\n",
      "0.9179298\n",
      "[Epoch 36/50] [Batch 120/300] [D loss: 0.752325] [G loss: 0.470288] time: 0:54:18.916171\n",
      "0.9058221\n",
      "[Epoch 36/50] [Batch 121/300] [D loss: 0.752318] [G loss: 0.483530] time: 0:54:19.203986\n",
      "0.94787985\n",
      "[Epoch 36/50] [Batch 122/300] [D loss: 0.752329] [G loss: 0.482533] time: 0:54:19.512346\n",
      "0.9466141\n",
      "[Epoch 36/50] [Batch 123/300] [D loss: 0.752331] [G loss: 0.481651] time: 0:54:19.804135\n",
      "0.90375715\n",
      "[Epoch 36/50] [Batch 124/300] [D loss: 0.752314] [G loss: 0.483006] time: 0:54:20.100694\n",
      "0.96893835\n",
      "[Epoch 36/50] [Batch 125/300] [D loss: 0.752329] [G loss: 0.493646] time: 0:54:20.404231\n",
      "0.9298024\n",
      "[Epoch 36/50] [Batch 126/300] [D loss: 0.752343] [G loss: 0.478388] time: 0:54:20.698671\n",
      "0.8846801\n",
      "[Epoch 36/50] [Batch 127/300] [D loss: 0.752326] [G loss: 0.476377] time: 0:54:20.989849\n",
      "0.94223434\n",
      "[Epoch 36/50] [Batch 128/300] [D loss: 0.752323] [G loss: 0.480439] time: 0:54:21.291787\n",
      "0.91804284\n",
      "[Epoch 36/50] [Batch 129/300] [D loss: 0.752298] [G loss: 0.474868] time: 0:54:21.593304\n",
      "0.94263583\n",
      "[Epoch 36/50] [Batch 130/300] [D loss: 0.752323] [G loss: 0.479288] time: 0:54:21.883813\n",
      "0.9254217\n",
      "[Epoch 36/50] [Batch 131/300] [D loss: 0.752324] [G loss: 0.473279] time: 0:54:22.167441\n",
      "0.8810429\n",
      "[Epoch 36/50] [Batch 132/300] [D loss: 0.752317] [G loss: 0.483043] time: 0:54:22.467463\n",
      "0.9119544\n",
      "[Epoch 36/50] [Batch 133/300] [D loss: 0.752313] [G loss: 0.482468] time: 0:54:22.758042\n",
      "0.92131513\n",
      "[Epoch 36/50] [Batch 134/300] [D loss: 0.752323] [G loss: 0.495645] time: 0:54:23.059605\n",
      "0.910141\n",
      "[Epoch 36/50] [Batch 135/300] [D loss: 0.752314] [G loss: 0.472433] time: 0:54:23.343313\n",
      "0.92734575\n",
      "[Epoch 36/50] [Batch 136/300] [D loss: 0.752315] [G loss: 0.481660] time: 0:54:23.633916\n",
      "0.95345765\n",
      "[Epoch 36/50] [Batch 137/300] [D loss: 0.752321] [G loss: 0.471721] time: 0:54:23.932194\n",
      "0.8836716\n",
      "[Epoch 36/50] [Batch 138/300] [D loss: 0.752316] [G loss: 0.474783] time: 0:54:24.225000\n",
      "0.91193587\n",
      "[Epoch 36/50] [Batch 139/300] [D loss: 0.752320] [G loss: 0.503216] time: 0:54:24.674321\n",
      "0.916888\n",
      "[Epoch 36/50] [Batch 140/300] [D loss: 0.752316] [G loss: 0.480955] time: 0:54:24.959144\n",
      "0.9114492\n",
      "[Epoch 36/50] [Batch 141/300] [D loss: 0.752321] [G loss: 0.516961] time: 0:54:25.258516\n",
      "0.9118119\n",
      "[Epoch 36/50] [Batch 142/300] [D loss: 0.752319] [G loss: 0.469434] time: 0:54:25.546315\n",
      "0.91725713\n",
      "[Epoch 36/50] [Batch 143/300] [D loss: 0.752316] [G loss: 0.471771] time: 0:54:25.826756\n",
      "0.8834169\n",
      "[Epoch 36/50] [Batch 144/300] [D loss: 0.752311] [G loss: 0.475087] time: 0:54:26.114011\n",
      "0.90849733\n",
      "[Epoch 36/50] [Batch 145/300] [D loss: 0.752303] [G loss: 0.485341] time: 0:54:26.398028\n",
      "0.907521\n",
      "[Epoch 36/50] [Batch 146/300] [D loss: 0.752303] [G loss: 0.494301] time: 0:54:26.700821\n",
      "0.93111044\n",
      "[Epoch 36/50] [Batch 147/300] [D loss: 0.752339] [G loss: 0.493494] time: 0:54:26.989672\n",
      "0.8806456\n",
      "[Epoch 36/50] [Batch 148/300] [D loss: 0.752318] [G loss: 0.475482] time: 0:54:27.280155\n",
      "0.9032197\n",
      "[Epoch 36/50] [Batch 149/300] [D loss: 0.752310] [G loss: 0.473129] time: 0:54:27.609143\n",
      "0.93839955\n",
      "[Epoch 36/50] [Batch 150/300] [D loss: 0.752318] [G loss: 0.477101] time: 0:54:27.909621\n",
      "0.945024\n",
      "[Epoch 36/50] [Batch 151/300] [D loss: 0.752320] [G loss: 0.476099] time: 0:54:28.193865\n",
      "0.9300883\n",
      "[Epoch 36/50] [Batch 152/300] [D loss: 0.752327] [G loss: 0.480872] time: 0:54:28.471625\n",
      "0.91568685\n",
      "[Epoch 36/50] [Batch 153/300] [D loss: 0.752331] [G loss: 0.483374] time: 0:54:28.773833\n",
      "0.921573\n",
      "[Epoch 36/50] [Batch 154/300] [D loss: 0.752313] [G loss: 0.477415] time: 0:54:29.083939\n",
      "0.9314625\n",
      "[Epoch 36/50] [Batch 155/300] [D loss: 0.752321] [G loss: 0.478372] time: 0:54:29.372253\n",
      "0.97134477\n",
      "[Epoch 36/50] [Batch 156/300] [D loss: 0.752321] [G loss: 0.479065] time: 0:54:29.679949\n",
      "0.95259213\n",
      "[Epoch 36/50] [Batch 157/300] [D loss: 0.752312] [G loss: 0.473082] time: 0:54:29.978298\n",
      "0.9177041\n",
      "[Epoch 36/50] [Batch 158/300] [D loss: 0.752314] [G loss: 0.479711] time: 0:54:30.273708\n",
      "0.92519283\n",
      "[Epoch 36/50] [Batch 159/300] [D loss: 0.752311] [G loss: 0.483958] time: 0:54:30.590147\n",
      "0.93541986\n",
      "[Epoch 36/50] [Batch 160/300] [D loss: 0.752315] [G loss: 0.478470] time: 0:54:30.890541\n",
      "0.9060006\n",
      "[Epoch 36/50] [Batch 161/300] [D loss: 0.752315] [G loss: 0.494072] time: 0:54:31.183080\n",
      "0.8990906\n",
      "[Epoch 36/50] [Batch 162/300] [D loss: 0.752336] [G loss: 0.471049] time: 0:54:31.483850\n",
      "0.94765633\n",
      "[Epoch 36/50] [Batch 163/300] [D loss: 0.752316] [G loss: 0.481901] time: 0:54:31.770367\n",
      "0.9293861\n",
      "[Epoch 36/50] [Batch 164/300] [D loss: 0.752309] [G loss: 0.476564] time: 0:54:32.073793\n",
      "0.9054505\n",
      "[Epoch 36/50] [Batch 165/300] [D loss: 0.752325] [G loss: 0.478420] time: 0:54:32.371287\n",
      "0.8959534\n",
      "[Epoch 36/50] [Batch 166/300] [D loss: 0.752313] [G loss: 0.489691] time: 0:54:32.672291\n",
      "0.8941529\n",
      "[Epoch 36/50] [Batch 167/300] [D loss: 0.752318] [G loss: 0.476905] time: 0:54:32.980872\n",
      "0.9358957\n",
      "[Epoch 36/50] [Batch 168/300] [D loss: 0.752320] [G loss: 0.498427] time: 0:54:33.276777\n",
      "0.86792904\n",
      "[Epoch 36/50] [Batch 169/300] [D loss: 0.752327] [G loss: 0.473703] time: 0:54:33.581339\n",
      "0.8718446\n",
      "[Epoch 36/50] [Batch 170/300] [D loss: 0.752330] [G loss: 0.481954] time: 0:54:33.870907\n",
      "0.953243\n",
      "[Epoch 36/50] [Batch 171/300] [D loss: 0.752311] [G loss: 0.469103] time: 0:54:34.173499\n",
      "0.91287225\n",
      "[Epoch 36/50] [Batch 172/300] [D loss: 0.752327] [G loss: 0.477585] time: 0:54:34.486078\n",
      "0.9413655\n",
      "[Epoch 36/50] [Batch 173/300] [D loss: 0.752328] [G loss: 0.478585] time: 0:54:34.793097\n",
      "0.9331587\n",
      "[Epoch 36/50] [Batch 174/300] [D loss: 0.752311] [G loss: 0.468819] time: 0:54:35.081758\n",
      "0.94276124\n",
      "[Epoch 36/50] [Batch 175/300] [D loss: 0.752305] [G loss: 0.480341] time: 0:54:35.364788\n",
      "0.92350215\n",
      "[Epoch 36/50] [Batch 176/300] [D loss: 0.752318] [G loss: 0.477353] time: 0:54:35.666125\n",
      "0.8959604\n",
      "[Epoch 36/50] [Batch 177/300] [D loss: 0.752334] [G loss: 0.485754] time: 0:54:35.978047\n",
      "0.95334315\n",
      "[Epoch 36/50] [Batch 178/300] [D loss: 0.752322] [G loss: 0.511172] time: 0:54:36.279629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94385344\n",
      "[Epoch 36/50] [Batch 179/300] [D loss: 0.752325] [G loss: 0.473911] time: 0:54:36.583907\n",
      "0.88985616\n",
      "[Epoch 36/50] [Batch 180/300] [D loss: 0.752327] [G loss: 0.476038] time: 0:54:36.856649\n",
      "0.8916731\n",
      "[Epoch 36/50] [Batch 181/300] [D loss: 0.752307] [G loss: 0.499427] time: 0:54:37.147354\n",
      "0.88320565\n",
      "[Epoch 36/50] [Batch 182/300] [D loss: 0.752332] [G loss: 0.497083] time: 0:54:37.436022\n",
      "0.9333653\n",
      "[Epoch 36/50] [Batch 183/300] [D loss: 0.752305] [G loss: 0.473920] time: 0:54:37.723751\n",
      "0.96892524\n",
      "[Epoch 36/50] [Batch 184/300] [D loss: 0.752329] [G loss: 0.470943] time: 0:54:38.026450\n",
      "0.9340825\n",
      "[Epoch 36/50] [Batch 185/300] [D loss: 0.752327] [G loss: 0.470023] time: 0:54:38.317906\n",
      "0.8740401\n",
      "[Epoch 36/50] [Batch 186/300] [D loss: 0.752323] [G loss: 0.475738] time: 0:54:38.599224\n",
      "0.9293234\n",
      "[Epoch 36/50] [Batch 187/300] [D loss: 0.752309] [G loss: 0.476939] time: 0:54:38.889024\n",
      "0.9367797\n",
      "[Epoch 36/50] [Batch 188/300] [D loss: 0.752313] [G loss: 0.473982] time: 0:54:39.178676\n",
      "0.95417476\n",
      "[Epoch 36/50] [Batch 189/300] [D loss: 0.752314] [G loss: 0.481675] time: 0:54:39.469802\n",
      "0.9169969\n",
      "[Epoch 36/50] [Batch 190/300] [D loss: 0.752310] [G loss: 0.526120] time: 0:54:39.755874\n",
      "0.92837554\n",
      "[Epoch 36/50] [Batch 191/300] [D loss: 0.752311] [G loss: 0.481988] time: 0:54:40.053511\n",
      "0.93779683\n",
      "[Epoch 36/50] [Batch 192/300] [D loss: 0.752318] [G loss: 0.481649] time: 0:54:40.352648\n",
      "0.9136305\n",
      "[Epoch 36/50] [Batch 193/300] [D loss: 0.752315] [G loss: 0.473029] time: 0:54:40.638631\n",
      "0.9369871\n",
      "[Epoch 36/50] [Batch 194/300] [D loss: 0.752320] [G loss: 0.470877] time: 0:54:40.928511\n",
      "0.95319915\n",
      "[Epoch 36/50] [Batch 195/300] [D loss: 0.752319] [G loss: 0.479774] time: 0:54:41.215772\n",
      "0.9394903\n",
      "[Epoch 36/50] [Batch 196/300] [D loss: 0.752308] [G loss: 0.471674] time: 0:54:41.512098\n",
      "0.9161106\n",
      "[Epoch 36/50] [Batch 197/300] [D loss: 0.752314] [G loss: 0.476570] time: 0:54:41.800790\n",
      "0.9624167\n",
      "[Epoch 36/50] [Batch 198/300] [D loss: 0.752321] [G loss: 0.494760] time: 0:54:42.108671\n",
      "0.89865804\n",
      "[Epoch 36/50] [Batch 199/300] [D loss: 0.752302] [G loss: 0.531018] time: 0:54:42.427346\n",
      "0.89909315\n",
      "[Epoch 36/50] [Batch 200/300] [D loss: 0.752314] [G loss: 0.476908] time: 0:54:42.726709\n",
      "0.9380226\n",
      "[Epoch 36/50] [Batch 201/300] [D loss: 0.752320] [G loss: 0.505305] time: 0:54:43.020815\n",
      "0.8862378\n",
      "[Epoch 36/50] [Batch 202/300] [D loss: 0.752331] [G loss: 0.477583] time: 0:54:43.309551\n",
      "0.92691284\n",
      "[Epoch 36/50] [Batch 203/300] [D loss: 0.752323] [G loss: 0.491781] time: 0:54:43.600800\n",
      "0.9495564\n",
      "[Epoch 36/50] [Batch 204/300] [D loss: 0.752319] [G loss: 0.493876] time: 0:54:43.897262\n",
      "0.88892454\n",
      "[Epoch 36/50] [Batch 205/300] [D loss: 0.752313] [G loss: 0.481935] time: 0:54:44.200654\n",
      "0.9176323\n",
      "[Epoch 36/50] [Batch 206/300] [D loss: 0.752309] [G loss: 0.473657] time: 0:54:44.508340\n",
      "0.9531512\n",
      "[Epoch 36/50] [Batch 207/300] [D loss: 0.752321] [G loss: 0.476202] time: 0:54:44.812249\n",
      "0.94321054\n",
      "[Epoch 36/50] [Batch 208/300] [D loss: 0.752316] [G loss: 0.473271] time: 0:54:45.113235\n",
      "0.9128008\n",
      "[Epoch 36/50] [Batch 209/300] [D loss: 0.752315] [G loss: 0.471619] time: 0:54:45.422461\n",
      "0.94133544\n",
      "[Epoch 36/50] [Batch 210/300] [D loss: 0.752316] [G loss: 0.492255] time: 0:54:45.713688\n",
      "0.9358804\n",
      "[Epoch 36/50] [Batch 211/300] [D loss: 0.752323] [G loss: 0.472033] time: 0:54:45.997518\n",
      "0.9493222\n",
      "[Epoch 36/50] [Batch 212/300] [D loss: 0.752312] [G loss: 0.474662] time: 0:54:46.286116\n",
      "0.919975\n",
      "[Epoch 36/50] [Batch 213/300] [D loss: 0.752314] [G loss: 0.479743] time: 0:54:46.576507\n",
      "0.8787649\n",
      "[Epoch 36/50] [Batch 214/300] [D loss: 0.752319] [G loss: 0.487711] time: 0:54:46.887590\n",
      "0.90544224\n",
      "[Epoch 36/50] [Batch 215/300] [D loss: 0.752322] [G loss: 0.489473] time: 0:54:47.143071\n",
      "0.9088514\n",
      "[Epoch 36/50] [Batch 216/300] [D loss: 0.752312] [G loss: 0.504367] time: 0:54:47.438431\n",
      "0.930726\n",
      "[Epoch 36/50] [Batch 217/300] [D loss: 0.752318] [G loss: 0.474745] time: 0:54:47.746163\n",
      "0.93824273\n",
      "[Epoch 36/50] [Batch 218/300] [D loss: 0.752324] [G loss: 0.471440] time: 0:54:48.048744\n",
      "0.9714773\n",
      "[Epoch 36/50] [Batch 219/300] [D loss: 0.752325] [G loss: 0.486088] time: 0:54:48.350305\n",
      "0.94337815\n",
      "[Epoch 36/50] [Batch 220/300] [D loss: 0.752297] [G loss: 0.493263] time: 0:54:48.662427\n",
      "0.91399294\n",
      "[Epoch 36/50] [Batch 221/300] [D loss: 0.752307] [G loss: 0.489325] time: 0:54:48.951046\n",
      "0.9508516\n",
      "[Epoch 36/50] [Batch 222/300] [D loss: 0.752331] [G loss: 0.474534] time: 0:54:49.269207\n",
      "0.92568463\n",
      "[Epoch 36/50] [Batch 223/300] [D loss: 0.752337] [G loss: 0.482349] time: 0:54:49.563230\n",
      "0.9414408\n",
      "[Epoch 36/50] [Batch 224/300] [D loss: 0.752307] [G loss: 0.489162] time: 0:54:49.842630\n",
      "0.9331589\n",
      "[Epoch 36/50] [Batch 225/300] [D loss: 0.752303] [G loss: 0.477299] time: 0:54:50.140607\n",
      "0.9421129\n",
      "[Epoch 36/50] [Batch 226/300] [D loss: 0.752318] [G loss: 0.534953] time: 0:54:50.428772\n",
      "0.9002647\n",
      "[Epoch 36/50] [Batch 227/300] [D loss: 0.752304] [G loss: 0.509423] time: 0:54:50.738830\n",
      "0.9112491\n",
      "[Epoch 36/50] [Batch 228/300] [D loss: 0.752311] [G loss: 0.481189] time: 0:54:51.052238\n",
      "0.97738314\n",
      "[Epoch 36/50] [Batch 229/300] [D loss: 0.752319] [G loss: 0.479910] time: 0:54:51.349898\n",
      "0.90555066\n",
      "[Epoch 36/50] [Batch 230/300] [D loss: 0.752314] [G loss: 0.511232] time: 0:54:51.638705\n",
      "0.9161585\n",
      "[Epoch 36/50] [Batch 231/300] [D loss: 0.752311] [G loss: 0.483713] time: 0:54:51.927170\n",
      "0.8746355\n",
      "[Epoch 36/50] [Batch 232/300] [D loss: 0.752319] [G loss: 0.482942] time: 0:54:52.224023\n",
      "0.90352416\n",
      "[Epoch 36/50] [Batch 233/300] [D loss: 0.752319] [G loss: 0.496542] time: 0:54:52.532201\n",
      "0.88486654\n",
      "[Epoch 36/50] [Batch 234/300] [D loss: 0.752319] [G loss: 0.473474] time: 0:54:52.833838\n",
      "0.9347066\n",
      "[Epoch 36/50] [Batch 235/300] [D loss: 0.752339] [G loss: 0.494770] time: 0:54:53.115453\n",
      "0.89512545\n",
      "[Epoch 36/50] [Batch 236/300] [D loss: 0.752309] [G loss: 0.484533] time: 0:54:53.413174\n",
      "0.9103496\n",
      "[Epoch 36/50] [Batch 237/300] [D loss: 0.752317] [G loss: 0.477462] time: 0:54:53.702382\n",
      "0.8860307\n",
      "[Epoch 36/50] [Batch 238/300] [D loss: 0.752319] [G loss: 0.474370] time: 0:54:53.994560\n",
      "0.94862556\n",
      "[Epoch 36/50] [Batch 239/300] [D loss: 0.752322] [G loss: 0.502121] time: 0:54:54.305062\n",
      "0.88727146\n",
      "[Epoch 36/50] [Batch 240/300] [D loss: 0.752326] [G loss: 0.478566] time: 0:54:54.595987\n",
      "0.9265352\n",
      "[Epoch 36/50] [Batch 241/300] [D loss: 0.752328] [G loss: 0.500323] time: 0:54:54.895174\n",
      "0.9054551\n",
      "[Epoch 36/50] [Batch 242/300] [D loss: 0.752327] [G loss: 0.487269] time: 0:54:55.191424\n",
      "0.89612055\n",
      "[Epoch 36/50] [Batch 243/300] [D loss: 0.752320] [G loss: 0.487624] time: 0:54:55.492151\n",
      "0.8873203\n",
      "[Epoch 36/50] [Batch 244/300] [D loss: 0.752307] [G loss: 0.487036] time: 0:54:55.800121\n",
      "0.8825887\n",
      "[Epoch 36/50] [Batch 245/300] [D loss: 0.752316] [G loss: 0.481655] time: 0:54:56.119374\n",
      "0.89957255\n",
      "[Epoch 36/50] [Batch 246/300] [D loss: 0.752311] [G loss: 0.477950] time: 0:54:56.420104\n",
      "0.9058028\n",
      "[Epoch 36/50] [Batch 247/300] [D loss: 0.752314] [G loss: 0.483167] time: 0:54:56.710632\n",
      "0.9221161\n",
      "[Epoch 36/50] [Batch 248/300] [D loss: 0.752326] [G loss: 0.502309] time: 0:54:57.015594\n",
      "0.9321461\n",
      "[Epoch 36/50] [Batch 249/300] [D loss: 0.752308] [G loss: 0.494614] time: 0:54:57.326879\n",
      "0.91896266\n",
      "[Epoch 36/50] [Batch 250/300] [D loss: 0.752327] [G loss: 0.480673] time: 0:54:57.626289\n",
      "0.9430439\n",
      "[Epoch 36/50] [Batch 251/300] [D loss: 0.752330] [G loss: 0.474828] time: 0:54:57.933653\n",
      "0.9158167\n",
      "[Epoch 36/50] [Batch 252/300] [D loss: 0.752308] [G loss: 0.474459] time: 0:54:58.238608\n",
      "0.8749234\n",
      "[Epoch 36/50] [Batch 253/300] [D loss: 0.752323] [G loss: 0.487991] time: 0:54:58.558217\n",
      "0.9141509\n",
      "[Epoch 36/50] [Batch 254/300] [D loss: 0.752324] [G loss: 0.477992] time: 0:54:58.852158\n",
      "0.9217308\n",
      "[Epoch 36/50] [Batch 255/300] [D loss: 0.752314] [G loss: 0.484876] time: 0:54:59.155673\n",
      "0.9338856\n",
      "[Epoch 36/50] [Batch 256/300] [D loss: 0.752312] [G loss: 0.499794] time: 0:54:59.441842\n",
      "0.8825107\n",
      "[Epoch 36/50] [Batch 257/300] [D loss: 0.752303] [G loss: 0.500142] time: 0:54:59.739549\n",
      "0.9462196\n",
      "[Epoch 36/50] [Batch 258/300] [D loss: 0.752314] [G loss: 0.478976] time: 0:55:00.042495\n",
      "0.92487997\n",
      "[Epoch 36/50] [Batch 259/300] [D loss: 0.752315] [G loss: 0.482096] time: 0:55:00.362280\n",
      "0.8999403\n",
      "[Epoch 36/50] [Batch 260/300] [D loss: 0.752315] [G loss: 0.479016] time: 0:55:00.670528\n",
      "0.9333181\n",
      "[Epoch 36/50] [Batch 261/300] [D loss: 0.752316] [G loss: 0.488533] time: 0:55:00.961697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9742701\n",
      "[Epoch 36/50] [Batch 262/300] [D loss: 0.752320] [G loss: 0.466943] time: 0:55:01.258029\n",
      "0.8942403\n",
      "[Epoch 36/50] [Batch 263/300] [D loss: 0.752300] [G loss: 0.487715] time: 0:55:01.546879\n",
      "0.9113383\n",
      "[Epoch 36/50] [Batch 264/300] [D loss: 0.752319] [G loss: 0.491147] time: 0:55:01.831271\n",
      "0.86757976\n",
      "[Epoch 36/50] [Batch 265/300] [D loss: 0.752306] [G loss: 0.487479] time: 0:55:02.112294\n",
      "0.94505006\n",
      "[Epoch 36/50] [Batch 266/300] [D loss: 0.752317] [G loss: 0.493597] time: 0:55:02.392405\n",
      "0.88672954\n",
      "[Epoch 36/50] [Batch 267/300] [D loss: 0.752301] [G loss: 0.470882] time: 0:55:02.694167\n",
      "0.9153121\n",
      "[Epoch 36/50] [Batch 268/300] [D loss: 0.752324] [G loss: 0.476595] time: 0:55:02.987757\n",
      "0.88111854\n",
      "[Epoch 36/50] [Batch 269/300] [D loss: 0.752303] [G loss: 0.487754] time: 0:55:03.291685\n",
      "0.9410735\n",
      "[Epoch 36/50] [Batch 270/300] [D loss: 0.752292] [G loss: 0.482002] time: 0:55:03.598981\n",
      "0.9310742\n",
      "[Epoch 36/50] [Batch 271/300] [D loss: 0.752300] [G loss: 0.478835] time: 0:55:03.889449\n",
      "0.884041\n",
      "[Epoch 36/50] [Batch 272/300] [D loss: 0.752308] [G loss: 0.492456] time: 0:55:04.185740\n",
      "0.92470527\n",
      "[Epoch 36/50] [Batch 273/300] [D loss: 0.752304] [G loss: 0.487370] time: 0:55:04.467623\n",
      "0.93037575\n",
      "[Epoch 36/50] [Batch 274/300] [D loss: 0.752333] [G loss: 0.476663] time: 0:55:04.758954\n",
      "0.944315\n",
      "[Epoch 36/50] [Batch 275/300] [D loss: 0.752316] [G loss: 0.492957] time: 0:55:05.048016\n",
      "0.8764441\n",
      "[Epoch 36/50] [Batch 276/300] [D loss: 0.752319] [G loss: 0.493724] time: 0:55:05.332751\n",
      "0.95158666\n",
      "[Epoch 36/50] [Batch 277/300] [D loss: 0.752328] [G loss: 0.470561] time: 0:55:05.633677\n",
      "0.9331629\n",
      "[Epoch 36/50] [Batch 278/300] [D loss: 0.752317] [G loss: 0.481014] time: 0:55:05.928940\n",
      "0.9100029\n",
      "[Epoch 36/50] [Batch 279/300] [D loss: 0.752319] [G loss: 0.479872] time: 0:55:06.246433\n",
      "0.88969016\n",
      "[Epoch 36/50] [Batch 280/300] [D loss: 0.752315] [G loss: 0.479798] time: 0:55:06.544893\n",
      "0.9509893\n",
      "[Epoch 36/50] [Batch 281/300] [D loss: 0.752306] [G loss: 0.491536] time: 0:55:06.827762\n",
      "0.9534261\n",
      "[Epoch 36/50] [Batch 282/300] [D loss: 0.752322] [G loss: 0.512415] time: 0:55:07.127476\n",
      "0.9398742\n",
      "[Epoch 36/50] [Batch 283/300] [D loss: 0.752343] [G loss: 0.494616] time: 0:55:07.429181\n",
      "0.9836505\n",
      "[Epoch 36/50] [Batch 284/300] [D loss: 0.752338] [G loss: 0.473457] time: 0:55:07.750504\n",
      "0.906761\n",
      "[Epoch 36/50] [Batch 285/300] [D loss: 0.752311] [G loss: 0.487287] time: 0:55:08.036836\n",
      "0.91157365\n",
      "[Epoch 36/50] [Batch 286/300] [D loss: 0.752328] [G loss: 0.488297] time: 0:55:08.348754\n",
      "0.9071972\n",
      "[Epoch 36/50] [Batch 287/300] [D loss: 0.752313] [G loss: 0.477315] time: 0:55:08.636845\n",
      "0.9229571\n",
      "[Epoch 36/50] [Batch 288/300] [D loss: 0.752310] [G loss: 0.474472] time: 0:55:08.928416\n",
      "0.9347792\n",
      "[Epoch 36/50] [Batch 289/300] [D loss: 0.752323] [G loss: 0.470052] time: 0:55:09.229223\n",
      "0.9092817\n",
      "[Epoch 36/50] [Batch 290/300] [D loss: 0.752330] [G loss: 0.481403] time: 0:55:09.514276\n",
      "0.9617947\n",
      "[Epoch 36/50] [Batch 291/300] [D loss: 0.752316] [G loss: 0.472693] time: 0:55:09.824662\n",
      "0.90927976\n",
      "[Epoch 36/50] [Batch 292/300] [D loss: 0.752315] [G loss: 0.487713] time: 0:55:10.121227\n",
      "0.935261\n",
      "[Epoch 36/50] [Batch 293/300] [D loss: 0.752314] [G loss: 0.501239] time: 0:55:10.420866\n",
      "0.9406846\n",
      "[Epoch 36/50] [Batch 294/300] [D loss: 0.752321] [G loss: 0.491145] time: 0:55:10.746040\n",
      "0.9214495\n",
      "[Epoch 36/50] [Batch 295/300] [D loss: 0.752324] [G loss: 0.474741] time: 0:55:11.037355\n",
      "0.87871224\n",
      "[Epoch 36/50] [Batch 296/300] [D loss: 0.752326] [G loss: 0.483265] time: 0:55:11.319995\n",
      "0.93337727\n",
      "[Epoch 36/50] [Batch 297/300] [D loss: 0.752310] [G loss: 0.472369] time: 0:55:11.626800\n",
      "0.88828343\n",
      "[Epoch 36/50] [Batch 298/300] [D loss: 0.752320] [G loss: 0.479401] time: 0:55:11.911243\n",
      "0.95298624\n",
      "[Epoch 36/50] [Batch 299/300] [D loss: 0.752329] [G loss: 0.488873] time: 0:55:12.216497\n",
      "0.9057906\n",
      "[Epoch 37/50] [Batch 0/300] [D loss: 0.752309] [G loss: 0.507898] time: 0:55:12.506873\n",
      "0.92820257\n",
      "[Epoch 37/50] [Batch 1/300] [D loss: 0.752316] [G loss: 0.472510] time: 0:55:12.803072\n",
      "0.9530869\n",
      "[Epoch 37/50] [Batch 2/300] [D loss: 0.752314] [G loss: 0.483385] time: 0:55:13.081386\n",
      "0.9313387\n",
      "[Epoch 37/50] [Batch 3/300] [D loss: 0.752313] [G loss: 0.481622] time: 0:55:13.360734\n",
      "0.9377242\n",
      "[Epoch 37/50] [Batch 4/300] [D loss: 0.752310] [G loss: 0.500698] time: 0:55:13.651247\n",
      "0.88119507\n",
      "[Epoch 37/50] [Batch 5/300] [D loss: 0.752317] [G loss: 0.490618] time: 0:55:13.940971\n",
      "0.886034\n",
      "[Epoch 37/50] [Batch 6/300] [D loss: 0.752312] [G loss: 0.479651] time: 0:55:14.212917\n",
      "0.90623784\n",
      "[Epoch 37/50] [Batch 7/300] [D loss: 0.752320] [G loss: 0.487343] time: 0:55:14.501903\n",
      "0.9350116\n",
      "[Epoch 37/50] [Batch 8/300] [D loss: 0.752308] [G loss: 0.473158] time: 0:55:14.799409\n",
      "0.97167873\n",
      "[Epoch 37/50] [Batch 9/300] [D loss: 0.752313] [G loss: 0.477866] time: 0:55:15.107138\n",
      "0.932977\n",
      "[Epoch 37/50] [Batch 10/300] [D loss: 0.752316] [G loss: 0.488735] time: 0:55:15.413189\n",
      "0.92801017\n",
      "[Epoch 37/50] [Batch 11/300] [D loss: 0.752311] [G loss: 0.484273] time: 0:55:15.710691\n",
      "0.9333003\n",
      "[Epoch 37/50] [Batch 12/300] [D loss: 0.752295] [G loss: 0.482793] time: 0:55:16.017518\n",
      "0.93073606\n",
      "[Epoch 37/50] [Batch 13/300] [D loss: 0.752315] [G loss: 0.474081] time: 0:55:16.314365\n",
      "0.9573725\n",
      "[Epoch 37/50] [Batch 14/300] [D loss: 0.752303] [G loss: 0.475251] time: 0:55:16.632611\n",
      "0.89793617\n",
      "[Epoch 37/50] [Batch 15/300] [D loss: 0.752339] [G loss: 0.496463] time: 0:55:16.927496\n",
      "0.90641993\n",
      "[Epoch 37/50] [Batch 16/300] [D loss: 0.752318] [G loss: 0.479033] time: 0:55:17.226134\n",
      "0.94205284\n",
      "[Epoch 37/50] [Batch 17/300] [D loss: 0.752320] [G loss: 0.478367] time: 0:55:17.527781\n",
      "0.9618357\n",
      "[Epoch 37/50] [Batch 18/300] [D loss: 0.752320] [G loss: 0.476781] time: 0:55:17.827259\n",
      "0.932394\n",
      "[Epoch 37/50] [Batch 19/300] [D loss: 0.752314] [G loss: 0.484676] time: 0:55:18.111536\n",
      "0.9479869\n",
      "[Epoch 37/50] [Batch 20/300] [D loss: 0.752328] [G loss: 0.477377] time: 0:55:18.406331\n",
      "0.94124293\n",
      "[Epoch 37/50] [Batch 21/300] [D loss: 0.752317] [G loss: 0.479396] time: 0:55:18.701595\n",
      "0.90863633\n",
      "[Epoch 37/50] [Batch 22/300] [D loss: 0.752319] [G loss: 0.471069] time: 0:55:19.001388\n",
      "0.9683664\n",
      "[Epoch 37/50] [Batch 23/300] [D loss: 0.752326] [G loss: 0.472439] time: 0:55:19.288465\n",
      "0.9055849\n",
      "[Epoch 37/50] [Batch 24/300] [D loss: 0.752329] [G loss: 0.483477] time: 0:55:19.607062\n",
      "0.94491297\n",
      "[Epoch 37/50] [Batch 25/300] [D loss: 0.752307] [G loss: 0.482055] time: 0:55:19.892010\n",
      "0.914311\n",
      "[Epoch 37/50] [Batch 26/300] [D loss: 0.752301] [G loss: 0.504469] time: 0:55:20.173969\n",
      "0.9085328\n",
      "[Epoch 37/50] [Batch 27/300] [D loss: 0.752328] [G loss: 0.478924] time: 0:55:20.483444\n",
      "0.93728906\n",
      "[Epoch 37/50] [Batch 28/300] [D loss: 0.752330] [G loss: 0.488557] time: 0:55:20.778884\n",
      "0.9483394\n",
      "[Epoch 37/50] [Batch 29/300] [D loss: 0.752304] [G loss: 0.496749] time: 0:55:21.087958\n",
      "0.94773155\n",
      "[Epoch 37/50] [Batch 30/300] [D loss: 0.752310] [G loss: 0.483287] time: 0:55:21.389364\n",
      "0.93443996\n",
      "[Epoch 37/50] [Batch 31/300] [D loss: 0.752309] [G loss: 0.498499] time: 0:55:21.687507\n",
      "0.9171384\n",
      "[Epoch 37/50] [Batch 32/300] [D loss: 0.752323] [G loss: 0.475435] time: 0:55:21.975986\n",
      "0.94551045\n",
      "[Epoch 37/50] [Batch 33/300] [D loss: 0.752301] [G loss: 0.497467] time: 0:55:22.279004\n",
      "0.9239765\n",
      "[Epoch 37/50] [Batch 34/300] [D loss: 0.752299] [G loss: 0.489604] time: 0:55:22.563462\n",
      "0.9230485\n",
      "[Epoch 37/50] [Batch 35/300] [D loss: 0.752321] [G loss: 0.486717] time: 0:55:22.844583\n",
      "0.8703303\n",
      "[Epoch 37/50] [Batch 37/300] [D loss: 0.752322] [G loss: 0.483657] time: 0:55:23.154167\n",
      "0.9404538\n",
      "[Epoch 37/50] [Batch 38/300] [D loss: 0.752318] [G loss: 0.491097] time: 0:55:23.459986\n",
      "0.90856194\n",
      "[Epoch 37/50] [Batch 39/300] [D loss: 0.752319] [G loss: 0.487123] time: 0:55:23.759803\n",
      "0.8854559\n",
      "[Epoch 37/50] [Batch 40/300] [D loss: 0.752313] [G loss: 0.471646] time: 0:55:24.070464\n",
      "0.91075975\n",
      "[Epoch 37/50] [Batch 41/300] [D loss: 0.752316] [G loss: 0.482172] time: 0:55:24.361778\n",
      "0.8989282\n",
      "[Epoch 37/50] [Batch 42/300] [D loss: 0.752318] [G loss: 0.490171] time: 0:55:24.647123\n",
      "0.92315334\n",
      "[Epoch 37/50] [Batch 43/300] [D loss: 0.752325] [G loss: 0.471737] time: 0:55:24.945152\n",
      "0.96174544\n",
      "[Epoch 37/50] [Batch 44/300] [D loss: 0.752308] [G loss: 0.509020] time: 0:55:25.221554\n",
      "0.9100539\n",
      "[Epoch 37/50] [Batch 45/300] [D loss: 0.752313] [G loss: 0.493315] time: 0:55:25.535579\n",
      "0.96018046\n",
      "[Epoch 37/50] [Batch 46/300] [D loss: 0.752323] [G loss: 0.489421] time: 0:55:25.839113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923255\n",
      "[Epoch 37/50] [Batch 47/300] [D loss: 0.752313] [G loss: 0.483112] time: 0:55:26.136558\n",
      "0.8992641\n",
      "[Epoch 37/50] [Batch 48/300] [D loss: 0.752312] [G loss: 0.476067] time: 0:55:26.432493\n",
      "0.9461854\n",
      "[Epoch 37/50] [Batch 49/300] [D loss: 0.752325] [G loss: 0.469482] time: 0:55:26.732077\n",
      "0.8926954\n",
      "[Epoch 37/50] [Batch 50/300] [D loss: 0.752322] [G loss: 0.481649] time: 0:55:27.041125\n",
      "0.8906515\n",
      "[Epoch 37/50] [Batch 51/300] [D loss: 0.752310] [G loss: 0.497931] time: 0:55:27.341582\n",
      "0.95999485\n",
      "[Epoch 37/50] [Batch 52/300] [D loss: 0.752320] [G loss: 0.470527] time: 0:55:27.637857\n",
      "0.91601706\n",
      "[Epoch 37/50] [Batch 53/300] [D loss: 0.752316] [G loss: 0.484093] time: 0:55:27.917439\n",
      "0.8989405\n",
      "[Epoch 37/50] [Batch 54/300] [D loss: 0.752299] [G loss: 0.478490] time: 0:55:28.199382\n",
      "0.93537015\n",
      "[Epoch 37/50] [Batch 55/300] [D loss: 0.752316] [G loss: 0.469731] time: 0:55:28.506314\n",
      "0.93072945\n",
      "[Epoch 37/50] [Batch 56/300] [D loss: 0.752315] [G loss: 0.479383] time: 0:55:28.808255\n",
      "0.9414757\n",
      "[Epoch 37/50] [Batch 57/300] [D loss: 0.752312] [G loss: 0.485184] time: 0:55:29.102308\n",
      "0.9038348\n",
      "[Epoch 37/50] [Batch 58/300] [D loss: 0.752301] [G loss: 0.480538] time: 0:55:29.384249\n",
      "0.94699675\n",
      "[Epoch 37/50] [Batch 59/300] [D loss: 0.752311] [G loss: 0.477456] time: 0:55:29.662927\n",
      "0.89600414\n",
      "[Epoch 37/50] [Batch 60/300] [D loss: 0.752306] [G loss: 0.501060] time: 0:55:29.969086\n",
      "0.9308675\n",
      "[Epoch 37/50] [Batch 61/300] [D loss: 0.752313] [G loss: 0.475274] time: 0:55:30.272267\n",
      "0.9167606\n",
      "[Epoch 37/50] [Batch 62/300] [D loss: 0.752306] [G loss: 0.492314] time: 0:55:30.579213\n",
      "0.94334126\n",
      "[Epoch 37/50] [Batch 63/300] [D loss: 0.752308] [G loss: 0.485314] time: 0:55:30.881144\n",
      "0.9272775\n",
      "[Epoch 37/50] [Batch 64/300] [D loss: 0.752317] [G loss: 0.481653] time: 0:55:31.180204\n",
      "0.87435395\n",
      "[Epoch 37/50] [Batch 65/300] [D loss: 0.752302] [G loss: 0.476410] time: 0:55:31.491494\n",
      "0.8855045\n",
      "[Epoch 37/50] [Batch 66/300] [D loss: 0.752315] [G loss: 0.490259] time: 0:55:31.801753\n",
      "0.92037314\n",
      "[Epoch 37/50] [Batch 67/300] [D loss: 0.752327] [G loss: 0.493928] time: 0:55:32.094446\n",
      "0.91671824\n",
      "[Epoch 37/50] [Batch 68/300] [D loss: 0.752302] [G loss: 0.492576] time: 0:55:32.394326\n",
      "0.9124436\n",
      "[Epoch 37/50] [Batch 69/300] [D loss: 0.752295] [G loss: 0.483922] time: 0:55:32.696228\n",
      "0.97162753\n",
      "[Epoch 37/50] [Batch 70/300] [D loss: 0.752312] [G loss: 0.480056] time: 0:55:32.980164\n",
      "0.9396544\n",
      "[Epoch 37/50] [Batch 71/300] [D loss: 0.752315] [G loss: 0.475352] time: 0:55:33.271176\n",
      "0.9175741\n",
      "[Epoch 37/50] [Batch 72/300] [D loss: 0.752298] [G loss: 0.488922] time: 0:55:33.553342\n",
      "0.9478626\n",
      "[Epoch 37/50] [Batch 73/300] [D loss: 0.752313] [G loss: 0.486177] time: 0:55:33.829928\n",
      "0.881788\n",
      "[Epoch 37/50] [Batch 74/300] [D loss: 0.752311] [G loss: 0.484109] time: 0:55:34.112697\n",
      "0.8853285\n",
      "[Epoch 37/50] [Batch 75/300] [D loss: 0.752314] [G loss: 0.483805] time: 0:55:34.403487\n",
      "0.9288504\n",
      "[Epoch 37/50] [Batch 76/300] [D loss: 0.752308] [G loss: 0.509280] time: 0:55:34.697494\n",
      "0.94205695\n",
      "[Epoch 37/50] [Batch 77/300] [D loss: 0.752326] [G loss: 0.481810] time: 0:55:35.001232\n",
      "0.9454391\n",
      "[Epoch 37/50] [Batch 78/300] [D loss: 0.752311] [G loss: 0.492650] time: 0:55:35.276141\n",
      "0.8526313\n",
      "[Epoch 37/50] [Batch 79/300] [D loss: 0.752300] [G loss: 0.491521] time: 0:55:35.572787\n",
      "0.9140246\n",
      "[Epoch 37/50] [Batch 80/300] [D loss: 0.752319] [G loss: 0.492633] time: 0:55:35.895543\n",
      "0.90853786\n",
      "[Epoch 37/50] [Batch 81/300] [D loss: 0.752308] [G loss: 0.483747] time: 0:55:36.212248\n",
      "0.9280007\n",
      "[Epoch 37/50] [Batch 82/300] [D loss: 0.752302] [G loss: 0.502523] time: 0:55:36.514647\n",
      "0.9529128\n",
      "[Epoch 37/50] [Batch 83/300] [D loss: 0.752299] [G loss: 0.494604] time: 0:55:36.811054\n",
      "0.91101617\n",
      "[Epoch 37/50] [Batch 84/300] [D loss: 0.752319] [G loss: 0.477484] time: 0:55:37.124774\n",
      "0.9048608\n",
      "[Epoch 37/50] [Batch 85/300] [D loss: 0.752318] [G loss: 0.510995] time: 0:55:37.429462\n",
      "0.9068169\n",
      "[Epoch 37/50] [Batch 86/300] [D loss: 0.752307] [G loss: 0.482784] time: 0:55:37.716259\n",
      "0.934843\n",
      "[Epoch 37/50] [Batch 87/300] [D loss: 0.752333] [G loss: 0.488925] time: 0:55:37.998005\n",
      "0.9057409\n",
      "[Epoch 37/50] [Batch 88/300] [D loss: 0.752309] [G loss: 0.481662] time: 0:55:38.273967\n",
      "0.928525\n",
      "[Epoch 37/50] [Batch 89/300] [D loss: 0.752317] [G loss: 0.475229] time: 0:55:38.555559\n",
      "0.91084427\n",
      "[Epoch 37/50] [Batch 90/300] [D loss: 0.752303] [G loss: 0.472498] time: 0:55:38.861876\n",
      "0.90600055\n",
      "[Epoch 37/50] [Batch 91/300] [D loss: 0.752303] [G loss: 0.476812] time: 0:55:39.135302\n",
      "0.95440966\n",
      "[Epoch 37/50] [Batch 92/300] [D loss: 0.752303] [G loss: 0.484582] time: 0:55:39.422571\n",
      "0.87419754\n",
      "[Epoch 37/50] [Batch 93/300] [D loss: 0.752317] [G loss: 0.475860] time: 0:55:39.715312\n",
      "0.91256166\n",
      "[Epoch 37/50] [Batch 94/300] [D loss: 0.752319] [G loss: 0.503997] time: 0:55:40.012051\n",
      "0.939847\n",
      "[Epoch 37/50] [Batch 95/300] [D loss: 0.752311] [G loss: 0.482164] time: 0:55:40.305064\n",
      "0.9433856\n",
      "[Epoch 37/50] [Batch 96/300] [D loss: 0.752318] [G loss: 0.477458] time: 0:55:40.609923\n",
      "0.8933799\n",
      "[Epoch 37/50] [Batch 97/300] [D loss: 0.752300] [G loss: 0.479675] time: 0:55:40.912989\n",
      "0.9669549\n",
      "[Epoch 37/50] [Batch 98/300] [D loss: 0.752302] [G loss: 0.501239] time: 0:55:41.221974\n",
      "0.9121277\n",
      "[Epoch 37/50] [Batch 99/300] [D loss: 0.752322] [G loss: 0.480820] time: 0:55:41.492942\n",
      "0.85266227\n",
      "[Epoch 37/50] [Batch 100/300] [D loss: 0.752313] [G loss: 0.473867] time: 0:55:41.804435\n",
      "0.9100844\n",
      "[Epoch 37/50] [Batch 101/300] [D loss: 0.752317] [G loss: 0.493174] time: 0:55:42.100165\n",
      "0.9309518\n",
      "[Epoch 37/50] [Batch 102/300] [D loss: 0.752304] [G loss: 0.480701] time: 0:55:42.391550\n",
      "0.8958362\n",
      "[Epoch 37/50] [Batch 103/300] [D loss: 0.752329] [G loss: 0.474774] time: 0:55:42.679720\n",
      "0.93521357\n",
      "[Epoch 37/50] [Batch 104/300] [D loss: 0.752310] [G loss: 0.491050] time: 0:55:42.953959\n",
      "0.93289566\n",
      "[Epoch 37/50] [Batch 105/300] [D loss: 0.752311] [G loss: 0.480676] time: 0:55:43.260147\n",
      "0.931482\n",
      "[Epoch 37/50] [Batch 106/300] [D loss: 0.752304] [G loss: 0.471385] time: 0:55:43.542920\n",
      "0.9070585\n",
      "[Epoch 37/50] [Batch 107/300] [D loss: 0.752311] [G loss: 0.475883] time: 0:55:43.843803\n",
      "0.92062825\n",
      "[Epoch 37/50] [Batch 108/300] [D loss: 0.752306] [G loss: 0.475120] time: 0:55:44.143576\n",
      "0.9315934\n",
      "[Epoch 37/50] [Batch 109/300] [D loss: 0.752303] [G loss: 0.475404] time: 0:55:44.440698\n",
      "0.9044878\n",
      "[Epoch 37/50] [Batch 110/300] [D loss: 0.752300] [G loss: 0.503374] time: 0:55:44.731931\n",
      "0.9532046\n",
      "[Epoch 37/50] [Batch 111/300] [D loss: 0.752321] [G loss: 0.494709] time: 0:55:45.023209\n",
      "0.9084398\n",
      "[Epoch 37/50] [Batch 112/300] [D loss: 0.752304] [G loss: 0.482903] time: 0:55:45.320507\n",
      "0.9504865\n",
      "[Epoch 37/50] [Batch 113/300] [D loss: 0.752316] [G loss: 0.475553] time: 0:55:45.609165\n",
      "0.93581265\n",
      "[Epoch 37/50] [Batch 114/300] [D loss: 0.752309] [G loss: 0.473154] time: 0:55:45.917387\n",
      "0.94623846\n",
      "[Epoch 37/50] [Batch 115/300] [D loss: 0.752330] [G loss: 0.477972] time: 0:55:46.234560\n",
      "0.9383034\n",
      "[Epoch 37/50] [Batch 116/300] [D loss: 0.752308] [G loss: 0.471885] time: 0:55:46.529482\n",
      "0.8989447\n",
      "[Epoch 37/50] [Batch 117/300] [D loss: 0.752312] [G loss: 0.486986] time: 0:55:46.823363\n",
      "0.9398217\n",
      "[Epoch 37/50] [Batch 118/300] [D loss: 0.752311] [G loss: 0.482726] time: 0:55:47.110431\n",
      "0.8995745\n",
      "[Epoch 37/50] [Batch 119/300] [D loss: 0.752299] [G loss: 0.483821] time: 0:55:47.401548\n",
      "0.9315257\n",
      "[Epoch 37/50] [Batch 120/300] [D loss: 0.752307] [G loss: 0.481983] time: 0:55:47.701324\n",
      "0.9464695\n",
      "[Epoch 37/50] [Batch 121/300] [D loss: 0.752316] [G loss: 0.477961] time: 0:55:47.988109\n",
      "0.9056001\n",
      "[Epoch 37/50] [Batch 122/300] [D loss: 0.752299] [G loss: 0.483925] time: 0:55:48.286080\n",
      "0.95631284\n",
      "[Epoch 37/50] [Batch 123/300] [D loss: 0.752306] [G loss: 0.490461] time: 0:55:48.582251\n",
      "0.9464023\n",
      "[Epoch 37/50] [Batch 124/300] [D loss: 0.752313] [G loss: 0.475220] time: 0:55:48.875586\n",
      "0.93316\n",
      "[Epoch 37/50] [Batch 125/300] [D loss: 0.752309] [G loss: 0.474349] time: 0:55:49.179028\n",
      "0.9319082\n",
      "[Epoch 37/50] [Batch 126/300] [D loss: 0.752313] [G loss: 0.487463] time: 0:55:49.452180\n",
      "0.95785904\n",
      "[Epoch 37/50] [Batch 127/300] [D loss: 0.752314] [G loss: 0.480602] time: 0:55:49.745144\n",
      "0.9691918\n",
      "[Epoch 37/50] [Batch 128/300] [D loss: 0.752313] [G loss: 0.479827] time: 0:55:50.042550\n",
      "0.9095683\n",
      "[Epoch 37/50] [Batch 129/300] [D loss: 0.752302] [G loss: 0.484465] time: 0:55:50.334303\n",
      "0.9248347\n",
      "[Epoch 37/50] [Batch 130/300] [D loss: 0.752314] [G loss: 0.484255] time: 0:55:50.626726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93240505\n",
      "[Epoch 37/50] [Batch 131/300] [D loss: 0.752311] [G loss: 0.478860] time: 0:55:50.929385\n",
      "0.9124437\n",
      "[Epoch 37/50] [Batch 132/300] [D loss: 0.752319] [G loss: 0.475855] time: 0:55:51.226866\n",
      "0.9279483\n",
      "[Epoch 37/50] [Batch 133/300] [D loss: 0.752302] [G loss: 0.493653] time: 0:55:51.520641\n",
      "0.93834263\n",
      "[Epoch 37/50] [Batch 134/300] [D loss: 0.752321] [G loss: 0.484217] time: 0:55:51.804561\n",
      "0.9562192\n",
      "[Epoch 37/50] [Batch 135/300] [D loss: 0.752308] [G loss: 0.476797] time: 0:55:52.106389\n",
      "0.94216174\n",
      "[Epoch 37/50] [Batch 136/300] [D loss: 0.752320] [G loss: 0.494273] time: 0:55:52.419896\n",
      "0.9447213\n",
      "[Epoch 37/50] [Batch 137/300] [D loss: 0.752296] [G loss: 0.480916] time: 0:55:52.698842\n",
      "0.8929076\n",
      "[Epoch 37/50] [Batch 138/300] [D loss: 0.752302] [G loss: 0.476103] time: 0:55:52.996840\n",
      "0.89412135\n",
      "[Epoch 37/50] [Batch 139/300] [D loss: 0.752320] [G loss: 0.501995] time: 0:55:53.284262\n",
      "0.9045243\n",
      "[Epoch 37/50] [Batch 140/300] [D loss: 0.752318] [G loss: 0.487073] time: 0:55:53.582798\n",
      "0.91297436\n",
      "[Epoch 37/50] [Batch 141/300] [D loss: 0.752300] [G loss: 0.486259] time: 0:55:53.884165\n",
      "0.9102939\n",
      "[Epoch 37/50] [Batch 142/300] [D loss: 0.752319] [G loss: 0.471037] time: 0:55:54.166770\n",
      "0.9477839\n",
      "[Epoch 37/50] [Batch 143/300] [D loss: 0.752308] [G loss: 0.532022] time: 0:55:54.466641\n",
      "0.9190361\n",
      "[Epoch 37/50] [Batch 144/300] [D loss: 0.752314] [G loss: 0.486735] time: 0:55:54.776733\n",
      "0.9327848\n",
      "[Epoch 37/50] [Batch 145/300] [D loss: 0.752310] [G loss: 0.485303] time: 0:55:55.080297\n",
      "0.97478324\n",
      "[Epoch 37/50] [Batch 146/300] [D loss: 0.752307] [G loss: 0.474460] time: 0:55:55.375196\n",
      "0.89089465\n",
      "[Epoch 37/50] [Batch 147/300] [D loss: 0.752302] [G loss: 0.481141] time: 0:55:55.671783\n",
      "0.916179\n",
      "[Epoch 37/50] [Batch 148/300] [D loss: 0.752310] [G loss: 0.474563] time: 0:55:55.977049\n",
      "0.93303007\n",
      "[Epoch 37/50] [Batch 149/300] [D loss: 0.752305] [G loss: 0.473290] time: 0:55:56.262858\n",
      "0.90531784\n",
      "[Epoch 37/50] [Batch 150/300] [D loss: 0.752309] [G loss: 0.474968] time: 0:55:56.568772\n",
      "0.91650075\n",
      "[Epoch 37/50] [Batch 151/300] [D loss: 0.752310] [G loss: 0.475844] time: 0:55:56.855848\n",
      "0.889214\n",
      "[Epoch 37/50] [Batch 152/300] [D loss: 0.752310] [G loss: 0.480348] time: 0:55:57.153686\n",
      "0.9292569\n",
      "[Epoch 37/50] [Batch 153/300] [D loss: 0.752317] [G loss: 0.470072] time: 0:55:57.457202\n",
      "0.9314883\n",
      "[Epoch 37/50] [Batch 154/300] [D loss: 0.752305] [G loss: 0.504416] time: 0:55:57.757511\n",
      "0.93863755\n",
      "[Epoch 37/50] [Batch 155/300] [D loss: 0.752322] [G loss: 0.476354] time: 0:55:58.054114\n",
      "0.9248297\n",
      "[Epoch 37/50] [Batch 156/300] [D loss: 0.752306] [G loss: 0.478022] time: 0:55:58.341006\n",
      "0.947392\n",
      "[Epoch 37/50] [Batch 157/300] [D loss: 0.752325] [G loss: 0.469031] time: 0:55:58.641168\n",
      "0.93302554\n",
      "[Epoch 37/50] [Batch 158/300] [D loss: 0.752303] [G loss: 0.485774] time: 0:55:58.917844\n",
      "0.89195913\n",
      "[Epoch 37/50] [Batch 159/300] [D loss: 0.752315] [G loss: 0.509657] time: 0:55:59.202523\n",
      "0.94250107\n",
      "[Epoch 37/50] [Batch 160/300] [D loss: 0.752309] [G loss: 0.489768] time: 0:55:59.494744\n",
      "0.94069844\n",
      "[Epoch 37/50] [Batch 161/300] [D loss: 0.752303] [G loss: 0.493258] time: 0:55:59.811660\n",
      "0.8994691\n",
      "[Epoch 37/50] [Batch 162/300] [D loss: 0.752318] [G loss: 0.481809] time: 0:56:00.104062\n",
      "0.94171685\n",
      "[Epoch 37/50] [Batch 163/300] [D loss: 0.752310] [G loss: 0.471345] time: 0:56:00.404103\n",
      "0.91655135\n",
      "[Epoch 37/50] [Batch 164/300] [D loss: 0.752310] [G loss: 0.487812] time: 0:56:00.701545\n",
      "0.9153752\n",
      "[Epoch 37/50] [Batch 165/300] [D loss: 0.752308] [G loss: 0.491593] time: 0:56:01.000178\n",
      "0.94709253\n",
      "[Epoch 37/50] [Batch 166/300] [D loss: 0.752317] [G loss: 0.484169] time: 0:56:01.291829\n",
      "0.89878744\n",
      "[Epoch 37/50] [Batch 167/300] [D loss: 0.752316] [G loss: 0.487419] time: 0:56:01.582852\n",
      "0.9395866\n",
      "[Epoch 37/50] [Batch 168/300] [D loss: 0.752313] [G loss: 0.485777] time: 0:56:01.882559\n",
      "0.92936236\n",
      "[Epoch 37/50] [Batch 169/300] [D loss: 0.752302] [G loss: 0.473413] time: 0:56:02.172735\n",
      "0.92451286\n",
      "[Epoch 37/50] [Batch 170/300] [D loss: 0.752291] [G loss: 0.477429] time: 0:56:02.465460\n",
      "0.9084954\n",
      "[Epoch 37/50] [Batch 171/300] [D loss: 0.752314] [G loss: 0.510596] time: 0:56:02.755129\n",
      "0.91378665\n",
      "[Epoch 37/50] [Batch 172/300] [D loss: 0.752315] [G loss: 0.472693] time: 0:56:03.050391\n",
      "0.8995204\n",
      "[Epoch 37/50] [Batch 173/300] [D loss: 0.752302] [G loss: 0.491672] time: 0:56:03.339464\n",
      "0.8803355\n",
      "[Epoch 37/50] [Batch 174/300] [D loss: 0.752306] [G loss: 0.475177] time: 0:56:03.654852\n",
      "0.89790696\n",
      "[Epoch 37/50] [Batch 175/300] [D loss: 0.752306] [G loss: 0.480815] time: 0:56:03.961667\n",
      "0.976341\n",
      "[Epoch 37/50] [Batch 176/300] [D loss: 0.752323] [G loss: 0.482434] time: 0:56:04.254792\n",
      "0.8857344\n",
      "[Epoch 37/50] [Batch 177/300] [D loss: 0.752309] [G loss: 0.478428] time: 0:56:04.549137\n",
      "0.9335499\n",
      "[Epoch 37/50] [Batch 178/300] [D loss: 0.752305] [G loss: 0.494942] time: 0:56:04.853372\n",
      "0.9066744\n",
      "[Epoch 37/50] [Batch 179/300] [D loss: 0.752320] [G loss: 0.480948] time: 0:56:05.153458\n",
      "0.89881366\n",
      "[Epoch 37/50] [Batch 180/300] [D loss: 0.752308] [G loss: 0.476452] time: 0:56:05.464991\n",
      "0.97115684\n",
      "[Epoch 37/50] [Batch 181/300] [D loss: 0.752301] [G loss: 0.489087] time: 0:56:05.768910\n",
      "0.88042396\n",
      "[Epoch 37/50] [Batch 182/300] [D loss: 0.752304] [G loss: 0.470427] time: 0:56:06.056748\n",
      "0.97168535\n",
      "[Epoch 37/50] [Batch 183/300] [D loss: 0.752309] [G loss: 0.474124] time: 0:56:06.357170\n",
      "0.9198818\n",
      "[Epoch 37/50] [Batch 184/300] [D loss: 0.752315] [G loss: 0.482385] time: 0:56:06.667067\n",
      "0.9133236\n",
      "[Epoch 37/50] [Batch 185/300] [D loss: 0.752315] [G loss: 0.487312] time: 0:56:06.979708\n",
      "0.9816353\n",
      "[Epoch 37/50] [Batch 186/300] [D loss: 0.752311] [G loss: 0.478243] time: 0:56:07.273484\n",
      "0.899178\n",
      "[Epoch 37/50] [Batch 187/300] [D loss: 0.752317] [G loss: 0.469534] time: 0:56:07.564245\n",
      "0.910595\n",
      "[Epoch 37/50] [Batch 188/300] [D loss: 0.752303] [G loss: 0.495290] time: 0:56:07.862043\n",
      "0.9530578\n",
      "[Epoch 37/50] [Batch 189/300] [D loss: 0.752306] [G loss: 0.476179] time: 0:56:08.164798\n",
      "0.9753916\n",
      "[Epoch 37/50] [Batch 190/300] [D loss: 0.752303] [G loss: 0.477164] time: 0:56:08.467814\n",
      "0.95885473\n",
      "[Epoch 37/50] [Batch 191/300] [D loss: 0.752310] [G loss: 0.491509] time: 0:56:08.759141\n",
      "0.9297144\n",
      "[Epoch 37/50] [Batch 192/300] [D loss: 0.752304] [G loss: 0.478990] time: 0:56:09.054516\n",
      "0.90331584\n",
      "[Epoch 37/50] [Batch 193/300] [D loss: 0.752306] [G loss: 0.479835] time: 0:56:09.348125\n",
      "0.9619773\n",
      "[Epoch 37/50] [Batch 194/300] [D loss: 0.752303] [G loss: 0.491390] time: 0:56:09.662855\n",
      "0.8848073\n",
      "[Epoch 37/50] [Batch 195/300] [D loss: 0.752304] [G loss: 0.481371] time: 0:56:10.080669\n",
      "0.9111407\n",
      "[Epoch 37/50] [Batch 196/300] [D loss: 0.752314] [G loss: 0.489198] time: 0:56:10.378944\n",
      "0.93359786\n",
      "[Epoch 37/50] [Batch 197/300] [D loss: 0.752310] [G loss: 0.480120] time: 0:56:10.679822\n",
      "0.9623801\n",
      "[Epoch 37/50] [Batch 198/300] [D loss: 0.752310] [G loss: 0.474559] time: 0:56:10.953868\n",
      "0.91365606\n",
      "[Epoch 37/50] [Batch 199/300] [D loss: 0.752306] [G loss: 0.485772] time: 0:56:11.216714\n",
      "0.9137482\n",
      "[Epoch 37/50] [Batch 200/300] [D loss: 0.752319] [G loss: 0.502447] time: 0:56:11.503575\n",
      "0.87583494\n",
      "[Epoch 37/50] [Batch 201/300] [D loss: 0.752309] [G loss: 0.486717] time: 0:56:11.795424\n",
      "0.98329765\n",
      "[Epoch 37/50] [Batch 202/300] [D loss: 0.752295] [G loss: 0.473000] time: 0:56:12.090136\n",
      "0.88578147\n",
      "[Epoch 37/50] [Batch 203/300] [D loss: 0.752305] [G loss: 0.484934] time: 0:56:12.400216\n",
      "0.8960783\n",
      "[Epoch 37/50] [Batch 204/300] [D loss: 0.752312] [G loss: 0.479896] time: 0:56:12.707829\n",
      "0.9532525\n",
      "[Epoch 37/50] [Batch 205/300] [D loss: 0.752308] [G loss: 0.475361] time: 0:56:13.012583\n",
      "0.9385338\n",
      "[Epoch 37/50] [Batch 206/300] [D loss: 0.752296] [G loss: 0.477093] time: 0:56:13.314952\n",
      "0.95335346\n",
      "[Epoch 37/50] [Batch 207/300] [D loss: 0.752300] [G loss: 0.486642] time: 0:56:13.615103\n",
      "0.9562989\n",
      "[Epoch 37/50] [Batch 208/300] [D loss: 0.752300] [G loss: 0.502259] time: 0:56:13.915790\n",
      "0.9453295\n",
      "[Epoch 37/50] [Batch 209/300] [D loss: 0.752313] [G loss: 0.471085] time: 0:56:14.199835\n",
      "0.9354841\n",
      "[Epoch 37/50] [Batch 210/300] [D loss: 0.752310] [G loss: 0.486784] time: 0:56:14.514075\n",
      "0.93179494\n",
      "[Epoch 37/50] [Batch 211/300] [D loss: 0.752303] [G loss: 0.487753] time: 0:56:14.815624\n",
      "0.88882905\n",
      "[Epoch 37/50] [Batch 212/300] [D loss: 0.752301] [G loss: 0.485330] time: 0:56:15.128563\n",
      "0.8969507\n",
      "[Epoch 37/50] [Batch 213/300] [D loss: 0.752307] [G loss: 0.486949] time: 0:56:15.427707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93381244\n",
      "[Epoch 37/50] [Batch 214/300] [D loss: 0.752311] [G loss: 0.482341] time: 0:56:15.705243\n",
      "0.95545036\n",
      "[Epoch 37/50] [Batch 215/300] [D loss: 0.752309] [G loss: 0.472957] time: 0:56:16.016683\n",
      "0.94435877\n",
      "[Epoch 37/50] [Batch 216/300] [D loss: 0.752303] [G loss: 0.488304] time: 0:56:16.309162\n",
      "0.9232822\n",
      "[Epoch 37/50] [Batch 217/300] [D loss: 0.752317] [G loss: 0.494516] time: 0:56:16.609443\n",
      "0.89896655\n",
      "[Epoch 37/50] [Batch 218/300] [D loss: 0.752311] [G loss: 0.472779] time: 0:56:16.913161\n",
      "0.9217283\n",
      "[Epoch 37/50] [Batch 219/300] [D loss: 0.752323] [G loss: 0.473944] time: 0:56:17.214513\n",
      "0.8914449\n",
      "[Epoch 37/50] [Batch 220/300] [D loss: 0.752308] [G loss: 0.477857] time: 0:56:17.510044\n",
      "0.95461947\n",
      "[Epoch 37/50] [Batch 221/300] [D loss: 0.752306] [G loss: 0.475445] time: 0:56:17.807539\n",
      "0.9147956\n",
      "[Epoch 37/50] [Batch 222/300] [D loss: 0.752328] [G loss: 0.484763] time: 0:56:18.112345\n",
      "0.93221474\n",
      "[Epoch 37/50] [Batch 223/300] [D loss: 0.752302] [G loss: 0.485199] time: 0:56:18.395944\n",
      "0.95742446\n",
      "[Epoch 37/50] [Batch 224/300] [D loss: 0.752315] [G loss: 0.479738] time: 0:56:18.687157\n",
      "0.9379754\n",
      "[Epoch 37/50] [Batch 225/300] [D loss: 0.752312] [G loss: 0.488992] time: 0:56:19.007744\n",
      "0.9158024\n",
      "[Epoch 37/50] [Batch 226/300] [D loss: 0.752304] [G loss: 0.486324] time: 0:56:19.319305\n",
      "0.9548204\n",
      "[Epoch 37/50] [Batch 227/300] [D loss: 0.752306] [G loss: 0.480292] time: 0:56:19.619333\n",
      "0.9233804\n",
      "[Epoch 37/50] [Batch 228/300] [D loss: 0.752309] [G loss: 0.476766] time: 0:56:19.908780\n",
      "0.9191274\n",
      "[Epoch 37/50] [Batch 229/300] [D loss: 0.752292] [G loss: 0.490348] time: 0:56:20.214067\n",
      "0.9298145\n",
      "[Epoch 37/50] [Batch 230/300] [D loss: 0.752318] [G loss: 0.473632] time: 0:56:20.517734\n",
      "0.9296379\n",
      "[Epoch 37/50] [Batch 231/300] [D loss: 0.752302] [G loss: 0.477257] time: 0:56:20.813909\n",
      "0.93100095\n",
      "[Epoch 37/50] [Batch 232/300] [D loss: 0.752311] [G loss: 0.468704] time: 0:56:21.118442\n",
      "0.92076737\n",
      "[Epoch 37/50] [Batch 233/300] [D loss: 0.752304] [G loss: 0.475979] time: 0:56:21.420096\n",
      "0.9331644\n",
      "[Epoch 37/50] [Batch 234/300] [D loss: 0.752296] [G loss: 0.465992] time: 0:56:21.703947\n",
      "0.9091134\n",
      "[Epoch 37/50] [Batch 235/300] [D loss: 0.752310] [G loss: 0.496204] time: 0:56:22.018803\n",
      "0.9270053\n",
      "[Epoch 37/50] [Batch 236/300] [D loss: 0.752305] [G loss: 0.475274] time: 0:56:22.310355\n",
      "0.9402084\n",
      "[Epoch 37/50] [Batch 237/300] [D loss: 0.752303] [G loss: 0.481217] time: 0:56:22.594148\n",
      "0.9472008\n",
      "[Epoch 37/50] [Batch 238/300] [D loss: 0.752306] [G loss: 0.486806] time: 0:56:22.867416\n",
      "0.9068408\n",
      "[Epoch 37/50] [Batch 239/300] [D loss: 0.752304] [G loss: 0.474794] time: 0:56:23.180911\n",
      "0.897779\n",
      "[Epoch 37/50] [Batch 240/300] [D loss: 0.752294] [G loss: 0.474958] time: 0:56:23.482926\n",
      "0.9177008\n",
      "[Epoch 37/50] [Batch 241/300] [D loss: 0.752323] [G loss: 0.491337] time: 0:56:23.783935\n",
      "0.9387574\n",
      "[Epoch 37/50] [Batch 242/300] [D loss: 0.752305] [G loss: 0.472238] time: 0:56:24.088036\n",
      "0.8939614\n",
      "[Epoch 37/50] [Batch 243/300] [D loss: 0.752314] [G loss: 0.502753] time: 0:56:24.385521\n",
      "0.8856673\n",
      "[Epoch 37/50] [Batch 244/300] [D loss: 0.752290] [G loss: 0.479271] time: 0:56:24.691545\n",
      "0.9020062\n",
      "[Epoch 37/50] [Batch 245/300] [D loss: 0.752319] [G loss: 0.472996] time: 0:56:24.990019\n",
      "0.91829294\n",
      "[Epoch 37/50] [Batch 246/300] [D loss: 0.752296] [G loss: 0.527680] time: 0:56:25.284324\n",
      "0.943286\n",
      "[Epoch 37/50] [Batch 247/300] [D loss: 0.752303] [G loss: 0.480901] time: 0:56:25.571566\n",
      "0.929198\n",
      "[Epoch 37/50] [Batch 248/300] [D loss: 0.752309] [G loss: 0.478058] time: 0:56:25.852715\n",
      "0.9375138\n",
      "[Epoch 37/50] [Batch 249/300] [D loss: 0.752303] [G loss: 0.503933] time: 0:56:26.143439\n",
      "0.9343037\n",
      "[Epoch 37/50] [Batch 250/300] [D loss: 0.752299] [G loss: 0.488298] time: 0:56:26.446027\n",
      "0.9600937\n",
      "[Epoch 37/50] [Batch 251/300] [D loss: 0.752312] [G loss: 0.479453] time: 0:56:26.726178\n",
      "0.9038047\n",
      "[Epoch 37/50] [Batch 252/300] [D loss: 0.752308] [G loss: 0.489478] time: 0:56:27.027122\n",
      "0.9194925\n",
      "[Epoch 37/50] [Batch 253/300] [D loss: 0.752291] [G loss: 0.500047] time: 0:56:27.334206\n",
      "0.8863575\n",
      "[Epoch 37/50] [Batch 254/300] [D loss: 0.752307] [G loss: 0.473548] time: 0:56:27.636081\n",
      "0.93955916\n",
      "[Epoch 37/50] [Batch 255/300] [D loss: 0.752310] [G loss: 0.488514] time: 0:56:27.942781\n",
      "0.9713514\n",
      "[Epoch 37/50] [Batch 256/300] [D loss: 0.752304] [G loss: 0.487254] time: 0:56:28.236587\n",
      "0.91907954\n",
      "[Epoch 37/50] [Batch 257/300] [D loss: 0.752305] [G loss: 0.479742] time: 0:56:28.507796\n",
      "0.9116972\n",
      "[Epoch 37/50] [Batch 258/300] [D loss: 0.752303] [G loss: 0.474143] time: 0:56:28.811921\n",
      "0.95545584\n",
      "[Epoch 37/50] [Batch 259/300] [D loss: 0.752300] [G loss: 0.482445] time: 0:56:29.117107\n",
      "0.9420025\n",
      "[Epoch 37/50] [Batch 260/300] [D loss: 0.752320] [G loss: 0.492844] time: 0:56:29.422760\n",
      "0.94668484\n",
      "[Epoch 37/50] [Batch 261/300] [D loss: 0.752317] [G loss: 0.490875] time: 0:56:29.704985\n",
      "0.89592224\n",
      "[Epoch 37/50] [Batch 262/300] [D loss: 0.752328] [G loss: 0.482533] time: 0:56:30.024152\n",
      "0.9163273\n",
      "[Epoch 37/50] [Batch 263/300] [D loss: 0.752291] [G loss: 0.479644] time: 0:56:30.323740\n",
      "0.971185\n",
      "[Epoch 37/50] [Batch 264/300] [D loss: 0.752309] [G loss: 0.472063] time: 0:56:30.622002\n",
      "0.9165447\n",
      "[Epoch 37/50] [Batch 265/300] [D loss: 0.752315] [G loss: 0.485196] time: 0:56:30.910022\n",
      "0.89148355\n",
      "[Epoch 37/50] [Batch 266/300] [D loss: 0.752302] [G loss: 0.495129] time: 0:56:31.214168\n",
      "0.92724895\n",
      "[Epoch 37/50] [Batch 267/300] [D loss: 0.752309] [G loss: 0.483431] time: 0:56:31.498062\n",
      "0.9126685\n",
      "[Epoch 37/50] [Batch 268/300] [D loss: 0.752299] [G loss: 0.499552] time: 0:56:31.771602\n",
      "0.9180625\n",
      "[Epoch 37/50] [Batch 269/300] [D loss: 0.752299] [G loss: 0.498728] time: 0:56:32.074169\n",
      "0.924184\n",
      "[Epoch 37/50] [Batch 270/300] [D loss: 0.752312] [G loss: 0.515382] time: 0:56:32.387081\n",
      "0.97535735\n",
      "[Epoch 37/50] [Batch 271/300] [D loss: 0.752298] [G loss: 0.489094] time: 0:56:32.673236\n",
      "0.8822713\n",
      "[Epoch 37/50] [Batch 272/300] [D loss: 0.752303] [G loss: 0.488356] time: 0:56:32.984989\n",
      "0.9266493\n",
      "[Epoch 37/50] [Batch 273/300] [D loss: 0.752314] [G loss: 0.494686] time: 0:56:33.267365\n",
      "0.9135379\n",
      "[Epoch 37/50] [Batch 274/300] [D loss: 0.752296] [G loss: 0.481080] time: 0:56:33.561998\n",
      "0.9366973\n",
      "[Epoch 37/50] [Batch 275/300] [D loss: 0.752318] [G loss: 0.485335] time: 0:56:33.870038\n",
      "0.9140654\n",
      "[Epoch 37/50] [Batch 276/300] [D loss: 0.752293] [G loss: 0.508139] time: 0:56:34.172939\n",
      "0.93076086\n",
      "[Epoch 37/50] [Batch 277/300] [D loss: 0.752310] [G loss: 0.478566] time: 0:56:34.470668\n",
      "0.9394291\n",
      "[Epoch 37/50] [Batch 278/300] [D loss: 0.752318] [G loss: 0.474354] time: 0:56:34.771486\n",
      "0.93529457\n",
      "[Epoch 37/50] [Batch 279/300] [D loss: 0.752299] [G loss: 0.499175] time: 0:56:35.095591\n",
      "0.91677064\n",
      "[Epoch 37/50] [Batch 280/300] [D loss: 0.752304] [G loss: 0.506190] time: 0:56:35.397122\n",
      "0.9375004\n",
      "[Epoch 37/50] [Batch 281/300] [D loss: 0.752315] [G loss: 0.488549] time: 0:56:35.707999\n",
      "0.8805651\n",
      "[Epoch 37/50] [Batch 282/300] [D loss: 0.752307] [G loss: 0.509607] time: 0:56:36.003662\n",
      "0.9027953\n",
      "[Epoch 37/50] [Batch 283/300] [D loss: 0.752303] [G loss: 0.475576] time: 0:56:36.303189\n",
      "0.9205222\n",
      "[Epoch 37/50] [Batch 284/300] [D loss: 0.752320] [G loss: 0.471116] time: 0:56:36.600884\n",
      "0.874048\n",
      "[Epoch 37/50] [Batch 285/300] [D loss: 0.752301] [G loss: 0.499005] time: 0:56:36.914156\n",
      "0.8851189\n",
      "[Epoch 37/50] [Batch 286/300] [D loss: 0.752305] [G loss: 0.498399] time: 0:56:37.203238\n",
      "0.8888177\n",
      "[Epoch 37/50] [Batch 287/300] [D loss: 0.752314] [G loss: 0.508626] time: 0:56:37.510596\n",
      "0.88090277\n",
      "[Epoch 37/50] [Batch 288/300] [D loss: 0.752319] [G loss: 0.481645] time: 0:56:37.802641\n",
      "0.8916258\n",
      "[Epoch 37/50] [Batch 289/300] [D loss: 0.752305] [G loss: 0.490706] time: 0:56:38.097471\n",
      "0.88744617\n",
      "[Epoch 37/50] [Batch 290/300] [D loss: 0.752315] [G loss: 0.481551] time: 0:56:38.406864\n",
      "0.873694\n",
      "[Epoch 37/50] [Batch 291/300] [D loss: 0.752309] [G loss: 0.486966] time: 0:56:38.728855\n",
      "0.9125468\n",
      "[Epoch 37/50] [Batch 292/300] [D loss: 0.752298] [G loss: 0.480563] time: 0:56:39.044030\n",
      "0.91545564\n",
      "[Epoch 37/50] [Batch 293/300] [D loss: 0.752306] [G loss: 0.494423] time: 0:56:39.360147\n",
      "0.9054181\n",
      "[Epoch 37/50] [Batch 294/300] [D loss: 0.752312] [G loss: 0.493043] time: 0:56:39.657833\n",
      "0.89949226\n",
      "[Epoch 37/50] [Batch 295/300] [D loss: 0.752303] [G loss: 0.493144] time: 0:56:39.969162\n",
      "0.92491746\n",
      "[Epoch 37/50] [Batch 296/300] [D loss: 0.752316] [G loss: 0.492944] time: 0:56:40.273089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9104001\n",
      "[Epoch 37/50] [Batch 297/300] [D loss: 0.752304] [G loss: 0.482723] time: 0:56:40.572450\n",
      "0.9685304\n",
      "[Epoch 37/50] [Batch 298/300] [D loss: 0.752305] [G loss: 0.485632] time: 0:56:40.892470\n",
      "0.92109156\n",
      "[Epoch 37/50] [Batch 299/300] [D loss: 0.752308] [G loss: 0.497863] time: 0:56:41.190722\n",
      "0.85328746\n",
      "[Epoch 38/50] [Batch 0/300] [D loss: 0.752297] [G loss: 0.483720] time: 0:56:41.496950\n",
      "0.9367404\n",
      "[Epoch 38/50] [Batch 1/300] [D loss: 0.752306] [G loss: 0.481457] time: 0:56:41.805940\n",
      "0.92244023\n",
      "[Epoch 38/50] [Batch 2/300] [D loss: 0.752317] [G loss: 0.494877] time: 0:56:42.103295\n",
      "0.94624966\n",
      "[Epoch 38/50] [Batch 3/300] [D loss: 0.752308] [G loss: 0.482883] time: 0:56:42.403098\n",
      "0.93154484\n",
      "[Epoch 38/50] [Batch 4/300] [D loss: 0.752307] [G loss: 0.475685] time: 0:56:42.710982\n",
      "0.95811576\n",
      "[Epoch 38/50] [Batch 5/300] [D loss: 0.752303] [G loss: 0.476728] time: 0:56:43.032295\n",
      "0.9309489\n",
      "[Epoch 38/50] [Batch 6/300] [D loss: 0.752309] [G loss: 0.480777] time: 0:56:43.342869\n",
      "0.98302245\n",
      "[Epoch 38/50] [Batch 7/300] [D loss: 0.752314] [G loss: 0.468496] time: 0:56:43.628460\n",
      "0.93629676\n",
      "[Epoch 38/50] [Batch 8/300] [D loss: 0.752303] [G loss: 0.516244] time: 0:56:43.924788\n",
      "0.9189337\n",
      "[Epoch 38/50] [Batch 9/300] [D loss: 0.752299] [G loss: 0.479970] time: 0:56:44.247125\n",
      "0.946719\n",
      "[Epoch 38/50] [Batch 10/300] [D loss: 0.752291] [G loss: 0.491554] time: 0:56:44.551982\n",
      "0.90578604\n",
      "[Epoch 38/50] [Batch 11/300] [D loss: 0.752307] [G loss: 0.484216] time: 0:56:44.844701\n",
      "0.94266343\n",
      "[Epoch 38/50] [Batch 12/300] [D loss: 0.752304] [G loss: 0.476611] time: 0:56:45.126790\n",
      "0.87633896\n",
      "[Epoch 38/50] [Batch 13/300] [D loss: 0.752291] [G loss: 0.480520] time: 0:56:45.423109\n",
      "0.9331377\n",
      "[Epoch 38/50] [Batch 14/300] [D loss: 0.752300] [G loss: 0.469871] time: 0:56:45.740161\n",
      "0.8931177\n",
      "[Epoch 38/50] [Batch 15/300] [D loss: 0.752318] [G loss: 0.487510] time: 0:56:46.049830\n",
      "0.90407187\n",
      "[Epoch 38/50] [Batch 16/300] [D loss: 0.752294] [G loss: 0.480816] time: 0:56:46.338869\n",
      "0.88594204\n",
      "[Epoch 38/50] [Batch 17/300] [D loss: 0.752292] [G loss: 0.484091] time: 0:56:46.644714\n",
      "0.93838185\n",
      "[Epoch 38/50] [Batch 18/300] [D loss: 0.752316] [G loss: 0.485159] time: 0:56:46.953959\n",
      "0.909167\n",
      "[Epoch 38/50] [Batch 19/300] [D loss: 0.752293] [G loss: 0.480911] time: 0:56:47.263438\n",
      "0.92802477\n",
      "[Epoch 38/50] [Batch 20/300] [D loss: 0.752306] [G loss: 0.474648] time: 0:56:47.557416\n",
      "0.92512536\n",
      "[Epoch 38/50] [Batch 21/300] [D loss: 0.752303] [G loss: 0.505586] time: 0:56:47.854493\n",
      "0.92966527\n",
      "[Epoch 38/50] [Batch 22/300] [D loss: 0.752319] [G loss: 0.502333] time: 0:56:48.181954\n",
      "0.9467275\n",
      "[Epoch 38/50] [Batch 23/300] [D loss: 0.752296] [G loss: 0.487913] time: 0:56:48.467532\n",
      "0.9590202\n",
      "[Epoch 38/50] [Batch 24/300] [D loss: 0.752305] [G loss: 0.489920] time: 0:56:48.751227\n",
      "0.9308739\n",
      "[Epoch 38/50] [Batch 25/300] [D loss: 0.752303] [G loss: 0.495722] time: 0:56:49.035997\n",
      "0.93875164\n",
      "[Epoch 38/50] [Batch 26/300] [D loss: 0.752315] [G loss: 0.480038] time: 0:56:49.319877\n",
      "0.8989889\n",
      "[Epoch 38/50] [Batch 27/300] [D loss: 0.752309] [G loss: 0.482700] time: 0:56:49.629514\n",
      "0.8743394\n",
      "[Epoch 38/50] [Batch 28/300] [D loss: 0.752297] [G loss: 0.531798] time: 0:56:49.924106\n",
      "0.9454455\n",
      "[Epoch 38/50] [Batch 29/300] [D loss: 0.752292] [G loss: 0.486447] time: 0:56:50.211268\n",
      "0.9074087\n",
      "[Epoch 38/50] [Batch 30/300] [D loss: 0.752302] [G loss: 0.487781] time: 0:56:50.516691\n",
      "0.89332396\n",
      "[Epoch 38/50] [Batch 31/300] [D loss: 0.752306] [G loss: 0.492184] time: 0:56:50.820820\n",
      "0.9452773\n",
      "[Epoch 38/50] [Batch 32/300] [D loss: 0.752311] [G loss: 0.482994] time: 0:56:51.136244\n",
      "0.92948025\n",
      "[Epoch 38/50] [Batch 33/300] [D loss: 0.752300] [G loss: 0.502200] time: 0:56:51.440325\n",
      "0.921254\n",
      "[Epoch 38/50] [Batch 34/300] [D loss: 0.752286] [G loss: 0.471576] time: 0:56:51.739850\n",
      "0.9668116\n",
      "[Epoch 38/50] [Batch 35/300] [D loss: 0.752315] [G loss: 0.482504] time: 0:56:52.047931\n",
      "0.922463\n",
      "[Epoch 38/50] [Batch 36/300] [D loss: 0.752305] [G loss: 0.477156] time: 0:56:52.356256\n",
      "0.89338946\n",
      "[Epoch 38/50] [Batch 38/300] [D loss: 0.752304] [G loss: 0.474597] time: 0:56:52.672586\n",
      "0.90467304\n",
      "[Epoch 38/50] [Batch 39/300] [D loss: 0.752296] [G loss: 0.476668] time: 0:56:52.974578\n",
      "0.9075866\n",
      "[Epoch 38/50] [Batch 40/300] [D loss: 0.752307] [G loss: 0.480483] time: 0:56:53.281605\n",
      "0.9288607\n",
      "[Epoch 38/50] [Batch 41/300] [D loss: 0.752294] [G loss: 0.477556] time: 0:56:53.579083\n",
      "0.94289774\n",
      "[Epoch 38/50] [Batch 42/300] [D loss: 0.752311] [G loss: 0.479472] time: 0:56:53.854802\n",
      "0.9159916\n",
      "[Epoch 38/50] [Batch 43/300] [D loss: 0.752314] [G loss: 0.479757] time: 0:56:54.160456\n",
      "0.93323785\n",
      "[Epoch 38/50] [Batch 44/300] [D loss: 0.752301] [G loss: 0.479357] time: 0:56:54.463593\n",
      "0.89879197\n",
      "[Epoch 38/50] [Batch 45/300] [D loss: 0.752287] [G loss: 0.477833] time: 0:56:54.764687\n",
      "0.92960954\n",
      "[Epoch 38/50] [Batch 46/300] [D loss: 0.752308] [G loss: 0.478202] time: 0:56:55.059943\n",
      "0.93950874\n",
      "[Epoch 38/50] [Batch 47/300] [D loss: 0.752293] [G loss: 0.478289] time: 0:56:55.364637\n",
      "0.9065357\n",
      "[Epoch 38/50] [Batch 48/300] [D loss: 0.752309] [G loss: 0.483319] time: 0:56:55.645122\n",
      "0.94308394\n",
      "[Epoch 38/50] [Batch 49/300] [D loss: 0.752321] [G loss: 0.489081] time: 0:56:55.959527\n",
      "0.9007969\n",
      "[Epoch 38/50] [Batch 50/300] [D loss: 0.752298] [G loss: 0.488790] time: 0:56:56.269886\n",
      "0.9422369\n",
      "[Epoch 38/50] [Batch 51/300] [D loss: 0.752302] [G loss: 0.473493] time: 0:56:56.567688\n",
      "0.9215724\n",
      "[Epoch 38/50] [Batch 52/300] [D loss: 0.752295] [G loss: 0.475439] time: 0:56:56.873900\n",
      "0.9317319\n",
      "[Epoch 38/50] [Batch 53/300] [D loss: 0.752291] [G loss: 0.499810] time: 0:56:57.177443\n",
      "0.91545004\n",
      "[Epoch 38/50] [Batch 54/300] [D loss: 0.752330] [G loss: 0.489170] time: 0:56:57.477001\n",
      "0.9090791\n",
      "[Epoch 38/50] [Batch 55/300] [D loss: 0.752308] [G loss: 0.480574] time: 0:56:57.772181\n",
      "0.93318397\n",
      "[Epoch 38/50] [Batch 56/300] [D loss: 0.752309] [G loss: 0.475571] time: 0:56:58.084607\n",
      "0.93906575\n",
      "[Epoch 38/50] [Batch 57/300] [D loss: 0.752307] [G loss: 0.480447] time: 0:56:58.387928\n",
      "0.9329837\n",
      "[Epoch 38/50] [Batch 58/300] [D loss: 0.752304] [G loss: 0.480345] time: 0:56:58.691851\n",
      "0.91404605\n",
      "[Epoch 38/50] [Batch 59/300] [D loss: 0.752310] [G loss: 0.477687] time: 0:56:59.010605\n",
      "0.9050457\n",
      "[Epoch 38/50] [Batch 60/300] [D loss: 0.752314] [G loss: 0.489880] time: 0:56:59.292500\n",
      "0.88572675\n",
      "[Epoch 38/50] [Batch 61/300] [D loss: 0.752302] [G loss: 0.502211] time: 0:56:59.609547\n",
      "0.9529217\n",
      "[Epoch 38/50] [Batch 62/300] [D loss: 0.752299] [G loss: 0.488223] time: 0:56:59.914274\n",
      "0.97520167\n",
      "[Epoch 38/50] [Batch 63/300] [D loss: 0.752297] [G loss: 0.482573] time: 0:57:00.213539\n",
      "0.8904653\n",
      "[Epoch 38/50] [Batch 64/300] [D loss: 0.752299] [G loss: 0.480758] time: 0:57:00.511788\n",
      "0.90761274\n",
      "[Epoch 38/50] [Batch 65/300] [D loss: 0.752307] [G loss: 0.476949] time: 0:57:00.808879\n",
      "0.93098956\n",
      "[Epoch 38/50] [Batch 66/300] [D loss: 0.752294] [G loss: 0.492013] time: 0:57:01.123776\n",
      "0.8814669\n",
      "[Epoch 38/50] [Batch 67/300] [D loss: 0.752313] [G loss: 0.471237] time: 0:57:01.415835\n",
      "0.86688805\n",
      "[Epoch 38/50] [Batch 68/300] [D loss: 0.752303] [G loss: 0.471872] time: 0:57:01.704504\n",
      "0.9137489\n",
      "[Epoch 38/50] [Batch 69/300] [D loss: 0.752296] [G loss: 0.477799] time: 0:57:02.006645\n",
      "0.89145106\n",
      "[Epoch 38/50] [Batch 70/300] [D loss: 0.752323] [G loss: 0.482313] time: 0:57:02.299110\n",
      "0.90649635\n",
      "[Epoch 38/50] [Batch 71/300] [D loss: 0.752299] [G loss: 0.488834] time: 0:57:02.598001\n",
      "0.9318504\n",
      "[Epoch 38/50] [Batch 72/300] [D loss: 0.752297] [G loss: 0.486770] time: 0:57:02.908462\n",
      "0.91685337\n",
      "[Epoch 38/50] [Batch 73/300] [D loss: 0.752301] [G loss: 0.485984] time: 0:57:03.177688\n",
      "0.93440276\n",
      "[Epoch 38/50] [Batch 74/300] [D loss: 0.752285] [G loss: 0.473647] time: 0:57:03.457672\n",
      "0.9169099\n",
      "[Epoch 38/50] [Batch 75/300] [D loss: 0.752291] [G loss: 0.480128] time: 0:57:03.751397\n",
      "0.9416782\n",
      "[Epoch 38/50] [Batch 76/300] [D loss: 0.752299] [G loss: 0.492128] time: 0:57:04.058320\n",
      "0.9058916\n",
      "[Epoch 38/50] [Batch 77/300] [D loss: 0.752294] [G loss: 0.481473] time: 0:57:04.369751\n",
      "0.94532794\n",
      "[Epoch 38/50] [Batch 78/300] [D loss: 0.752293] [G loss: 0.489182] time: 0:57:04.667145\n",
      "0.91213655\n",
      "[Epoch 38/50] [Batch 79/300] [D loss: 0.752300] [G loss: 0.486575] time: 0:57:04.957629\n",
      "0.9612057\n",
      "[Epoch 38/50] [Batch 80/300] [D loss: 0.752303] [G loss: 0.489854] time: 0:57:05.277084\n",
      "0.94635624\n",
      "[Epoch 38/50] [Batch 81/300] [D loss: 0.752299] [G loss: 0.466488] time: 0:57:05.588435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92928\n",
      "[Epoch 38/50] [Batch 82/300] [D loss: 0.752310] [G loss: 0.477712] time: 0:57:05.886520\n",
      "0.97618\n",
      "[Epoch 38/50] [Batch 83/300] [D loss: 0.752297] [G loss: 0.488042] time: 0:57:06.163766\n",
      "0.8884286\n",
      "[Epoch 38/50] [Batch 84/300] [D loss: 0.752312] [G loss: 0.483629] time: 0:57:06.462073\n",
      "0.9348132\n",
      "[Epoch 38/50] [Batch 85/300] [D loss: 0.752298] [G loss: 0.502169] time: 0:57:06.771893\n",
      "0.939431\n",
      "[Epoch 38/50] [Batch 86/300] [D loss: 0.752298] [G loss: 0.499819] time: 0:57:07.071411\n",
      "0.9085195\n",
      "[Epoch 38/50] [Batch 87/300] [D loss: 0.752300] [G loss: 0.481587] time: 0:57:07.385434\n",
      "0.9763126\n",
      "[Epoch 38/50] [Batch 88/300] [D loss: 0.752299] [G loss: 0.492538] time: 0:57:07.692596\n",
      "0.90830183\n",
      "[Epoch 38/50] [Batch 89/300] [D loss: 0.752303] [G loss: 0.479745] time: 0:57:07.995126\n",
      "0.94628143\n",
      "[Epoch 38/50] [Batch 90/300] [D loss: 0.752310] [G loss: 0.504232] time: 0:57:08.290143\n",
      "0.93887186\n",
      "[Epoch 38/50] [Batch 91/300] [D loss: 0.752303] [G loss: 0.481198] time: 0:57:08.608113\n",
      "0.8806669\n",
      "[Epoch 38/50] [Batch 92/300] [D loss: 0.752297] [G loss: 0.478081] time: 0:57:08.886615\n",
      "0.8857202\n",
      "[Epoch 38/50] [Batch 93/300] [D loss: 0.752303] [G loss: 0.481080] time: 0:57:09.190666\n",
      "0.9105175\n",
      "[Epoch 38/50] [Batch 94/300] [D loss: 0.752308] [G loss: 0.476691] time: 0:57:09.500489\n",
      "0.935802\n",
      "[Epoch 38/50] [Batch 95/300] [D loss: 0.752287] [G loss: 0.499557] time: 0:57:09.804048\n",
      "0.92579794\n",
      "[Epoch 38/50] [Batch 96/300] [D loss: 0.752297] [G loss: 0.467795] time: 0:57:10.105883\n",
      "0.90322757\n",
      "[Epoch 38/50] [Batch 97/300] [D loss: 0.752296] [G loss: 0.500500] time: 0:57:10.396924\n",
      "0.8679908\n",
      "[Epoch 38/50] [Batch 98/300] [D loss: 0.752301] [G loss: 0.496515] time: 0:57:10.712707\n",
      "0.9178025\n",
      "[Epoch 38/50] [Batch 99/300] [D loss: 0.752300] [G loss: 0.483802] time: 0:57:11.013676\n",
      "0.9470101\n",
      "[Epoch 38/50] [Batch 100/300] [D loss: 0.752295] [G loss: 0.489513] time: 0:57:11.303566\n",
      "0.9089081\n",
      "[Epoch 38/50] [Batch 101/300] [D loss: 0.752292] [G loss: 0.480295] time: 0:57:11.618981\n",
      "0.9372286\n",
      "[Epoch 38/50] [Batch 102/300] [D loss: 0.752318] [G loss: 0.472275] time: 0:57:11.932965\n",
      "0.93261313\n",
      "[Epoch 38/50] [Batch 103/300] [D loss: 0.752295] [G loss: 0.476105] time: 0:57:12.239683\n",
      "0.93580014\n",
      "[Epoch 38/50] [Batch 104/300] [D loss: 0.752298] [G loss: 0.487282] time: 0:57:12.542239\n",
      "0.88973784\n",
      "[Epoch 38/50] [Batch 105/300] [D loss: 0.752301] [G loss: 0.482716] time: 0:57:12.831506\n",
      "0.91772336\n",
      "[Epoch 38/50] [Batch 106/300] [D loss: 0.752282] [G loss: 0.498918] time: 0:57:13.125224\n",
      "0.89915895\n",
      "[Epoch 38/50] [Batch 107/300] [D loss: 0.752296] [G loss: 0.488163] time: 0:57:13.423448\n",
      "0.8831026\n",
      "[Epoch 38/50] [Batch 108/300] [D loss: 0.752294] [G loss: 0.484323] time: 0:57:13.728143\n",
      "0.961293\n",
      "[Epoch 38/50] [Batch 109/300] [D loss: 0.752309] [G loss: 0.496962] time: 0:57:14.024305\n",
      "0.9255647\n",
      "[Epoch 38/50] [Batch 110/300] [D loss: 0.752304] [G loss: 0.478731] time: 0:57:14.345796\n",
      "0.91692215\n",
      "[Epoch 38/50] [Batch 111/300] [D loss: 0.752300] [G loss: 0.485734] time: 0:57:14.623369\n",
      "0.8841498\n",
      "[Epoch 38/50] [Batch 112/300] [D loss: 0.752309] [G loss: 0.483451] time: 0:57:14.937612\n",
      "0.93422216\n",
      "[Epoch 38/50] [Batch 113/300] [D loss: 0.752308] [G loss: 0.477874] time: 0:57:15.238043\n",
      "0.9173141\n",
      "[Epoch 38/50] [Batch 114/300] [D loss: 0.752304] [G loss: 0.476087] time: 0:57:15.545397\n",
      "0.92915195\n",
      "[Epoch 38/50] [Batch 115/300] [D loss: 0.752312] [G loss: 0.475961] time: 0:57:15.851622\n",
      "0.90005356\n",
      "[Epoch 38/50] [Batch 116/300] [D loss: 0.752298] [G loss: 0.477159] time: 0:57:16.164195\n",
      "0.90718746\n",
      "[Epoch 38/50] [Batch 117/300] [D loss: 0.752298] [G loss: 0.502514] time: 0:57:16.453483\n",
      "0.93502825\n",
      "[Epoch 38/50] [Batch 118/300] [D loss: 0.752294] [G loss: 0.471663] time: 0:57:16.741848\n",
      "0.9167258\n",
      "[Epoch 38/50] [Batch 119/300] [D loss: 0.752305] [G loss: 0.476161] time: 0:57:17.051709\n",
      "0.9358744\n",
      "[Epoch 38/50] [Batch 120/300] [D loss: 0.752295] [G loss: 0.499007] time: 0:57:17.350479\n",
      "0.8699508\n",
      "[Epoch 38/50] [Batch 121/300] [D loss: 0.752306] [G loss: 0.483513] time: 0:57:17.669915\n",
      "0.91927195\n",
      "[Epoch 38/50] [Batch 122/300] [D loss: 0.752311] [G loss: 0.480114] time: 0:57:17.982569\n",
      "0.9337271\n",
      "[Epoch 38/50] [Batch 123/300] [D loss: 0.752294] [G loss: 0.514963] time: 0:57:18.283538\n",
      "0.89769316\n",
      "[Epoch 38/50] [Batch 124/300] [D loss: 0.752292] [G loss: 0.480757] time: 0:57:18.586663\n",
      "0.94323397\n",
      "[Epoch 38/50] [Batch 125/300] [D loss: 0.752301] [G loss: 0.488309] time: 0:57:18.882439\n",
      "0.9690955\n",
      "[Epoch 38/50] [Batch 126/300] [D loss: 0.752306] [G loss: 0.484042] time: 0:57:19.186045\n",
      "0.9121046\n",
      "[Epoch 38/50] [Batch 127/300] [D loss: 0.752318] [G loss: 0.476529] time: 0:57:19.504155\n",
      "0.9713934\n",
      "[Epoch 38/50] [Batch 128/300] [D loss: 0.752306] [G loss: 0.469500] time: 0:57:19.812550\n",
      "0.89068246\n",
      "[Epoch 38/50] [Batch 129/300] [D loss: 0.752294] [G loss: 0.475185] time: 0:57:20.103767\n",
      "0.93450326\n",
      "[Epoch 38/50] [Batch 130/300] [D loss: 0.752306] [G loss: 0.476769] time: 0:57:20.415423\n",
      "0.91700697\n",
      "[Epoch 38/50] [Batch 131/300] [D loss: 0.752306] [G loss: 0.466960] time: 0:57:20.727261\n",
      "0.90819573\n",
      "[Epoch 38/50] [Batch 132/300] [D loss: 0.752303] [G loss: 0.475303] time: 0:57:21.033634\n",
      "0.93930703\n",
      "[Epoch 38/50] [Batch 133/300] [D loss: 0.752298] [G loss: 0.483000] time: 0:57:21.332042\n",
      "0.929854\n",
      "[Epoch 38/50] [Batch 134/300] [D loss: 0.752324] [G loss: 0.471628] time: 0:57:21.636196\n",
      "0.9545886\n",
      "[Epoch 38/50] [Batch 135/300] [D loss: 0.752299] [G loss: 0.480714] time: 0:57:21.938861\n",
      "0.94742197\n",
      "[Epoch 38/50] [Batch 136/300] [D loss: 0.752310] [G loss: 0.465308] time: 0:57:22.225826\n",
      "0.94277674\n",
      "[Epoch 38/50] [Batch 137/300] [D loss: 0.752308] [G loss: 0.469215] time: 0:57:22.533060\n",
      "0.89948505\n",
      "[Epoch 38/50] [Batch 138/300] [D loss: 0.752298] [G loss: 0.485732] time: 0:57:22.835111\n",
      "0.93719\n",
      "[Epoch 38/50] [Batch 139/300] [D loss: 0.752322] [G loss: 0.485826] time: 0:57:23.137807\n",
      "0.95091724\n",
      "[Epoch 38/50] [Batch 140/300] [D loss: 0.752315] [G loss: 0.473188] time: 0:57:23.438972\n",
      "0.94188076\n",
      "[Epoch 38/50] [Batch 141/300] [D loss: 0.752299] [G loss: 0.505052] time: 0:57:23.739247\n",
      "0.9711812\n",
      "[Epoch 38/50] [Batch 142/300] [D loss: 0.752290] [G loss: 0.482675] time: 0:57:24.026782\n",
      "0.9138333\n",
      "[Epoch 38/50] [Batch 143/300] [D loss: 0.752311] [G loss: 0.501866] time: 0:57:24.329242\n",
      "0.8884485\n",
      "[Epoch 38/50] [Batch 144/300] [D loss: 0.752300] [G loss: 0.511772] time: 0:57:24.632947\n",
      "0.8892917\n",
      "[Epoch 38/50] [Batch 145/300] [D loss: 0.752296] [G loss: 0.477021] time: 0:57:24.932945\n",
      "0.88938326\n",
      "[Epoch 38/50] [Batch 146/300] [D loss: 0.752296] [G loss: 0.475882] time: 0:57:25.254315\n",
      "0.9271142\n",
      "[Epoch 38/50] [Batch 147/300] [D loss: 0.752301] [G loss: 0.478954] time: 0:57:25.564320\n",
      "0.9105348\n",
      "[Epoch 38/50] [Batch 148/300] [D loss: 0.752304] [G loss: 0.481268] time: 0:57:25.867803\n",
      "0.9399211\n",
      "[Epoch 38/50] [Batch 149/300] [D loss: 0.752301] [G loss: 0.481498] time: 0:57:26.167754\n",
      "0.9269226\n",
      "[Epoch 38/50] [Batch 150/300] [D loss: 0.752301] [G loss: 0.476228] time: 0:57:26.466905\n",
      "0.9430024\n",
      "[Epoch 38/50] [Batch 151/300] [D loss: 0.752304] [G loss: 0.478972] time: 0:57:26.770099\n",
      "0.97609234\n",
      "[Epoch 38/50] [Batch 152/300] [D loss: 0.752305] [G loss: 0.480435] time: 0:57:27.075063\n",
      "0.9297538\n",
      "[Epoch 38/50] [Batch 153/300] [D loss: 0.752300] [G loss: 0.475692] time: 0:57:27.368028\n",
      "0.92205137\n",
      "[Epoch 38/50] [Batch 154/300] [D loss: 0.752307] [G loss: 0.512963] time: 0:57:27.671753\n",
      "0.91336757\n",
      "[Epoch 38/50] [Batch 155/300] [D loss: 0.752300] [G loss: 0.496468] time: 0:57:27.980195\n",
      "0.91365165\n",
      "[Epoch 38/50] [Batch 156/300] [D loss: 0.752307] [G loss: 0.468433] time: 0:57:28.284843\n",
      "0.8719666\n",
      "[Epoch 38/50] [Batch 157/300] [D loss: 0.752303] [G loss: 0.476396] time: 0:57:28.575946\n",
      "0.89518005\n",
      "[Epoch 38/50] [Batch 158/300] [D loss: 0.752294] [G loss: 0.473419] time: 0:57:28.878701\n",
      "0.8680213\n",
      "[Epoch 38/50] [Batch 159/300] [D loss: 0.752306] [G loss: 0.482631] time: 0:57:29.180967\n",
      "0.91638726\n",
      "[Epoch 38/50] [Batch 160/300] [D loss: 0.752313] [G loss: 0.489711] time: 0:57:29.462158\n",
      "0.9330187\n",
      "[Epoch 38/50] [Batch 161/300] [D loss: 0.752303] [G loss: 0.475231] time: 0:57:29.773104\n",
      "0.9168108\n",
      "[Epoch 38/50] [Batch 162/300] [D loss: 0.752289] [G loss: 0.476504] time: 0:57:30.064329\n",
      "0.9759409\n",
      "[Epoch 38/50] [Batch 163/300] [D loss: 0.752297] [G loss: 0.473681] time: 0:57:30.363625\n",
      "0.939964\n",
      "[Epoch 38/50] [Batch 164/300] [D loss: 0.752309] [G loss: 0.478211] time: 0:57:30.672649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908294\n",
      "[Epoch 38/50] [Batch 165/300] [D loss: 0.752298] [G loss: 0.473288] time: 0:57:30.973960\n",
      "0.9057446\n",
      "[Epoch 38/50] [Batch 166/300] [D loss: 0.752294] [G loss: 0.484039] time: 0:57:31.289369\n",
      "0.928557\n",
      "[Epoch 38/50] [Batch 167/300] [D loss: 0.752300] [G loss: 0.487645] time: 0:57:31.585940\n",
      "0.8909626\n",
      "[Epoch 38/50] [Batch 168/300] [D loss: 0.752298] [G loss: 0.478559] time: 0:57:31.882895\n",
      "0.9302779\n",
      "[Epoch 38/50] [Batch 169/300] [D loss: 0.752306] [G loss: 0.471578] time: 0:57:32.177079\n",
      "0.946095\n",
      "[Epoch 38/50] [Batch 170/300] [D loss: 0.752297] [G loss: 0.477950] time: 0:57:32.478443\n",
      "0.91633326\n",
      "[Epoch 38/50] [Batch 171/300] [D loss: 0.752297] [G loss: 0.487357] time: 0:57:32.782977\n",
      "0.9455369\n",
      "[Epoch 38/50] [Batch 172/300] [D loss: 0.752299] [G loss: 0.487566] time: 0:57:33.066705\n",
      "0.93194026\n",
      "[Epoch 38/50] [Batch 173/300] [D loss: 0.752301] [G loss: 0.484143] time: 0:57:33.361243\n",
      "0.90349835\n",
      "[Epoch 38/50] [Batch 174/300] [D loss: 0.752294] [G loss: 0.479992] time: 0:57:33.654829\n",
      "0.92481154\n",
      "[Epoch 38/50] [Batch 175/300] [D loss: 0.752295] [G loss: 0.477894] time: 0:57:33.957369\n",
      "0.9159517\n",
      "[Epoch 38/50] [Batch 176/300] [D loss: 0.752299] [G loss: 0.475961] time: 0:57:34.255364\n",
      "0.8936696\n",
      "[Epoch 38/50] [Batch 177/300] [D loss: 0.752301] [G loss: 0.486166] time: 0:57:34.538693\n",
      "0.93709034\n",
      "[Epoch 38/50] [Batch 178/300] [D loss: 0.752318] [G loss: 0.483178] time: 0:57:34.843192\n",
      "0.89733166\n",
      "[Epoch 38/50] [Batch 179/300] [D loss: 0.752288] [G loss: 0.479444] time: 0:57:35.144115\n",
      "0.94470376\n",
      "[Epoch 38/50] [Batch 180/300] [D loss: 0.752278] [G loss: 0.472073] time: 0:57:35.440828\n",
      "0.8843088\n",
      "[Epoch 38/50] [Batch 181/300] [D loss: 0.752321] [G loss: 0.478654] time: 0:57:35.747211\n",
      "0.93352574\n",
      "[Epoch 38/50] [Batch 182/300] [D loss: 0.752310] [G loss: 0.485349] time: 0:57:36.041734\n",
      "0.9204114\n",
      "[Epoch 38/50] [Batch 183/300] [D loss: 0.752282] [G loss: 0.489992] time: 0:57:36.339460\n",
      "0.9818092\n",
      "[Epoch 38/50] [Batch 184/300] [D loss: 0.752295] [G loss: 0.471672] time: 0:57:36.621797\n",
      "0.92942595\n",
      "[Epoch 38/50] [Batch 185/300] [D loss: 0.752301] [G loss: 0.474388] time: 0:57:36.917152\n",
      "0.9077222\n",
      "[Epoch 38/50] [Batch 186/300] [D loss: 0.752290] [G loss: 0.488308] time: 0:57:37.229513\n",
      "0.9499534\n",
      "[Epoch 38/50] [Batch 187/300] [D loss: 0.752301] [G loss: 0.486898] time: 0:57:37.538591\n",
      "0.97069734\n",
      "[Epoch 38/50] [Batch 188/300] [D loss: 0.752297] [G loss: 0.477818] time: 0:57:37.832785\n",
      "0.8986314\n",
      "[Epoch 38/50] [Batch 189/300] [D loss: 0.752307] [G loss: 0.490098] time: 0:57:38.129798\n",
      "0.88609725\n",
      "[Epoch 38/50] [Batch 190/300] [D loss: 0.752295] [G loss: 0.477695] time: 0:57:38.435698\n",
      "0.8945088\n",
      "[Epoch 38/50] [Batch 191/300] [D loss: 0.752289] [G loss: 0.487876] time: 0:57:38.754656\n",
      "0.89152867\n",
      "[Epoch 38/50] [Batch 192/300] [D loss: 0.752297] [G loss: 0.488676] time: 0:57:39.060391\n",
      "0.9079943\n",
      "[Epoch 38/50] [Batch 193/300] [D loss: 0.752289] [G loss: 0.489319] time: 0:57:39.340311\n",
      "0.90846425\n",
      "[Epoch 38/50] [Batch 194/300] [D loss: 0.752304] [G loss: 0.472379] time: 0:57:39.640275\n",
      "0.8808408\n",
      "[Epoch 38/50] [Batch 195/300] [D loss: 0.752298] [G loss: 0.489537] time: 0:57:39.957252\n",
      "0.91115093\n",
      "[Epoch 38/50] [Batch 196/300] [D loss: 0.752294] [G loss: 0.495934] time: 0:57:40.255062\n",
      "0.91608095\n",
      "[Epoch 38/50] [Batch 197/300] [D loss: 0.752305] [G loss: 0.490737] time: 0:57:40.571190\n",
      "0.97116286\n",
      "[Epoch 38/50] [Batch 198/300] [D loss: 0.752291] [G loss: 0.470125] time: 0:57:40.847194\n",
      "0.93329763\n",
      "[Epoch 38/50] [Batch 199/300] [D loss: 0.752292] [G loss: 0.484862] time: 0:57:41.132757\n",
      "0.9599152\n",
      "[Epoch 38/50] [Batch 200/300] [D loss: 0.752296] [G loss: 0.485798] time: 0:57:41.431984\n",
      "0.9016405\n",
      "[Epoch 38/50] [Batch 201/300] [D loss: 0.752298] [G loss: 0.480031] time: 0:57:41.706248\n",
      "0.96818656\n",
      "[Epoch 38/50] [Batch 202/300] [D loss: 0.752303] [G loss: 0.472310] time: 0:57:41.969176\n",
      "0.9463389\n",
      "[Epoch 38/50] [Batch 203/300] [D loss: 0.752301] [G loss: 0.507470] time: 0:57:42.264826\n",
      "0.93555456\n",
      "[Epoch 38/50] [Batch 204/300] [D loss: 0.752307] [G loss: 0.495241] time: 0:57:42.581075\n",
      "0.871814\n",
      "[Epoch 38/50] [Batch 205/300] [D loss: 0.752308] [G loss: 0.482215] time: 0:57:42.857825\n",
      "0.93743736\n",
      "[Epoch 38/50] [Batch 206/300] [D loss: 0.752295] [G loss: 0.474255] time: 0:57:43.160506\n",
      "0.91164356\n",
      "[Epoch 38/50] [Batch 207/300] [D loss: 0.752298] [G loss: 0.486699] time: 0:57:43.463691\n",
      "0.9699673\n",
      "[Epoch 38/50] [Batch 208/300] [D loss: 0.752294] [G loss: 0.491717] time: 0:57:43.761366\n",
      "0.94256324\n",
      "[Epoch 38/50] [Batch 209/300] [D loss: 0.752303] [G loss: 0.481500] time: 0:57:44.069323\n",
      "0.9238307\n",
      "[Epoch 38/50] [Batch 210/300] [D loss: 0.752307] [G loss: 0.491125] time: 0:57:44.371090\n",
      "0.9204521\n",
      "[Epoch 38/50] [Batch 211/300] [D loss: 0.752298] [G loss: 0.483768] time: 0:57:44.674855\n",
      "0.9137292\n",
      "[Epoch 38/50] [Batch 212/300] [D loss: 0.752301] [G loss: 0.489676] time: 0:57:44.978200\n",
      "0.91618603\n",
      "[Epoch 38/50] [Batch 213/300] [D loss: 0.752305] [G loss: 0.497648] time: 0:57:45.276460\n",
      "0.915955\n",
      "[Epoch 38/50] [Batch 214/300] [D loss: 0.752296] [G loss: 0.469332] time: 0:57:45.582999\n",
      "0.9455647\n",
      "[Epoch 38/50] [Batch 215/300] [D loss: 0.752294] [G loss: 0.508434] time: 0:57:45.887094\n",
      "0.92847276\n",
      "[Epoch 38/50] [Batch 216/300] [D loss: 0.752298] [G loss: 0.473576] time: 0:57:46.187022\n",
      "0.91666937\n",
      "[Epoch 38/50] [Batch 217/300] [D loss: 0.752292] [G loss: 0.487940] time: 0:57:46.467212\n",
      "0.9397785\n",
      "[Epoch 38/50] [Batch 218/300] [D loss: 0.752304] [G loss: 0.488939] time: 0:57:46.763417\n",
      "0.9830273\n",
      "[Epoch 38/50] [Batch 219/300] [D loss: 0.752296] [G loss: 0.480820] time: 0:57:47.053331\n",
      "0.8878805\n",
      "[Epoch 38/50] [Batch 220/300] [D loss: 0.752290] [G loss: 0.524003] time: 0:57:47.364716\n",
      "0.9331713\n",
      "[Epoch 38/50] [Batch 221/300] [D loss: 0.752299] [G loss: 0.480319] time: 0:57:47.670304\n",
      "0.97546333\n",
      "[Epoch 38/50] [Batch 222/300] [D loss: 0.752285] [G loss: 0.494748] time: 0:57:47.957450\n",
      "0.94149995\n",
      "[Epoch 38/50] [Batch 223/300] [D loss: 0.752299] [G loss: 0.505290] time: 0:57:48.248000\n",
      "0.928128\n",
      "[Epoch 38/50] [Batch 224/300] [D loss: 0.752281] [G loss: 0.502327] time: 0:57:48.543050\n",
      "0.9580744\n",
      "[Epoch 38/50] [Batch 225/300] [D loss: 0.752310] [G loss: 0.487539] time: 0:57:48.851052\n",
      "0.90040636\n",
      "[Epoch 38/50] [Batch 226/300] [D loss: 0.752308] [G loss: 0.500903] time: 0:57:49.151944\n",
      "0.90668744\n",
      "[Epoch 38/50] [Batch 227/300] [D loss: 0.752287] [G loss: 0.479925] time: 0:57:49.574883\n",
      "0.92430896\n",
      "[Epoch 38/50] [Batch 228/300] [D loss: 0.752289] [G loss: 0.508023] time: 0:57:49.874034\n",
      "0.9479874\n",
      "[Epoch 38/50] [Batch 229/300] [D loss: 0.752298] [G loss: 0.494092] time: 0:57:50.151865\n",
      "0.9317128\n",
      "[Epoch 38/50] [Batch 230/300] [D loss: 0.752305] [G loss: 0.481239] time: 0:57:50.453572\n",
      "0.93175507\n",
      "[Epoch 38/50] [Batch 231/300] [D loss: 0.752310] [G loss: 0.478768] time: 0:57:50.756216\n",
      "0.9549281\n",
      "[Epoch 38/50] [Batch 232/300] [D loss: 0.752301] [G loss: 0.477032] time: 0:57:51.058734\n",
      "0.9326782\n",
      "[Epoch 38/50] [Batch 233/300] [D loss: 0.752289] [G loss: 0.503020] time: 0:57:51.355794\n",
      "0.8932273\n",
      "[Epoch 38/50] [Batch 234/300] [D loss: 0.752309] [G loss: 0.495180] time: 0:57:51.640727\n",
      "0.9412461\n",
      "[Epoch 38/50] [Batch 235/300] [D loss: 0.752304] [G loss: 0.475317] time: 0:57:51.934939\n",
      "0.8876281\n",
      "[Epoch 38/50] [Batch 236/300] [D loss: 0.752307] [G loss: 0.481848] time: 0:57:52.230973\n",
      "0.9327356\n",
      "[Epoch 38/50] [Batch 237/300] [D loss: 0.752308] [G loss: 0.489247] time: 0:57:52.532783\n",
      "0.90914893\n",
      "[Epoch 38/50] [Batch 238/300] [D loss: 0.752326] [G loss: 0.506730] time: 0:57:52.828181\n",
      "0.9685063\n",
      "[Epoch 38/50] [Batch 239/300] [D loss: 0.752309] [G loss: 0.509554] time: 0:57:53.125170\n",
      "0.8981584\n",
      "[Epoch 38/50] [Batch 240/300] [D loss: 0.752306] [G loss: 0.488341] time: 0:57:53.425043\n",
      "0.9482592\n",
      "[Epoch 38/50] [Batch 241/300] [D loss: 0.752320] [G loss: 0.480633] time: 0:57:53.723594\n",
      "0.8872757\n",
      "[Epoch 38/50] [Batch 242/300] [D loss: 0.752316] [G loss: 0.476997] time: 0:57:54.027637\n",
      "0.98285943\n",
      "[Epoch 38/50] [Batch 243/300] [D loss: 0.752303] [G loss: 0.483259] time: 0:57:54.327054\n",
      "0.97616094\n",
      "[Epoch 38/50] [Batch 244/300] [D loss: 0.752286] [G loss: 0.477212] time: 0:57:54.620121\n",
      "0.9104767\n",
      "[Epoch 38/50] [Batch 245/300] [D loss: 0.752301] [G loss: 0.482095] time: 0:57:54.922484\n",
      "0.9449651\n",
      "[Epoch 38/50] [Batch 246/300] [D loss: 0.752305] [G loss: 0.470217] time: 0:57:55.233629\n",
      "0.94236374\n",
      "[Epoch 38/50] [Batch 247/300] [D loss: 0.752324] [G loss: 0.469736] time: 0:57:55.530455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8836899\n",
      "[Epoch 38/50] [Batch 248/300] [D loss: 0.752292] [G loss: 0.469903] time: 0:57:55.829968\n",
      "0.91440034\n",
      "[Epoch 38/50] [Batch 249/300] [D loss: 0.752294] [G loss: 0.477229] time: 0:57:56.143285\n",
      "0.97110814\n",
      "[Epoch 38/50] [Batch 250/300] [D loss: 0.752306] [G loss: 0.473710] time: 0:57:56.440318\n",
      "0.9160156\n",
      "[Epoch 38/50] [Batch 251/300] [D loss: 0.752298] [G loss: 0.476874] time: 0:57:56.748996\n",
      "0.8895518\n",
      "[Epoch 38/50] [Batch 252/300] [D loss: 0.752299] [G loss: 0.501185] time: 0:57:57.067595\n",
      "0.9217443\n",
      "[Epoch 38/50] [Batch 253/300] [D loss: 0.752310] [G loss: 0.487706] time: 0:57:57.372098\n",
      "0.93179935\n",
      "[Epoch 38/50] [Batch 254/300] [D loss: 0.752302] [G loss: 0.488932] time: 0:57:57.677883\n",
      "0.87201065\n",
      "[Epoch 38/50] [Batch 255/300] [D loss: 0.752291] [G loss: 0.489666] time: 0:57:57.995617\n",
      "0.9307644\n",
      "[Epoch 38/50] [Batch 256/300] [D loss: 0.752312] [G loss: 0.481961] time: 0:57:58.313299\n",
      "0.9476106\n",
      "[Epoch 38/50] [Batch 257/300] [D loss: 0.752294] [G loss: 0.489312] time: 0:57:58.591392\n",
      "0.9001486\n",
      "[Epoch 38/50] [Batch 258/300] [D loss: 0.752303] [G loss: 0.485752] time: 0:57:58.889922\n",
      "0.93553203\n",
      "[Epoch 38/50] [Batch 259/300] [D loss: 0.752294] [G loss: 0.505946] time: 0:57:59.181510\n",
      "0.8989844\n",
      "[Epoch 38/50] [Batch 260/300] [D loss: 0.752297] [G loss: 0.477354] time: 0:57:59.499964\n",
      "0.8676224\n",
      "[Epoch 38/50] [Batch 261/300] [D loss: 0.752295] [G loss: 0.483768] time: 0:57:59.810652\n",
      "0.9130904\n",
      "[Epoch 38/50] [Batch 262/300] [D loss: 0.752294] [G loss: 0.481521] time: 0:58:00.113391\n",
      "0.90507936\n",
      "[Epoch 38/50] [Batch 263/300] [D loss: 0.752296] [G loss: 0.476034] time: 0:58:00.424456\n",
      "0.96198255\n",
      "[Epoch 38/50] [Batch 264/300] [D loss: 0.752295] [G loss: 0.487862] time: 0:58:00.719214\n",
      "0.93253237\n",
      "[Epoch 38/50] [Batch 265/300] [D loss: 0.752285] [G loss: 0.496633] time: 0:58:01.018761\n",
      "0.92255235\n",
      "[Epoch 38/50] [Batch 266/300] [D loss: 0.752304] [G loss: 0.468848] time: 0:58:01.305844\n",
      "0.867698\n",
      "[Epoch 38/50] [Batch 267/300] [D loss: 0.752287] [G loss: 0.478069] time: 0:58:01.593752\n",
      "0.92174006\n",
      "[Epoch 38/50] [Batch 268/300] [D loss: 0.752308] [G loss: 0.486873] time: 0:58:01.887906\n",
      "0.93980795\n",
      "[Epoch 38/50] [Batch 269/300] [D loss: 0.752309] [G loss: 0.477694] time: 0:58:02.175743\n",
      "0.9190364\n",
      "[Epoch 38/50] [Batch 270/300] [D loss: 0.752291] [G loss: 0.489584] time: 0:58:02.475968\n",
      "0.9056186\n",
      "[Epoch 38/50] [Batch 271/300] [D loss: 0.752304] [G loss: 0.472312] time: 0:58:02.764280\n",
      "0.8799663\n",
      "[Epoch 38/50] [Batch 272/300] [D loss: 0.752280] [G loss: 0.482730] time: 0:58:03.058257\n",
      "0.9094185\n",
      "[Epoch 38/50] [Batch 273/300] [D loss: 0.752305] [G loss: 0.477897] time: 0:58:03.348336\n",
      "0.91107935\n",
      "[Epoch 38/50] [Batch 274/300] [D loss: 0.752300] [G loss: 0.477306] time: 0:58:03.654707\n",
      "0.93778825\n",
      "[Epoch 38/50] [Batch 275/300] [D loss: 0.752299] [G loss: 0.506608] time: 0:58:03.947740\n",
      "0.94590396\n",
      "[Epoch 38/50] [Batch 276/300] [D loss: 0.752296] [G loss: 0.485700] time: 0:58:04.264027\n",
      "0.9231763\n",
      "[Epoch 38/50] [Batch 277/300] [D loss: 0.752285] [G loss: 0.478158] time: 0:58:04.557177\n",
      "0.9155457\n",
      "[Epoch 38/50] [Batch 278/300] [D loss: 0.752300] [G loss: 0.483347] time: 0:58:04.855818\n",
      "0.9152253\n",
      "[Epoch 38/50] [Batch 279/300] [D loss: 0.752288] [G loss: 0.479573] time: 0:58:05.158533\n",
      "0.95063\n",
      "[Epoch 38/50] [Batch 280/300] [D loss: 0.752297] [G loss: 0.469138] time: 0:58:05.469828\n",
      "0.93083364\n",
      "[Epoch 38/50] [Batch 281/300] [D loss: 0.752286] [G loss: 0.478134] time: 0:58:05.776990\n",
      "0.9389971\n",
      "[Epoch 38/50] [Batch 282/300] [D loss: 0.752293] [G loss: 0.473847] time: 0:58:06.067120\n",
      "0.9449132\n",
      "[Epoch 38/50] [Batch 283/300] [D loss: 0.752287] [G loss: 0.474699] time: 0:58:06.353446\n",
      "0.93872046\n",
      "[Epoch 38/50] [Batch 284/300] [D loss: 0.752298] [G loss: 0.469034] time: 0:58:06.652682\n",
      "0.8990658\n",
      "[Epoch 38/50] [Batch 285/300] [D loss: 0.752301] [G loss: 0.476478] time: 0:58:06.954214\n",
      "0.94780475\n",
      "[Epoch 38/50] [Batch 286/300] [D loss: 0.752293] [G loss: 0.485743] time: 0:58:07.261046\n",
      "0.88291997\n",
      "[Epoch 38/50] [Batch 287/300] [D loss: 0.752315] [G loss: 0.475292] time: 0:58:07.571675\n",
      "0.9163666\n",
      "[Epoch 38/50] [Batch 288/300] [D loss: 0.752290] [G loss: 0.518012] time: 0:58:07.861861\n",
      "0.9246247\n",
      "[Epoch 38/50] [Batch 289/300] [D loss: 0.752301] [G loss: 0.475498] time: 0:58:08.169775\n",
      "0.94385815\n",
      "[Epoch 38/50] [Batch 290/300] [D loss: 0.752300] [G loss: 0.487560] time: 0:58:08.469691\n",
      "0.91247624\n",
      "[Epoch 38/50] [Batch 291/300] [D loss: 0.752294] [G loss: 0.483346] time: 0:58:08.785320\n",
      "0.94583017\n",
      "[Epoch 38/50] [Batch 292/300] [D loss: 0.752282] [G loss: 0.480139] time: 0:58:09.097589\n",
      "0.905241\n",
      "[Epoch 38/50] [Batch 293/300] [D loss: 0.752287] [G loss: 0.514722] time: 0:58:09.390950\n",
      "0.90674144\n",
      "[Epoch 38/50] [Batch 294/300] [D loss: 0.752304] [G loss: 0.470423] time: 0:58:09.680563\n",
      "0.8948938\n",
      "[Epoch 38/50] [Batch 295/300] [D loss: 0.752293] [G loss: 0.481687] time: 0:58:09.981830\n",
      "0.92596096\n",
      "[Epoch 38/50] [Batch 296/300] [D loss: 0.752308] [G loss: 0.490292] time: 0:58:10.288801\n",
      "0.9448767\n",
      "[Epoch 38/50] [Batch 297/300] [D loss: 0.752293] [G loss: 0.475780] time: 0:58:10.600727\n",
      "0.9141076\n",
      "[Epoch 38/50] [Batch 298/300] [D loss: 0.752294] [G loss: 0.485037] time: 0:58:10.911974\n",
      "0.8983391\n",
      "[Epoch 38/50] [Batch 299/300] [D loss: 0.752291] [G loss: 0.479446] time: 0:58:11.216514\n",
      "0.899674\n",
      "[Epoch 39/50] [Batch 0/300] [D loss: 0.752290] [G loss: 0.507764] time: 0:58:11.517700\n",
      "0.8721022\n",
      "[Epoch 39/50] [Batch 1/300] [D loss: 0.752304] [G loss: 0.492482] time: 0:58:11.831565\n",
      "0.9052959\n",
      "[Epoch 39/50] [Batch 2/300] [D loss: 0.752288] [G loss: 0.506342] time: 0:58:12.158622\n",
      "0.94204855\n",
      "[Epoch 39/50] [Batch 3/300] [D loss: 0.752298] [G loss: 0.488187] time: 0:58:12.464030\n",
      "0.90841794\n",
      "[Epoch 39/50] [Batch 4/300] [D loss: 0.752308] [G loss: 0.484763] time: 0:58:12.765874\n",
      "0.93966883\n",
      "[Epoch 39/50] [Batch 5/300] [D loss: 0.752300] [G loss: 0.501790] time: 0:58:13.064682\n",
      "0.9589303\n",
      "[Epoch 39/50] [Batch 6/300] [D loss: 0.752297] [G loss: 0.468892] time: 0:58:13.373793\n",
      "0.8987322\n",
      "[Epoch 39/50] [Batch 7/300] [D loss: 0.752296] [G loss: 0.489345] time: 0:58:13.661055\n",
      "0.9544616\n",
      "[Epoch 39/50] [Batch 8/300] [D loss: 0.752281] [G loss: 0.480404] time: 0:58:13.945357\n",
      "0.9391158\n",
      "[Epoch 39/50] [Batch 9/300] [D loss: 0.752298] [G loss: 0.511533] time: 0:58:14.247699\n",
      "0.8788395\n",
      "[Epoch 39/50] [Batch 10/300] [D loss: 0.752291] [G loss: 0.471697] time: 0:58:14.549657\n",
      "0.8917275\n",
      "[Epoch 39/50] [Batch 11/300] [D loss: 0.752295] [G loss: 0.469871] time: 0:58:14.842351\n",
      "0.9535721\n",
      "[Epoch 39/50] [Batch 12/300] [D loss: 0.752308] [G loss: 0.468166] time: 0:58:15.137869\n",
      "0.8992758\n",
      "[Epoch 39/50] [Batch 13/300] [D loss: 0.752289] [G loss: 0.478134] time: 0:58:15.435523\n",
      "0.93000907\n",
      "[Epoch 39/50] [Batch 14/300] [D loss: 0.752300] [G loss: 0.479813] time: 0:58:15.730005\n",
      "0.9531211\n",
      "[Epoch 39/50] [Batch 15/300] [D loss: 0.752284] [G loss: 0.487309] time: 0:58:16.054631\n",
      "0.93247706\n",
      "[Epoch 39/50] [Batch 16/300] [D loss: 0.752294] [G loss: 0.485301] time: 0:58:16.365094\n",
      "0.90826577\n",
      "[Epoch 39/50] [Batch 17/300] [D loss: 0.752288] [G loss: 0.474268] time: 0:58:16.676555\n",
      "0.89970714\n",
      "[Epoch 39/50] [Batch 18/300] [D loss: 0.752309] [G loss: 0.474948] time: 0:58:16.981339\n",
      "0.95639896\n",
      "[Epoch 39/50] [Batch 19/300] [D loss: 0.752298] [G loss: 0.481327] time: 0:58:17.282219\n",
      "0.89611834\n",
      "[Epoch 39/50] [Batch 20/300] [D loss: 0.752305] [G loss: 0.479849] time: 0:58:17.584675\n",
      "0.92701054\n",
      "[Epoch 39/50] [Batch 21/300] [D loss: 0.752291] [G loss: 0.486084] time: 0:58:17.896501\n",
      "0.97140115\n",
      "[Epoch 39/50] [Batch 22/300] [D loss: 0.752294] [G loss: 0.474676] time: 0:58:18.212633\n",
      "0.9587267\n",
      "[Epoch 39/50] [Batch 23/300] [D loss: 0.752281] [G loss: 0.492904] time: 0:58:18.509020\n",
      "0.9215233\n",
      "[Epoch 39/50] [Batch 24/300] [D loss: 0.752314] [G loss: 0.466906] time: 0:58:18.790094\n",
      "0.91606045\n",
      "[Epoch 39/50] [Batch 25/300] [D loss: 0.752309] [G loss: 0.474066] time: 0:58:19.094263\n",
      "0.9576619\n",
      "[Epoch 39/50] [Batch 26/300] [D loss: 0.752286] [G loss: 0.470215] time: 0:58:19.401299\n",
      "0.94461083\n",
      "[Epoch 39/50] [Batch 27/300] [D loss: 0.752285] [G loss: 0.499813] time: 0:58:19.701831\n",
      "0.91593295\n",
      "[Epoch 39/50] [Batch 28/300] [D loss: 0.752303] [G loss: 0.488316] time: 0:58:20.010168\n",
      "0.89187\n",
      "[Epoch 39/50] [Batch 29/300] [D loss: 0.752303] [G loss: 0.477397] time: 0:58:20.327708\n",
      "0.9100065\n",
      "[Epoch 39/50] [Batch 30/300] [D loss: 0.752284] [G loss: 0.474244] time: 0:58:20.631765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8910742\n",
      "[Epoch 39/50] [Batch 31/300] [D loss: 0.752308] [G loss: 0.472316] time: 0:58:20.954371\n",
      "0.9195264\n",
      "[Epoch 39/50] [Batch 32/300] [D loss: 0.752280] [G loss: 0.481880] time: 0:58:21.254723\n",
      "0.8865394\n",
      "[Epoch 39/50] [Batch 33/300] [D loss: 0.752309] [G loss: 0.476704] time: 0:58:21.561149\n",
      "0.9067624\n",
      "[Epoch 39/50] [Batch 34/300] [D loss: 0.752286] [G loss: 0.492562] time: 0:58:21.861543\n",
      "0.9327063\n",
      "[Epoch 39/50] [Batch 35/300] [D loss: 0.752295] [G loss: 0.487348] time: 0:58:22.162481\n",
      "0.93831855\n",
      "[Epoch 39/50] [Batch 36/300] [D loss: 0.752288] [G loss: 0.484137] time: 0:58:22.463982\n",
      "0.9469368\n",
      "[Epoch 39/50] [Batch 37/300] [D loss: 0.752297] [G loss: 0.485615] time: 0:58:22.764687\n",
      "0.9529729\n",
      "[Epoch 39/50] [Batch 39/300] [D loss: 0.752282] [G loss: 0.500232] time: 0:58:23.078600\n",
      "0.929267\n",
      "[Epoch 39/50] [Batch 40/300] [D loss: 0.752286] [G loss: 0.476822] time: 0:58:23.372100\n",
      "0.91665936\n",
      "[Epoch 39/50] [Batch 41/300] [D loss: 0.752286] [G loss: 0.467368] time: 0:58:23.674894\n",
      "0.9054957\n",
      "[Epoch 39/50] [Batch 42/300] [D loss: 0.752321] [G loss: 0.501843] time: 0:58:23.974678\n",
      "0.9170254\n",
      "[Epoch 39/50] [Batch 43/300] [D loss: 0.752295] [G loss: 0.470735] time: 0:58:24.271071\n",
      "0.9562816\n",
      "[Epoch 39/50] [Batch 44/300] [D loss: 0.752302] [G loss: 0.472682] time: 0:58:24.567512\n",
      "0.91428906\n",
      "[Epoch 39/50] [Batch 45/300] [D loss: 0.752286] [G loss: 0.468518] time: 0:58:24.863738\n",
      "0.96040756\n",
      "[Epoch 39/50] [Batch 46/300] [D loss: 0.752308] [G loss: 0.483534] time: 0:58:25.143927\n",
      "0.9624204\n",
      "[Epoch 39/50] [Batch 47/300] [D loss: 0.752280] [G loss: 0.505120] time: 0:58:25.461969\n",
      "0.9469889\n",
      "[Epoch 39/50] [Batch 48/300] [D loss: 0.752286] [G loss: 0.473383] time: 0:58:25.756723\n",
      "0.88243294\n",
      "[Epoch 39/50] [Batch 49/300] [D loss: 0.752286] [G loss: 0.470864] time: 0:58:26.064019\n",
      "0.9532253\n",
      "[Epoch 39/50] [Batch 50/300] [D loss: 0.752292] [G loss: 0.484375] time: 0:58:26.358920\n",
      "0.8903529\n",
      "[Epoch 39/50] [Batch 51/300] [D loss: 0.752299] [G loss: 0.478868] time: 0:58:26.647876\n",
      "0.91582584\n",
      "[Epoch 39/50] [Batch 52/300] [D loss: 0.752297] [G loss: 0.478796] time: 0:58:26.952318\n",
      "0.93939847\n",
      "[Epoch 39/50] [Batch 53/300] [D loss: 0.752293] [G loss: 0.483248] time: 0:58:27.261765\n",
      "0.94695526\n",
      "[Epoch 39/50] [Batch 54/300] [D loss: 0.752284] [G loss: 0.480606] time: 0:58:27.553516\n",
      "0.97101235\n",
      "[Epoch 39/50] [Batch 55/300] [D loss: 0.752301] [G loss: 0.479481] time: 0:58:27.849659\n",
      "0.89309853\n",
      "[Epoch 39/50] [Batch 56/300] [D loss: 0.752294] [G loss: 0.467883] time: 0:58:28.150216\n",
      "0.9343104\n",
      "[Epoch 39/50] [Batch 57/300] [D loss: 0.752297] [G loss: 0.480938] time: 0:58:28.468892\n",
      "0.9081742\n",
      "[Epoch 39/50] [Batch 58/300] [D loss: 0.752295] [G loss: 0.465997] time: 0:58:28.769837\n",
      "0.9837548\n",
      "[Epoch 39/50] [Batch 59/300] [D loss: 0.752303] [G loss: 0.467560] time: 0:58:29.059688\n",
      "0.90580386\n",
      "[Epoch 39/50] [Batch 60/300] [D loss: 0.752301] [G loss: 0.472615] time: 0:58:29.346751\n",
      "0.91388196\n",
      "[Epoch 39/50] [Batch 61/300] [D loss: 0.752291] [G loss: 0.480406] time: 0:58:29.634192\n",
      "0.88632935\n",
      "[Epoch 39/50] [Batch 62/300] [D loss: 0.752291] [G loss: 0.471722] time: 0:58:29.935118\n",
      "0.90792704\n",
      "[Epoch 39/50] [Batch 63/300] [D loss: 0.752297] [G loss: 0.485132] time: 0:58:30.243423\n",
      "0.93796015\n",
      "[Epoch 39/50] [Batch 64/300] [D loss: 0.752299] [G loss: 0.470774] time: 0:58:30.527927\n",
      "0.919261\n",
      "[Epoch 39/50] [Batch 65/300] [D loss: 0.752296] [G loss: 0.468511] time: 0:58:30.829333\n",
      "0.9076329\n",
      "[Epoch 39/50] [Batch 66/300] [D loss: 0.752286] [G loss: 0.471472] time: 0:58:31.120813\n",
      "0.94752127\n",
      "[Epoch 39/50] [Batch 67/300] [D loss: 0.752284] [G loss: 0.466888] time: 0:58:31.416778\n",
      "0.91995686\n",
      "[Epoch 39/50] [Batch 68/300] [D loss: 0.752298] [G loss: 0.473695] time: 0:58:31.723394\n",
      "0.90842444\n",
      "[Epoch 39/50] [Batch 69/300] [D loss: 0.752275] [G loss: 0.504834] time: 0:58:32.021315\n",
      "0.95005655\n",
      "[Epoch 39/50] [Batch 70/300] [D loss: 0.752300] [G loss: 0.478596] time: 0:58:32.344124\n",
      "0.9322705\n",
      "[Epoch 39/50] [Batch 71/300] [D loss: 0.752291] [G loss: 0.475045] time: 0:58:32.639202\n",
      "0.941458\n",
      "[Epoch 39/50] [Batch 72/300] [D loss: 0.752314] [G loss: 0.472371] time: 0:58:32.944072\n",
      "0.94596106\n",
      "[Epoch 39/50] [Batch 73/300] [D loss: 0.752290] [G loss: 0.480902] time: 0:58:33.230208\n",
      "0.929169\n",
      "[Epoch 39/50] [Batch 74/300] [D loss: 0.752305] [G loss: 0.471155] time: 0:58:33.518156\n",
      "0.982922\n",
      "[Epoch 39/50] [Batch 75/300] [D loss: 0.752305] [G loss: 0.483656] time: 0:58:33.830221\n",
      "0.8676546\n",
      "[Epoch 39/50] [Batch 76/300] [D loss: 0.752287] [G loss: 0.475947] time: 0:58:34.132160\n",
      "0.9333725\n",
      "[Epoch 39/50] [Batch 77/300] [D loss: 0.752298] [G loss: 0.477657] time: 0:58:34.413582\n",
      "0.92542225\n",
      "[Epoch 39/50] [Batch 78/300] [D loss: 0.752296] [G loss: 0.513964] time: 0:58:34.692798\n",
      "0.93121594\n",
      "[Epoch 39/50] [Batch 79/300] [D loss: 0.752296] [G loss: 0.479046] time: 0:58:34.971661\n",
      "0.9028122\n",
      "[Epoch 39/50] [Batch 80/300] [D loss: 0.752297] [G loss: 0.483390] time: 0:58:35.273884\n",
      "0.9139021\n",
      "[Epoch 39/50] [Batch 81/300] [D loss: 0.752292] [G loss: 0.480769] time: 0:58:35.585171\n",
      "0.88958544\n",
      "[Epoch 39/50] [Batch 82/300] [D loss: 0.752293] [G loss: 0.483215] time: 0:58:35.891599\n",
      "0.8612897\n",
      "[Epoch 39/50] [Batch 83/300] [D loss: 0.752283] [G loss: 0.505838] time: 0:58:36.212651\n",
      "0.9015932\n",
      "[Epoch 39/50] [Batch 84/300] [D loss: 0.752297] [G loss: 0.467276] time: 0:58:36.512762\n",
      "0.9064112\n",
      "[Epoch 39/50] [Batch 85/300] [D loss: 0.752293] [G loss: 0.478937] time: 0:58:36.817377\n",
      "0.898616\n",
      "[Epoch 39/50] [Batch 86/300] [D loss: 0.752297] [G loss: 0.478669] time: 0:58:37.118589\n",
      "0.95788056\n",
      "[Epoch 39/50] [Batch 87/300] [D loss: 0.752299] [G loss: 0.470853] time: 0:58:37.402685\n",
      "0.9321044\n",
      "[Epoch 39/50] [Batch 88/300] [D loss: 0.752290] [G loss: 0.475467] time: 0:58:37.689018\n",
      "0.9552519\n",
      "[Epoch 39/50] [Batch 89/300] [D loss: 0.752287] [G loss: 0.470508] time: 0:58:37.991851\n",
      "0.93129826\n",
      "[Epoch 39/50] [Batch 90/300] [D loss: 0.752280] [G loss: 0.474763] time: 0:58:38.297166\n",
      "0.9373679\n",
      "[Epoch 39/50] [Batch 91/300] [D loss: 0.752294] [G loss: 0.476371] time: 0:58:38.602950\n",
      "0.9385715\n",
      "[Epoch 39/50] [Batch 92/300] [D loss: 0.752284] [G loss: 0.476673] time: 0:58:38.899134\n",
      "0.9062874\n",
      "[Epoch 39/50] [Batch 93/300] [D loss: 0.752288] [G loss: 0.485563] time: 0:58:39.197916\n",
      "0.92896914\n",
      "[Epoch 39/50] [Batch 94/300] [D loss: 0.752301] [G loss: 0.479725] time: 0:58:39.498203\n",
      "0.9134634\n",
      "[Epoch 39/50] [Batch 95/300] [D loss: 0.752299] [G loss: 0.490377] time: 0:58:39.809884\n",
      "0.8763254\n",
      "[Epoch 39/50] [Batch 96/300] [D loss: 0.752281] [G loss: 0.482115] time: 0:58:40.117662\n",
      "0.9348965\n",
      "[Epoch 39/50] [Batch 97/300] [D loss: 0.752301] [G loss: 0.501858] time: 0:58:40.427976\n",
      "0.8873946\n",
      "[Epoch 39/50] [Batch 98/300] [D loss: 0.752322] [G loss: 0.480351] time: 0:58:40.730700\n",
      "0.8983889\n",
      "[Epoch 39/50] [Batch 99/300] [D loss: 0.752292] [G loss: 0.470932] time: 0:58:41.018410\n",
      "0.92923546\n",
      "[Epoch 39/50] [Batch 100/300] [D loss: 0.752306] [G loss: 0.493732] time: 0:58:41.326429\n",
      "0.9307979\n",
      "[Epoch 39/50] [Batch 101/300] [D loss: 0.752287] [G loss: 0.469095] time: 0:58:41.637525\n",
      "0.8988626\n",
      "[Epoch 39/50] [Batch 102/300] [D loss: 0.752302] [G loss: 0.468864] time: 0:58:41.956693\n",
      "0.97614306\n",
      "[Epoch 39/50] [Batch 103/300] [D loss: 0.752286] [G loss: 0.479396] time: 0:58:42.249577\n",
      "0.8553203\n",
      "[Epoch 39/50] [Batch 104/300] [D loss: 0.752312] [G loss: 0.495337] time: 0:58:42.541476\n",
      "0.87640446\n",
      "[Epoch 39/50] [Batch 105/300] [D loss: 0.752288] [G loss: 0.473720] time: 0:58:42.836551\n",
      "0.90819067\n",
      "[Epoch 39/50] [Batch 106/300] [D loss: 0.752278] [G loss: 0.488958] time: 0:58:43.134809\n",
      "0.938893\n",
      "[Epoch 39/50] [Batch 107/300] [D loss: 0.752292] [G loss: 0.479461] time: 0:58:43.451755\n",
      "0.925559\n",
      "[Epoch 39/50] [Batch 108/300] [D loss: 0.752294] [G loss: 0.468303] time: 0:58:43.744878\n",
      "0.8988878\n",
      "[Epoch 39/50] [Batch 109/300] [D loss: 0.752297] [G loss: 0.476444] time: 0:58:44.047132\n",
      "0.9261005\n",
      "[Epoch 39/50] [Batch 110/300] [D loss: 0.752302] [G loss: 0.484943] time: 0:58:44.338730\n",
      "0.9136743\n",
      "[Epoch 39/50] [Batch 111/300] [D loss: 0.752303] [G loss: 0.468151] time: 0:58:44.645203\n",
      "0.88912827\n",
      "[Epoch 39/50] [Batch 112/300] [D loss: 0.752286] [G loss: 0.469340] time: 0:58:44.955961\n",
      "0.8841436\n",
      "[Epoch 39/50] [Batch 113/300] [D loss: 0.752290] [G loss: 0.478482] time: 0:58:45.266376\n",
      "0.9169701\n",
      "[Epoch 39/50] [Batch 114/300] [D loss: 0.752302] [G loss: 0.477922] time: 0:58:45.568443\n",
      "0.89515096\n",
      "[Epoch 39/50] [Batch 115/300] [D loss: 0.752285] [G loss: 0.469931] time: 0:58:45.892564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94094443\n",
      "[Epoch 39/50] [Batch 116/300] [D loss: 0.752277] [G loss: 0.474255] time: 0:58:46.195634\n",
      "0.97076654\n",
      "[Epoch 39/50] [Batch 117/300] [D loss: 0.752282] [G loss: 0.475185] time: 0:58:46.499160\n",
      "0.92905205\n",
      "[Epoch 39/50] [Batch 118/300] [D loss: 0.752306] [G loss: 0.493201] time: 0:58:46.790909\n",
      "0.9338767\n",
      "[Epoch 39/50] [Batch 119/300] [D loss: 0.752288] [G loss: 0.472733] time: 0:58:47.087926\n",
      "0.9090729\n",
      "[Epoch 39/50] [Batch 120/300] [D loss: 0.752305] [G loss: 0.486194] time: 0:58:47.383506\n",
      "0.9442304\n",
      "[Epoch 39/50] [Batch 121/300] [D loss: 0.752289] [G loss: 0.471404] time: 0:58:47.677902\n",
      "0.881933\n",
      "[Epoch 39/50] [Batch 122/300] [D loss: 0.752287] [G loss: 0.477595] time: 0:58:47.978297\n",
      "0.94261295\n",
      "[Epoch 39/50] [Batch 123/300] [D loss: 0.752306] [G loss: 0.497382] time: 0:58:48.268080\n",
      "0.904836\n",
      "[Epoch 39/50] [Batch 124/300] [D loss: 0.752294] [G loss: 0.489485] time: 0:58:48.553089\n",
      "0.93100065\n",
      "[Epoch 39/50] [Batch 125/300] [D loss: 0.752289] [G loss: 0.485005] time: 0:58:48.837760\n",
      "0.96929187\n",
      "[Epoch 39/50] [Batch 126/300] [D loss: 0.752305] [G loss: 0.465118] time: 0:58:49.126562\n",
      "0.93392104\n",
      "[Epoch 39/50] [Batch 127/300] [D loss: 0.752288] [G loss: 0.480644] time: 0:58:49.421458\n",
      "0.91414046\n",
      "[Epoch 39/50] [Batch 128/300] [D loss: 0.752277] [G loss: 0.499608] time: 0:58:49.696840\n",
      "0.88508683\n",
      "[Epoch 39/50] [Batch 129/300] [D loss: 0.752298] [G loss: 0.487688] time: 0:58:49.980432\n",
      "0.93391085\n",
      "[Epoch 39/50] [Batch 130/300] [D loss: 0.752306] [G loss: 0.472840] time: 0:58:50.279812\n",
      "0.91180617\n",
      "[Epoch 39/50] [Batch 131/300] [D loss: 0.752289] [G loss: 0.482827] time: 0:58:50.572052\n",
      "0.93261844\n",
      "[Epoch 39/50] [Batch 132/300] [D loss: 0.752296] [G loss: 0.468621] time: 0:58:50.862514\n",
      "0.93476963\n",
      "[Epoch 39/50] [Batch 133/300] [D loss: 0.752288] [G loss: 0.507984] time: 0:58:51.158954\n",
      "0.95324725\n",
      "[Epoch 39/50] [Batch 134/300] [D loss: 0.752286] [G loss: 0.479999] time: 0:58:51.454748\n",
      "0.884861\n",
      "[Epoch 39/50] [Batch 135/300] [D loss: 0.752286] [G loss: 0.471680] time: 0:58:51.746296\n",
      "0.92124224\n",
      "[Epoch 39/50] [Batch 136/300] [D loss: 0.752296] [G loss: 0.481008] time: 0:58:52.046710\n",
      "0.92268723\n",
      "[Epoch 39/50] [Batch 137/300] [D loss: 0.752298] [G loss: 0.489850] time: 0:58:52.355947\n",
      "0.90924007\n",
      "[Epoch 39/50] [Batch 138/300] [D loss: 0.752283] [G loss: 0.493121] time: 0:58:52.651503\n",
      "0.8765669\n",
      "[Epoch 39/50] [Batch 139/300] [D loss: 0.752288] [G loss: 0.481687] time: 0:58:52.947340\n",
      "0.97127753\n",
      "[Epoch 39/50] [Batch 140/300] [D loss: 0.752306] [G loss: 0.470765] time: 0:58:53.257148\n",
      "0.91582346\n",
      "[Epoch 39/50] [Batch 141/300] [D loss: 0.752288] [G loss: 0.472507] time: 0:58:53.563304\n",
      "0.9221644\n",
      "[Epoch 39/50] [Batch 142/300] [D loss: 0.752299] [G loss: 0.466629] time: 0:58:53.861950\n",
      "0.9715915\n",
      "[Epoch 39/50] [Batch 143/300] [D loss: 0.752284] [G loss: 0.476545] time: 0:58:54.153594\n",
      "0.9416626\n",
      "[Epoch 39/50] [Batch 144/300] [D loss: 0.752286] [G loss: 0.479656] time: 0:58:54.459560\n",
      "0.954334\n",
      "[Epoch 39/50] [Batch 145/300] [D loss: 0.752290] [G loss: 0.510637] time: 0:58:54.768780\n",
      "0.91569185\n",
      "[Epoch 39/50] [Batch 146/300] [D loss: 0.752296] [G loss: 0.484200] time: 0:58:55.069576\n",
      "0.9241917\n",
      "[Epoch 39/50] [Batch 147/300] [D loss: 0.752295] [G loss: 0.467276] time: 0:58:55.378740\n",
      "0.8986619\n",
      "[Epoch 39/50] [Batch 148/300] [D loss: 0.752292] [G loss: 0.479084] time: 0:58:55.697143\n",
      "0.9390512\n",
      "[Epoch 39/50] [Batch 149/300] [D loss: 0.752287] [G loss: 0.469848] time: 0:58:55.992108\n",
      "0.94946545\n",
      "[Epoch 39/50] [Batch 150/300] [D loss: 0.752294] [G loss: 0.479532] time: 0:58:56.312384\n",
      "0.921418\n",
      "[Epoch 39/50] [Batch 151/300] [D loss: 0.752285] [G loss: 0.478825] time: 0:58:56.606789\n",
      "0.9743158\n",
      "[Epoch 39/50] [Batch 152/300] [D loss: 0.752289] [G loss: 0.482500] time: 0:58:56.907610\n",
      "0.9372987\n",
      "[Epoch 39/50] [Batch 153/300] [D loss: 0.752285] [G loss: 0.493393] time: 0:58:57.199209\n",
      "0.89596254\n",
      "[Epoch 39/50] [Batch 154/300] [D loss: 0.752271] [G loss: 0.485446] time: 0:58:57.492000\n",
      "0.9139383\n",
      "[Epoch 39/50] [Batch 155/300] [D loss: 0.752294] [G loss: 0.505607] time: 0:58:57.776407\n",
      "0.88894886\n",
      "[Epoch 39/50] [Batch 156/300] [D loss: 0.752290] [G loss: 0.483076] time: 0:58:58.070730\n",
      "0.90320355\n",
      "[Epoch 39/50] [Batch 157/300] [D loss: 0.752283] [G loss: 0.472893] time: 0:58:58.386696\n",
      "0.9291506\n",
      "[Epoch 39/50] [Batch 158/300] [D loss: 0.752303] [G loss: 0.479359] time: 0:58:58.693703\n",
      "0.93173283\n",
      "[Epoch 39/50] [Batch 159/300] [D loss: 0.752293] [G loss: 0.485286] time: 0:58:58.992398\n",
      "0.91529185\n",
      "[Epoch 39/50] [Batch 160/300] [D loss: 0.752282] [G loss: 0.474708] time: 0:58:59.280284\n",
      "0.8988312\n",
      "[Epoch 39/50] [Batch 161/300] [D loss: 0.752302] [G loss: 0.491513] time: 0:58:59.582762\n",
      "0.97424984\n",
      "[Epoch 39/50] [Batch 162/300] [D loss: 0.752295] [G loss: 0.485001] time: 0:58:59.877775\n",
      "0.9306538\n",
      "[Epoch 39/50] [Batch 163/300] [D loss: 0.752286] [G loss: 0.468401] time: 0:59:00.170585\n",
      "0.9083145\n",
      "[Epoch 39/50] [Batch 164/300] [D loss: 0.752292] [G loss: 0.488756] time: 0:59:00.452620\n",
      "0.9380308\n",
      "[Epoch 39/50] [Batch 165/300] [D loss: 0.752304] [G loss: 0.473760] time: 0:59:00.756603\n",
      "0.9057738\n",
      "[Epoch 39/50] [Batch 166/300] [D loss: 0.752319] [G loss: 0.467717] time: 0:59:01.058640\n",
      "0.93819577\n",
      "[Epoch 39/50] [Batch 167/300] [D loss: 0.752300] [G loss: 0.482410] time: 0:59:01.366670\n",
      "0.9125239\n",
      "[Epoch 39/50] [Batch 168/300] [D loss: 0.752310] [G loss: 0.480660] time: 0:59:01.670344\n",
      "0.946127\n",
      "[Epoch 39/50] [Batch 169/300] [D loss: 0.752297] [G loss: 0.476518] time: 0:59:01.979756\n",
      "0.96839285\n",
      "[Epoch 39/50] [Batch 170/300] [D loss: 0.752283] [G loss: 0.488350] time: 0:59:02.278928\n",
      "0.9451309\n",
      "[Epoch 39/50] [Batch 171/300] [D loss: 0.752289] [G loss: 0.481370] time: 0:59:02.562465\n",
      "0.8695232\n",
      "[Epoch 39/50] [Batch 172/300] [D loss: 0.752283] [G loss: 0.496646] time: 0:59:02.872145\n",
      "0.8912285\n",
      "[Epoch 39/50] [Batch 173/300] [D loss: 0.752288] [G loss: 0.485709] time: 0:59:03.171743\n",
      "0.9329451\n",
      "[Epoch 39/50] [Batch 174/300] [D loss: 0.752291] [G loss: 0.477930] time: 0:59:03.471170\n",
      "0.92416495\n",
      "[Epoch 39/50] [Batch 175/300] [D loss: 0.752301] [G loss: 0.484481] time: 0:59:03.772707\n",
      "0.9252324\n",
      "[Epoch 39/50] [Batch 176/300] [D loss: 0.752287] [G loss: 0.513939] time: 0:59:04.064214\n",
      "0.8920505\n",
      "[Epoch 39/50] [Batch 177/300] [D loss: 0.752293] [G loss: 0.474173] time: 0:59:04.366073\n",
      "0.8812091\n",
      "[Epoch 39/50] [Batch 178/300] [D loss: 0.752293] [G loss: 0.488645] time: 0:59:04.675085\n",
      "0.926218\n",
      "[Epoch 39/50] [Batch 179/300] [D loss: 0.752290] [G loss: 0.496935] time: 0:59:04.978522\n",
      "0.90291166\n",
      "[Epoch 39/50] [Batch 180/300] [D loss: 0.752279] [G loss: 0.482736] time: 0:59:05.271957\n",
      "0.930007\n",
      "[Epoch 39/50] [Batch 181/300] [D loss: 0.752288] [G loss: 0.470553] time: 0:59:05.559756\n",
      "0.94006044\n",
      "[Epoch 39/50] [Batch 182/300] [D loss: 0.752290] [G loss: 0.479529] time: 0:59:05.875088\n",
      "0.867094\n",
      "[Epoch 39/50] [Batch 183/300] [D loss: 0.752298] [G loss: 0.482585] time: 0:59:06.182060\n",
      "0.9519992\n",
      "[Epoch 39/50] [Batch 184/300] [D loss: 0.752279] [G loss: 0.467366] time: 0:59:06.469853\n",
      "0.91223454\n",
      "[Epoch 39/50] [Batch 185/300] [D loss: 0.752294] [G loss: 0.471039] time: 0:59:06.774390\n",
      "0.9556988\n",
      "[Epoch 39/50] [Batch 186/300] [D loss: 0.752294] [G loss: 0.467850] time: 0:59:07.090516\n",
      "0.95065683\n",
      "[Epoch 39/50] [Batch 187/300] [D loss: 0.752284] [G loss: 0.483642] time: 0:59:07.386131\n",
      "0.9133671\n",
      "[Epoch 39/50] [Batch 188/300] [D loss: 0.752296] [G loss: 0.484865] time: 0:59:07.674137\n",
      "0.9024091\n",
      "[Epoch 39/50] [Batch 189/300] [D loss: 0.752279] [G loss: 0.474818] time: 0:59:07.961826\n",
      "0.9458284\n",
      "[Epoch 39/50] [Batch 190/300] [D loss: 0.752295] [G loss: 0.470314] time: 0:59:08.266963\n",
      "0.9572342\n",
      "[Epoch 39/50] [Batch 191/300] [D loss: 0.752296] [G loss: 0.470436] time: 0:59:08.561747\n",
      "0.8898256\n",
      "[Epoch 39/50] [Batch 192/300] [D loss: 0.752291] [G loss: 0.483944] time: 0:59:08.860838\n",
      "0.9152546\n",
      "[Epoch 39/50] [Batch 193/300] [D loss: 0.752282] [G loss: 0.490959] time: 0:59:09.159377\n",
      "0.9550977\n",
      "[Epoch 39/50] [Batch 194/300] [D loss: 0.752283] [G loss: 0.486207] time: 0:59:09.467169\n",
      "0.9277019\n",
      "[Epoch 39/50] [Batch 195/300] [D loss: 0.752295] [G loss: 0.484827] time: 0:59:09.781127\n",
      "0.86498886\n",
      "[Epoch 39/50] [Batch 196/300] [D loss: 0.752285] [G loss: 0.473641] time: 0:59:10.078189\n",
      "0.93118\n",
      "[Epoch 39/50] [Batch 197/300] [D loss: 0.752298] [G loss: 0.479251] time: 0:59:10.383146\n",
      "0.92198163\n",
      "[Epoch 39/50] [Batch 198/300] [D loss: 0.752283] [G loss: 0.466802] time: 0:59:10.683063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214824\n",
      "[Epoch 39/50] [Batch 199/300] [D loss: 0.752293] [G loss: 0.494525] time: 0:59:10.978332\n",
      "0.8996725\n",
      "[Epoch 39/50] [Batch 200/300] [D loss: 0.752287] [G loss: 0.478540] time: 0:59:11.275619\n",
      "0.98397946\n",
      "[Epoch 39/50] [Batch 201/300] [D loss: 0.752292] [G loss: 0.471439] time: 0:59:11.598549\n",
      "0.8954582\n",
      "[Epoch 39/50] [Batch 202/300] [D loss: 0.752291] [G loss: 0.468769] time: 0:59:11.915064\n",
      "0.9100892\n",
      "[Epoch 39/50] [Batch 203/300] [D loss: 0.752293] [G loss: 0.473401] time: 0:59:12.213513\n",
      "0.9319288\n",
      "[Epoch 39/50] [Batch 204/300] [D loss: 0.752289] [G loss: 0.489375] time: 0:59:12.509498\n",
      "0.93092483\n",
      "[Epoch 39/50] [Batch 205/300] [D loss: 0.752282] [G loss: 0.478442] time: 0:59:12.813337\n",
      "0.89842653\n",
      "[Epoch 39/50] [Batch 206/300] [D loss: 0.752298] [G loss: 0.465864] time: 0:59:13.128681\n",
      "0.91764\n",
      "[Epoch 39/50] [Batch 207/300] [D loss: 0.752288] [G loss: 0.477160] time: 0:59:13.438863\n",
      "0.93010384\n",
      "[Epoch 39/50] [Batch 208/300] [D loss: 0.752288] [G loss: 0.484242] time: 0:59:13.755846\n",
      "0.8949623\n",
      "[Epoch 39/50] [Batch 209/300] [D loss: 0.752290] [G loss: 0.474586] time: 0:59:14.047676\n",
      "0.90064573\n",
      "[Epoch 39/50] [Batch 210/300] [D loss: 0.752307] [G loss: 0.463383] time: 0:59:14.349475\n",
      "0.9039977\n",
      "[Epoch 39/50] [Batch 211/300] [D loss: 0.752290] [G loss: 0.489199] time: 0:59:14.660623\n",
      "0.9078848\n",
      "[Epoch 39/50] [Batch 212/300] [D loss: 0.752285] [G loss: 0.479226] time: 0:59:14.979764\n",
      "0.931905\n",
      "[Epoch 39/50] [Batch 213/300] [D loss: 0.752288] [G loss: 0.467661] time: 0:59:15.281744\n",
      "0.90349334\n",
      "[Epoch 39/50] [Batch 214/300] [D loss: 0.752288] [G loss: 0.465546] time: 0:59:15.577771\n",
      "0.9330198\n",
      "[Epoch 39/50] [Batch 215/300] [D loss: 0.752286] [G loss: 0.502877] time: 0:59:15.863380\n",
      "0.928607\n",
      "[Epoch 39/50] [Batch 216/300] [D loss: 0.752298] [G loss: 0.469674] time: 0:59:16.165904\n",
      "0.9516451\n",
      "[Epoch 39/50] [Batch 217/300] [D loss: 0.752282] [G loss: 0.472871] time: 0:59:16.472129\n",
      "0.96050787\n",
      "[Epoch 39/50] [Batch 218/300] [D loss: 0.752295] [G loss: 0.474509] time: 0:59:16.782622\n",
      "0.95664746\n",
      "[Epoch 39/50] [Batch 219/300] [D loss: 0.752290] [G loss: 0.475245] time: 0:59:17.076533\n",
      "0.97457176\n",
      "[Epoch 39/50] [Batch 220/300] [D loss: 0.752299] [G loss: 0.475374] time: 0:59:17.383211\n",
      "0.87385625\n",
      "[Epoch 39/50] [Batch 221/300] [D loss: 0.752295] [G loss: 0.471633] time: 0:59:17.669559\n",
      "0.88884324\n",
      "[Epoch 39/50] [Batch 222/300] [D loss: 0.752280] [G loss: 0.483505] time: 0:59:17.957772\n",
      "0.93695974\n",
      "[Epoch 39/50] [Batch 223/300] [D loss: 0.752278] [G loss: 0.473727] time: 0:59:18.254327\n",
      "0.94808644\n",
      "[Epoch 39/50] [Batch 224/300] [D loss: 0.752291] [G loss: 0.479176] time: 0:59:18.557332\n",
      "0.9366353\n",
      "[Epoch 39/50] [Batch 225/300] [D loss: 0.752288] [G loss: 0.482603] time: 0:59:18.858246\n",
      "0.9595981\n",
      "[Epoch 39/50] [Batch 226/300] [D loss: 0.752278] [G loss: 0.480258] time: 0:59:19.142640\n",
      "0.9496803\n",
      "[Epoch 39/50] [Batch 227/300] [D loss: 0.752296] [G loss: 0.479099] time: 0:59:19.448569\n",
      "0.91380054\n",
      "[Epoch 39/50] [Batch 228/300] [D loss: 0.752290] [G loss: 0.467212] time: 0:59:19.749212\n",
      "0.9482419\n",
      "[Epoch 39/50] [Batch 229/300] [D loss: 0.752291] [G loss: 0.470884] time: 0:59:20.044144\n",
      "0.89691895\n",
      "[Epoch 39/50] [Batch 230/300] [D loss: 0.752294] [G loss: 0.479399] time: 0:59:20.337683\n",
      "0.8851664\n",
      "[Epoch 39/50] [Batch 231/300] [D loss: 0.752296] [G loss: 0.480642] time: 0:59:20.649005\n",
      "0.93791515\n",
      "[Epoch 39/50] [Batch 232/300] [D loss: 0.752290] [G loss: 0.489210] time: 0:59:20.952291\n",
      "0.9069069\n",
      "[Epoch 39/50] [Batch 233/300] [D loss: 0.752297] [G loss: 0.475778] time: 0:59:21.256181\n",
      "0.9515479\n",
      "[Epoch 39/50] [Batch 234/300] [D loss: 0.752295] [G loss: 0.473041] time: 0:59:21.554353\n",
      "0.9098592\n",
      "[Epoch 39/50] [Batch 235/300] [D loss: 0.752300] [G loss: 0.490604] time: 0:59:21.858651\n",
      "0.94061136\n",
      "[Epoch 39/50] [Batch 236/300] [D loss: 0.752297] [G loss: 0.478066] time: 0:59:22.166347\n",
      "0.9498587\n",
      "[Epoch 39/50] [Batch 237/300] [D loss: 0.752292] [G loss: 0.477143] time: 0:59:22.460089\n",
      "0.91679287\n",
      "[Epoch 39/50] [Batch 238/300] [D loss: 0.752295] [G loss: 0.489716] time: 0:59:22.768595\n",
      "0.8958766\n",
      "[Epoch 39/50] [Batch 239/300] [D loss: 0.752286] [G loss: 0.478830] time: 0:59:23.075022\n",
      "0.9235466\n",
      "[Epoch 39/50] [Batch 240/300] [D loss: 0.752302] [G loss: 0.467237] time: 0:59:23.364640\n",
      "0.9419207\n",
      "[Epoch 39/50] [Batch 241/300] [D loss: 0.752295] [G loss: 0.497583] time: 0:59:23.672525\n",
      "0.91572666\n",
      "[Epoch 39/50] [Batch 242/300] [D loss: 0.752289] [G loss: 0.476056] time: 0:59:23.974238\n",
      "0.9335359\n",
      "[Epoch 39/50] [Batch 243/300] [D loss: 0.752288] [G loss: 0.471277] time: 0:59:24.287046\n",
      "0.93498594\n",
      "[Epoch 39/50] [Batch 244/300] [D loss: 0.752272] [G loss: 0.474835] time: 0:59:24.588957\n",
      "0.91978955\n",
      "[Epoch 39/50] [Batch 245/300] [D loss: 0.752289] [G loss: 0.486914] time: 0:59:24.856428\n",
      "0.9391622\n",
      "[Epoch 39/50] [Batch 246/300] [D loss: 0.752286] [G loss: 0.482600] time: 0:59:25.137812\n",
      "0.88098615\n",
      "[Epoch 39/50] [Batch 247/300] [D loss: 0.752292] [G loss: 0.482718] time: 0:59:25.418288\n",
      "0.9719012\n",
      "[Epoch 39/50] [Batch 248/300] [D loss: 0.752288] [G loss: 0.472531] time: 0:59:25.706076\n",
      "0.9066129\n",
      "[Epoch 39/50] [Batch 249/300] [D loss: 0.752289] [G loss: 0.509864] time: 0:59:26.009015\n",
      "0.9288749\n",
      "[Epoch 39/50] [Batch 250/300] [D loss: 0.752287] [G loss: 0.472960] time: 0:59:26.299511\n",
      "0.9167652\n",
      "[Epoch 39/50] [Batch 251/300] [D loss: 0.752286] [G loss: 0.484685] time: 0:59:26.584442\n",
      "0.93859816\n",
      "[Epoch 39/50] [Batch 252/300] [D loss: 0.752296] [G loss: 0.467268] time: 0:59:26.861900\n",
      "0.9055939\n",
      "[Epoch 39/50] [Batch 253/300] [D loss: 0.752273] [G loss: 0.472131] time: 0:59:27.153868\n",
      "0.90413123\n",
      "[Epoch 39/50] [Batch 254/300] [D loss: 0.752299] [G loss: 0.479082] time: 0:59:27.464628\n",
      "0.8529306\n",
      "[Epoch 39/50] [Batch 255/300] [D loss: 0.752302] [G loss: 0.492409] time: 0:59:27.772895\n",
      "0.94430846\n",
      "[Epoch 39/50] [Batch 256/300] [D loss: 0.752295] [G loss: 0.475060] time: 0:59:28.080665\n",
      "0.93985695\n",
      "[Epoch 39/50] [Batch 257/300] [D loss: 0.752291] [G loss: 0.475401] time: 0:59:28.385399\n",
      "0.90725607\n",
      "[Epoch 39/50] [Batch 258/300] [D loss: 0.752292] [G loss: 0.486521] time: 0:59:28.684575\n",
      "0.9055571\n",
      "[Epoch 39/50] [Batch 259/300] [D loss: 0.752291] [G loss: 0.474187] time: 0:59:28.988312\n",
      "0.9144392\n",
      "[Epoch 39/50] [Batch 260/300] [D loss: 0.752296] [G loss: 0.493755] time: 0:59:29.299044\n",
      "0.9835958\n",
      "[Epoch 39/50] [Batch 261/300] [D loss: 0.752287] [G loss: 0.480903] time: 0:59:29.556783\n",
      "0.91182756\n",
      "[Epoch 39/50] [Batch 262/300] [D loss: 0.752287] [G loss: 0.477307] time: 0:59:29.850547\n",
      "0.9332177\n",
      "[Epoch 39/50] [Batch 263/300] [D loss: 0.752282] [G loss: 0.470340] time: 0:59:30.160698\n",
      "0.89479035\n",
      "[Epoch 39/50] [Batch 264/300] [D loss: 0.752301] [G loss: 0.477768] time: 0:59:30.450108\n",
      "0.97566813\n",
      "[Epoch 39/50] [Batch 265/300] [D loss: 0.752286] [G loss: 0.488025] time: 0:59:30.742922\n",
      "0.9476278\n",
      "[Epoch 39/50] [Batch 266/300] [D loss: 0.752287] [G loss: 0.515294] time: 0:59:31.023141\n",
      "0.90896773\n",
      "[Epoch 39/50] [Batch 267/300] [D loss: 0.752288] [G loss: 0.480826] time: 0:59:31.332933\n",
      "0.91362303\n",
      "[Epoch 39/50] [Batch 268/300] [D loss: 0.752286] [G loss: 0.469295] time: 0:59:31.633044\n",
      "0.9367961\n",
      "[Epoch 39/50] [Batch 269/300] [D loss: 0.752287] [G loss: 0.482449] time: 0:59:31.927835\n",
      "0.9156391\n",
      "[Epoch 39/50] [Batch 270/300] [D loss: 0.752269] [G loss: 0.474948] time: 0:59:32.230732\n",
      "0.95240474\n",
      "[Epoch 39/50] [Batch 271/300] [D loss: 0.752284] [G loss: 0.469675] time: 0:59:32.535946\n",
      "0.898943\n",
      "[Epoch 39/50] [Batch 272/300] [D loss: 0.752280] [G loss: 0.476106] time: 0:59:32.841332\n",
      "0.94190365\n",
      "[Epoch 39/50] [Batch 273/300] [D loss: 0.752300] [G loss: 0.485750] time: 0:59:33.289159\n",
      "0.91547126\n",
      "[Epoch 39/50] [Batch 274/300] [D loss: 0.752324] [G loss: 0.487106] time: 0:59:33.604817\n",
      "0.9152698\n",
      "[Epoch 39/50] [Batch 275/300] [D loss: 0.752289] [G loss: 0.478151] time: 0:59:33.913274\n",
      "0.92939526\n",
      "[Epoch 39/50] [Batch 276/300] [D loss: 0.752297] [G loss: 0.494486] time: 0:59:34.211817\n",
      "0.9308696\n",
      "[Epoch 39/50] [Batch 277/300] [D loss: 0.752299] [G loss: 0.481587] time: 0:59:34.511787\n",
      "0.92656344\n",
      "[Epoch 39/50] [Batch 278/300] [D loss: 0.752293] [G loss: 0.491900] time: 0:59:34.822815\n",
      "0.91196185\n",
      "[Epoch 39/50] [Batch 279/300] [D loss: 0.752289] [G loss: 0.472387] time: 0:59:35.113482\n",
      "0.93394727\n",
      "[Epoch 39/50] [Batch 280/300] [D loss: 0.752295] [G loss: 0.491866] time: 0:59:35.410314\n",
      "0.9423509\n",
      "[Epoch 39/50] [Batch 281/300] [D loss: 0.752282] [G loss: 0.478779] time: 0:59:35.690792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8937402\n",
      "[Epoch 39/50] [Batch 282/300] [D loss: 0.752283] [G loss: 0.474939] time: 0:59:36.004734\n",
      "0.96460205\n",
      "[Epoch 39/50] [Batch 283/300] [D loss: 0.752278] [G loss: 0.489341] time: 0:59:36.310530\n",
      "0.8923218\n",
      "[Epoch 39/50] [Batch 284/300] [D loss: 0.752291] [G loss: 0.471634] time: 0:59:36.601286\n",
      "0.9401639\n",
      "[Epoch 39/50] [Batch 285/300] [D loss: 0.752284] [G loss: 0.498798] time: 0:59:36.889277\n",
      "0.9167854\n",
      "[Epoch 39/50] [Batch 286/300] [D loss: 0.752291] [G loss: 0.501987] time: 0:59:37.174172\n",
      "0.9123058\n",
      "[Epoch 39/50] [Batch 287/300] [D loss: 0.752288] [G loss: 0.492491] time: 0:59:37.483783\n",
      "0.9337895\n",
      "[Epoch 39/50] [Batch 288/300] [D loss: 0.752288] [G loss: 0.483197] time: 0:59:37.776444\n",
      "0.9248738\n",
      "[Epoch 39/50] [Batch 289/300] [D loss: 0.752289] [G loss: 0.476635] time: 0:59:38.081585\n",
      "0.9056816\n",
      "[Epoch 39/50] [Batch 290/300] [D loss: 0.752297] [G loss: 0.477500] time: 0:59:38.385116\n",
      "0.94559073\n",
      "[Epoch 39/50] [Batch 291/300] [D loss: 0.752286] [G loss: 0.492013] time: 0:59:38.679754\n",
      "0.93341136\n",
      "[Epoch 39/50] [Batch 292/300] [D loss: 0.752279] [G loss: 0.485692] time: 0:59:38.996170\n",
      "0.917116\n",
      "[Epoch 39/50] [Batch 293/300] [D loss: 0.752285] [G loss: 0.495737] time: 0:59:39.307810\n",
      "0.96848196\n",
      "[Epoch 39/50] [Batch 294/300] [D loss: 0.752280] [G loss: 0.479684] time: 0:59:39.615703\n",
      "0.8839256\n",
      "[Epoch 39/50] [Batch 295/300] [D loss: 0.752279] [G loss: 0.470831] time: 0:59:39.917458\n",
      "0.9246519\n",
      "[Epoch 39/50] [Batch 296/300] [D loss: 0.752285] [G loss: 0.487673] time: 0:59:40.211181\n",
      "0.9393168\n",
      "[Epoch 39/50] [Batch 297/300] [D loss: 0.752292] [G loss: 0.479192] time: 0:59:40.506951\n",
      "0.8766673\n",
      "[Epoch 39/50] [Batch 298/300] [D loss: 0.752303] [G loss: 0.476457] time: 0:59:40.799176\n",
      "0.96052784\n",
      "[Epoch 39/50] [Batch 299/300] [D loss: 0.752295] [G loss: 0.476101] time: 0:59:41.098045\n",
      "0.94418246\n",
      "[Epoch 40/50] [Batch 0/300] [D loss: 0.752298] [G loss: 0.474687] time: 0:59:41.391496\n",
      "0.9462042\n",
      "[Epoch 40/50] [Batch 1/300] [D loss: 0.752285] [G loss: 0.472569] time: 0:59:41.676772\n",
      "0.8917649\n",
      "[Epoch 40/50] [Batch 2/300] [D loss: 0.752290] [G loss: 0.498809] time: 0:59:41.976159\n",
      "0.9237097\n",
      "[Epoch 40/50] [Batch 3/300] [D loss: 0.752290] [G loss: 0.472791] time: 0:59:42.281831\n",
      "0.9433975\n",
      "[Epoch 40/50] [Batch 4/300] [D loss: 0.752274] [G loss: 0.511371] time: 0:59:42.570944\n",
      "0.9275748\n",
      "[Epoch 40/50] [Batch 5/300] [D loss: 0.752302] [G loss: 0.501225] time: 0:59:42.874626\n",
      "0.92897505\n",
      "[Epoch 40/50] [Batch 6/300] [D loss: 0.752264] [G loss: 0.489783] time: 0:59:43.193300\n",
      "0.93715817\n",
      "[Epoch 40/50] [Batch 7/300] [D loss: 0.752294] [G loss: 0.486024] time: 0:59:43.487853\n",
      "0.9251185\n",
      "[Epoch 40/50] [Batch 8/300] [D loss: 0.752289] [G loss: 0.476691] time: 0:59:43.778467\n",
      "0.89420444\n",
      "[Epoch 40/50] [Batch 9/300] [D loss: 0.752291] [G loss: 0.467439] time: 0:59:44.085458\n",
      "0.89394635\n",
      "[Epoch 40/50] [Batch 10/300] [D loss: 0.752289] [G loss: 0.480780] time: 0:59:44.387261\n",
      "0.93245775\n",
      "[Epoch 40/50] [Batch 11/300] [D loss: 0.752306] [G loss: 0.496440] time: 0:59:44.672602\n",
      "0.9335517\n",
      "[Epoch 40/50] [Batch 12/300] [D loss: 0.752283] [G loss: 0.498839] time: 0:59:44.976377\n",
      "0.92552423\n",
      "[Epoch 40/50] [Batch 13/300] [D loss: 0.752287] [G loss: 0.484102] time: 0:59:45.266486\n",
      "0.90519375\n",
      "[Epoch 40/50] [Batch 14/300] [D loss: 0.752282] [G loss: 0.472894] time: 0:59:45.556544\n",
      "0.9421742\n",
      "[Epoch 40/50] [Batch 15/300] [D loss: 0.752278] [G loss: 0.471289] time: 0:59:45.860553\n",
      "0.9352297\n",
      "[Epoch 40/50] [Batch 16/300] [D loss: 0.752286] [G loss: 0.478404] time: 0:59:46.161142\n",
      "0.91123\n",
      "[Epoch 40/50] [Batch 17/300] [D loss: 0.752272] [G loss: 0.472363] time: 0:59:46.457190\n",
      "0.97160745\n",
      "[Epoch 40/50] [Batch 18/300] [D loss: 0.752278] [G loss: 0.477694] time: 0:59:46.757009\n",
      "0.93803495\n",
      "[Epoch 40/50] [Batch 19/300] [D loss: 0.752284] [G loss: 0.485339] time: 0:59:47.053253\n",
      "0.90846974\n",
      "[Epoch 40/50] [Batch 20/300] [D loss: 0.752281] [G loss: 0.506855] time: 0:59:47.356386\n",
      "0.97620636\n",
      "[Epoch 40/50] [Batch 21/300] [D loss: 0.752292] [G loss: 0.473393] time: 0:59:47.647800\n",
      "0.8956167\n",
      "[Epoch 40/50] [Batch 22/300] [D loss: 0.752292] [G loss: 0.484920] time: 0:59:47.946411\n",
      "0.9074721\n",
      "[Epoch 40/50] [Batch 23/300] [D loss: 0.752286] [G loss: 0.468511] time: 0:59:48.248669\n",
      "0.8977886\n",
      "[Epoch 40/50] [Batch 24/300] [D loss: 0.752284] [G loss: 0.490767] time: 0:59:48.552447\n",
      "0.9454724\n",
      "[Epoch 40/50] [Batch 25/300] [D loss: 0.752275] [G loss: 0.485972] time: 0:59:48.877296\n",
      "0.9374911\n",
      "[Epoch 40/50] [Batch 26/300] [D loss: 0.752294] [G loss: 0.483913] time: 0:59:49.178400\n",
      "0.93055767\n",
      "[Epoch 40/50] [Batch 27/300] [D loss: 0.752289] [G loss: 0.482084] time: 0:59:49.491500\n",
      "0.8841028\n",
      "[Epoch 40/50] [Batch 28/300] [D loss: 0.752292] [G loss: 0.484569] time: 0:59:49.794157\n",
      "0.96906704\n",
      "[Epoch 40/50] [Batch 29/300] [D loss: 0.752277] [G loss: 0.475999] time: 0:59:50.091295\n",
      "0.9465304\n",
      "[Epoch 40/50] [Batch 30/300] [D loss: 0.752299] [G loss: 0.475593] time: 0:59:50.368219\n",
      "0.9665647\n",
      "[Epoch 40/50] [Batch 31/300] [D loss: 0.752279] [G loss: 0.479483] time: 0:59:50.659618\n",
      "0.9060529\n",
      "[Epoch 40/50] [Batch 32/300] [D loss: 0.752287] [G loss: 0.478643] time: 0:59:50.945469\n",
      "0.90660566\n",
      "[Epoch 40/50] [Batch 33/300] [D loss: 0.752290] [G loss: 0.487527] time: 0:59:51.246393\n",
      "0.8930629\n",
      "[Epoch 40/50] [Batch 34/300] [D loss: 0.752293] [G loss: 0.473410] time: 0:59:51.550623\n",
      "0.9165475\n",
      "[Epoch 40/50] [Batch 35/300] [D loss: 0.752285] [G loss: 0.487376] time: 0:59:51.848426\n",
      "0.9423482\n",
      "[Epoch 40/50] [Batch 36/300] [D loss: 0.752288] [G loss: 0.487855] time: 0:59:52.156321\n",
      "0.9460977\n",
      "[Epoch 40/50] [Batch 37/300] [D loss: 0.752269] [G loss: 0.484103] time: 0:59:52.475732\n",
      "0.8793499\n",
      "[Epoch 40/50] [Batch 38/300] [D loss: 0.752284] [G loss: 0.476816] time: 0:59:52.760825\n",
      "0.9202871\n",
      "[Epoch 40/50] [Batch 40/300] [D loss: 0.752287] [G loss: 0.463918] time: 0:59:53.078013\n",
      "0.87339425\n",
      "[Epoch 40/50] [Batch 41/300] [D loss: 0.752293] [G loss: 0.478702] time: 0:59:53.368049\n",
      "0.95485324\n",
      "[Epoch 40/50] [Batch 42/300] [D loss: 0.752295] [G loss: 0.475250] time: 0:59:53.674592\n",
      "0.9167757\n",
      "[Epoch 40/50] [Batch 43/300] [D loss: 0.752279] [G loss: 0.481544] time: 0:59:53.970711\n",
      "0.908753\n",
      "[Epoch 40/50] [Batch 44/300] [D loss: 0.752295] [G loss: 0.504512] time: 0:59:54.259024\n",
      "0.9397574\n",
      "[Epoch 40/50] [Batch 45/300] [D loss: 0.752304] [G loss: 0.479056] time: 0:59:54.561391\n",
      "0.90284306\n",
      "[Epoch 40/50] [Batch 46/300] [D loss: 0.752283] [G loss: 0.494593] time: 0:59:54.856664\n",
      "0.9753259\n",
      "[Epoch 40/50] [Batch 47/300] [D loss: 0.752272] [G loss: 0.487981] time: 0:59:55.158446\n",
      "0.93603945\n",
      "[Epoch 40/50] [Batch 48/300] [D loss: 0.752287] [G loss: 0.478434] time: 0:59:55.451401\n",
      "0.97085077\n",
      "[Epoch 40/50] [Batch 49/300] [D loss: 0.752282] [G loss: 0.479982] time: 0:59:55.729754\n",
      "0.92949003\n",
      "[Epoch 40/50] [Batch 50/300] [D loss: 0.752281] [G loss: 0.478411] time: 0:59:56.016834\n",
      "0.9669683\n",
      "[Epoch 40/50] [Batch 51/300] [D loss: 0.752279] [G loss: 0.476313] time: 0:59:56.339319\n",
      "0.93825585\n",
      "[Epoch 40/50] [Batch 52/300] [D loss: 0.752271] [G loss: 0.482365] time: 0:59:56.634099\n",
      "0.95210344\n",
      "[Epoch 40/50] [Batch 53/300] [D loss: 0.752284] [G loss: 0.482981] time: 0:59:56.936056\n",
      "0.92048615\n",
      "[Epoch 40/50] [Batch 54/300] [D loss: 0.752286] [G loss: 0.486619] time: 0:59:57.244980\n",
      "0.9222374\n",
      "[Epoch 40/50] [Batch 55/300] [D loss: 0.752282] [G loss: 0.471919] time: 0:59:57.548534\n",
      "0.9756358\n",
      "[Epoch 40/50] [Batch 56/300] [D loss: 0.752285] [G loss: 0.497454] time: 0:59:57.851377\n",
      "0.9458148\n",
      "[Epoch 40/50] [Batch 57/300] [D loss: 0.752296] [G loss: 0.494266] time: 0:59:58.156678\n",
      "0.88965124\n",
      "[Epoch 40/50] [Batch 58/300] [D loss: 0.752280] [G loss: 0.493873] time: 0:59:58.467051\n",
      "0.8537469\n",
      "[Epoch 40/50] [Batch 59/300] [D loss: 0.752284] [G loss: 0.471365] time: 0:59:58.755809\n",
      "0.9468555\n",
      "[Epoch 40/50] [Batch 60/300] [D loss: 0.752280] [G loss: 0.478729] time: 0:59:59.058168\n",
      "0.9407952\n",
      "[Epoch 40/50] [Batch 61/300] [D loss: 0.752284] [G loss: 0.479108] time: 0:59:59.361416\n",
      "0.94578475\n",
      "[Epoch 40/50] [Batch 62/300] [D loss: 0.752300] [G loss: 0.463783] time: 0:59:59.657480\n",
      "0.95034057\n",
      "[Epoch 40/50] [Batch 63/300] [D loss: 0.752290] [G loss: 0.470981] time: 0:59:59.950744\n",
      "0.91114444\n",
      "[Epoch 40/50] [Batch 64/300] [D loss: 0.752282] [G loss: 0.483762] time: 1:00:00.250854\n",
      "0.91721535\n",
      "[Epoch 40/50] [Batch 65/300] [D loss: 0.752291] [G loss: 0.472502] time: 1:00:00.546743\n",
      "0.88508207\n",
      "[Epoch 40/50] [Batch 66/300] [D loss: 0.752294] [G loss: 0.474292] time: 1:00:00.867362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9170583\n",
      "[Epoch 40/50] [Batch 67/300] [D loss: 0.752275] [G loss: 0.477635] time: 1:00:01.162689\n",
      "0.93299717\n",
      "[Epoch 40/50] [Batch 68/300] [D loss: 0.752287] [G loss: 0.495665] time: 1:00:01.457496\n",
      "0.93116206\n",
      "[Epoch 40/50] [Batch 69/300] [D loss: 0.752273] [G loss: 0.474555] time: 1:00:01.752894\n",
      "0.92462546\n",
      "[Epoch 40/50] [Batch 70/300] [D loss: 0.752281] [G loss: 0.469046] time: 1:00:02.055588\n",
      "0.9618508\n",
      "[Epoch 40/50] [Batch 71/300] [D loss: 0.752271] [G loss: 0.486897] time: 1:00:02.342829\n",
      "0.95349425\n",
      "[Epoch 40/50] [Batch 72/300] [D loss: 0.752271] [G loss: 0.481960] time: 1:00:02.636742\n",
      "0.9427714\n",
      "[Epoch 40/50] [Batch 73/300] [D loss: 0.752283] [G loss: 0.468787] time: 1:00:02.939488\n",
      "0.9306779\n",
      "[Epoch 40/50] [Batch 74/300] [D loss: 0.752279] [G loss: 0.475120] time: 1:00:03.233083\n",
      "0.94523597\n",
      "[Epoch 40/50] [Batch 75/300] [D loss: 0.752291] [G loss: 0.493482] time: 1:00:03.536955\n",
      "0.9468878\n",
      "[Epoch 40/50] [Batch 76/300] [D loss: 0.752288] [G loss: 0.480570] time: 1:00:03.834235\n",
      "0.9307604\n",
      "[Epoch 40/50] [Batch 77/300] [D loss: 0.752272] [G loss: 0.505340] time: 1:00:04.142507\n",
      "0.96003056\n",
      "[Epoch 40/50] [Batch 78/300] [D loss: 0.752273] [G loss: 0.470416] time: 1:00:04.451209\n",
      "0.9598306\n",
      "[Epoch 40/50] [Batch 79/300] [D loss: 0.752285] [G loss: 0.476945] time: 1:00:04.746993\n",
      "0.90981644\n",
      "[Epoch 40/50] [Batch 80/300] [D loss: 0.752290] [G loss: 0.471637] time: 1:00:05.048113\n",
      "0.91845614\n",
      "[Epoch 40/50] [Batch 81/300] [D loss: 0.752286] [G loss: 0.472741] time: 1:00:05.335258\n",
      "0.8960193\n",
      "[Epoch 40/50] [Batch 82/300] [D loss: 0.752289] [G loss: 0.479237] time: 1:00:05.634918\n",
      "0.90978557\n",
      "[Epoch 40/50] [Batch 83/300] [D loss: 0.752288] [G loss: 0.468019] time: 1:00:05.923822\n",
      "0.9461684\n",
      "[Epoch 40/50] [Batch 84/300] [D loss: 0.752290] [G loss: 0.481736] time: 1:00:06.226303\n",
      "0.90379995\n",
      "[Epoch 40/50] [Batch 85/300] [D loss: 0.752285] [G loss: 0.504624] time: 1:00:06.530033\n",
      "0.9531527\n",
      "[Epoch 40/50] [Batch 86/300] [D loss: 0.752286] [G loss: 0.485084] time: 1:00:06.836830\n",
      "0.91109276\n",
      "[Epoch 40/50] [Batch 87/300] [D loss: 0.752279] [G loss: 0.481219] time: 1:00:07.139108\n",
      "0.9342482\n",
      "[Epoch 40/50] [Batch 88/300] [D loss: 0.752291] [G loss: 0.478013] time: 1:00:07.420820\n",
      "0.92908335\n",
      "[Epoch 40/50] [Batch 89/300] [D loss: 0.752288] [G loss: 0.479450] time: 1:00:07.715556\n",
      "0.8942532\n",
      "[Epoch 40/50] [Batch 90/300] [D loss: 0.752278] [G loss: 0.472822] time: 1:00:08.023539\n",
      "0.9367799\n",
      "[Epoch 40/50] [Batch 91/300] [D loss: 0.752303] [G loss: 0.468325] time: 1:00:08.313877\n",
      "0.9429367\n",
      "[Epoch 40/50] [Batch 92/300] [D loss: 0.752288] [G loss: 0.503196] time: 1:00:08.613508\n",
      "0.90305585\n",
      "[Epoch 40/50] [Batch 93/300] [D loss: 0.752300] [G loss: 0.491670] time: 1:00:08.919509\n",
      "0.8953615\n",
      "[Epoch 40/50] [Batch 94/300] [D loss: 0.752284] [G loss: 0.474215] time: 1:00:09.213408\n",
      "0.9300845\n",
      "[Epoch 40/50] [Batch 95/300] [D loss: 0.752281] [G loss: 0.467847] time: 1:00:09.517304\n",
      "0.94624203\n",
      "[Epoch 40/50] [Batch 96/300] [D loss: 0.752293] [G loss: 0.469343] time: 1:00:09.833334\n",
      "0.9253996\n",
      "[Epoch 40/50] [Batch 97/300] [D loss: 0.752287] [G loss: 0.487808] time: 1:00:10.131742\n",
      "0.94252306\n",
      "[Epoch 40/50] [Batch 98/300] [D loss: 0.752291] [G loss: 0.482018] time: 1:00:10.416231\n",
      "0.94761544\n",
      "[Epoch 40/50] [Batch 99/300] [D loss: 0.752291] [G loss: 0.493845] time: 1:00:10.719433\n",
      "0.9287822\n",
      "[Epoch 40/50] [Batch 100/300] [D loss: 0.752290] [G loss: 0.482303] time: 1:00:11.025377\n",
      "0.9115966\n",
      "[Epoch 40/50] [Batch 101/300] [D loss: 0.752301] [G loss: 0.482248] time: 1:00:11.324741\n",
      "0.94321966\n",
      "[Epoch 40/50] [Batch 102/300] [D loss: 0.752289] [G loss: 0.478772] time: 1:00:11.637168\n",
      "0.94636345\n",
      "[Epoch 40/50] [Batch 103/300] [D loss: 0.752288] [G loss: 0.480946] time: 1:00:11.953890\n",
      "0.88102126\n",
      "[Epoch 40/50] [Batch 104/300] [D loss: 0.752267] [G loss: 0.497333] time: 1:00:12.238795\n",
      "0.94289875\n",
      "[Epoch 40/50] [Batch 105/300] [D loss: 0.752274] [G loss: 0.472855] time: 1:00:12.541050\n",
      "0.9194565\n",
      "[Epoch 40/50] [Batch 106/300] [D loss: 0.752278] [G loss: 0.502523] time: 1:00:12.830820\n",
      "0.90694714\n",
      "[Epoch 40/50] [Batch 107/300] [D loss: 0.752290] [G loss: 0.472758] time: 1:00:13.117066\n",
      "0.93153095\n",
      "[Epoch 40/50] [Batch 108/300] [D loss: 0.752286] [G loss: 0.470085] time: 1:00:13.405086\n",
      "0.9003059\n",
      "[Epoch 40/50] [Batch 109/300] [D loss: 0.752279] [G loss: 0.477347] time: 1:00:13.681981\n",
      "0.92684436\n",
      "[Epoch 40/50] [Batch 110/300] [D loss: 0.752274] [G loss: 0.471265] time: 1:00:13.984996\n",
      "0.98230416\n",
      "[Epoch 40/50] [Batch 111/300] [D loss: 0.752285] [G loss: 0.462488] time: 1:00:14.269009\n",
      "0.92553926\n",
      "[Epoch 40/50] [Batch 112/300] [D loss: 0.752286] [G loss: 0.475582] time: 1:00:14.560147\n",
      "0.96078795\n",
      "[Epoch 40/50] [Batch 113/300] [D loss: 0.752274] [G loss: 0.491921] time: 1:00:14.845707\n",
      "0.9381854\n",
      "[Epoch 40/50] [Batch 114/300] [D loss: 0.752273] [G loss: 0.478046] time: 1:00:15.133455\n",
      "0.87056714\n",
      "[Epoch 40/50] [Batch 115/300] [D loss: 0.752287] [G loss: 0.481981] time: 1:00:15.426668\n",
      "0.91315794\n",
      "[Epoch 40/50] [Batch 116/300] [D loss: 0.752286] [G loss: 0.476346] time: 1:00:15.720779\n",
      "0.92319083\n",
      "[Epoch 40/50] [Batch 117/300] [D loss: 0.752273] [G loss: 0.474164] time: 1:00:16.024660\n",
      "0.91771835\n",
      "[Epoch 40/50] [Batch 118/300] [D loss: 0.752280] [G loss: 0.477563] time: 1:00:16.336544\n",
      "0.9742388\n",
      "[Epoch 40/50] [Batch 119/300] [D loss: 0.752303] [G loss: 0.499478] time: 1:00:16.617315\n",
      "0.9062204\n",
      "[Epoch 40/50] [Batch 120/300] [D loss: 0.752287] [G loss: 0.472326] time: 1:00:16.899667\n",
      "0.87639624\n",
      "[Epoch 40/50] [Batch 121/300] [D loss: 0.752290] [G loss: 0.466875] time: 1:00:17.206812\n",
      "0.94245785\n",
      "[Epoch 40/50] [Batch 122/300] [D loss: 0.752273] [G loss: 0.472411] time: 1:00:17.497945\n",
      "0.9758318\n",
      "[Epoch 40/50] [Batch 123/300] [D loss: 0.752282] [G loss: 0.472378] time: 1:00:17.800138\n",
      "0.9252389\n",
      "[Epoch 40/50] [Batch 124/300] [D loss: 0.752266] [G loss: 0.472542] time: 1:00:18.097308\n",
      "0.89530706\n",
      "[Epoch 40/50] [Batch 125/300] [D loss: 0.752277] [G loss: 0.476323] time: 1:00:18.386609\n",
      "0.9248774\n",
      "[Epoch 40/50] [Batch 126/300] [D loss: 0.752289] [G loss: 0.477908] time: 1:00:18.685929\n",
      "0.91085976\n",
      "[Epoch 40/50] [Batch 127/300] [D loss: 0.752296] [G loss: 0.480730] time: 1:00:18.981527\n",
      "0.930207\n",
      "[Epoch 40/50] [Batch 128/300] [D loss: 0.752280] [G loss: 0.475845] time: 1:00:19.280844\n",
      "0.9174488\n",
      "[Epoch 40/50] [Batch 129/300] [D loss: 0.752279] [G loss: 0.483229] time: 1:00:19.576427\n",
      "0.9331095\n",
      "[Epoch 40/50] [Batch 130/300] [D loss: 0.752289] [G loss: 0.470090] time: 1:00:19.875124\n",
      "0.9420624\n",
      "[Epoch 40/50] [Batch 131/300] [D loss: 0.752280] [G loss: 0.486502] time: 1:00:20.137082\n",
      "0.90522546\n",
      "[Epoch 40/50] [Batch 132/300] [D loss: 0.752281] [G loss: 0.481304] time: 1:00:20.432969\n",
      "0.90625983\n",
      "[Epoch 40/50] [Batch 133/300] [D loss: 0.752285] [G loss: 0.484606] time: 1:00:20.719391\n",
      "0.878907\n",
      "[Epoch 40/50] [Batch 134/300] [D loss: 0.752283] [G loss: 0.475408] time: 1:00:21.022359\n",
      "0.9558954\n",
      "[Epoch 40/50] [Batch 135/300] [D loss: 0.752287] [G loss: 0.487223] time: 1:00:21.338296\n",
      "0.9215574\n",
      "[Epoch 40/50] [Batch 136/300] [D loss: 0.752291] [G loss: 0.468714] time: 1:00:21.639211\n",
      "0.9268603\n",
      "[Epoch 40/50] [Batch 137/300] [D loss: 0.752273] [G loss: 0.491749] time: 1:00:21.940179\n",
      "0.902345\n",
      "[Epoch 40/50] [Batch 138/300] [D loss: 0.752272] [G loss: 0.479397] time: 1:00:22.229326\n",
      "0.94767857\n",
      "[Epoch 40/50] [Batch 139/300] [D loss: 0.752297] [G loss: 0.515326] time: 1:00:22.528859\n",
      "0.894406\n",
      "[Epoch 40/50] [Batch 140/300] [D loss: 0.752285] [G loss: 0.486295] time: 1:00:22.823210\n",
      "0.93937904\n",
      "[Epoch 40/50] [Batch 141/300] [D loss: 0.752294] [G loss: 0.479645] time: 1:00:23.130176\n",
      "0.9480624\n",
      "[Epoch 40/50] [Batch 142/300] [D loss: 0.752286] [G loss: 0.469900] time: 1:00:23.425756\n",
      "0.93158287\n",
      "[Epoch 40/50] [Batch 143/300] [D loss: 0.752274] [G loss: 0.483407] time: 1:00:23.727930\n",
      "0.89371896\n",
      "[Epoch 40/50] [Batch 144/300] [D loss: 0.752280] [G loss: 0.498041] time: 1:00:24.024859\n",
      "0.9157948\n",
      "[Epoch 40/50] [Batch 145/300] [D loss: 0.752286] [G loss: 0.492884] time: 1:00:24.317006\n",
      "0.88034326\n",
      "[Epoch 40/50] [Batch 146/300] [D loss: 0.752268] [G loss: 0.483063] time: 1:00:24.638165\n",
      "0.9775853\n",
      "[Epoch 40/50] [Batch 147/300] [D loss: 0.752288] [G loss: 0.470346] time: 1:00:24.933729\n",
      "0.8921159\n",
      "[Epoch 40/50] [Batch 148/300] [D loss: 0.752291] [G loss: 0.481995] time: 1:00:25.245527\n",
      "0.9225456\n",
      "[Epoch 40/50] [Batch 149/300] [D loss: 0.752288] [G loss: 0.470633] time: 1:00:25.555276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937171\n",
      "[Epoch 40/50] [Batch 150/300] [D loss: 0.752274] [G loss: 0.485476] time: 1:00:25.859514\n",
      "0.9139374\n",
      "[Epoch 40/50] [Batch 151/300] [D loss: 0.752278] [G loss: 0.475558] time: 1:00:26.156609\n",
      "0.8885245\n",
      "[Epoch 40/50] [Batch 152/300] [D loss: 0.752289] [G loss: 0.472209] time: 1:00:26.455587\n",
      "0.91369486\n",
      "[Epoch 40/50] [Batch 153/300] [D loss: 0.752275] [G loss: 0.481463] time: 1:00:26.761883\n",
      "0.8874356\n",
      "[Epoch 40/50] [Batch 154/300] [D loss: 0.752281] [G loss: 0.473370] time: 1:00:27.056363\n",
      "0.92921257\n",
      "[Epoch 40/50] [Batch 155/300] [D loss: 0.752292] [G loss: 0.490633] time: 1:00:27.346747\n",
      "0.9168038\n",
      "[Epoch 40/50] [Batch 156/300] [D loss: 0.752272] [G loss: 0.478615] time: 1:00:27.631846\n",
      "0.96995753\n",
      "[Epoch 40/50] [Batch 157/300] [D loss: 0.752303] [G loss: 0.481667] time: 1:00:27.914888\n",
      "0.8931914\n",
      "[Epoch 40/50] [Batch 158/300] [D loss: 0.752283] [G loss: 0.479552] time: 1:00:28.213253\n",
      "0.89786464\n",
      "[Epoch 40/50] [Batch 159/300] [D loss: 0.752274] [G loss: 0.492272] time: 1:00:28.517581\n",
      "0.9336281\n",
      "[Epoch 40/50] [Batch 160/300] [D loss: 0.752276] [G loss: 0.482174] time: 1:00:28.819970\n",
      "0.87191266\n",
      "[Epoch 40/50] [Batch 161/300] [D loss: 0.752278] [G loss: 0.475350] time: 1:00:29.117601\n",
      "0.9053838\n",
      "[Epoch 40/50] [Batch 162/300] [D loss: 0.752280] [G loss: 0.481484] time: 1:00:29.412161\n",
      "0.9379988\n",
      "[Epoch 40/50] [Batch 163/300] [D loss: 0.752283] [G loss: 0.480137] time: 1:00:29.706293\n",
      "0.9315036\n",
      "[Epoch 40/50] [Batch 164/300] [D loss: 0.752279] [G loss: 0.476810] time: 1:00:29.984235\n",
      "0.8824107\n",
      "[Epoch 40/50] [Batch 165/300] [D loss: 0.752282] [G loss: 0.476627] time: 1:00:30.290673\n",
      "0.8474181\n",
      "[Epoch 40/50] [Batch 166/300] [D loss: 0.752289] [G loss: 0.513703] time: 1:00:30.594744\n",
      "0.9398511\n",
      "[Epoch 40/50] [Batch 167/300] [D loss: 0.752275] [G loss: 0.481310] time: 1:00:30.896178\n",
      "0.94838613\n",
      "[Epoch 40/50] [Batch 168/300] [D loss: 0.752280] [G loss: 0.475002] time: 1:00:31.185795\n",
      "0.93784475\n",
      "[Epoch 40/50] [Batch 169/300] [D loss: 0.752299] [G loss: 0.468137] time: 1:00:31.468188\n",
      "0.90853614\n",
      "[Epoch 40/50] [Batch 170/300] [D loss: 0.752293] [G loss: 0.491209] time: 1:00:31.746783\n",
      "0.93753165\n",
      "[Epoch 40/50] [Batch 171/300] [D loss: 0.752278] [G loss: 0.482931] time: 1:00:32.062463\n",
      "0.90540653\n",
      "[Epoch 40/50] [Batch 172/300] [D loss: 0.752286] [G loss: 0.487974] time: 1:00:32.352627\n",
      "0.9520173\n",
      "[Epoch 40/50] [Batch 173/300] [D loss: 0.752277] [G loss: 0.475688] time: 1:00:32.649882\n",
      "0.88090473\n",
      "[Epoch 40/50] [Batch 174/300] [D loss: 0.752283] [G loss: 0.482203] time: 1:00:32.946586\n",
      "0.91417533\n",
      "[Epoch 40/50] [Batch 175/300] [D loss: 0.752306] [G loss: 0.486993] time: 1:00:33.234891\n",
      "0.92535347\n",
      "[Epoch 40/50] [Batch 176/300] [D loss: 0.752282] [G loss: 0.475418] time: 1:00:33.542858\n",
      "0.88951284\n",
      "[Epoch 40/50] [Batch 177/300] [D loss: 0.752275] [G loss: 0.482191] time: 1:00:33.847488\n",
      "0.9559775\n",
      "[Epoch 40/50] [Batch 178/300] [D loss: 0.752268] [G loss: 0.486479] time: 1:00:34.156123\n",
      "0.9249266\n",
      "[Epoch 40/50] [Batch 179/300] [D loss: 0.752271] [G loss: 0.476083] time: 1:00:34.438614\n",
      "0.9165349\n",
      "[Epoch 40/50] [Batch 180/300] [D loss: 0.752272] [G loss: 0.484141] time: 1:00:34.735233\n",
      "0.8758356\n",
      "[Epoch 40/50] [Batch 181/300] [D loss: 0.752274] [G loss: 0.481078] time: 1:00:35.015507\n",
      "0.94175386\n",
      "[Epoch 40/50] [Batch 182/300] [D loss: 0.752288] [G loss: 0.499164] time: 1:00:35.305169\n",
      "0.9819557\n",
      "[Epoch 40/50] [Batch 183/300] [D loss: 0.752289] [G loss: 0.484417] time: 1:00:35.582444\n",
      "0.9168646\n",
      "[Epoch 40/50] [Batch 184/300] [D loss: 0.752296] [G loss: 0.497993] time: 1:00:35.869514\n",
      "0.87054485\n",
      "[Epoch 40/50] [Batch 185/300] [D loss: 0.752291] [G loss: 0.475126] time: 1:00:36.169297\n",
      "0.9828227\n",
      "[Epoch 40/50] [Batch 186/300] [D loss: 0.752283] [G loss: 0.484753] time: 1:00:36.466749\n",
      "0.85261655\n",
      "[Epoch 40/50] [Batch 187/300] [D loss: 0.752281] [G loss: 0.480822] time: 1:00:36.761209\n",
      "0.9390761\n",
      "[Epoch 40/50] [Batch 188/300] [D loss: 0.752285] [G loss: 0.474904] time: 1:00:37.078772\n",
      "0.8643097\n",
      "[Epoch 40/50] [Batch 189/300] [D loss: 0.752287] [G loss: 0.481373] time: 1:00:37.379113\n",
      "0.95595336\n",
      "[Epoch 40/50] [Batch 190/300] [D loss: 0.752272] [G loss: 0.472311] time: 1:00:37.680127\n",
      "0.9302853\n",
      "[Epoch 40/50] [Batch 191/300] [D loss: 0.752282] [G loss: 0.475183] time: 1:00:37.963812\n",
      "0.91658306\n",
      "[Epoch 40/50] [Batch 192/300] [D loss: 0.752273] [G loss: 0.498104] time: 1:00:38.268671\n",
      "0.89093536\n",
      "[Epoch 40/50] [Batch 193/300] [D loss: 0.752289] [G loss: 0.493336] time: 1:00:38.555686\n",
      "0.9460166\n",
      "[Epoch 40/50] [Batch 194/300] [D loss: 0.752286] [G loss: 0.491883] time: 1:00:38.863249\n",
      "0.93064076\n",
      "[Epoch 40/50] [Batch 195/300] [D loss: 0.752280] [G loss: 0.489214] time: 1:00:39.146970\n",
      "0.9140119\n",
      "[Epoch 40/50] [Batch 196/300] [D loss: 0.752290] [G loss: 0.473638] time: 1:00:39.457785\n",
      "0.91428924\n",
      "[Epoch 40/50] [Batch 197/300] [D loss: 0.752290] [G loss: 0.471649] time: 1:00:39.742822\n",
      "0.93105096\n",
      "[Epoch 40/50] [Batch 198/300] [D loss: 0.752293] [G loss: 0.472508] time: 1:00:40.040622\n",
      "0.9170231\n",
      "[Epoch 40/50] [Batch 199/300] [D loss: 0.752278] [G loss: 0.467295] time: 1:00:40.325425\n",
      "0.90554476\n",
      "[Epoch 40/50] [Batch 200/300] [D loss: 0.752290] [G loss: 0.475966] time: 1:00:40.609432\n",
      "0.9368021\n",
      "[Epoch 40/50] [Batch 201/300] [D loss: 0.752278] [G loss: 0.490019] time: 1:00:40.897211\n",
      "0.90898067\n",
      "[Epoch 40/50] [Batch 202/300] [D loss: 0.752283] [G loss: 0.502832] time: 1:00:41.193095\n",
      "0.9630384\n",
      "[Epoch 40/50] [Batch 203/300] [D loss: 0.752296] [G loss: 0.490112] time: 1:00:41.508221\n",
      "0.8818426\n",
      "[Epoch 40/50] [Batch 204/300] [D loss: 0.752290] [G loss: 0.483523] time: 1:00:41.809773\n",
      "0.9524395\n",
      "[Epoch 40/50] [Batch 205/300] [D loss: 0.752278] [G loss: 0.485490] time: 1:00:42.093894\n",
      "0.9305024\n",
      "[Epoch 40/50] [Batch 206/300] [D loss: 0.752291] [G loss: 0.482398] time: 1:00:42.394300\n",
      "0.9319293\n",
      "[Epoch 40/50] [Batch 207/300] [D loss: 0.752273] [G loss: 0.476266] time: 1:00:42.679567\n",
      "0.8810039\n",
      "[Epoch 40/50] [Batch 208/300] [D loss: 0.752271] [G loss: 0.492231] time: 1:00:42.984094\n",
      "0.899708\n",
      "[Epoch 40/50] [Batch 209/300] [D loss: 0.752272] [G loss: 0.474734] time: 1:00:43.290512\n",
      "0.9316718\n",
      "[Epoch 40/50] [Batch 210/300] [D loss: 0.752283] [G loss: 0.478420] time: 1:00:43.600023\n",
      "0.90695125\n",
      "[Epoch 40/50] [Batch 211/300] [D loss: 0.752277] [G loss: 0.474760] time: 1:00:43.899203\n",
      "0.88079363\n",
      "[Epoch 40/50] [Batch 212/300] [D loss: 0.752291] [G loss: 0.475658] time: 1:00:44.205530\n",
      "0.9558727\n",
      "[Epoch 40/50] [Batch 213/300] [D loss: 0.752289] [G loss: 0.502032] time: 1:00:44.471856\n",
      "0.9201262\n",
      "[Epoch 40/50] [Batch 214/300] [D loss: 0.752284] [G loss: 0.465521] time: 1:00:44.751546\n",
      "0.9117949\n",
      "[Epoch 40/50] [Batch 215/300] [D loss: 0.752287] [G loss: 0.471960] time: 1:00:45.041068\n",
      "0.9319139\n",
      "[Epoch 40/50] [Batch 216/300] [D loss: 0.752285] [G loss: 0.467377] time: 1:00:45.349108\n",
      "0.8745248\n",
      "[Epoch 40/50] [Batch 217/300] [D loss: 0.752275] [G loss: 0.483808] time: 1:00:45.655327\n",
      "0.89173937\n",
      "[Epoch 40/50] [Batch 218/300] [D loss: 0.752276] [G loss: 0.484648] time: 1:00:45.960068\n",
      "0.9051259\n",
      "[Epoch 40/50] [Batch 219/300] [D loss: 0.752291] [G loss: 0.481501] time: 1:00:46.273872\n",
      "0.9378765\n",
      "[Epoch 40/50] [Batch 220/300] [D loss: 0.752274] [G loss: 0.485828] time: 1:00:46.565860\n",
      "0.9105831\n",
      "[Epoch 40/50] [Batch 221/300] [D loss: 0.752288] [G loss: 0.471954] time: 1:00:46.857364\n",
      "0.9330818\n",
      "[Epoch 40/50] [Batch 222/300] [D loss: 0.752290] [G loss: 0.476492] time: 1:00:47.151231\n",
      "0.93153995\n",
      "[Epoch 40/50] [Batch 223/300] [D loss: 0.752267] [G loss: 0.478665] time: 1:00:47.446821\n",
      "0.9618425\n",
      "[Epoch 40/50] [Batch 224/300] [D loss: 0.752278] [G loss: 0.490846] time: 1:00:47.743313\n",
      "0.9348571\n",
      "[Epoch 40/50] [Batch 225/300] [D loss: 0.752284] [G loss: 0.487305] time: 1:00:48.017574\n",
      "0.9148924\n",
      "[Epoch 40/50] [Batch 226/300] [D loss: 0.752282] [G loss: 0.510104] time: 1:00:48.327379\n",
      "0.92150134\n",
      "[Epoch 40/50] [Batch 227/300] [D loss: 0.752287] [G loss: 0.467419] time: 1:00:48.626408\n",
      "0.913202\n",
      "[Epoch 40/50] [Batch 228/300] [D loss: 0.752293] [G loss: 0.474972] time: 1:00:48.916091\n",
      "0.9159107\n",
      "[Epoch 40/50] [Batch 229/300] [D loss: 0.752263] [G loss: 0.486837] time: 1:00:49.203930\n",
      "0.92755246\n",
      "[Epoch 40/50] [Batch 230/300] [D loss: 0.752277] [G loss: 0.474391] time: 1:00:49.506942\n",
      "0.9590745\n",
      "[Epoch 40/50] [Batch 231/300] [D loss: 0.752278] [G loss: 0.481787] time: 1:00:49.819541\n",
      "0.9158993\n",
      "[Epoch 40/50] [Batch 232/300] [D loss: 0.752289] [G loss: 0.482503] time: 1:00:50.111220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9135974\n",
      "[Epoch 40/50] [Batch 233/300] [D loss: 0.752273] [G loss: 0.507629] time: 1:00:50.385320\n",
      "0.9377133\n",
      "[Epoch 40/50] [Batch 234/300] [D loss: 0.752270] [G loss: 0.483512] time: 1:00:50.673981\n",
      "0.9477046\n",
      "[Epoch 40/50] [Batch 235/300] [D loss: 0.752283] [G loss: 0.475907] time: 1:00:50.969225\n",
      "0.9313453\n",
      "[Epoch 40/50] [Batch 236/300] [D loss: 0.752290] [G loss: 0.499823] time: 1:00:51.270757\n",
      "0.93275994\n",
      "[Epoch 40/50] [Batch 237/300] [D loss: 0.752277] [G loss: 0.487552] time: 1:00:51.557553\n",
      "0.92028326\n",
      "[Epoch 40/50] [Batch 238/300] [D loss: 0.752274] [G loss: 0.484912] time: 1:00:51.861284\n",
      "0.94594723\n",
      "[Epoch 40/50] [Batch 239/300] [D loss: 0.752299] [G loss: 0.478519] time: 1:00:52.161393\n",
      "0.92483336\n",
      "[Epoch 40/50] [Batch 240/300] [D loss: 0.752278] [G loss: 0.476039] time: 1:00:52.465035\n",
      "0.9519062\n",
      "[Epoch 40/50] [Batch 241/300] [D loss: 0.752275] [G loss: 0.473520] time: 1:00:52.757665\n",
      "0.9082207\n",
      "[Epoch 40/50] [Batch 242/300] [D loss: 0.752285] [G loss: 0.484215] time: 1:00:53.039215\n",
      "0.9246854\n",
      "[Epoch 40/50] [Batch 243/300] [D loss: 0.752268] [G loss: 0.483751] time: 1:00:53.347568\n",
      "0.95424074\n",
      "[Epoch 40/50] [Batch 244/300] [D loss: 0.752268] [G loss: 0.492485] time: 1:00:53.643588\n",
      "0.91293496\n",
      "[Epoch 40/50] [Batch 245/300] [D loss: 0.752281] [G loss: 0.478645] time: 1:00:53.932761\n",
      "0.9213338\n",
      "[Epoch 40/50] [Batch 246/300] [D loss: 0.752279] [G loss: 0.492872] time: 1:00:54.231638\n",
      "0.9201855\n",
      "[Epoch 40/50] [Batch 247/300] [D loss: 0.752271] [G loss: 0.475215] time: 1:00:54.525222\n",
      "0.9691078\n",
      "[Epoch 40/50] [Batch 248/300] [D loss: 0.752288] [G loss: 0.502442] time: 1:00:54.788207\n",
      "0.8883721\n",
      "[Epoch 40/50] [Batch 249/300] [D loss: 0.752281] [G loss: 0.480356] time: 1:00:55.078786\n",
      "0.95793605\n",
      "[Epoch 40/50] [Batch 250/300] [D loss: 0.752269] [G loss: 0.493016] time: 1:00:55.373898\n",
      "0.925463\n",
      "[Epoch 40/50] [Batch 251/300] [D loss: 0.752288] [G loss: 0.501621] time: 1:00:55.677353\n",
      "0.9330618\n",
      "[Epoch 40/50] [Batch 252/300] [D loss: 0.752289] [G loss: 0.476679] time: 1:00:55.972261\n",
      "0.928935\n",
      "[Epoch 40/50] [Batch 253/300] [D loss: 0.752291] [G loss: 0.492859] time: 1:00:56.276752\n",
      "0.9294632\n",
      "[Epoch 40/50] [Batch 254/300] [D loss: 0.752276] [G loss: 0.485156] time: 1:00:56.579898\n",
      "0.9128248\n",
      "[Epoch 40/50] [Batch 255/300] [D loss: 0.752285] [G loss: 0.468786] time: 1:00:56.882348\n",
      "0.9776173\n",
      "[Epoch 40/50] [Batch 256/300] [D loss: 0.752285] [G loss: 0.486126] time: 1:00:57.179663\n",
      "0.9223998\n",
      "[Epoch 40/50] [Batch 257/300] [D loss: 0.752276] [G loss: 0.472610] time: 1:00:57.465287\n",
      "0.91564816\n",
      "[Epoch 40/50] [Batch 258/300] [D loss: 0.752283] [G loss: 0.474830] time: 1:00:57.774356\n",
      "0.96018887\n",
      "[Epoch 40/50] [Batch 259/300] [D loss: 0.752291] [G loss: 0.470152] time: 1:00:58.070849\n",
      "0.90558654\n",
      "[Epoch 40/50] [Batch 260/300] [D loss: 0.752280] [G loss: 0.483464] time: 1:00:58.362932\n",
      "0.89837885\n",
      "[Epoch 40/50] [Batch 261/300] [D loss: 0.752285] [G loss: 0.487071] time: 1:00:58.668998\n",
      "0.950119\n",
      "[Epoch 40/50] [Batch 262/300] [D loss: 0.752290] [G loss: 0.482608] time: 1:00:58.968749\n",
      "0.9570705\n",
      "[Epoch 40/50] [Batch 263/300] [D loss: 0.752282] [G loss: 0.478824] time: 1:00:59.263800\n",
      "0.9094012\n",
      "[Epoch 40/50] [Batch 264/300] [D loss: 0.752278] [G loss: 0.488466] time: 1:00:59.577896\n",
      "0.9403427\n",
      "[Epoch 40/50] [Batch 265/300] [D loss: 0.752278] [G loss: 0.480995] time: 1:00:59.874882\n",
      "0.8996789\n",
      "[Epoch 40/50] [Batch 266/300] [D loss: 0.752278] [G loss: 0.487465] time: 1:01:00.172276\n",
      "0.93266153\n",
      "[Epoch 40/50] [Batch 267/300] [D loss: 0.752280] [G loss: 0.471556] time: 1:01:00.458604\n",
      "0.9224102\n",
      "[Epoch 40/50] [Batch 268/300] [D loss: 0.752273] [G loss: 0.491067] time: 1:01:00.756161\n",
      "0.92308354\n",
      "[Epoch 40/50] [Batch 269/300] [D loss: 0.752286] [G loss: 0.475517] time: 1:01:01.048989\n",
      "0.9396778\n",
      "[Epoch 40/50] [Batch 270/300] [D loss: 0.752280] [G loss: 0.472568] time: 1:01:01.327927\n",
      "0.9307471\n",
      "[Epoch 40/50] [Batch 271/300] [D loss: 0.752284] [G loss: 0.487962] time: 1:01:01.644280\n",
      "0.9262224\n",
      "[Epoch 40/50] [Batch 272/300] [D loss: 0.752284] [G loss: 0.471147] time: 1:01:01.950586\n",
      "0.953171\n",
      "[Epoch 40/50] [Batch 273/300] [D loss: 0.752276] [G loss: 0.481199] time: 1:01:02.248792\n",
      "0.8983349\n",
      "[Epoch 40/50] [Batch 274/300] [D loss: 0.752281] [G loss: 0.479525] time: 1:01:02.546262\n",
      "0.93552715\n",
      "[Epoch 40/50] [Batch 275/300] [D loss: 0.752269] [G loss: 0.477220] time: 1:01:02.839950\n",
      "0.9533666\n",
      "[Epoch 40/50] [Batch 276/300] [D loss: 0.752281] [G loss: 0.495682] time: 1:01:03.140642\n",
      "0.93187195\n",
      "[Epoch 40/50] [Batch 277/300] [D loss: 0.752289] [G loss: 0.476028] time: 1:01:03.438202\n",
      "0.9204462\n",
      "[Epoch 40/50] [Batch 278/300] [D loss: 0.752266] [G loss: 0.489926] time: 1:01:03.739592\n",
      "0.93556577\n",
      "[Epoch 40/50] [Batch 279/300] [D loss: 0.752285] [G loss: 0.472610] time: 1:01:04.026532\n",
      "0.8870196\n",
      "[Epoch 40/50] [Batch 280/300] [D loss: 0.752275] [G loss: 0.489197] time: 1:01:04.320283\n",
      "0.933387\n",
      "[Epoch 40/50] [Batch 281/300] [D loss: 0.752298] [G loss: 0.473550] time: 1:01:04.619604\n",
      "0.91279715\n",
      "[Epoch 40/50] [Batch 282/300] [D loss: 0.752277] [G loss: 0.472901] time: 1:01:04.918761\n",
      "0.9057278\n",
      "[Epoch 40/50] [Batch 283/300] [D loss: 0.752300] [G loss: 0.469275] time: 1:01:05.238730\n",
      "0.9452047\n",
      "[Epoch 40/50] [Batch 284/300] [D loss: 0.752285] [G loss: 0.478993] time: 1:01:05.532682\n",
      "0.94059163\n",
      "[Epoch 40/50] [Batch 285/300] [D loss: 0.752288] [G loss: 0.476759] time: 1:01:05.823939\n",
      "0.9353812\n",
      "[Epoch 40/50] [Batch 286/300] [D loss: 0.752287] [G loss: 0.492443] time: 1:01:06.123639\n",
      "0.89003134\n",
      "[Epoch 40/50] [Batch 287/300] [D loss: 0.752273] [G loss: 0.492156] time: 1:01:06.429377\n",
      "0.9198373\n",
      "[Epoch 40/50] [Batch 288/300] [D loss: 0.752280] [G loss: 0.486221] time: 1:01:06.734634\n",
      "0.8865592\n",
      "[Epoch 40/50] [Batch 289/300] [D loss: 0.752288] [G loss: 0.488938] time: 1:01:07.026489\n",
      "0.8992098\n",
      "[Epoch 40/50] [Batch 290/300] [D loss: 0.752280] [G loss: 0.465113] time: 1:01:07.332286\n",
      "0.93688756\n",
      "[Epoch 40/50] [Batch 291/300] [D loss: 0.752274] [G loss: 0.501443] time: 1:01:07.640375\n",
      "0.9388123\n",
      "[Epoch 40/50] [Batch 292/300] [D loss: 0.752286] [G loss: 0.506923] time: 1:01:07.938818\n",
      "0.9220813\n",
      "[Epoch 40/50] [Batch 293/300] [D loss: 0.752274] [G loss: 0.483096] time: 1:01:08.228670\n",
      "0.8985388\n",
      "[Epoch 40/50] [Batch 294/300] [D loss: 0.752287] [G loss: 0.466792] time: 1:01:08.539503\n",
      "0.933047\n",
      "[Epoch 40/50] [Batch 295/300] [D loss: 0.752272] [G loss: 0.470581] time: 1:01:08.827820\n",
      "0.9250517\n",
      "[Epoch 40/50] [Batch 296/300] [D loss: 0.752284] [G loss: 0.472457] time: 1:01:09.117400\n",
      "0.9155612\n",
      "[Epoch 40/50] [Batch 297/300] [D loss: 0.752277] [G loss: 0.475343] time: 1:01:09.418408\n",
      "0.936114\n",
      "[Epoch 40/50] [Batch 298/300] [D loss: 0.752269] [G loss: 0.479458] time: 1:01:09.706443\n",
      "0.9472148\n",
      "[Epoch 40/50] [Batch 299/300] [D loss: 0.752282] [G loss: 0.478993] time: 1:01:10.008232\n",
      "0.90913707\n",
      "[Epoch 41/50] [Batch 0/300] [D loss: 0.752285] [G loss: 0.470304] time: 1:01:10.293949\n",
      "0.8790352\n",
      "[Epoch 41/50] [Batch 1/300] [D loss: 0.752281] [G loss: 0.472033] time: 1:01:10.587712\n",
      "0.9529087\n",
      "[Epoch 41/50] [Batch 2/300] [D loss: 0.752278] [G loss: 0.469056] time: 1:01:10.899767\n",
      "0.93351984\n",
      "[Epoch 41/50] [Batch 3/300] [D loss: 0.752288] [G loss: 0.483091] time: 1:01:11.207292\n",
      "0.91517633\n",
      "[Epoch 41/50] [Batch 4/300] [D loss: 0.752289] [G loss: 0.481714] time: 1:01:11.501330\n",
      "0.9371956\n",
      "[Epoch 41/50] [Batch 5/300] [D loss: 0.752280] [G loss: 0.482837] time: 1:01:11.802229\n",
      "0.90513927\n",
      "[Epoch 41/50] [Batch 6/300] [D loss: 0.752280] [G loss: 0.478550] time: 1:01:12.093393\n",
      "0.9157\n",
      "[Epoch 41/50] [Batch 7/300] [D loss: 0.752280] [G loss: 0.480320] time: 1:01:12.380653\n",
      "0.9137346\n",
      "[Epoch 41/50] [Batch 8/300] [D loss: 0.752269] [G loss: 0.488415] time: 1:01:12.683212\n",
      "0.9002273\n",
      "[Epoch 41/50] [Batch 9/300] [D loss: 0.752272] [G loss: 0.485695] time: 1:01:12.966943\n",
      "0.9442709\n",
      "[Epoch 41/50] [Batch 10/300] [D loss: 0.752283] [G loss: 0.483022] time: 1:01:13.276350\n",
      "0.9083483\n",
      "[Epoch 41/50] [Batch 11/300] [D loss: 0.752278] [G loss: 0.474100] time: 1:01:13.576938\n",
      "0.95881575\n",
      "[Epoch 41/50] [Batch 12/300] [D loss: 0.752283] [G loss: 0.494805] time: 1:01:13.864201\n",
      "0.9328591\n",
      "[Epoch 41/50] [Batch 13/300] [D loss: 0.752276] [G loss: 0.472357] time: 1:01:14.169513\n",
      "0.90774775\n",
      "[Epoch 41/50] [Batch 14/300] [D loss: 0.752277] [G loss: 0.480994] time: 1:01:14.454452\n",
      "0.881954\n",
      "[Epoch 41/50] [Batch 15/300] [D loss: 0.752270] [G loss: 0.472896] time: 1:01:14.758579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420654\n",
      "[Epoch 41/50] [Batch 16/300] [D loss: 0.752286] [G loss: 0.487442] time: 1:01:15.051871\n",
      "0.9196539\n",
      "[Epoch 41/50] [Batch 17/300] [D loss: 0.752285] [G loss: 0.472140] time: 1:01:15.359717\n",
      "0.9052861\n",
      "[Epoch 41/50] [Batch 18/300] [D loss: 0.752265] [G loss: 0.473227] time: 1:01:15.681485\n",
      "0.9090672\n",
      "[Epoch 41/50] [Batch 19/300] [D loss: 0.752290] [G loss: 0.484591] time: 1:01:15.974666\n",
      "0.93074656\n",
      "[Epoch 41/50] [Batch 20/300] [D loss: 0.752278] [G loss: 0.485641] time: 1:01:16.260685\n",
      "0.90044624\n",
      "[Epoch 41/50] [Batch 21/300] [D loss: 0.752279] [G loss: 0.475641] time: 1:01:16.550031\n",
      "0.95323324\n",
      "[Epoch 41/50] [Batch 22/300] [D loss: 0.752281] [G loss: 0.493888] time: 1:01:16.844100\n",
      "0.94534916\n",
      "[Epoch 41/50] [Batch 23/300] [D loss: 0.752284] [G loss: 0.490035] time: 1:01:17.160486\n",
      "0.9127352\n",
      "[Epoch 41/50] [Batch 24/300] [D loss: 0.752280] [G loss: 0.475310] time: 1:01:17.459433\n",
      "0.9063635\n",
      "[Epoch 41/50] [Batch 25/300] [D loss: 0.752277] [G loss: 0.472899] time: 1:01:17.752882\n",
      "0.92478794\n",
      "[Epoch 41/50] [Batch 26/300] [D loss: 0.752287] [G loss: 0.471566] time: 1:01:18.053858\n",
      "0.9601999\n",
      "[Epoch 41/50] [Batch 27/300] [D loss: 0.752295] [G loss: 0.479857] time: 1:01:18.351764\n",
      "0.94413424\n",
      "[Epoch 41/50] [Batch 28/300] [D loss: 0.752261] [G loss: 0.470916] time: 1:01:18.630675\n",
      "0.9244275\n",
      "[Epoch 41/50] [Batch 29/300] [D loss: 0.752282] [G loss: 0.468479] time: 1:01:18.906371\n",
      "0.9091413\n",
      "[Epoch 41/50] [Batch 30/300] [D loss: 0.752275] [G loss: 0.472905] time: 1:01:19.203246\n",
      "0.92848206\n",
      "[Epoch 41/50] [Batch 31/300] [D loss: 0.752280] [G loss: 0.494587] time: 1:01:19.490538\n",
      "0.9224458\n",
      "[Epoch 41/50] [Batch 32/300] [D loss: 0.752276] [G loss: 0.476553] time: 1:01:19.800007\n",
      "0.93829703\n",
      "[Epoch 41/50] [Batch 33/300] [D loss: 0.752269] [G loss: 0.501803] time: 1:01:20.102554\n",
      "0.9079792\n",
      "[Epoch 41/50] [Batch 34/300] [D loss: 0.752287] [G loss: 0.484537] time: 1:01:20.401413\n",
      "0.96004206\n",
      "[Epoch 41/50] [Batch 35/300] [D loss: 0.752274] [G loss: 0.483277] time: 1:01:20.718686\n",
      "0.8826824\n",
      "[Epoch 41/50] [Batch 36/300] [D loss: 0.752274] [G loss: 0.484830] time: 1:01:21.024239\n",
      "0.93437505\n",
      "[Epoch 41/50] [Batch 37/300] [D loss: 0.752273] [G loss: 0.480841] time: 1:01:21.322002\n",
      "0.9366583\n",
      "[Epoch 41/50] [Batch 38/300] [D loss: 0.752281] [G loss: 0.480258] time: 1:01:21.616097\n",
      "0.9460175\n",
      "[Epoch 41/50] [Batch 39/300] [D loss: 0.752271] [G loss: 0.483592] time: 1:01:21.916763\n",
      "0.94499135\n",
      "[Epoch 41/50] [Batch 41/300] [D loss: 0.752287] [G loss: 0.472106] time: 1:01:22.238230\n",
      "0.8959839\n",
      "[Epoch 41/50] [Batch 42/300] [D loss: 0.752277] [G loss: 0.481721] time: 1:01:22.540266\n",
      "0.89964676\n",
      "[Epoch 41/50] [Batch 43/300] [D loss: 0.752281] [G loss: 0.481164] time: 1:01:22.840952\n",
      "0.91664356\n",
      "[Epoch 41/50] [Batch 44/300] [D loss: 0.752286] [G loss: 0.486329] time: 1:01:23.146519\n",
      "0.9314975\n",
      "[Epoch 41/50] [Batch 45/300] [D loss: 0.752277] [G loss: 0.467699] time: 1:01:23.442792\n",
      "0.8759652\n",
      "[Epoch 41/50] [Batch 46/300] [D loss: 0.752278] [G loss: 0.472470] time: 1:01:23.745081\n",
      "0.9474792\n",
      "[Epoch 41/50] [Batch 47/300] [D loss: 0.752274] [G loss: 0.468966] time: 1:01:24.063988\n",
      "0.9117672\n",
      "[Epoch 41/50] [Batch 48/300] [D loss: 0.752268] [G loss: 0.472036] time: 1:01:24.368362\n",
      "0.9034352\n",
      "[Epoch 41/50] [Batch 49/300] [D loss: 0.752285] [G loss: 0.478561] time: 1:01:24.657554\n",
      "0.92637426\n",
      "[Epoch 41/50] [Batch 50/300] [D loss: 0.752276] [G loss: 0.482321] time: 1:01:24.955423\n",
      "0.901319\n",
      "[Epoch 41/50] [Batch 51/300] [D loss: 0.752271] [G loss: 0.478339] time: 1:01:25.256346\n",
      "0.93302584\n",
      "[Epoch 41/50] [Batch 52/300] [D loss: 0.752292] [G loss: 0.471760] time: 1:01:25.554674\n",
      "0.8860397\n",
      "[Epoch 41/50] [Batch 53/300] [D loss: 0.752277] [G loss: 0.478881] time: 1:01:25.842463\n",
      "0.96576214\n",
      "[Epoch 41/50] [Batch 54/300] [D loss: 0.752269] [G loss: 0.477481] time: 1:01:26.141562\n",
      "0.92536575\n",
      "[Epoch 41/50] [Batch 55/300] [D loss: 0.752270] [G loss: 0.512520] time: 1:01:26.433343\n",
      "0.94029427\n",
      "[Epoch 41/50] [Batch 56/300] [D loss: 0.752276] [G loss: 0.498622] time: 1:01:26.740118\n",
      "0.8922486\n",
      "[Epoch 41/50] [Batch 57/300] [D loss: 0.752278] [G loss: 0.468908] time: 1:01:27.040411\n",
      "0.976357\n",
      "[Epoch 41/50] [Batch 58/300] [D loss: 0.752274] [G loss: 0.476187] time: 1:01:27.349335\n",
      "0.885947\n",
      "[Epoch 41/50] [Batch 59/300] [D loss: 0.752274] [G loss: 0.470623] time: 1:01:27.647888\n",
      "0.9303263\n",
      "[Epoch 41/50] [Batch 60/300] [D loss: 0.752273] [G loss: 0.480411] time: 1:01:27.950774\n",
      "0.9159594\n",
      "[Epoch 41/50] [Batch 61/300] [D loss: 0.752284] [G loss: 0.472325] time: 1:01:28.233646\n",
      "0.94616604\n",
      "[Epoch 41/50] [Batch 62/300] [D loss: 0.752283] [G loss: 0.480783] time: 1:01:28.534914\n",
      "0.88497573\n",
      "[Epoch 41/50] [Batch 63/300] [D loss: 0.752272] [G loss: 0.476884] time: 1:01:28.830423\n",
      "0.88671094\n",
      "[Epoch 41/50] [Batch 64/300] [D loss: 0.752284] [G loss: 0.479079] time: 1:01:29.126340\n",
      "0.9308297\n",
      "[Epoch 41/50] [Batch 65/300] [D loss: 0.752280] [G loss: 0.478646] time: 1:01:29.422738\n",
      "0.95529276\n",
      "[Epoch 41/50] [Batch 66/300] [D loss: 0.752270] [G loss: 0.483740] time: 1:01:29.727846\n",
      "0.8656159\n",
      "[Epoch 41/50] [Batch 67/300] [D loss: 0.752271] [G loss: 0.476158] time: 1:01:30.001072\n",
      "0.93051714\n",
      "[Epoch 41/50] [Batch 68/300] [D loss: 0.752272] [G loss: 0.507820] time: 1:01:30.301819\n",
      "0.9010131\n",
      "[Epoch 41/50] [Batch 69/300] [D loss: 0.752276] [G loss: 0.485886] time: 1:01:30.598096\n",
      "0.9418638\n",
      "[Epoch 41/50] [Batch 70/300] [D loss: 0.752294] [G loss: 0.473739] time: 1:01:30.884799\n",
      "0.9419294\n",
      "[Epoch 41/50] [Batch 71/300] [D loss: 0.752268] [G loss: 0.479579] time: 1:01:31.198408\n",
      "0.95953065\n",
      "[Epoch 41/50] [Batch 72/300] [D loss: 0.752289] [G loss: 0.476464] time: 1:01:31.500132\n",
      "0.94331765\n",
      "[Epoch 41/50] [Batch 73/300] [D loss: 0.752275] [G loss: 0.484686] time: 1:01:31.793750\n",
      "0.93850183\n",
      "[Epoch 41/50] [Batch 74/300] [D loss: 0.752276] [G loss: 0.490766] time: 1:01:32.090742\n",
      "0.93292147\n",
      "[Epoch 41/50] [Batch 75/300] [D loss: 0.752300] [G loss: 0.479523] time: 1:01:32.402896\n",
      "0.8934129\n",
      "[Epoch 41/50] [Batch 76/300] [D loss: 0.752276] [G loss: 0.469667] time: 1:01:32.695697\n",
      "0.8864868\n",
      "[Epoch 41/50] [Batch 77/300] [D loss: 0.752266] [G loss: 0.480566] time: 1:01:32.992314\n",
      "0.9323513\n",
      "[Epoch 41/50] [Batch 78/300] [D loss: 0.752276] [G loss: 0.475519] time: 1:01:33.299072\n",
      "0.93596524\n",
      "[Epoch 41/50] [Batch 79/300] [D loss: 0.752279] [G loss: 0.474370] time: 1:01:33.573941\n",
      "0.88334495\n",
      "[Epoch 41/50] [Batch 80/300] [D loss: 0.752260] [G loss: 0.473826] time: 1:01:33.880878\n",
      "0.88208914\n",
      "[Epoch 41/50] [Batch 81/300] [D loss: 0.752285] [G loss: 0.473568] time: 1:01:34.170941\n",
      "0.9390096\n",
      "[Epoch 41/50] [Batch 82/300] [D loss: 0.752270] [G loss: 0.469232] time: 1:01:34.473918\n",
      "0.96051484\n",
      "[Epoch 41/50] [Batch 83/300] [D loss: 0.752273] [G loss: 0.497895] time: 1:01:34.757403\n",
      "0.88534284\n",
      "[Epoch 41/50] [Batch 84/300] [D loss: 0.752293] [G loss: 0.475729] time: 1:01:35.042473\n",
      "0.96166253\n",
      "[Epoch 41/50] [Batch 85/300] [D loss: 0.752286] [G loss: 0.470009] time: 1:01:35.342937\n",
      "0.9547837\n",
      "[Epoch 41/50] [Batch 86/300] [D loss: 0.752279] [G loss: 0.468977] time: 1:01:35.633070\n",
      "0.87725085\n",
      "[Epoch 41/50] [Batch 87/300] [D loss: 0.752273] [G loss: 0.471859] time: 1:01:35.926815\n",
      "0.93321615\n",
      "[Epoch 41/50] [Batch 88/300] [D loss: 0.752299] [G loss: 0.470558] time: 1:01:36.219872\n",
      "0.9600017\n",
      "[Epoch 41/50] [Batch 89/300] [D loss: 0.752270] [G loss: 0.470397] time: 1:01:36.515710\n",
      "0.95944214\n",
      "[Epoch 41/50] [Batch 90/300] [D loss: 0.752298] [G loss: 0.482801] time: 1:01:36.804463\n",
      "0.91218096\n",
      "[Epoch 41/50] [Batch 91/300] [D loss: 0.752276] [G loss: 0.477989] time: 1:01:37.108212\n",
      "0.89124894\n",
      "[Epoch 41/50] [Batch 92/300] [D loss: 0.752264] [G loss: 0.475254] time: 1:01:37.394256\n",
      "0.9060848\n",
      "[Epoch 41/50] [Batch 93/300] [D loss: 0.752286] [G loss: 0.477953] time: 1:01:37.689920\n",
      "0.953031\n",
      "[Epoch 41/50] [Batch 94/300] [D loss: 0.752276] [G loss: 0.482015] time: 1:01:37.981808\n",
      "0.96682245\n",
      "[Epoch 41/50] [Batch 95/300] [D loss: 0.752287] [G loss: 0.471499] time: 1:01:38.248208\n",
      "0.90772206\n",
      "[Epoch 41/50] [Batch 96/300] [D loss: 0.752278] [G loss: 0.500055] time: 1:01:38.509693\n",
      "0.9499313\n",
      "[Epoch 41/50] [Batch 97/300] [D loss: 0.752279] [G loss: 0.481249] time: 1:01:38.829091\n",
      "0.92683697\n",
      "[Epoch 41/50] [Batch 98/300] [D loss: 0.752293] [G loss: 0.474357] time: 1:01:39.104363\n",
      "0.92035484\n",
      "[Epoch 41/50] [Batch 99/300] [D loss: 0.752256] [G loss: 0.501256] time: 1:01:39.387132\n",
      "0.89885134\n",
      "[Epoch 41/50] [Batch 100/300] [D loss: 0.752268] [G loss: 0.481437] time: 1:01:39.678613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9383948\n",
      "[Epoch 41/50] [Batch 101/300] [D loss: 0.752283] [G loss: 0.473411] time: 1:01:39.977553\n",
      "0.93033767\n",
      "[Epoch 41/50] [Batch 102/300] [D loss: 0.752294] [G loss: 0.471434] time: 1:01:40.275847\n",
      "0.93135756\n",
      "[Epoch 41/50] [Batch 103/300] [D loss: 0.752278] [G loss: 0.478635] time: 1:01:40.570010\n",
      "0.9306008\n",
      "[Epoch 41/50] [Batch 104/300] [D loss: 0.752274] [G loss: 0.470460] time: 1:01:40.842312\n",
      "0.90880173\n",
      "[Epoch 41/50] [Batch 105/300] [D loss: 0.752290] [G loss: 0.482017] time: 1:01:41.148786\n",
      "0.9339674\n",
      "[Epoch 41/50] [Batch 106/300] [D loss: 0.752281] [G loss: 0.495382] time: 1:01:41.436895\n",
      "0.91651994\n",
      "[Epoch 41/50] [Batch 107/300] [D loss: 0.752269] [G loss: 0.482454] time: 1:01:41.713176\n",
      "0.909687\n",
      "[Epoch 41/50] [Batch 108/300] [D loss: 0.752273] [G loss: 0.478675] time: 1:01:42.015886\n",
      "0.93425626\n",
      "[Epoch 41/50] [Batch 109/300] [D loss: 0.752261] [G loss: 0.474670] time: 1:01:42.315252\n",
      "0.94482136\n",
      "[Epoch 41/50] [Batch 110/300] [D loss: 0.752271] [G loss: 0.477848] time: 1:01:42.612822\n",
      "0.90191966\n",
      "[Epoch 41/50] [Batch 111/300] [D loss: 0.752273] [G loss: 0.468904] time: 1:01:42.905703\n",
      "0.90002817\n",
      "[Epoch 41/50] [Batch 112/300] [D loss: 0.752282] [G loss: 0.472381] time: 1:01:43.210443\n",
      "0.90952444\n",
      "[Epoch 41/50] [Batch 113/300] [D loss: 0.752270] [G loss: 0.485794] time: 1:01:43.519844\n",
      "0.9217648\n",
      "[Epoch 41/50] [Batch 114/300] [D loss: 0.752281] [G loss: 0.471529] time: 1:01:43.806856\n",
      "0.9280214\n",
      "[Epoch 41/50] [Batch 115/300] [D loss: 0.752285] [G loss: 0.473473] time: 1:01:44.098382\n",
      "0.87699777\n",
      "[Epoch 41/50] [Batch 116/300] [D loss: 0.752272] [G loss: 0.484999] time: 1:01:44.375098\n",
      "0.9565845\n",
      "[Epoch 41/50] [Batch 117/300] [D loss: 0.752288] [G loss: 0.472391] time: 1:01:44.688348\n",
      "0.89328486\n",
      "[Epoch 41/50] [Batch 118/300] [D loss: 0.752278] [G loss: 0.473896] time: 1:01:44.977749\n",
      "0.9284554\n",
      "[Epoch 41/50] [Batch 119/300] [D loss: 0.752278] [G loss: 0.475467] time: 1:01:45.272898\n",
      "0.9188722\n",
      "[Epoch 41/50] [Batch 120/300] [D loss: 0.752272] [G loss: 0.472538] time: 1:01:45.568106\n",
      "0.89148766\n",
      "[Epoch 41/50] [Batch 121/300] [D loss: 0.752267] [G loss: 0.471548] time: 1:01:45.866891\n",
      "0.92906815\n",
      "[Epoch 41/50] [Batch 122/300] [D loss: 0.752284] [G loss: 0.496124] time: 1:01:46.153600\n",
      "0.94550157\n",
      "[Epoch 41/50] [Batch 123/300] [D loss: 0.752276] [G loss: 0.471719] time: 1:01:46.441142\n",
      "0.9100733\n",
      "[Epoch 41/50] [Batch 124/300] [D loss: 0.752269] [G loss: 0.477864] time: 1:01:46.735179\n",
      "0.9190298\n",
      "[Epoch 41/50] [Batch 125/300] [D loss: 0.752272] [G loss: 0.480998] time: 1:01:47.043380\n",
      "0.95762664\n",
      "[Epoch 41/50] [Batch 126/300] [D loss: 0.752287] [G loss: 0.471636] time: 1:01:47.357206\n",
      "0.89593554\n",
      "[Epoch 41/50] [Batch 127/300] [D loss: 0.752272] [G loss: 0.478713] time: 1:01:47.646355\n",
      "0.8955648\n",
      "[Epoch 41/50] [Batch 128/300] [D loss: 0.752268] [G loss: 0.478929] time: 1:01:47.933946\n",
      "0.90379715\n",
      "[Epoch 41/50] [Batch 129/300] [D loss: 0.752273] [G loss: 0.487449] time: 1:01:48.207494\n",
      "0.9566608\n",
      "[Epoch 41/50] [Batch 130/300] [D loss: 0.752271] [G loss: 0.480662] time: 1:01:48.508380\n",
      "0.9403818\n",
      "[Epoch 41/50] [Batch 131/300] [D loss: 0.752271] [G loss: 0.477489] time: 1:01:48.804369\n",
      "0.9259779\n",
      "[Epoch 41/50] [Batch 132/300] [D loss: 0.752280] [G loss: 0.475125] time: 1:01:49.108419\n",
      "0.9448264\n",
      "[Epoch 41/50] [Batch 133/300] [D loss: 0.752282] [G loss: 0.471050] time: 1:01:49.408452\n",
      "0.93372583\n",
      "[Epoch 41/50] [Batch 134/300] [D loss: 0.752270] [G loss: 0.478894] time: 1:01:49.710133\n",
      "0.9083376\n",
      "[Epoch 41/50] [Batch 135/300] [D loss: 0.752290] [G loss: 0.473829] time: 1:01:49.997432\n",
      "0.90656877\n",
      "[Epoch 41/50] [Batch 136/300] [D loss: 0.752286] [G loss: 0.468498] time: 1:01:50.300265\n",
      "0.93842477\n",
      "[Epoch 41/50] [Batch 137/300] [D loss: 0.752297] [G loss: 0.470108] time: 1:01:50.587117\n",
      "0.9172031\n",
      "[Epoch 41/50] [Batch 138/300] [D loss: 0.752285] [G loss: 0.477478] time: 1:01:50.884079\n",
      "0.91677815\n",
      "[Epoch 41/50] [Batch 139/300] [D loss: 0.752276] [G loss: 0.480924] time: 1:01:51.216357\n",
      "0.93638754\n",
      "[Epoch 41/50] [Batch 140/300] [D loss: 0.752272] [G loss: 0.470708] time: 1:01:51.503346\n",
      "0.9231002\n",
      "[Epoch 41/50] [Batch 141/300] [D loss: 0.752263] [G loss: 0.467352] time: 1:01:51.799606\n",
      "0.8931199\n",
      "[Epoch 41/50] [Batch 142/300] [D loss: 0.752266] [G loss: 0.479987] time: 1:01:52.095091\n",
      "0.87432355\n",
      "[Epoch 41/50] [Batch 143/300] [D loss: 0.752284] [G loss: 0.481570] time: 1:01:52.386956\n",
      "0.8885186\n",
      "[Epoch 41/50] [Batch 144/300] [D loss: 0.752285] [G loss: 0.499571] time: 1:01:52.685356\n",
      "0.9497878\n",
      "[Epoch 41/50] [Batch 145/300] [D loss: 0.752274] [G loss: 0.467878] time: 1:01:52.981228\n",
      "0.9237333\n",
      "[Epoch 41/50] [Batch 146/300] [D loss: 0.752280] [G loss: 0.475771] time: 1:01:53.274271\n",
      "0.93068665\n",
      "[Epoch 41/50] [Batch 147/300] [D loss: 0.752286] [G loss: 0.476618] time: 1:01:53.563580\n",
      "0.9030917\n",
      "[Epoch 41/50] [Batch 148/300] [D loss: 0.752288] [G loss: 0.467918] time: 1:01:53.867093\n",
      "0.9461871\n",
      "[Epoch 41/50] [Batch 149/300] [D loss: 0.752291] [G loss: 0.473137] time: 1:01:54.165173\n",
      "0.8993249\n",
      "[Epoch 41/50] [Batch 150/300] [D loss: 0.752278] [G loss: 0.479309] time: 1:01:54.454547\n",
      "0.93992233\n",
      "[Epoch 41/50] [Batch 151/300] [D loss: 0.752269] [G loss: 0.480974] time: 1:01:54.750460\n",
      "0.9425823\n",
      "[Epoch 41/50] [Batch 152/300] [D loss: 0.752279] [G loss: 0.482993] time: 1:01:55.053997\n",
      "0.9074874\n",
      "[Epoch 41/50] [Batch 153/300] [D loss: 0.752282] [G loss: 0.472465] time: 1:01:55.359868\n",
      "0.91250163\n",
      "[Epoch 41/50] [Batch 154/300] [D loss: 0.752275] [G loss: 0.466926] time: 1:01:55.666277\n",
      "0.95342326\n",
      "[Epoch 41/50] [Batch 155/300] [D loss: 0.752274] [G loss: 0.470176] time: 1:01:55.966637\n",
      "0.95956373\n",
      "[Epoch 41/50] [Batch 156/300] [D loss: 0.752281] [G loss: 0.468105] time: 1:01:56.268986\n",
      "0.94730157\n",
      "[Epoch 41/50] [Batch 157/300] [D loss: 0.752280] [G loss: 0.475812] time: 1:01:56.555204\n",
      "0.9126392\n",
      "[Epoch 41/50] [Batch 158/300] [D loss: 0.752280] [G loss: 0.476103] time: 1:01:56.848152\n",
      "0.88883376\n",
      "[Epoch 41/50] [Batch 159/300] [D loss: 0.752282] [G loss: 0.473432] time: 1:01:57.152990\n",
      "0.90743047\n",
      "[Epoch 41/50] [Batch 160/300] [D loss: 0.752265] [G loss: 0.484559] time: 1:01:57.448130\n",
      "0.93348044\n",
      "[Epoch 41/50] [Batch 161/300] [D loss: 0.752286] [G loss: 0.477241] time: 1:01:57.759554\n",
      "0.9773089\n",
      "[Epoch 41/50] [Batch 162/300] [D loss: 0.752283] [G loss: 0.477918] time: 1:01:58.048587\n",
      "0.932527\n",
      "[Epoch 41/50] [Batch 163/300] [D loss: 0.752268] [G loss: 0.468945] time: 1:01:58.343414\n",
      "0.8854069\n",
      "[Epoch 41/50] [Batch 164/300] [D loss: 0.752273] [G loss: 0.466316] time: 1:01:58.640785\n",
      "0.9462208\n",
      "[Epoch 41/50] [Batch 165/300] [D loss: 0.752277] [G loss: 0.466669] time: 1:01:58.935541\n",
      "0.9601428\n",
      "[Epoch 41/50] [Batch 166/300] [D loss: 0.752269] [G loss: 0.465136] time: 1:01:59.222665\n",
      "0.9599959\n",
      "[Epoch 41/50] [Batch 167/300] [D loss: 0.752273] [G loss: 0.477217] time: 1:01:59.518370\n",
      "0.93325853\n",
      "[Epoch 41/50] [Batch 168/300] [D loss: 0.752266] [G loss: 0.473594] time: 1:01:59.817222\n",
      "0.93243957\n",
      "[Epoch 41/50] [Batch 169/300] [D loss: 0.752260] [G loss: 0.473610] time: 1:02:00.115404\n",
      "0.9420282\n",
      "[Epoch 41/50] [Batch 170/300] [D loss: 0.752270] [G loss: 0.480510] time: 1:02:00.419822\n",
      "0.922317\n",
      "[Epoch 41/50] [Batch 171/300] [D loss: 0.752273] [G loss: 0.466539] time: 1:02:00.719328\n",
      "0.9497738\n",
      "[Epoch 41/50] [Batch 172/300] [D loss: 0.752273] [G loss: 0.466336] time: 1:02:01.011661\n",
      "0.893142\n",
      "[Epoch 41/50] [Batch 173/300] [D loss: 0.752274] [G loss: 0.480771] time: 1:02:01.285689\n",
      "0.9268214\n",
      "[Epoch 41/50] [Batch 174/300] [D loss: 0.752281] [G loss: 0.467378] time: 1:02:01.574774\n",
      "0.93196577\n",
      "[Epoch 41/50] [Batch 175/300] [D loss: 0.752277] [G loss: 0.470014] time: 1:02:01.857243\n",
      "0.9113946\n",
      "[Epoch 41/50] [Batch 176/300] [D loss: 0.752268] [G loss: 0.480280] time: 1:02:02.126818\n",
      "0.9452254\n",
      "[Epoch 41/50] [Batch 177/300] [D loss: 0.752279] [G loss: 0.477570] time: 1:02:02.427847\n",
      "0.9249711\n",
      "[Epoch 41/50] [Batch 178/300] [D loss: 0.752268] [G loss: 0.483829] time: 1:02:02.726101\n",
      "0.9161434\n",
      "[Epoch 41/50] [Batch 179/300] [D loss: 0.752273] [G loss: 0.471295] time: 1:02:03.044313\n",
      "0.8989466\n",
      "[Epoch 41/50] [Batch 180/300] [D loss: 0.752273] [G loss: 0.470635] time: 1:02:03.340114\n",
      "0.953255\n",
      "[Epoch 41/50] [Batch 181/300] [D loss: 0.752276] [G loss: 0.493189] time: 1:02:03.635757\n",
      "0.884701\n",
      "[Epoch 41/50] [Batch 182/300] [D loss: 0.752277] [G loss: 0.489877] time: 1:02:03.938425\n",
      "0.88004255\n",
      "[Epoch 41/50] [Batch 183/300] [D loss: 0.752274] [G loss: 0.473658] time: 1:02:04.227575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94127464\n",
      "[Epoch 41/50] [Batch 184/300] [D loss: 0.752270] [G loss: 0.478210] time: 1:02:04.551465\n",
      "0.9083052\n",
      "[Epoch 41/50] [Batch 185/300] [D loss: 0.752268] [G loss: 0.466178] time: 1:02:04.841511\n",
      "0.90297884\n",
      "[Epoch 41/50] [Batch 186/300] [D loss: 0.752267] [G loss: 0.495573] time: 1:02:05.136748\n",
      "0.9792233\n",
      "[Epoch 41/50] [Batch 187/300] [D loss: 0.752283] [G loss: 0.468222] time: 1:02:05.436501\n",
      "0.9477916\n",
      "[Epoch 41/50] [Batch 188/300] [D loss: 0.752273] [G loss: 0.475350] time: 1:02:05.734687\n",
      "0.91757506\n",
      "[Epoch 41/50] [Batch 189/300] [D loss: 0.752265] [G loss: 0.494629] time: 1:02:06.032007\n",
      "0.9247244\n",
      "[Epoch 41/50] [Batch 190/300] [D loss: 0.752284] [G loss: 0.469153] time: 1:02:06.325594\n",
      "0.9352569\n",
      "[Epoch 41/50] [Batch 191/300] [D loss: 0.752273] [G loss: 0.477105] time: 1:02:06.636697\n",
      "0.91600513\n",
      "[Epoch 41/50] [Batch 192/300] [D loss: 0.752258] [G loss: 0.491995] time: 1:02:06.950148\n",
      "0.91625553\n",
      "[Epoch 41/50] [Batch 193/300] [D loss: 0.752271] [G loss: 0.477952] time: 1:02:07.242336\n",
      "0.9236273\n",
      "[Epoch 41/50] [Batch 194/300] [D loss: 0.752273] [G loss: 0.492548] time: 1:02:07.534480\n",
      "0.9311073\n",
      "[Epoch 41/50] [Batch 195/300] [D loss: 0.752288] [G loss: 0.497732] time: 1:02:07.835902\n",
      "0.9256926\n",
      "[Epoch 41/50] [Batch 196/300] [D loss: 0.752279] [G loss: 0.482686] time: 1:02:08.126508\n",
      "0.9048505\n",
      "[Epoch 41/50] [Batch 197/300] [D loss: 0.752279] [G loss: 0.473023] time: 1:02:08.428928\n",
      "0.90771776\n",
      "[Epoch 41/50] [Batch 198/300] [D loss: 0.752279] [G loss: 0.468743] time: 1:02:08.727157\n",
      "0.90805095\n",
      "[Epoch 41/50] [Batch 199/300] [D loss: 0.752266] [G loss: 0.479937] time: 1:02:09.042108\n",
      "0.9076999\n",
      "[Epoch 41/50] [Batch 200/300] [D loss: 0.752278] [G loss: 0.473719] time: 1:02:09.318507\n",
      "0.96653\n",
      "[Epoch 41/50] [Batch 201/300] [D loss: 0.752270] [G loss: 0.471330] time: 1:02:09.624624\n",
      "0.9412787\n",
      "[Epoch 41/50] [Batch 202/300] [D loss: 0.752269] [G loss: 0.484942] time: 1:02:09.927471\n",
      "0.92718583\n",
      "[Epoch 41/50] [Batch 203/300] [D loss: 0.752282] [G loss: 0.482901] time: 1:02:10.226071\n",
      "0.96673924\n",
      "[Epoch 41/50] [Batch 204/300] [D loss: 0.752287] [G loss: 0.468262] time: 1:02:10.528457\n",
      "0.9470122\n",
      "[Epoch 41/50] [Batch 205/300] [D loss: 0.752276] [G loss: 0.466789] time: 1:02:10.816769\n",
      "0.9108488\n",
      "[Epoch 41/50] [Batch 206/300] [D loss: 0.752264] [G loss: 0.471460] time: 1:02:11.111805\n",
      "0.9092099\n",
      "[Epoch 41/50] [Batch 207/300] [D loss: 0.752275] [G loss: 0.484057] time: 1:02:11.394607\n",
      "0.91400343\n",
      "[Epoch 41/50] [Batch 208/300] [D loss: 0.752275] [G loss: 0.480007] time: 1:02:11.686700\n",
      "0.94000894\n",
      "[Epoch 41/50] [Batch 209/300] [D loss: 0.752292] [G loss: 0.483679] time: 1:02:12.004932\n",
      "0.9393146\n",
      "[Epoch 41/50] [Batch 210/300] [D loss: 0.752276] [G loss: 0.484144] time: 1:02:12.300828\n",
      "0.9369409\n",
      "[Epoch 41/50] [Batch 211/300] [D loss: 0.752268] [G loss: 0.478115] time: 1:02:12.590471\n",
      "0.9452447\n",
      "[Epoch 41/50] [Batch 212/300] [D loss: 0.752280] [G loss: 0.483345] time: 1:02:12.896857\n",
      "0.8929921\n",
      "[Epoch 41/50] [Batch 213/300] [D loss: 0.752271] [G loss: 0.480835] time: 1:02:13.172203\n",
      "0.9043687\n",
      "[Epoch 41/50] [Batch 214/300] [D loss: 0.752272] [G loss: 0.478385] time: 1:02:13.477492\n",
      "0.9241972\n",
      "[Epoch 41/50] [Batch 215/300] [D loss: 0.752273] [G loss: 0.494085] time: 1:02:13.780071\n",
      "0.960157\n",
      "[Epoch 41/50] [Batch 216/300] [D loss: 0.752275] [G loss: 0.467499] time: 1:02:14.070675\n",
      "0.93068856\n",
      "[Epoch 41/50] [Batch 217/300] [D loss: 0.752281] [G loss: 0.474507] time: 1:02:14.342693\n",
      "0.90831083\n",
      "[Epoch 41/50] [Batch 218/300] [D loss: 0.752267] [G loss: 0.472641] time: 1:02:14.638366\n",
      "0.8900227\n",
      "[Epoch 41/50] [Batch 219/300] [D loss: 0.752267] [G loss: 0.481750] time: 1:02:14.936901\n",
      "0.9054343\n",
      "[Epoch 41/50] [Batch 220/300] [D loss: 0.752276] [G loss: 0.505450] time: 1:02:15.238620\n",
      "0.9279712\n",
      "[Epoch 41/50] [Batch 221/300] [D loss: 0.752261] [G loss: 0.491536] time: 1:02:15.513606\n",
      "0.89622116\n",
      "[Epoch 41/50] [Batch 222/300] [D loss: 0.752276] [G loss: 0.483289] time: 1:02:15.811635\n",
      "0.8736132\n",
      "[Epoch 41/50] [Batch 223/300] [D loss: 0.752266] [G loss: 0.469841] time: 1:02:16.111545\n",
      "0.94856626\n",
      "[Epoch 41/50] [Batch 224/300] [D loss: 0.752287] [G loss: 0.483551] time: 1:02:16.418435\n",
      "0.87023467\n",
      "[Epoch 41/50] [Batch 225/300] [D loss: 0.752273] [G loss: 0.474604] time: 1:02:16.700568\n",
      "0.9381127\n",
      "[Epoch 41/50] [Batch 226/300] [D loss: 0.752279] [G loss: 0.482275] time: 1:02:16.999989\n",
      "0.9083295\n",
      "[Epoch 41/50] [Batch 227/300] [D loss: 0.752272] [G loss: 0.477425] time: 1:02:17.302431\n",
      "0.94128203\n",
      "[Epoch 41/50] [Batch 228/300] [D loss: 0.752275] [G loss: 0.472145] time: 1:02:17.602612\n",
      "0.91649723\n",
      "[Epoch 41/50] [Batch 229/300] [D loss: 0.752261] [G loss: 0.488016] time: 1:02:17.895469\n",
      "0.92949367\n",
      "[Epoch 41/50] [Batch 230/300] [D loss: 0.752273] [G loss: 0.468350] time: 1:02:18.186206\n",
      "0.93494266\n",
      "[Epoch 41/50] [Batch 231/300] [D loss: 0.752268] [G loss: 0.478049] time: 1:02:18.489703\n",
      "0.91638756\n",
      "[Epoch 41/50] [Batch 232/300] [D loss: 0.752278] [G loss: 0.473002] time: 1:02:18.777045\n",
      "0.8854749\n",
      "[Epoch 41/50] [Batch 233/300] [D loss: 0.752269] [G loss: 0.502184] time: 1:02:19.083176\n",
      "0.9109879\n",
      "[Epoch 41/50] [Batch 234/300] [D loss: 0.752274] [G loss: 0.484049] time: 1:02:19.383756\n",
      "0.9038132\n",
      "[Epoch 41/50] [Batch 235/300] [D loss: 0.752276] [G loss: 0.478904] time: 1:02:19.683749\n",
      "0.9375625\n",
      "[Epoch 41/50] [Batch 236/300] [D loss: 0.752273] [G loss: 0.476258] time: 1:02:19.987720\n",
      "0.93704414\n",
      "[Epoch 41/50] [Batch 237/300] [D loss: 0.752254] [G loss: 0.477280] time: 1:02:20.276263\n",
      "0.9194462\n",
      "[Epoch 41/50] [Batch 238/300] [D loss: 0.752280] [G loss: 0.467628] time: 1:02:20.555870\n",
      "0.93207496\n",
      "[Epoch 41/50] [Batch 239/300] [D loss: 0.752278] [G loss: 0.475434] time: 1:02:20.857031\n",
      "0.9250501\n",
      "[Epoch 41/50] [Batch 240/300] [D loss: 0.752287] [G loss: 0.470047] time: 1:02:21.153064\n",
      "0.94621944\n",
      "[Epoch 41/50] [Batch 241/300] [D loss: 0.752293] [G loss: 0.468276] time: 1:02:21.444359\n",
      "0.8846287\n",
      "[Epoch 41/50] [Batch 242/300] [D loss: 0.752268] [G loss: 0.490128] time: 1:02:21.731171\n",
      "0.9037523\n",
      "[Epoch 41/50] [Batch 243/300] [D loss: 0.752275] [G loss: 0.472735] time: 1:02:22.015757\n",
      "0.9383025\n",
      "[Epoch 41/50] [Batch 244/300] [D loss: 0.752271] [G loss: 0.505422] time: 1:02:22.304257\n",
      "0.91295\n",
      "[Epoch 41/50] [Batch 245/300] [D loss: 0.752268] [G loss: 0.469033] time: 1:02:22.600964\n",
      "0.9293205\n",
      "[Epoch 41/50] [Batch 246/300] [D loss: 0.752274] [G loss: 0.485454] time: 1:02:22.890144\n",
      "0.9335274\n",
      "[Epoch 41/50] [Batch 247/300] [D loss: 0.752267] [G loss: 0.473103] time: 1:02:23.190463\n",
      "0.9099605\n",
      "[Epoch 41/50] [Batch 248/300] [D loss: 0.752279] [G loss: 0.493280] time: 1:02:23.490391\n",
      "0.9289513\n",
      "[Epoch 41/50] [Batch 249/300] [D loss: 0.752272] [G loss: 0.511869] time: 1:02:23.819080\n",
      "0.9469104\n",
      "[Epoch 41/50] [Batch 250/300] [D loss: 0.752267] [G loss: 0.488586] time: 1:02:24.122776\n",
      "0.926696\n",
      "[Epoch 41/50] [Batch 251/300] [D loss: 0.752267] [G loss: 0.472668] time: 1:02:24.419425\n",
      "0.9289196\n",
      "[Epoch 41/50] [Batch 252/300] [D loss: 0.752277] [G loss: 0.484116] time: 1:02:24.694044\n",
      "0.89905053\n",
      "[Epoch 41/50] [Batch 253/300] [D loss: 0.752272] [G loss: 0.469572] time: 1:02:24.993689\n",
      "0.94069415\n",
      "[Epoch 41/50] [Batch 254/300] [D loss: 0.752277] [G loss: 0.489927] time: 1:02:25.300482\n",
      "0.91668344\n",
      "[Epoch 41/50] [Batch 255/300] [D loss: 0.752273] [G loss: 0.479953] time: 1:02:25.599616\n",
      "0.8946988\n",
      "[Epoch 41/50] [Batch 256/300] [D loss: 0.752271] [G loss: 0.478900] time: 1:02:25.902850\n",
      "0.90882134\n",
      "[Epoch 41/50] [Batch 257/300] [D loss: 0.752272] [G loss: 0.472313] time: 1:02:26.192096\n",
      "0.87155724\n",
      "[Epoch 41/50] [Batch 258/300] [D loss: 0.752271] [G loss: 0.471778] time: 1:02:26.494051\n",
      "0.90394026\n",
      "[Epoch 41/50] [Batch 259/300] [D loss: 0.752273] [G loss: 0.482134] time: 1:02:26.790274\n",
      "0.96010184\n",
      "[Epoch 41/50] [Batch 260/300] [D loss: 0.752283] [G loss: 0.472542] time: 1:02:27.064679\n",
      "0.93882656\n",
      "[Epoch 41/50] [Batch 261/300] [D loss: 0.752288] [G loss: 0.467598] time: 1:02:27.360404\n",
      "0.96017647\n",
      "[Epoch 41/50] [Batch 262/300] [D loss: 0.752276] [G loss: 0.471558] time: 1:02:27.662829\n",
      "0.9563244\n",
      "[Epoch 41/50] [Batch 263/300] [D loss: 0.752267] [G loss: 0.484168] time: 1:02:27.959973\n",
      "0.9302675\n",
      "[Epoch 41/50] [Batch 264/300] [D loss: 0.752276] [G loss: 0.467049] time: 1:02:28.265534\n",
      "0.934099\n",
      "[Epoch 41/50] [Batch 265/300] [D loss: 0.752270] [G loss: 0.472997] time: 1:02:28.565510\n",
      "0.9029023\n",
      "[Epoch 41/50] [Batch 266/300] [D loss: 0.752278] [G loss: 0.471055] time: 1:02:28.869808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94206166\n",
      "[Epoch 41/50] [Batch 267/300] [D loss: 0.752274] [G loss: 0.480110] time: 1:02:29.171310\n",
      "0.8994362\n",
      "[Epoch 41/50] [Batch 268/300] [D loss: 0.752263] [G loss: 0.479416] time: 1:02:29.464535\n",
      "0.95311517\n",
      "[Epoch 41/50] [Batch 269/300] [D loss: 0.752273] [G loss: 0.484139] time: 1:02:29.767623\n",
      "0.92924047\n",
      "[Epoch 41/50] [Batch 270/300] [D loss: 0.752280] [G loss: 0.479453] time: 1:02:30.069363\n",
      "0.9562097\n",
      "[Epoch 41/50] [Batch 271/300] [D loss: 0.752274] [G loss: 0.475937] time: 1:02:30.370858\n",
      "0.925\n",
      "[Epoch 41/50] [Batch 272/300] [D loss: 0.752276] [G loss: 0.519925] time: 1:02:30.657930\n",
      "0.9343119\n",
      "[Epoch 41/50] [Batch 273/300] [D loss: 0.752259] [G loss: 0.477808] time: 1:02:30.960190\n",
      "0.90844584\n",
      "[Epoch 41/50] [Batch 274/300] [D loss: 0.752276] [G loss: 0.493447] time: 1:02:31.266801\n",
      "0.9449694\n",
      "[Epoch 41/50] [Batch 275/300] [D loss: 0.752274] [G loss: 0.476946] time: 1:02:31.564862\n",
      "0.89923745\n",
      "[Epoch 41/50] [Batch 276/300] [D loss: 0.752271] [G loss: 0.473952] time: 1:02:31.863726\n",
      "0.9469619\n",
      "[Epoch 41/50] [Batch 277/300] [D loss: 0.752265] [G loss: 0.472546] time: 1:02:32.171956\n",
      "0.8930788\n",
      "[Epoch 41/50] [Batch 278/300] [D loss: 0.752260] [G loss: 0.477727] time: 1:02:32.474036\n",
      "0.9315031\n",
      "[Epoch 41/50] [Batch 279/300] [D loss: 0.752273] [G loss: 0.485168] time: 1:02:32.771084\n",
      "0.92856956\n",
      "[Epoch 41/50] [Batch 280/300] [D loss: 0.752271] [G loss: 0.480094] time: 1:02:33.064998\n",
      "0.9058206\n",
      "[Epoch 41/50] [Batch 281/300] [D loss: 0.752272] [G loss: 0.468750] time: 1:02:33.369014\n",
      "0.91190976\n",
      "[Epoch 41/50] [Batch 282/300] [D loss: 0.752274] [G loss: 0.475954] time: 1:02:33.672488\n",
      "0.9316516\n",
      "[Epoch 41/50] [Batch 283/300] [D loss: 0.752287] [G loss: 0.479645] time: 1:02:33.957435\n",
      "0.9407107\n",
      "[Epoch 41/50] [Batch 284/300] [D loss: 0.752280] [G loss: 0.480620] time: 1:02:34.249073\n",
      "0.9258211\n",
      "[Epoch 41/50] [Batch 285/300] [D loss: 0.752276] [G loss: 0.482494] time: 1:02:34.550179\n",
      "0.93152755\n",
      "[Epoch 41/50] [Batch 286/300] [D loss: 0.752274] [G loss: 0.482354] time: 1:02:34.853263\n",
      "0.9332568\n",
      "[Epoch 41/50] [Batch 287/300] [D loss: 0.752264] [G loss: 0.487164] time: 1:02:35.152648\n",
      "0.942789\n",
      "[Epoch 41/50] [Batch 288/300] [D loss: 0.752273] [G loss: 0.499075] time: 1:02:35.465197\n",
      "0.87253976\n",
      "[Epoch 41/50] [Batch 289/300] [D loss: 0.752279] [G loss: 0.484247] time: 1:02:35.761922\n",
      "0.9757633\n",
      "[Epoch 41/50] [Batch 290/300] [D loss: 0.752280] [G loss: 0.476719] time: 1:02:36.065907\n",
      "0.92163515\n",
      "[Epoch 41/50] [Batch 291/300] [D loss: 0.752263] [G loss: 0.476547] time: 1:02:36.377286\n",
      "0.9058666\n",
      "[Epoch 41/50] [Batch 292/300] [D loss: 0.752277] [G loss: 0.480747] time: 1:02:36.672344\n",
      "0.8850873\n",
      "[Epoch 41/50] [Batch 293/300] [D loss: 0.752278] [G loss: 0.482705] time: 1:02:36.961864\n",
      "0.9611179\n",
      "[Epoch 41/50] [Batch 294/300] [D loss: 0.752273] [G loss: 0.475374] time: 1:02:37.272172\n",
      "0.9092081\n",
      "[Epoch 41/50] [Batch 295/300] [D loss: 0.752280] [G loss: 0.480565] time: 1:02:37.571710\n",
      "0.8523483\n",
      "[Epoch 41/50] [Batch 296/300] [D loss: 0.752254] [G loss: 0.476080] time: 1:02:37.867691\n",
      "0.87393636\n",
      "[Epoch 41/50] [Batch 297/300] [D loss: 0.752270] [G loss: 0.493560] time: 1:02:38.167135\n",
      "0.9121104\n",
      "[Epoch 41/50] [Batch 298/300] [D loss: 0.752274] [G loss: 0.476017] time: 1:02:38.460402\n",
      "0.9318511\n",
      "[Epoch 41/50] [Batch 299/300] [D loss: 0.752280] [G loss: 0.485431] time: 1:02:38.775409\n",
      "0.8737492\n",
      "[Epoch 42/50] [Batch 0/300] [D loss: 0.752279] [G loss: 0.482513] time: 1:02:39.059800\n",
      "0.9206002\n",
      "[Epoch 42/50] [Batch 1/300] [D loss: 0.752280] [G loss: 0.481508] time: 1:02:39.370934\n",
      "0.9006326\n",
      "[Epoch 42/50] [Batch 2/300] [D loss: 0.752268] [G loss: 0.483929] time: 1:02:39.676031\n",
      "0.8648471\n",
      "[Epoch 42/50] [Batch 3/300] [D loss: 0.752285] [G loss: 0.470897] time: 1:02:39.965694\n",
      "0.89580756\n",
      "[Epoch 42/50] [Batch 4/300] [D loss: 0.752268] [G loss: 0.488878] time: 1:02:40.264346\n",
      "0.9330101\n",
      "[Epoch 42/50] [Batch 5/300] [D loss: 0.752265] [G loss: 0.489449] time: 1:02:40.579167\n",
      "0.9349847\n",
      "[Epoch 42/50] [Batch 6/300] [D loss: 0.752271] [G loss: 0.499085] time: 1:02:40.875731\n",
      "0.8862402\n",
      "[Epoch 42/50] [Batch 7/300] [D loss: 0.752254] [G loss: 0.482179] time: 1:02:41.166591\n",
      "0.9697717\n",
      "[Epoch 42/50] [Batch 8/300] [D loss: 0.752279] [G loss: 0.481077] time: 1:02:41.465962\n",
      "0.86764234\n",
      "[Epoch 42/50] [Batch 9/300] [D loss: 0.752268] [G loss: 0.495913] time: 1:02:41.757787\n",
      "0.9056762\n",
      "[Epoch 42/50] [Batch 10/300] [D loss: 0.752264] [G loss: 0.519852] time: 1:02:42.054455\n",
      "0.9051397\n",
      "[Epoch 42/50] [Batch 11/300] [D loss: 0.752277] [G loss: 0.484564] time: 1:02:42.352416\n",
      "0.89183235\n",
      "[Epoch 42/50] [Batch 12/300] [D loss: 0.752272] [G loss: 0.481085] time: 1:02:42.655482\n",
      "0.89919394\n",
      "[Epoch 42/50] [Batch 13/300] [D loss: 0.752280] [G loss: 0.491038] time: 1:02:42.958015\n",
      "0.9129234\n",
      "[Epoch 42/50] [Batch 14/300] [D loss: 0.752272] [G loss: 0.488033] time: 1:02:43.274205\n",
      "0.9419215\n",
      "[Epoch 42/50] [Batch 15/300] [D loss: 0.752260] [G loss: 0.481980] time: 1:02:43.572965\n",
      "0.9029708\n",
      "[Epoch 42/50] [Batch 16/300] [D loss: 0.752282] [G loss: 0.476031] time: 1:02:43.872987\n",
      "0.93186325\n",
      "[Epoch 42/50] [Batch 17/300] [D loss: 0.752278] [G loss: 0.513366] time: 1:02:44.172077\n",
      "0.8758585\n",
      "[Epoch 42/50] [Batch 18/300] [D loss: 0.752271] [G loss: 0.473468] time: 1:02:44.467005\n",
      "0.8869365\n",
      "[Epoch 42/50] [Batch 19/300] [D loss: 0.752269] [G loss: 0.481710] time: 1:02:44.750387\n",
      "0.9159995\n",
      "[Epoch 42/50] [Batch 20/300] [D loss: 0.752275] [G loss: 0.477816] time: 1:02:45.026147\n",
      "0.9169202\n",
      "[Epoch 42/50] [Batch 21/300] [D loss: 0.752263] [G loss: 0.481351] time: 1:02:45.324056\n",
      "0.93167114\n",
      "[Epoch 42/50] [Batch 22/300] [D loss: 0.752266] [G loss: 0.470617] time: 1:02:45.623430\n",
      "0.94724184\n",
      "[Epoch 42/50] [Batch 23/300] [D loss: 0.752274] [G loss: 0.477254] time: 1:02:45.921563\n",
      "0.9712681\n",
      "[Epoch 42/50] [Batch 24/300] [D loss: 0.752266] [G loss: 0.476821] time: 1:02:46.204573\n",
      "0.8887384\n",
      "[Epoch 42/50] [Batch 25/300] [D loss: 0.752264] [G loss: 0.485238] time: 1:02:46.506406\n",
      "0.8950321\n",
      "[Epoch 42/50] [Batch 26/300] [D loss: 0.752276] [G loss: 0.483814] time: 1:02:46.804132\n",
      "0.8862321\n",
      "[Epoch 42/50] [Batch 27/300] [D loss: 0.752266] [G loss: 0.485648] time: 1:02:47.091472\n",
      "0.93559074\n",
      "[Epoch 42/50] [Batch 28/300] [D loss: 0.752276] [G loss: 0.494952] time: 1:02:47.393293\n",
      "0.8824644\n",
      "[Epoch 42/50] [Batch 29/300] [D loss: 0.752281] [G loss: 0.489213] time: 1:02:47.695059\n",
      "0.92008084\n",
      "[Epoch 42/50] [Batch 30/300] [D loss: 0.752267] [G loss: 0.495730] time: 1:02:47.994161\n",
      "0.90903187\n",
      "[Epoch 42/50] [Batch 31/300] [D loss: 0.752262] [G loss: 0.476222] time: 1:02:48.286453\n",
      "0.9253102\n",
      "[Epoch 42/50] [Batch 32/300] [D loss: 0.752278] [G loss: 0.469520] time: 1:02:48.600942\n",
      "0.9316075\n",
      "[Epoch 42/50] [Batch 33/300] [D loss: 0.752265] [G loss: 0.465730] time: 1:02:48.878585\n",
      "0.8829541\n",
      "[Epoch 42/50] [Batch 34/300] [D loss: 0.752282] [G loss: 0.482951] time: 1:02:49.176164\n",
      "0.92809993\n",
      "[Epoch 42/50] [Batch 35/300] [D loss: 0.752264] [G loss: 0.468145] time: 1:02:49.446900\n",
      "0.906784\n",
      "[Epoch 42/50] [Batch 36/300] [D loss: 0.752269] [G loss: 0.490551] time: 1:02:49.743206\n",
      "0.9524386\n",
      "[Epoch 42/50] [Batch 37/300] [D loss: 0.752278] [G loss: 0.468976] time: 1:02:50.042105\n",
      "0.9090536\n",
      "[Epoch 42/50] [Batch 38/300] [D loss: 0.752258] [G loss: 0.488697] time: 1:02:50.327252\n",
      "0.88900185\n",
      "[Epoch 42/50] [Batch 39/300] [D loss: 0.752273] [G loss: 0.476418] time: 1:02:50.625916\n",
      "0.91637725\n",
      "[Epoch 42/50] [Batch 40/300] [D loss: 0.752276] [G loss: 0.495808] time: 1:02:50.918419\n",
      "0.91662216\n",
      "[Epoch 42/50] [Batch 42/300] [D loss: 0.752275] [G loss: 0.488511] time: 1:02:51.223336\n",
      "0.9179759\n",
      "[Epoch 42/50] [Batch 43/300] [D loss: 0.752299] [G loss: 0.485371] time: 1:02:51.519818\n",
      "0.93062544\n",
      "[Epoch 42/50] [Batch 44/300] [D loss: 0.752278] [G loss: 0.486363] time: 1:02:51.829360\n",
      "0.91286033\n",
      "[Epoch 42/50] [Batch 45/300] [D loss: 0.752276] [G loss: 0.475897] time: 1:02:52.134806\n",
      "0.9082985\n",
      "[Epoch 42/50] [Batch 46/300] [D loss: 0.752283] [G loss: 0.502048] time: 1:02:52.436591\n",
      "0.93339306\n",
      "[Epoch 42/50] [Batch 47/300] [D loss: 0.752270] [G loss: 0.496410] time: 1:02:52.728434\n",
      "0.8755085\n",
      "[Epoch 42/50] [Batch 48/300] [D loss: 0.752288] [G loss: 0.471244] time: 1:02:53.028852\n",
      "0.90686655\n",
      "[Epoch 42/50] [Batch 49/300] [D loss: 0.752274] [G loss: 0.473668] time: 1:02:53.321252\n",
      "0.9162445\n",
      "[Epoch 42/50] [Batch 50/300] [D loss: 0.752278] [G loss: 0.465655] time: 1:02:53.614712\n",
      "0.92657226\n",
      "[Epoch 42/50] [Batch 51/300] [D loss: 0.752274] [G loss: 0.466856] time: 1:02:53.911705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94209987\n",
      "[Epoch 42/50] [Batch 52/300] [D loss: 0.752266] [G loss: 0.477254] time: 1:02:54.199761\n",
      "0.9137485\n",
      "[Epoch 42/50] [Batch 53/300] [D loss: 0.752275] [G loss: 0.477197] time: 1:02:54.507791\n",
      "0.93491346\n",
      "[Epoch 42/50] [Batch 54/300] [D loss: 0.752261] [G loss: 0.464571] time: 1:02:54.809572\n",
      "0.9711132\n",
      "[Epoch 42/50] [Batch 55/300] [D loss: 0.752276] [G loss: 0.473154] time: 1:02:55.118114\n",
      "0.9424599\n",
      "[Epoch 42/50] [Batch 56/300] [D loss: 0.752268] [G loss: 0.481160] time: 1:02:55.406468\n",
      "0.91617584\n",
      "[Epoch 42/50] [Batch 57/300] [D loss: 0.752273] [G loss: 0.483806] time: 1:02:55.702357\n",
      "0.90558916\n",
      "[Epoch 42/50] [Batch 58/300] [D loss: 0.752272] [G loss: 0.470228] time: 1:02:56.005964\n",
      "0.8923397\n",
      "[Epoch 42/50] [Batch 59/300] [D loss: 0.752270] [G loss: 0.467683] time: 1:02:56.295934\n",
      "0.9022646\n",
      "[Epoch 42/50] [Batch 60/300] [D loss: 0.752277] [G loss: 0.494694] time: 1:02:56.583940\n",
      "0.8941818\n",
      "[Epoch 42/50] [Batch 61/300] [D loss: 0.752259] [G loss: 0.466915] time: 1:02:56.881587\n",
      "0.91237456\n",
      "[Epoch 42/50] [Batch 62/300] [D loss: 0.752280] [G loss: 0.472790] time: 1:02:57.183402\n",
      "0.9416048\n",
      "[Epoch 42/50] [Batch 63/300] [D loss: 0.752258] [G loss: 0.474271] time: 1:02:57.497258\n",
      "0.9168672\n",
      "[Epoch 42/50] [Batch 64/300] [D loss: 0.752259] [G loss: 0.492748] time: 1:02:57.794635\n",
      "0.93816113\n",
      "[Epoch 42/50] [Batch 65/300] [D loss: 0.752277] [G loss: 0.466065] time: 1:02:58.099955\n",
      "0.94268674\n",
      "[Epoch 42/50] [Batch 66/300] [D loss: 0.752264] [G loss: 0.478834] time: 1:02:58.403873\n",
      "0.9666392\n",
      "[Epoch 42/50] [Batch 67/300] [D loss: 0.752260] [G loss: 0.488261] time: 1:02:58.693153\n",
      "0.91385823\n",
      "[Epoch 42/50] [Batch 68/300] [D loss: 0.752267] [G loss: 0.475476] time: 1:02:58.994983\n",
      "0.91694564\n",
      "[Epoch 42/50] [Batch 69/300] [D loss: 0.752271] [G loss: 0.484039] time: 1:02:59.269679\n",
      "0.9212206\n",
      "[Epoch 42/50] [Batch 70/300] [D loss: 0.752270] [G loss: 0.494511] time: 1:02:59.566353\n",
      "0.931715\n",
      "[Epoch 42/50] [Batch 71/300] [D loss: 0.752268] [G loss: 0.480591] time: 1:02:59.850816\n",
      "0.8951797\n",
      "[Epoch 42/50] [Batch 72/300] [D loss: 0.752270] [G loss: 0.499169] time: 1:03:00.155977\n",
      "0.9179146\n",
      "[Epoch 42/50] [Batch 73/300] [D loss: 0.752271] [G loss: 0.499305] time: 1:03:00.454604\n",
      "0.93342143\n",
      "[Epoch 42/50] [Batch 74/300] [D loss: 0.752252] [G loss: 0.476672] time: 1:03:00.760995\n",
      "0.8974102\n",
      "[Epoch 42/50] [Batch 75/300] [D loss: 0.752264] [G loss: 0.490683] time: 1:03:01.073127\n",
      "0.8933651\n",
      "[Epoch 42/50] [Batch 76/300] [D loss: 0.752283] [G loss: 0.480420] time: 1:03:01.360944\n",
      "0.8812725\n",
      "[Epoch 42/50] [Batch 77/300] [D loss: 0.752262] [G loss: 0.480073] time: 1:03:01.655320\n",
      "0.8838125\n",
      "[Epoch 42/50] [Batch 78/300] [D loss: 0.752269] [G loss: 0.472812] time: 1:03:01.970858\n",
      "0.89956903\n",
      "[Epoch 42/50] [Batch 79/300] [D loss: 0.752263] [G loss: 0.478288] time: 1:03:02.275345\n",
      "0.9383126\n",
      "[Epoch 42/50] [Batch 80/300] [D loss: 0.752273] [G loss: 0.468621] time: 1:03:02.557315\n",
      "0.89320606\n",
      "[Epoch 42/50] [Batch 81/300] [D loss: 0.752266] [G loss: 0.479818] time: 1:03:02.851415\n",
      "0.91700083\n",
      "[Epoch 42/50] [Batch 82/300] [D loss: 0.752279] [G loss: 0.468359] time: 1:03:03.134262\n",
      "0.91780907\n",
      "[Epoch 42/50] [Batch 83/300] [D loss: 0.752265] [G loss: 0.486448] time: 1:03:03.431954\n",
      "0.9201091\n",
      "[Epoch 42/50] [Batch 84/300] [D loss: 0.752275] [G loss: 0.466895] time: 1:03:03.718964\n",
      "0.9077166\n",
      "[Epoch 42/50] [Batch 85/300] [D loss: 0.752271] [G loss: 0.467499] time: 1:03:04.003536\n",
      "0.927093\n",
      "[Epoch 42/50] [Batch 86/300] [D loss: 0.752279] [G loss: 0.475984] time: 1:03:04.312356\n",
      "0.93297225\n",
      "[Epoch 42/50] [Batch 87/300] [D loss: 0.752276] [G loss: 0.473269] time: 1:03:04.614101\n",
      "0.9152848\n",
      "[Epoch 42/50] [Batch 88/300] [D loss: 0.752269] [G loss: 0.470149] time: 1:03:04.917121\n",
      "0.9417854\n",
      "[Epoch 42/50] [Batch 89/300] [D loss: 0.752282] [G loss: 0.466475] time: 1:03:05.200441\n",
      "0.9122495\n",
      "[Epoch 42/50] [Batch 90/300] [D loss: 0.752262] [G loss: 0.476942] time: 1:03:05.495493\n",
      "0.8899958\n",
      "[Epoch 42/50] [Batch 91/300] [D loss: 0.752276] [G loss: 0.474326] time: 1:03:05.794883\n",
      "0.9074369\n",
      "[Epoch 42/50] [Batch 92/300] [D loss: 0.752277] [G loss: 0.494107] time: 1:03:06.092382\n",
      "0.89606524\n",
      "[Epoch 42/50] [Batch 93/300] [D loss: 0.752270] [G loss: 0.471994] time: 1:03:06.407583\n",
      "0.9087472\n",
      "[Epoch 42/50] [Batch 94/300] [D loss: 0.752287] [G loss: 0.473893] time: 1:03:06.707080\n",
      "0.9316419\n",
      "[Epoch 42/50] [Batch 95/300] [D loss: 0.752270] [G loss: 0.469728] time: 1:03:07.012185\n",
      "0.9447637\n",
      "[Epoch 42/50] [Batch 96/300] [D loss: 0.752271] [G loss: 0.480864] time: 1:03:07.308889\n",
      "0.95658857\n",
      "[Epoch 42/50] [Batch 97/300] [D loss: 0.752283] [G loss: 0.469834] time: 1:03:07.603493\n",
      "0.9201481\n",
      "[Epoch 42/50] [Batch 98/300] [D loss: 0.752271] [G loss: 0.481873] time: 1:03:07.890999\n",
      "0.935335\n",
      "[Epoch 42/50] [Batch 99/300] [D loss: 0.752268] [G loss: 0.471226] time: 1:03:08.203176\n",
      "0.93768\n",
      "[Epoch 42/50] [Batch 100/300] [D loss: 0.752270] [G loss: 0.478347] time: 1:03:08.474393\n",
      "0.9755833\n",
      "[Epoch 42/50] [Batch 101/300] [D loss: 0.752277] [G loss: 0.471597] time: 1:03:08.779610\n",
      "0.9173331\n",
      "[Epoch 42/50] [Batch 102/300] [D loss: 0.752263] [G loss: 0.475643] time: 1:03:09.066281\n",
      "0.9331792\n",
      "[Epoch 42/50] [Batch 103/300] [D loss: 0.752269] [G loss: 0.500607] time: 1:03:09.380858\n",
      "0.91586727\n",
      "[Epoch 42/50] [Batch 104/300] [D loss: 0.752262] [G loss: 0.469865] time: 1:03:09.677068\n",
      "0.9139273\n",
      "[Epoch 42/50] [Batch 105/300] [D loss: 0.752264] [G loss: 0.472659] time: 1:03:09.982840\n",
      "0.8850255\n",
      "[Epoch 42/50] [Batch 106/300] [D loss: 0.752275] [G loss: 0.474324] time: 1:03:10.288896\n",
      "0.8909111\n",
      "[Epoch 42/50] [Batch 107/300] [D loss: 0.752275] [G loss: 0.469771] time: 1:03:10.573456\n",
      "0.9363651\n",
      "[Epoch 42/50] [Batch 108/300] [D loss: 0.752263] [G loss: 0.474496] time: 1:03:10.868387\n",
      "0.89900583\n",
      "[Epoch 42/50] [Batch 109/300] [D loss: 0.752270] [G loss: 0.477845] time: 1:03:11.176506\n",
      "0.93108684\n",
      "[Epoch 42/50] [Batch 110/300] [D loss: 0.752286] [G loss: 0.472846] time: 1:03:11.467998\n",
      "0.9390976\n",
      "[Epoch 42/50] [Batch 111/300] [D loss: 0.752282] [G loss: 0.475910] time: 1:03:11.754163\n",
      "0.90880936\n",
      "[Epoch 42/50] [Batch 112/300] [D loss: 0.752274] [G loss: 0.474912] time: 1:03:12.049345\n",
      "0.9372039\n",
      "[Epoch 42/50] [Batch 113/300] [D loss: 0.752263] [G loss: 0.468680] time: 1:03:12.358997\n",
      "0.8836902\n",
      "[Epoch 42/50] [Batch 114/300] [D loss: 0.752268] [G loss: 0.474092] time: 1:03:12.654576\n",
      "0.92018074\n",
      "[Epoch 42/50] [Batch 115/300] [D loss: 0.752261] [G loss: 0.475810] time: 1:03:12.946139\n",
      "0.8840702\n",
      "[Epoch 42/50] [Batch 116/300] [D loss: 0.752278] [G loss: 0.470991] time: 1:03:13.244231\n",
      "0.95339316\n",
      "[Epoch 42/50] [Batch 117/300] [D loss: 0.752276] [G loss: 0.487236] time: 1:03:13.534981\n",
      "0.93131495\n",
      "[Epoch 42/50] [Batch 118/300] [D loss: 0.752273] [G loss: 0.473459] time: 1:03:13.836956\n",
      "0.9057804\n",
      "[Epoch 42/50] [Batch 119/300] [D loss: 0.752257] [G loss: 0.490057] time: 1:03:14.137097\n",
      "0.88208956\n",
      "[Epoch 42/50] [Batch 120/300] [D loss: 0.752269] [G loss: 0.488322] time: 1:03:14.422247\n",
      "0.90562314\n",
      "[Epoch 42/50] [Batch 121/300] [D loss: 0.752269] [G loss: 0.480156] time: 1:03:14.717360\n",
      "0.9231012\n",
      "[Epoch 42/50] [Batch 122/300] [D loss: 0.752273] [G loss: 0.475592] time: 1:03:15.017251\n",
      "0.92986614\n",
      "[Epoch 42/50] [Batch 123/300] [D loss: 0.752264] [G loss: 0.479368] time: 1:03:15.322806\n",
      "0.9350645\n",
      "[Epoch 42/50] [Batch 124/300] [D loss: 0.752276] [G loss: 0.474056] time: 1:03:15.626134\n",
      "0.94625777\n",
      "[Epoch 42/50] [Batch 125/300] [D loss: 0.752289] [G loss: 0.477223] time: 1:03:15.933707\n",
      "0.8545229\n",
      "[Epoch 42/50] [Batch 126/300] [D loss: 0.752276] [G loss: 0.485640] time: 1:03:16.233035\n",
      "0.93518734\n",
      "[Epoch 42/50] [Batch 127/300] [D loss: 0.752272] [G loss: 0.481883] time: 1:03:16.536623\n",
      "0.91398144\n",
      "[Epoch 42/50] [Batch 128/300] [D loss: 0.752266] [G loss: 0.477681] time: 1:03:16.843389\n",
      "0.89072084\n",
      "[Epoch 42/50] [Batch 129/300] [D loss: 0.752259] [G loss: 0.497487] time: 1:03:17.143701\n",
      "0.9573617\n",
      "[Epoch 42/50] [Batch 130/300] [D loss: 0.752279] [G loss: 0.476788] time: 1:03:17.463583\n",
      "0.9458096\n",
      "[Epoch 42/50] [Batch 131/300] [D loss: 0.752268] [G loss: 0.511297] time: 1:03:17.762397\n",
      "0.92512465\n",
      "[Epoch 42/50] [Batch 132/300] [D loss: 0.752266] [G loss: 0.468524] time: 1:03:18.070528\n",
      "0.908237\n",
      "[Epoch 42/50] [Batch 133/300] [D loss: 0.752278] [G loss: 0.473508] time: 1:03:18.381085\n",
      "0.9705016\n",
      "[Epoch 42/50] [Batch 134/300] [D loss: 0.752261] [G loss: 0.478943] time: 1:03:18.694423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89525247\n",
      "[Epoch 42/50] [Batch 135/300] [D loss: 0.752262] [G loss: 0.470535] time: 1:03:18.996023\n",
      "0.9832659\n",
      "[Epoch 42/50] [Batch 136/300] [D loss: 0.752282] [G loss: 0.480552] time: 1:03:19.304094\n",
      "0.93610305\n",
      "[Epoch 42/50] [Batch 137/300] [D loss: 0.752277] [G loss: 0.472717] time: 1:03:19.602077\n",
      "0.93748903\n",
      "[Epoch 42/50] [Batch 138/300] [D loss: 0.752275] [G loss: 0.481963] time: 1:03:19.902316\n",
      "0.91183925\n",
      "[Epoch 42/50] [Batch 139/300] [D loss: 0.752263] [G loss: 0.471648] time: 1:03:20.196652\n",
      "0.9080456\n",
      "[Epoch 42/50] [Batch 140/300] [D loss: 0.752271] [G loss: 0.479558] time: 1:03:20.512203\n",
      "0.91387206\n",
      "[Epoch 42/50] [Batch 141/300] [D loss: 0.752283] [G loss: 0.484475] time: 1:03:20.791317\n",
      "0.9222436\n",
      "[Epoch 42/50] [Batch 142/300] [D loss: 0.752262] [G loss: 0.485575] time: 1:03:21.071633\n",
      "0.9086246\n",
      "[Epoch 42/50] [Batch 143/300] [D loss: 0.752262] [G loss: 0.475098] time: 1:03:21.361268\n",
      "0.8919537\n",
      "[Epoch 42/50] [Batch 144/300] [D loss: 0.752261] [G loss: 0.511588] time: 1:03:21.670289\n",
      "0.8843587\n",
      "[Epoch 42/50] [Batch 145/300] [D loss: 0.752261] [G loss: 0.469092] time: 1:03:21.980238\n",
      "0.96452445\n",
      "[Epoch 42/50] [Batch 146/300] [D loss: 0.752277] [G loss: 0.489614] time: 1:03:22.262504\n",
      "0.9533878\n",
      "[Epoch 42/50] [Batch 147/300] [D loss: 0.752266] [G loss: 0.478377] time: 1:03:22.562740\n",
      "0.9385293\n",
      "[Epoch 42/50] [Batch 148/300] [D loss: 0.752262] [G loss: 0.480359] time: 1:03:22.846550\n",
      "0.9307253\n",
      "[Epoch 42/50] [Batch 149/300] [D loss: 0.752284] [G loss: 0.485040] time: 1:03:23.149439\n",
      "0.975401\n",
      "[Epoch 42/50] [Batch 150/300] [D loss: 0.752272] [G loss: 0.475938] time: 1:03:23.444883\n",
      "0.89547664\n",
      "[Epoch 42/50] [Batch 151/300] [D loss: 0.752290] [G loss: 0.478426] time: 1:03:23.751859\n",
      "0.9258092\n",
      "[Epoch 42/50] [Batch 152/300] [D loss: 0.752272] [G loss: 0.471533] time: 1:03:24.055352\n",
      "0.87024254\n",
      "[Epoch 42/50] [Batch 153/300] [D loss: 0.752279] [G loss: 0.484588] time: 1:03:24.369966\n",
      "0.9549718\n",
      "[Epoch 42/50] [Batch 154/300] [D loss: 0.752256] [G loss: 0.479071] time: 1:03:24.691354\n",
      "0.95486474\n",
      "[Epoch 42/50] [Batch 155/300] [D loss: 0.752267] [G loss: 0.473022] time: 1:03:24.965274\n",
      "0.93129945\n",
      "[Epoch 42/50] [Batch 156/300] [D loss: 0.752255] [G loss: 0.480277] time: 1:03:25.253003\n",
      "0.9283511\n",
      "[Epoch 42/50] [Batch 157/300] [D loss: 0.752283] [G loss: 0.468992] time: 1:03:25.543685\n",
      "0.88054657\n",
      "[Epoch 42/50] [Batch 158/300] [D loss: 0.752264] [G loss: 0.477129] time: 1:03:25.850158\n",
      "0.9450652\n",
      "[Epoch 42/50] [Batch 159/300] [D loss: 0.752285] [G loss: 0.475639] time: 1:03:26.145819\n",
      "0.9563334\n",
      "[Epoch 42/50] [Batch 160/300] [D loss: 0.752269] [G loss: 0.479491] time: 1:03:26.435104\n",
      "0.92014855\n",
      "[Epoch 42/50] [Batch 161/300] [D loss: 0.752260] [G loss: 0.503788] time: 1:03:26.730296\n",
      "0.9137327\n",
      "[Epoch 42/50] [Batch 162/300] [D loss: 0.752279] [G loss: 0.482921] time: 1:03:27.006887\n",
      "0.92213106\n",
      "[Epoch 42/50] [Batch 163/300] [D loss: 0.752276] [G loss: 0.470324] time: 1:03:27.305496\n",
      "0.95313734\n",
      "[Epoch 42/50] [Batch 164/300] [D loss: 0.752256] [G loss: 0.470041] time: 1:03:27.596910\n",
      "0.9320483\n",
      "[Epoch 42/50] [Batch 165/300] [D loss: 0.752255] [G loss: 0.487631] time: 1:03:27.890011\n",
      "0.9310139\n",
      "[Epoch 42/50] [Batch 166/300] [D loss: 0.752269] [G loss: 0.468824] time: 1:03:28.204283\n",
      "0.97437793\n",
      "[Epoch 42/50] [Batch 167/300] [D loss: 0.752271] [G loss: 0.467317] time: 1:03:28.510202\n",
      "0.9819214\n",
      "[Epoch 42/50] [Batch 168/300] [D loss: 0.752265] [G loss: 0.481056] time: 1:03:28.794999\n",
      "0.93083876\n",
      "[Epoch 42/50] [Batch 169/300] [D loss: 0.752269] [G loss: 0.471770] time: 1:03:29.090597\n",
      "0.9366967\n",
      "[Epoch 42/50] [Batch 170/300] [D loss: 0.752260] [G loss: 0.477949] time: 1:03:29.392254\n",
      "0.8719411\n",
      "[Epoch 42/50] [Batch 171/300] [D loss: 0.752270] [G loss: 0.487401] time: 1:03:29.671220\n",
      "0.9082677\n",
      "[Epoch 42/50] [Batch 172/300] [D loss: 0.752278] [G loss: 0.481438] time: 1:03:29.973339\n",
      "0.9334255\n",
      "[Epoch 42/50] [Batch 173/300] [D loss: 0.752276] [G loss: 0.479344] time: 1:03:30.276120\n",
      "0.9293005\n",
      "[Epoch 42/50] [Batch 174/300] [D loss: 0.752281] [G loss: 0.479408] time: 1:03:30.571249\n",
      "0.91073626\n",
      "[Epoch 42/50] [Batch 175/300] [D loss: 0.752255] [G loss: 0.473185] time: 1:03:30.858821\n",
      "0.94700843\n",
      "[Epoch 42/50] [Batch 176/300] [D loss: 0.752262] [G loss: 0.480852] time: 1:03:31.152194\n",
      "0.8707493\n",
      "[Epoch 42/50] [Batch 177/300] [D loss: 0.752258] [G loss: 0.463497] time: 1:03:31.450038\n",
      "0.9446697\n",
      "[Epoch 42/50] [Batch 178/300] [D loss: 0.752274] [G loss: 0.480605] time: 1:03:31.771130\n",
      "0.899216\n",
      "[Epoch 42/50] [Batch 179/300] [D loss: 0.752276] [G loss: 0.487201] time: 1:03:32.069292\n",
      "0.9115699\n",
      "[Epoch 42/50] [Batch 180/300] [D loss: 0.752255] [G loss: 0.485991] time: 1:03:32.366066\n",
      "0.9333584\n",
      "[Epoch 42/50] [Batch 181/300] [D loss: 0.752269] [G loss: 0.471741] time: 1:03:32.663681\n",
      "0.95302624\n",
      "[Epoch 42/50] [Batch 182/300] [D loss: 0.752277] [G loss: 0.468032] time: 1:03:32.955028\n",
      "0.9751446\n",
      "[Epoch 42/50] [Batch 183/300] [D loss: 0.752271] [G loss: 0.490493] time: 1:03:33.254011\n",
      "0.9463152\n",
      "[Epoch 42/50] [Batch 184/300] [D loss: 0.752267] [G loss: 0.468788] time: 1:03:33.520519\n",
      "0.8979985\n",
      "[Epoch 42/50] [Batch 185/300] [D loss: 0.752274] [G loss: 0.470964] time: 1:03:33.828415\n",
      "0.9122296\n",
      "[Epoch 42/50] [Batch 186/300] [D loss: 0.752267] [G loss: 0.482726] time: 1:03:34.098665\n",
      "0.90706795\n",
      "[Epoch 42/50] [Batch 187/300] [D loss: 0.752265] [G loss: 0.473373] time: 1:03:34.384234\n",
      "0.9064493\n",
      "[Epoch 42/50] [Batch 188/300] [D loss: 0.752256] [G loss: 0.497433] time: 1:03:34.689131\n",
      "0.90546685\n",
      "[Epoch 42/50] [Batch 189/300] [D loss: 0.752270] [G loss: 0.481459] time: 1:03:34.976338\n",
      "0.92340493\n",
      "[Epoch 42/50] [Batch 190/300] [D loss: 0.752271] [G loss: 0.489376] time: 1:03:35.269318\n",
      "0.9317494\n",
      "[Epoch 42/50] [Batch 191/300] [D loss: 0.752262] [G loss: 0.504636] time: 1:03:35.547830\n",
      "0.93354195\n",
      "[Epoch 42/50] [Batch 192/300] [D loss: 0.752271] [G loss: 0.474065] time: 1:03:35.847472\n",
      "0.933268\n",
      "[Epoch 42/50] [Batch 193/300] [D loss: 0.752257] [G loss: 0.481431] time: 1:03:36.158458\n",
      "0.91579175\n",
      "[Epoch 42/50] [Batch 194/300] [D loss: 0.752264] [G loss: 0.477418] time: 1:03:36.457487\n",
      "0.9358241\n",
      "[Epoch 42/50] [Batch 195/300] [D loss: 0.752264] [G loss: 0.466241] time: 1:03:36.720342\n",
      "0.9532284\n",
      "[Epoch 42/50] [Batch 196/300] [D loss: 0.752252] [G loss: 0.467263] time: 1:03:37.017264\n",
      "0.91807383\n",
      "[Epoch 42/50] [Batch 197/300] [D loss: 0.752254] [G loss: 0.469262] time: 1:03:37.308116\n",
      "0.8888101\n",
      "[Epoch 42/50] [Batch 198/300] [D loss: 0.752263] [G loss: 0.467273] time: 1:03:37.630050\n",
      "0.9167959\n",
      "[Epoch 42/50] [Batch 199/300] [D loss: 0.752261] [G loss: 0.476447] time: 1:03:37.932735\n",
      "0.9089778\n",
      "[Epoch 42/50] [Batch 200/300] [D loss: 0.752269] [G loss: 0.474634] time: 1:03:38.230132\n",
      "0.9537136\n",
      "[Epoch 42/50] [Batch 201/300] [D loss: 0.752269] [G loss: 0.481996] time: 1:03:38.524436\n",
      "0.9057141\n",
      "[Epoch 42/50] [Batch 202/300] [D loss: 0.752262] [G loss: 0.473911] time: 1:03:38.833613\n",
      "0.90922433\n",
      "[Epoch 42/50] [Batch 203/300] [D loss: 0.752270] [G loss: 0.478566] time: 1:03:39.136443\n",
      "0.92468214\n",
      "[Epoch 42/50] [Batch 204/300] [D loss: 0.752259] [G loss: 0.467855] time: 1:03:39.437114\n",
      "0.9616905\n",
      "[Epoch 42/50] [Batch 205/300] [D loss: 0.752264] [G loss: 0.494600] time: 1:03:39.755632\n",
      "0.92728597\n",
      "[Epoch 42/50] [Batch 206/300] [D loss: 0.752263] [G loss: 0.489206] time: 1:03:40.041759\n",
      "0.93619156\n",
      "[Epoch 42/50] [Batch 207/300] [D loss: 0.752259] [G loss: 0.473044] time: 1:03:40.332591\n",
      "0.9247473\n",
      "[Epoch 42/50] [Batch 208/300] [D loss: 0.752273] [G loss: 0.469815] time: 1:03:40.627527\n",
      "0.9469805\n",
      "[Epoch 42/50] [Batch 209/300] [D loss: 0.752267] [G loss: 0.481035] time: 1:03:40.937817\n",
      "0.87021\n",
      "[Epoch 42/50] [Batch 210/300] [D loss: 0.752260] [G loss: 0.489718] time: 1:03:41.260868\n",
      "0.8933825\n",
      "[Epoch 42/50] [Batch 211/300] [D loss: 0.752249] [G loss: 0.493073] time: 1:03:41.552500\n",
      "0.9336686\n",
      "[Epoch 42/50] [Batch 212/300] [D loss: 0.752272] [G loss: 0.481977] time: 1:03:41.845917\n",
      "0.9385298\n",
      "[Epoch 42/50] [Batch 213/300] [D loss: 0.752275] [G loss: 0.472758] time: 1:03:42.152526\n",
      "0.94539934\n",
      "[Epoch 42/50] [Batch 214/300] [D loss: 0.752272] [G loss: 0.481087] time: 1:03:42.451801\n",
      "0.87190914\n",
      "[Epoch 42/50] [Batch 215/300] [D loss: 0.752260] [G loss: 0.466681] time: 1:03:42.749953\n",
      "0.91708565\n",
      "[Epoch 42/50] [Batch 216/300] [D loss: 0.752264] [G loss: 0.483004] time: 1:03:43.065975\n",
      "0.88199025\n",
      "[Epoch 42/50] [Batch 217/300] [D loss: 0.752274] [G loss: 0.476666] time: 1:03:43.350070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9021918\n",
      "[Epoch 42/50] [Batch 218/300] [D loss: 0.752266] [G loss: 0.472140] time: 1:03:43.644380\n",
      "0.93320626\n",
      "[Epoch 42/50] [Batch 219/300] [D loss: 0.752277] [G loss: 0.477341] time: 1:03:43.935183\n",
      "0.8899532\n",
      "[Epoch 42/50] [Batch 220/300] [D loss: 0.752262] [G loss: 0.486227] time: 1:03:44.236476\n",
      "0.91703343\n",
      "[Epoch 42/50] [Batch 221/300] [D loss: 0.752262] [G loss: 0.485301] time: 1:03:44.539145\n",
      "0.9258024\n",
      "[Epoch 42/50] [Batch 222/300] [D loss: 0.752251] [G loss: 0.480907] time: 1:03:44.835993\n",
      "0.9120378\n",
      "[Epoch 42/50] [Batch 223/300] [D loss: 0.752264] [G loss: 0.478232] time: 1:03:45.151007\n",
      "0.9573315\n",
      "[Epoch 42/50] [Batch 224/300] [D loss: 0.752259] [G loss: 0.476153] time: 1:03:45.465049\n",
      "0.9069865\n",
      "[Epoch 42/50] [Batch 225/300] [D loss: 0.752261] [G loss: 0.467977] time: 1:03:45.747262\n",
      "0.87378246\n",
      "[Epoch 42/50] [Batch 226/300] [D loss: 0.752263] [G loss: 0.467092] time: 1:03:46.048312\n",
      "0.90634197\n",
      "[Epoch 42/50] [Batch 227/300] [D loss: 0.752265] [G loss: 0.471737] time: 1:03:46.357880\n",
      "0.9297429\n",
      "[Epoch 42/50] [Batch 228/300] [D loss: 0.752272] [G loss: 0.479207] time: 1:03:46.653866\n",
      "0.95507115\n",
      "[Epoch 42/50] [Batch 229/300] [D loss: 0.752256] [G loss: 0.484078] time: 1:03:46.951573\n",
      "0.90585566\n",
      "[Epoch 42/50] [Batch 230/300] [D loss: 0.752260] [G loss: 0.480113] time: 1:03:47.239060\n",
      "0.92684317\n",
      "[Epoch 42/50] [Batch 231/300] [D loss: 0.752267] [G loss: 0.467276] time: 1:03:47.558558\n",
      "0.92504996\n",
      "[Epoch 42/50] [Batch 232/300] [D loss: 0.752268] [G loss: 0.486423] time: 1:03:47.864001\n",
      "0.92413634\n",
      "[Epoch 42/50] [Batch 233/300] [D loss: 0.752253] [G loss: 0.498544] time: 1:03:48.141723\n",
      "0.95053476\n",
      "[Epoch 42/50] [Batch 234/300] [D loss: 0.752268] [G loss: 0.468258] time: 1:03:48.434984\n",
      "0.95034313\n",
      "[Epoch 42/50] [Batch 235/300] [D loss: 0.752263] [G loss: 0.476066] time: 1:03:48.744230\n",
      "0.9428907\n",
      "[Epoch 42/50] [Batch 236/300] [D loss: 0.752276] [G loss: 0.479113] time: 1:03:49.025257\n",
      "0.9690464\n",
      "[Epoch 42/50] [Batch 237/300] [D loss: 0.752258] [G loss: 0.466405] time: 1:03:49.315782\n",
      "0.97586966\n",
      "[Epoch 42/50] [Batch 238/300] [D loss: 0.752260] [G loss: 0.490371] time: 1:03:49.617563\n",
      "0.9537017\n",
      "[Epoch 42/50] [Batch 239/300] [D loss: 0.752268] [G loss: 0.475285] time: 1:03:49.917193\n",
      "0.8888338\n",
      "[Epoch 42/50] [Batch 240/300] [D loss: 0.752270] [G loss: 0.474293] time: 1:03:50.236445\n",
      "0.9572343\n",
      "[Epoch 42/50] [Batch 241/300] [D loss: 0.752280] [G loss: 0.485539] time: 1:03:50.536906\n",
      "0.9412196\n",
      "[Epoch 42/50] [Batch 242/300] [D loss: 0.752281] [G loss: 0.468621] time: 1:03:50.851356\n",
      "0.9538867\n",
      "[Epoch 42/50] [Batch 243/300] [D loss: 0.752284] [G loss: 0.485716] time: 1:03:51.156705\n",
      "0.91472703\n",
      "[Epoch 42/50] [Batch 244/300] [D loss: 0.752256] [G loss: 0.467265] time: 1:03:51.457105\n",
      "0.93014914\n",
      "[Epoch 42/50] [Batch 245/300] [D loss: 0.752272] [G loss: 0.471134] time: 1:03:51.753740\n",
      "0.91295\n",
      "[Epoch 42/50] [Batch 246/300] [D loss: 0.752271] [G loss: 0.474442] time: 1:03:52.142403\n",
      "0.89969915\n",
      "[Epoch 42/50] [Batch 247/300] [D loss: 0.752266] [G loss: 0.477147] time: 1:03:52.420218\n",
      "0.92376703\n",
      "[Epoch 42/50] [Batch 248/300] [D loss: 0.752273] [G loss: 0.473917] time: 1:03:52.700465\n",
      "0.93317866\n",
      "[Epoch 42/50] [Batch 249/300] [D loss: 0.752272] [G loss: 0.480062] time: 1:03:53.000620\n",
      "0.9318096\n",
      "[Epoch 42/50] [Batch 250/300] [D loss: 0.752278] [G loss: 0.480662] time: 1:03:53.308754\n",
      "0.95245916\n",
      "[Epoch 42/50] [Batch 251/300] [D loss: 0.752272] [G loss: 0.483928] time: 1:03:53.601389\n",
      "0.9604804\n",
      "[Epoch 42/50] [Batch 252/300] [D loss: 0.752261] [G loss: 0.474224] time: 1:03:53.899623\n",
      "0.9668078\n",
      "[Epoch 42/50] [Batch 253/300] [D loss: 0.752268] [G loss: 0.468788] time: 1:03:54.189966\n",
      "0.90226173\n",
      "[Epoch 42/50] [Batch 254/300] [D loss: 0.752267] [G loss: 0.475559] time: 1:03:54.479822\n",
      "0.9512594\n",
      "[Epoch 42/50] [Batch 255/300] [D loss: 0.752263] [G loss: 0.475307] time: 1:03:54.781864\n",
      "0.94485927\n",
      "[Epoch 42/50] [Batch 256/300] [D loss: 0.752263] [G loss: 0.476912] time: 1:03:55.084587\n",
      "0.91775155\n",
      "[Epoch 42/50] [Batch 257/300] [D loss: 0.752266] [G loss: 0.479429] time: 1:03:55.383457\n",
      "0.9069185\n",
      "[Epoch 42/50] [Batch 258/300] [D loss: 0.752265] [G loss: 0.489709] time: 1:03:55.693332\n",
      "0.91962576\n",
      "[Epoch 42/50] [Batch 259/300] [D loss: 0.752275] [G loss: 0.476091] time: 1:03:55.989599\n",
      "0.90837365\n",
      "[Epoch 42/50] [Batch 260/300] [D loss: 0.752269] [G loss: 0.472783] time: 1:03:56.279192\n",
      "0.95572335\n",
      "[Epoch 42/50] [Batch 261/300] [D loss: 0.752266] [G loss: 0.478470] time: 1:03:56.593261\n",
      "0.98263454\n",
      "[Epoch 42/50] [Batch 262/300] [D loss: 0.752261] [G loss: 0.473416] time: 1:03:56.863047\n",
      "0.97555834\n",
      "[Epoch 42/50] [Batch 263/300] [D loss: 0.752272] [G loss: 0.478571] time: 1:03:57.147526\n",
      "0.94370526\n",
      "[Epoch 42/50] [Batch 264/300] [D loss: 0.752251] [G loss: 0.487821] time: 1:03:57.439610\n",
      "0.9524749\n",
      "[Epoch 42/50] [Batch 265/300] [D loss: 0.752282] [G loss: 0.490852] time: 1:03:57.736854\n",
      "0.880698\n",
      "[Epoch 42/50] [Batch 266/300] [D loss: 0.752273] [G loss: 0.470646] time: 1:03:58.036859\n",
      "0.94719553\n",
      "[Epoch 42/50] [Batch 267/300] [D loss: 0.752258] [G loss: 0.526754] time: 1:03:58.329407\n",
      "0.9313027\n",
      "[Epoch 42/50] [Batch 268/300] [D loss: 0.752267] [G loss: 0.474790] time: 1:03:58.610198\n",
      "0.9549887\n",
      "[Epoch 42/50] [Batch 269/300] [D loss: 0.752267] [G loss: 0.473340] time: 1:03:58.902900\n",
      "0.9398081\n",
      "[Epoch 42/50] [Batch 270/300] [D loss: 0.752270] [G loss: 0.472364] time: 1:03:59.204665\n",
      "0.9129258\n",
      "[Epoch 42/50] [Batch 271/300] [D loss: 0.752263] [G loss: 0.481288] time: 1:03:59.509875\n",
      "0.8941143\n",
      "[Epoch 42/50] [Batch 272/300] [D loss: 0.752263] [G loss: 0.469800] time: 1:03:59.795051\n",
      "0.9243955\n",
      "[Epoch 42/50] [Batch 273/300] [D loss: 0.752272] [G loss: 0.474411] time: 1:04:00.070961\n",
      "0.9086183\n",
      "[Epoch 42/50] [Batch 274/300] [D loss: 0.752272] [G loss: 0.485462] time: 1:04:00.364110\n",
      "0.92497724\n",
      "[Epoch 42/50] [Batch 275/300] [D loss: 0.752270] [G loss: 0.478811] time: 1:04:00.660523\n",
      "0.92130595\n",
      "[Epoch 42/50] [Batch 276/300] [D loss: 0.752259] [G loss: 0.490811] time: 1:04:00.982042\n",
      "0.8986768\n",
      "[Epoch 42/50] [Batch 277/300] [D loss: 0.752272] [G loss: 0.482080] time: 1:04:01.301639\n",
      "0.903156\n",
      "[Epoch 42/50] [Batch 278/300] [D loss: 0.752265] [G loss: 0.468645] time: 1:04:01.591008\n",
      "0.95667267\n",
      "[Epoch 42/50] [Batch 279/300] [D loss: 0.752265] [G loss: 0.474065] time: 1:04:01.886553\n",
      "0.91426444\n",
      "[Epoch 42/50] [Batch 280/300] [D loss: 0.752262] [G loss: 0.466734] time: 1:04:02.187176\n",
      "0.89540416\n",
      "[Epoch 42/50] [Batch 281/300] [D loss: 0.752274] [G loss: 0.481933] time: 1:04:02.502876\n",
      "0.9715266\n",
      "[Epoch 42/50] [Batch 282/300] [D loss: 0.752271] [G loss: 0.476007] time: 1:04:02.807942\n",
      "0.9384792\n",
      "[Epoch 42/50] [Batch 283/300] [D loss: 0.752272] [G loss: 0.470873] time: 1:04:03.107921\n",
      "0.9481439\n",
      "[Epoch 42/50] [Batch 284/300] [D loss: 0.752266] [G loss: 0.476405] time: 1:04:03.406519\n",
      "0.94696015\n",
      "[Epoch 42/50] [Batch 285/300] [D loss: 0.752274] [G loss: 0.467403] time: 1:04:03.677166\n",
      "0.90281296\n",
      "[Epoch 42/50] [Batch 286/300] [D loss: 0.752263] [G loss: 0.492104] time: 1:04:03.996064\n",
      "0.8858462\n",
      "[Epoch 42/50] [Batch 287/300] [D loss: 0.752261] [G loss: 0.467083] time: 1:04:04.281049\n",
      "0.92289656\n",
      "[Epoch 42/50] [Batch 288/300] [D loss: 0.752273] [G loss: 0.469270] time: 1:04:04.576362\n",
      "0.9050786\n",
      "[Epoch 42/50] [Batch 289/300] [D loss: 0.752270] [G loss: 0.469247] time: 1:04:04.868012\n",
      "0.93017966\n",
      "[Epoch 42/50] [Batch 290/300] [D loss: 0.752267] [G loss: 0.488174] time: 1:04:05.166142\n",
      "0.8875945\n",
      "[Epoch 42/50] [Batch 291/300] [D loss: 0.752264] [G loss: 0.467519] time: 1:04:05.464218\n",
      "0.9043028\n",
      "[Epoch 42/50] [Batch 292/300] [D loss: 0.752261] [G loss: 0.472384] time: 1:04:05.765514\n",
      "0.9087434\n",
      "[Epoch 42/50] [Batch 293/300] [D loss: 0.752274] [G loss: 0.479324] time: 1:04:06.060115\n",
      "0.89515775\n",
      "[Epoch 42/50] [Batch 294/300] [D loss: 0.752277] [G loss: 0.467007] time: 1:04:06.367764\n",
      "0.9643969\n",
      "[Epoch 42/50] [Batch 295/300] [D loss: 0.752267] [G loss: 0.467835] time: 1:04:06.673675\n",
      "0.97624284\n",
      "[Epoch 42/50] [Batch 296/300] [D loss: 0.752280] [G loss: 0.471901] time: 1:04:06.967930\n",
      "0.875071\n",
      "[Epoch 42/50] [Batch 297/300] [D loss: 0.752281] [G loss: 0.480001] time: 1:04:07.253311\n",
      "0.9132724\n",
      "[Epoch 42/50] [Batch 298/300] [D loss: 0.752268] [G loss: 0.472577] time: 1:04:07.559299\n",
      "0.9161704\n",
      "[Epoch 42/50] [Batch 299/300] [D loss: 0.752264] [G loss: 0.486571] time: 1:04:07.836263\n",
      "0.8809208\n",
      "[Epoch 43/50] [Batch 0/300] [D loss: 0.752259] [G loss: 0.473460] time: 1:04:08.143390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8890023\n",
      "[Epoch 43/50] [Batch 1/300] [D loss: 0.752261] [G loss: 0.485670] time: 1:04:08.439744\n",
      "0.9376378\n",
      "[Epoch 43/50] [Batch 2/300] [D loss: 0.752264] [G loss: 0.490427] time: 1:04:08.735425\n",
      "0.95619935\n",
      "[Epoch 43/50] [Batch 3/300] [D loss: 0.752252] [G loss: 0.470294] time: 1:04:09.025267\n",
      "0.8914141\n",
      "[Epoch 43/50] [Batch 4/300] [D loss: 0.752265] [G loss: 0.495738] time: 1:04:09.303900\n",
      "0.95336133\n",
      "[Epoch 43/50] [Batch 5/300] [D loss: 0.752272] [G loss: 0.472327] time: 1:04:09.602402\n",
      "0.90965813\n",
      "[Epoch 43/50] [Batch 6/300] [D loss: 0.752251] [G loss: 0.479911] time: 1:04:09.916023\n",
      "0.9216504\n",
      "[Epoch 43/50] [Batch 7/300] [D loss: 0.752254] [G loss: 0.479082] time: 1:04:10.208618\n",
      "0.8942242\n",
      "[Epoch 43/50] [Batch 8/300] [D loss: 0.752272] [G loss: 0.472107] time: 1:04:10.509897\n",
      "0.9289103\n",
      "[Epoch 43/50] [Batch 9/300] [D loss: 0.752260] [G loss: 0.473720] time: 1:04:10.808141\n",
      "0.9307298\n",
      "[Epoch 43/50] [Batch 10/300] [D loss: 0.752268] [G loss: 0.469458] time: 1:04:11.096792\n",
      "0.9419568\n",
      "[Epoch 43/50] [Batch 11/300] [D loss: 0.752270] [G loss: 0.489884] time: 1:04:11.407514\n",
      "0.8853543\n",
      "[Epoch 43/50] [Batch 12/300] [D loss: 0.752263] [G loss: 0.489927] time: 1:04:11.716253\n",
      "0.9281848\n",
      "[Epoch 43/50] [Batch 13/300] [D loss: 0.752255] [G loss: 0.488580] time: 1:04:12.012874\n",
      "0.9170001\n",
      "[Epoch 43/50] [Batch 14/300] [D loss: 0.752260] [G loss: 0.470760] time: 1:04:12.304921\n",
      "0.9255307\n",
      "[Epoch 43/50] [Batch 15/300] [D loss: 0.752268] [G loss: 0.476731] time: 1:04:12.609278\n",
      "0.9469895\n",
      "[Epoch 43/50] [Batch 16/300] [D loss: 0.752288] [G loss: 0.484946] time: 1:04:12.907580\n",
      "0.95802253\n",
      "[Epoch 43/50] [Batch 17/300] [D loss: 0.752261] [G loss: 0.499183] time: 1:04:13.195755\n",
      "0.9532475\n",
      "[Epoch 43/50] [Batch 18/300] [D loss: 0.752259] [G loss: 0.484872] time: 1:04:13.492584\n",
      "0.956351\n",
      "[Epoch 43/50] [Batch 19/300] [D loss: 0.752268] [G loss: 0.482520] time: 1:04:13.799632\n",
      "0.95688564\n",
      "[Epoch 43/50] [Batch 20/300] [D loss: 0.752276] [G loss: 0.479148] time: 1:04:14.086890\n",
      "0.91438407\n",
      "[Epoch 43/50] [Batch 21/300] [D loss: 0.752266] [G loss: 0.477934] time: 1:04:14.374606\n",
      "0.91187876\n",
      "[Epoch 43/50] [Batch 22/300] [D loss: 0.752262] [G loss: 0.472356] time: 1:04:14.661109\n",
      "0.9123227\n",
      "[Epoch 43/50] [Batch 23/300] [D loss: 0.752255] [G loss: 0.465332] time: 1:04:14.966570\n",
      "0.9379668\n",
      "[Epoch 43/50] [Batch 24/300] [D loss: 0.752253] [G loss: 0.469701] time: 1:04:15.258281\n",
      "0.8733422\n",
      "[Epoch 43/50] [Batch 25/300] [D loss: 0.752262] [G loss: 0.474874] time: 1:04:15.558975\n",
      "0.9471264\n",
      "[Epoch 43/50] [Batch 26/300] [D loss: 0.752259] [G loss: 0.487227] time: 1:04:15.853030\n",
      "0.91176414\n",
      "[Epoch 43/50] [Batch 27/300] [D loss: 0.752263] [G loss: 0.470916] time: 1:04:16.159169\n",
      "0.9329839\n",
      "[Epoch 43/50] [Batch 28/300] [D loss: 0.752250] [G loss: 0.471958] time: 1:04:16.438916\n",
      "0.8682688\n",
      "[Epoch 43/50] [Batch 29/300] [D loss: 0.752256] [G loss: 0.482317] time: 1:04:16.730156\n",
      "0.925132\n",
      "[Epoch 43/50] [Batch 30/300] [D loss: 0.752277] [G loss: 0.466334] time: 1:04:17.021774\n",
      "0.9295884\n",
      "[Epoch 43/50] [Batch 31/300] [D loss: 0.752254] [G loss: 0.471238] time: 1:04:17.338943\n",
      "0.9192365\n",
      "[Epoch 43/50] [Batch 32/300] [D loss: 0.752256] [G loss: 0.473842] time: 1:04:17.629932\n",
      "0.9449892\n",
      "[Epoch 43/50] [Batch 33/300] [D loss: 0.752247] [G loss: 0.486795] time: 1:04:17.932345\n",
      "0.8775308\n",
      "[Epoch 43/50] [Batch 34/300] [D loss: 0.752265] [G loss: 0.466178] time: 1:04:18.236944\n",
      "0.9260061\n",
      "[Epoch 43/50] [Batch 35/300] [D loss: 0.752271] [G loss: 0.489472] time: 1:04:18.528928\n",
      "0.8996205\n",
      "[Epoch 43/50] [Batch 36/300] [D loss: 0.752263] [G loss: 0.474201] time: 1:04:18.833930\n",
      "0.93139505\n",
      "[Epoch 43/50] [Batch 37/300] [D loss: 0.752265] [G loss: 0.476600] time: 1:04:19.116796\n",
      "0.9300134\n",
      "[Epoch 43/50] [Batch 38/300] [D loss: 0.752262] [G loss: 0.472332] time: 1:04:19.415938\n",
      "0.9053657\n",
      "[Epoch 43/50] [Batch 39/300] [D loss: 0.752251] [G loss: 0.476794] time: 1:04:19.719051\n",
      "0.95228034\n",
      "[Epoch 43/50] [Batch 40/300] [D loss: 0.752261] [G loss: 0.514286] time: 1:04:20.021578\n",
      "0.9160688\n",
      "[Epoch 43/50] [Batch 41/300] [D loss: 0.752272] [G loss: 0.465987] time: 1:04:20.336666\n",
      "0.91229993\n",
      "[Epoch 43/50] [Batch 43/300] [D loss: 0.752251] [G loss: 0.483330] time: 1:04:20.662814\n",
      "0.8914382\n",
      "[Epoch 43/50] [Batch 44/300] [D loss: 0.752262] [G loss: 0.497050] time: 1:04:20.959187\n",
      "0.9544181\n",
      "[Epoch 43/50] [Batch 45/300] [D loss: 0.752270] [G loss: 0.468736] time: 1:04:21.250019\n",
      "0.97630167\n",
      "[Epoch 43/50] [Batch 46/300] [D loss: 0.752264] [G loss: 0.468718] time: 1:04:21.538439\n",
      "0.9245865\n",
      "[Epoch 43/50] [Batch 47/300] [D loss: 0.752258] [G loss: 0.472187] time: 1:04:21.851853\n",
      "0.90839416\n",
      "[Epoch 43/50] [Batch 48/300] [D loss: 0.752255] [G loss: 0.468812] time: 1:04:22.152591\n",
      "0.9496939\n",
      "[Epoch 43/50] [Batch 49/300] [D loss: 0.752270] [G loss: 0.489015] time: 1:04:22.432995\n",
      "0.9102506\n",
      "[Epoch 43/50] [Batch 50/300] [D loss: 0.752261] [G loss: 0.483594] time: 1:04:22.737414\n",
      "0.88366914\n",
      "[Epoch 43/50] [Batch 51/300] [D loss: 0.752253] [G loss: 0.489404] time: 1:04:23.038710\n",
      "0.9094221\n",
      "[Epoch 43/50] [Batch 52/300] [D loss: 0.752259] [G loss: 0.500046] time: 1:04:23.345774\n",
      "0.8895948\n",
      "[Epoch 43/50] [Batch 53/300] [D loss: 0.752267] [G loss: 0.479839] time: 1:04:23.609547\n",
      "0.93273276\n",
      "[Epoch 43/50] [Batch 54/300] [D loss: 0.752262] [G loss: 0.470120] time: 1:04:23.916013\n",
      "0.929416\n",
      "[Epoch 43/50] [Batch 55/300] [D loss: 0.752246] [G loss: 0.471987] time: 1:04:24.198395\n",
      "0.90792555\n",
      "[Epoch 43/50] [Batch 56/300] [D loss: 0.752258] [G loss: 0.469006] time: 1:04:24.471494\n",
      "0.89552957\n",
      "[Epoch 43/50] [Batch 57/300] [D loss: 0.752261] [G loss: 0.469359] time: 1:04:24.775326\n",
      "0.9075062\n",
      "[Epoch 43/50] [Batch 58/300] [D loss: 0.752263] [G loss: 0.480131] time: 1:04:25.075767\n",
      "0.9454878\n",
      "[Epoch 43/50] [Batch 59/300] [D loss: 0.752261] [G loss: 0.462998] time: 1:04:25.379500\n",
      "0.9373271\n",
      "[Epoch 43/50] [Batch 60/300] [D loss: 0.752265] [G loss: 0.469543] time: 1:04:25.653975\n",
      "0.9059825\n",
      "[Epoch 43/50] [Batch 61/300] [D loss: 0.752262] [G loss: 0.466914] time: 1:04:25.975291\n",
      "0.9333966\n",
      "[Epoch 43/50] [Batch 62/300] [D loss: 0.752252] [G loss: 0.474608] time: 1:04:26.276793\n",
      "0.9136463\n",
      "[Epoch 43/50] [Batch 63/300] [D loss: 0.752273] [G loss: 0.468488] time: 1:04:26.574103\n",
      "0.98357224\n",
      "[Epoch 43/50] [Batch 64/300] [D loss: 0.752253] [G loss: 0.474321] time: 1:04:26.871228\n",
      "0.9711978\n",
      "[Epoch 43/50] [Batch 65/300] [D loss: 0.752264] [G loss: 0.467785] time: 1:04:27.180759\n",
      "0.945777\n",
      "[Epoch 43/50] [Batch 66/300] [D loss: 0.752282] [G loss: 0.469790] time: 1:04:27.478384\n",
      "0.93549824\n",
      "[Epoch 43/50] [Batch 67/300] [D loss: 0.752266] [G loss: 0.478390] time: 1:04:27.763882\n",
      "0.93162614\n",
      "[Epoch 43/50] [Batch 68/300] [D loss: 0.752258] [G loss: 0.474562] time: 1:04:28.079441\n",
      "0.90183574\n",
      "[Epoch 43/50] [Batch 69/300] [D loss: 0.752260] [G loss: 0.468470] time: 1:04:28.377372\n",
      "0.8960192\n",
      "[Epoch 43/50] [Batch 70/300] [D loss: 0.752256] [G loss: 0.473116] time: 1:04:28.674557\n",
      "0.88497\n",
      "[Epoch 43/50] [Batch 71/300] [D loss: 0.752251] [G loss: 0.497180] time: 1:04:28.982059\n",
      "0.88285184\n",
      "[Epoch 43/50] [Batch 72/300] [D loss: 0.752276] [G loss: 0.464602] time: 1:04:29.287266\n",
      "0.9480383\n",
      "[Epoch 43/50] [Batch 73/300] [D loss: 0.752268] [G loss: 0.466729] time: 1:04:29.584559\n",
      "0.9171336\n",
      "[Epoch 43/50] [Batch 74/300] [D loss: 0.752265] [G loss: 0.484016] time: 1:04:29.885692\n",
      "0.9247677\n",
      "[Epoch 43/50] [Batch 75/300] [D loss: 0.752260] [G loss: 0.465429] time: 1:04:30.182058\n",
      "0.9294038\n",
      "[Epoch 43/50] [Batch 76/300] [D loss: 0.752262] [G loss: 0.476221] time: 1:04:30.483301\n",
      "0.93477654\n",
      "[Epoch 43/50] [Batch 77/300] [D loss: 0.752253] [G loss: 0.486371] time: 1:04:30.784218\n",
      "0.89573336\n",
      "[Epoch 43/50] [Batch 78/300] [D loss: 0.752255] [G loss: 0.472642] time: 1:04:31.085581\n",
      "0.9136594\n",
      "[Epoch 43/50] [Batch 79/300] [D loss: 0.752265] [G loss: 0.474954] time: 1:04:31.379979\n",
      "0.9271142\n",
      "[Epoch 43/50] [Batch 80/300] [D loss: 0.752255] [G loss: 0.483247] time: 1:04:31.683943\n",
      "0.88731885\n",
      "[Epoch 43/50] [Batch 81/300] [D loss: 0.752266] [G loss: 0.474648] time: 1:04:31.989401\n",
      "0.9384442\n",
      "[Epoch 43/50] [Batch 82/300] [D loss: 0.752261] [G loss: 0.473142] time: 1:04:32.273634\n",
      "0.9121871\n",
      "[Epoch 43/50] [Batch 83/300] [D loss: 0.752269] [G loss: 0.482401] time: 1:04:32.565573\n",
      "0.9066259\n",
      "[Epoch 43/50] [Batch 84/300] [D loss: 0.752276] [G loss: 0.466513] time: 1:04:32.873158\n",
      "0.9468088\n",
      "[Epoch 43/50] [Batch 85/300] [D loss: 0.752266] [G loss: 0.471521] time: 1:04:33.169949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9319108\n",
      "[Epoch 43/50] [Batch 86/300] [D loss: 0.752249] [G loss: 0.467710] time: 1:04:33.476682\n",
      "0.8865788\n",
      "[Epoch 43/50] [Batch 87/300] [D loss: 0.752267] [G loss: 0.468533] time: 1:04:33.766797\n",
      "0.96006614\n",
      "[Epoch 43/50] [Batch 88/300] [D loss: 0.752251] [G loss: 0.488711] time: 1:04:34.043330\n",
      "0.9059934\n",
      "[Epoch 43/50] [Batch 89/300] [D loss: 0.752263] [G loss: 0.473489] time: 1:04:34.308583\n",
      "0.9057109\n",
      "[Epoch 43/50] [Batch 90/300] [D loss: 0.752260] [G loss: 0.469026] time: 1:04:34.623421\n",
      "0.8989025\n",
      "[Epoch 43/50] [Batch 91/300] [D loss: 0.752262] [G loss: 0.474603] time: 1:04:34.933022\n",
      "0.88089204\n",
      "[Epoch 43/50] [Batch 92/300] [D loss: 0.752267] [G loss: 0.484598] time: 1:04:35.218440\n",
      "0.9305964\n",
      "[Epoch 43/50] [Batch 93/300] [D loss: 0.752270] [G loss: 0.461609] time: 1:04:35.513321\n",
      "0.88744754\n",
      "[Epoch 43/50] [Batch 94/300] [D loss: 0.752269] [G loss: 0.481678] time: 1:04:35.809747\n",
      "0.9054696\n",
      "[Epoch 43/50] [Batch 95/300] [D loss: 0.752258] [G loss: 0.492641] time: 1:04:36.128573\n",
      "0.9397652\n",
      "[Epoch 43/50] [Batch 96/300] [D loss: 0.752271] [G loss: 0.470598] time: 1:04:36.436087\n",
      "0.90678626\n",
      "[Epoch 43/50] [Batch 97/300] [D loss: 0.752258] [G loss: 0.470655] time: 1:04:36.720963\n",
      "0.89969754\n",
      "[Epoch 43/50] [Batch 98/300] [D loss: 0.752258] [G loss: 0.475528] time: 1:04:37.010151\n",
      "0.8736038\n",
      "[Epoch 43/50] [Batch 99/300] [D loss: 0.752247] [G loss: 0.481477] time: 1:04:37.321064\n",
      "0.94007283\n",
      "[Epoch 43/50] [Batch 100/300] [D loss: 0.752266] [G loss: 0.469793] time: 1:04:37.626942\n",
      "0.85268193\n",
      "[Epoch 43/50] [Batch 101/300] [D loss: 0.752259] [G loss: 0.476937] time: 1:04:37.922970\n",
      "0.94498444\n",
      "[Epoch 43/50] [Batch 102/300] [D loss: 0.752259] [G loss: 0.468913] time: 1:04:38.223490\n",
      "0.96885544\n",
      "[Epoch 43/50] [Batch 103/300] [D loss: 0.752266] [G loss: 0.477775] time: 1:04:38.512748\n",
      "0.8790004\n",
      "[Epoch 43/50] [Batch 104/300] [D loss: 0.752265] [G loss: 0.466749] time: 1:04:38.801485\n",
      "0.9477961\n",
      "[Epoch 43/50] [Batch 105/300] [D loss: 0.752258] [G loss: 0.471886] time: 1:04:39.107109\n",
      "0.9073584\n",
      "[Epoch 43/50] [Batch 106/300] [D loss: 0.752270] [G loss: 0.464012] time: 1:04:39.413282\n",
      "0.92606586\n",
      "[Epoch 43/50] [Batch 107/300] [D loss: 0.752257] [G loss: 0.483976] time: 1:04:39.727160\n",
      "0.95329267\n",
      "[Epoch 43/50] [Batch 108/300] [D loss: 0.752277] [G loss: 0.483277] time: 1:04:40.026673\n",
      "0.9168853\n",
      "[Epoch 43/50] [Batch 109/300] [D loss: 0.752256] [G loss: 0.482890] time: 1:04:40.335997\n",
      "0.94222397\n",
      "[Epoch 43/50] [Batch 110/300] [D loss: 0.752254] [G loss: 0.476283] time: 1:04:40.625588\n",
      "0.93863577\n",
      "[Epoch 43/50] [Batch 111/300] [D loss: 0.752263] [G loss: 0.479526] time: 1:04:40.927708\n",
      "0.9307623\n",
      "[Epoch 43/50] [Batch 112/300] [D loss: 0.752268] [G loss: 0.462324] time: 1:04:41.217655\n",
      "0.9120667\n",
      "[Epoch 43/50] [Batch 113/300] [D loss: 0.752263] [G loss: 0.475066] time: 1:04:41.522743\n",
      "0.8860325\n",
      "[Epoch 43/50] [Batch 114/300] [D loss: 0.752256] [G loss: 0.479178] time: 1:04:41.809836\n",
      "0.9097705\n",
      "[Epoch 43/50] [Batch 115/300] [D loss: 0.752260] [G loss: 0.478919] time: 1:04:42.119238\n",
      "0.98304296\n",
      "[Epoch 43/50] [Batch 116/300] [D loss: 0.752266] [G loss: 0.474108] time: 1:04:42.418148\n",
      "0.91197205\n",
      "[Epoch 43/50] [Batch 117/300] [D loss: 0.752268] [G loss: 0.476271] time: 1:04:42.714177\n",
      "0.9752867\n",
      "[Epoch 43/50] [Batch 118/300] [D loss: 0.752261] [G loss: 0.478112] time: 1:04:43.002577\n",
      "0.93337893\n",
      "[Epoch 43/50] [Batch 119/300] [D loss: 0.752260] [G loss: 0.472470] time: 1:04:43.298599\n",
      "0.91934127\n",
      "[Epoch 43/50] [Batch 120/300] [D loss: 0.752260] [G loss: 0.477148] time: 1:04:43.593874\n",
      "0.9744187\n",
      "[Epoch 43/50] [Batch 121/300] [D loss: 0.752261] [G loss: 0.470434] time: 1:04:43.895484\n",
      "0.9077118\n",
      "[Epoch 43/50] [Batch 122/300] [D loss: 0.752262] [G loss: 0.470361] time: 1:04:44.202621\n",
      "0.9312308\n",
      "[Epoch 43/50] [Batch 123/300] [D loss: 0.752261] [G loss: 0.472691] time: 1:04:44.509079\n",
      "0.8905398\n",
      "[Epoch 43/50] [Batch 124/300] [D loss: 0.752270] [G loss: 0.472756] time: 1:04:44.805848\n",
      "0.90296793\n",
      "[Epoch 43/50] [Batch 125/300] [D loss: 0.752264] [G loss: 0.472153] time: 1:04:45.121198\n",
      "0.9198969\n",
      "[Epoch 43/50] [Batch 126/300] [D loss: 0.752257] [G loss: 0.467537] time: 1:04:45.422557\n",
      "0.887379\n",
      "[Epoch 43/50] [Batch 127/300] [D loss: 0.752254] [G loss: 0.487268] time: 1:04:45.726652\n",
      "0.9131756\n",
      "[Epoch 43/50] [Batch 128/300] [D loss: 0.752262] [G loss: 0.467639] time: 1:04:46.020001\n",
      "0.9061826\n",
      "[Epoch 43/50] [Batch 129/300] [D loss: 0.752267] [G loss: 0.463808] time: 1:04:46.316583\n",
      "0.9126382\n",
      "[Epoch 43/50] [Batch 130/300] [D loss: 0.752262] [G loss: 0.480253] time: 1:04:46.621370\n",
      "0.95634127\n",
      "[Epoch 43/50] [Batch 131/300] [D loss: 0.752270] [G loss: 0.466458] time: 1:04:46.921281\n",
      "0.92355174\n",
      "[Epoch 43/50] [Batch 132/300] [D loss: 0.752255] [G loss: 0.473498] time: 1:04:47.220069\n",
      "0.9343767\n",
      "[Epoch 43/50] [Batch 133/300] [D loss: 0.752254] [G loss: 0.468146] time: 1:04:47.521444\n",
      "0.9319024\n",
      "[Epoch 43/50] [Batch 134/300] [D loss: 0.752260] [G loss: 0.466476] time: 1:04:47.814667\n",
      "0.94768643\n",
      "[Epoch 43/50] [Batch 135/300] [D loss: 0.752279] [G loss: 0.469673] time: 1:04:48.108337\n",
      "0.9308886\n",
      "[Epoch 43/50] [Batch 136/300] [D loss: 0.752259] [G loss: 0.469239] time: 1:04:48.418521\n",
      "0.9050052\n",
      "[Epoch 43/50] [Batch 137/300] [D loss: 0.752261] [G loss: 0.473942] time: 1:04:48.714707\n",
      "0.91522044\n",
      "[Epoch 43/50] [Batch 138/300] [D loss: 0.752277] [G loss: 0.463616] time: 1:04:49.001236\n",
      "0.89907044\n",
      "[Epoch 43/50] [Batch 139/300] [D loss: 0.752265] [G loss: 0.469742] time: 1:04:49.292086\n",
      "0.8836351\n",
      "[Epoch 43/50] [Batch 140/300] [D loss: 0.752260] [G loss: 0.463525] time: 1:04:49.603277\n",
      "0.89213276\n",
      "[Epoch 43/50] [Batch 141/300] [D loss: 0.752257] [G loss: 0.479387] time: 1:04:49.906100\n",
      "0.8598576\n",
      "[Epoch 43/50] [Batch 142/300] [D loss: 0.752251] [G loss: 0.474131] time: 1:04:50.225890\n",
      "0.90668845\n",
      "[Epoch 43/50] [Batch 143/300] [D loss: 0.752273] [G loss: 0.505636] time: 1:04:50.526125\n",
      "0.93601376\n",
      "[Epoch 43/50] [Batch 144/300] [D loss: 0.752270] [G loss: 0.464973] time: 1:04:50.835661\n",
      "0.91626096\n",
      "[Epoch 43/50] [Batch 145/300] [D loss: 0.752284] [G loss: 0.483917] time: 1:04:51.142193\n",
      "0.94104695\n",
      "[Epoch 43/50] [Batch 146/300] [D loss: 0.752263] [G loss: 0.483933] time: 1:04:51.447237\n",
      "0.873849\n",
      "[Epoch 43/50] [Batch 147/300] [D loss: 0.752264] [G loss: 0.481629] time: 1:04:51.743711\n",
      "0.8852784\n",
      "[Epoch 43/50] [Batch 148/300] [D loss: 0.752253] [G loss: 0.476922] time: 1:04:52.046163\n",
      "0.9249115\n",
      "[Epoch 43/50] [Batch 149/300] [D loss: 0.752284] [G loss: 0.464794] time: 1:04:52.342330\n",
      "0.94504356\n",
      "[Epoch 43/50] [Batch 150/300] [D loss: 0.752286] [G loss: 0.465782] time: 1:04:52.653940\n",
      "0.92148155\n",
      "[Epoch 43/50] [Batch 151/300] [D loss: 0.752275] [G loss: 0.465745] time: 1:04:52.941476\n",
      "0.9330953\n",
      "[Epoch 43/50] [Batch 152/300] [D loss: 0.752254] [G loss: 0.475541] time: 1:04:53.249476\n",
      "0.9746453\n",
      "[Epoch 43/50] [Batch 153/300] [D loss: 0.752276] [G loss: 0.490552] time: 1:04:53.540238\n",
      "0.93097526\n",
      "[Epoch 43/50] [Batch 154/300] [D loss: 0.752262] [G loss: 0.469056] time: 1:04:53.838674\n",
      "0.92932755\n",
      "[Epoch 43/50] [Batch 155/300] [D loss: 0.752269] [G loss: 0.490723] time: 1:04:54.134434\n",
      "0.9292318\n",
      "[Epoch 43/50] [Batch 156/300] [D loss: 0.752259] [G loss: 0.483489] time: 1:04:54.452484\n",
      "0.9355128\n",
      "[Epoch 43/50] [Batch 157/300] [D loss: 0.752275] [G loss: 0.475488] time: 1:04:54.752344\n",
      "0.8959191\n",
      "[Epoch 43/50] [Batch 158/300] [D loss: 0.752259] [G loss: 0.483045] time: 1:04:55.068335\n",
      "0.93959457\n",
      "[Epoch 43/50] [Batch 159/300] [D loss: 0.752270] [G loss: 0.466132] time: 1:04:55.372676\n",
      "0.93591887\n",
      "[Epoch 43/50] [Batch 160/300] [D loss: 0.752263] [G loss: 0.476494] time: 1:04:55.671796\n",
      "0.9136999\n",
      "[Epoch 43/50] [Batch 161/300] [D loss: 0.752265] [G loss: 0.469902] time: 1:04:55.977477\n",
      "0.9469096\n",
      "[Epoch 43/50] [Batch 162/300] [D loss: 0.752259] [G loss: 0.477454] time: 1:04:56.287672\n",
      "0.9351571\n",
      "[Epoch 43/50] [Batch 163/300] [D loss: 0.752261] [G loss: 0.468486] time: 1:04:56.554322\n",
      "0.93084645\n",
      "[Epoch 43/50] [Batch 164/300] [D loss: 0.752256] [G loss: 0.473811] time: 1:04:56.850872\n",
      "0.9038779\n",
      "[Epoch 43/50] [Batch 165/300] [D loss: 0.752260] [G loss: 0.467756] time: 1:04:57.160033\n",
      "0.93073505\n",
      "[Epoch 43/50] [Batch 166/300] [D loss: 0.752262] [G loss: 0.479243] time: 1:04:57.453887\n",
      "0.8899228\n",
      "[Epoch 43/50] [Batch 167/300] [D loss: 0.752264] [G loss: 0.527579] time: 1:04:57.752954\n",
      "0.9468456\n",
      "[Epoch 43/50] [Batch 168/300] [D loss: 0.752256] [G loss: 0.474164] time: 1:04:58.047636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420381\n",
      "[Epoch 43/50] [Batch 169/300] [D loss: 0.752259] [G loss: 0.489512] time: 1:04:58.337539\n",
      "0.92219764\n",
      "[Epoch 43/50] [Batch 170/300] [D loss: 0.752274] [G loss: 0.474962] time: 1:04:58.624623\n",
      "0.9355455\n",
      "[Epoch 43/50] [Batch 171/300] [D loss: 0.752273] [G loss: 0.469525] time: 1:04:58.928683\n",
      "0.93758965\n",
      "[Epoch 43/50] [Batch 172/300] [D loss: 0.752257] [G loss: 0.471164] time: 1:04:59.241547\n",
      "0.91397876\n",
      "[Epoch 43/50] [Batch 173/300] [D loss: 0.752256] [G loss: 0.485185] time: 1:04:59.535262\n",
      "0.96897596\n",
      "[Epoch 43/50] [Batch 174/300] [D loss: 0.752259] [G loss: 0.469591] time: 1:04:59.829916\n",
      "0.89527804\n",
      "[Epoch 43/50] [Batch 175/300] [D loss: 0.752253] [G loss: 0.476795] time: 1:05:00.149008\n",
      "0.9377144\n",
      "[Epoch 43/50] [Batch 176/300] [D loss: 0.752285] [G loss: 0.479513] time: 1:05:00.449327\n",
      "0.9094071\n",
      "[Epoch 43/50] [Batch 177/300] [D loss: 0.752254] [G loss: 0.471579] time: 1:05:00.756021\n",
      "0.9389637\n",
      "[Epoch 43/50] [Batch 178/300] [D loss: 0.752265] [G loss: 0.475245] time: 1:05:01.048045\n",
      "0.88128537\n",
      "[Epoch 43/50] [Batch 179/300] [D loss: 0.752263] [G loss: 0.493870] time: 1:05:01.335188\n",
      "0.8780098\n",
      "[Epoch 43/50] [Batch 180/300] [D loss: 0.752265] [G loss: 0.485090] time: 1:05:01.618561\n",
      "0.9212096\n",
      "[Epoch 43/50] [Batch 181/300] [D loss: 0.752253] [G loss: 0.487041] time: 1:05:01.917785\n",
      "0.9498214\n",
      "[Epoch 43/50] [Batch 182/300] [D loss: 0.752266] [G loss: 0.471749] time: 1:05:02.236631\n",
      "0.8951929\n",
      "[Epoch 43/50] [Batch 183/300] [D loss: 0.752258] [G loss: 0.482889] time: 1:05:02.529579\n",
      "0.90215683\n",
      "[Epoch 43/50] [Batch 184/300] [D loss: 0.752266] [G loss: 0.472940] time: 1:05:02.812247\n",
      "0.9184458\n",
      "[Epoch 43/50] [Batch 185/300] [D loss: 0.752248] [G loss: 0.474372] time: 1:05:03.102565\n",
      "0.91426843\n",
      "[Epoch 43/50] [Batch 186/300] [D loss: 0.752257] [G loss: 0.472235] time: 1:05:03.409775\n",
      "0.9463827\n",
      "[Epoch 43/50] [Batch 187/300] [D loss: 0.752253] [G loss: 0.465739] time: 1:05:03.720668\n",
      "0.91011816\n",
      "[Epoch 43/50] [Batch 188/300] [D loss: 0.752261] [G loss: 0.486903] time: 1:05:04.026178\n",
      "0.90549564\n",
      "[Epoch 43/50] [Batch 189/300] [D loss: 0.752272] [G loss: 0.474182] time: 1:05:04.321703\n",
      "0.8706002\n",
      "[Epoch 43/50] [Batch 190/300] [D loss: 0.752267] [G loss: 0.486814] time: 1:05:04.614725\n",
      "0.8877161\n",
      "[Epoch 43/50] [Batch 191/300] [D loss: 0.752255] [G loss: 0.473240] time: 1:05:04.888812\n",
      "0.93837595\n",
      "[Epoch 43/50] [Batch 192/300] [D loss: 0.752254] [G loss: 0.470739] time: 1:05:05.196104\n",
      "0.93897766\n",
      "[Epoch 43/50] [Batch 193/300] [D loss: 0.752265] [G loss: 0.471230] time: 1:05:05.497156\n",
      "0.8940463\n",
      "[Epoch 43/50] [Batch 194/300] [D loss: 0.752266] [G loss: 0.471951] time: 1:05:05.825084\n",
      "0.8866343\n",
      "[Epoch 43/50] [Batch 195/300] [D loss: 0.752267] [G loss: 0.476388] time: 1:05:06.117242\n",
      "0.9356858\n",
      "[Epoch 43/50] [Batch 196/300] [D loss: 0.752266] [G loss: 0.473388] time: 1:05:06.413660\n",
      "0.8675637\n",
      "[Epoch 43/50] [Batch 197/300] [D loss: 0.752249] [G loss: 0.480957] time: 1:05:06.727446\n",
      "0.9334251\n",
      "[Epoch 43/50] [Batch 198/300] [D loss: 0.752256] [G loss: 0.473872] time: 1:05:07.022179\n",
      "0.9832402\n",
      "[Epoch 43/50] [Batch 199/300] [D loss: 0.752269] [G loss: 0.480916] time: 1:05:07.332408\n",
      "0.90703267\n",
      "[Epoch 43/50] [Batch 200/300] [D loss: 0.752268] [G loss: 0.474768] time: 1:05:07.648481\n",
      "0.9244259\n",
      "[Epoch 43/50] [Batch 201/300] [D loss: 0.752277] [G loss: 0.483186] time: 1:05:07.956013\n",
      "0.9461024\n",
      "[Epoch 43/50] [Batch 202/300] [D loss: 0.752258] [G loss: 0.520792] time: 1:05:08.264698\n",
      "0.9102287\n",
      "[Epoch 43/50] [Batch 203/300] [D loss: 0.752255] [G loss: 0.469918] time: 1:05:08.558889\n",
      "0.94679546\n",
      "[Epoch 43/50] [Batch 204/300] [D loss: 0.752266] [G loss: 0.475953] time: 1:05:08.861858\n",
      "0.9270768\n",
      "[Epoch 43/50] [Batch 205/300] [D loss: 0.752261] [G loss: 0.475839] time: 1:05:09.160601\n",
      "0.91916054\n",
      "[Epoch 43/50] [Batch 206/300] [D loss: 0.752249] [G loss: 0.467130] time: 1:05:09.468157\n",
      "0.89632344\n",
      "[Epoch 43/50] [Batch 207/300] [D loss: 0.752251] [G loss: 0.480879] time: 1:05:09.753496\n",
      "0.9134655\n",
      "[Epoch 43/50] [Batch 208/300] [D loss: 0.752265] [G loss: 0.502276] time: 1:05:10.035276\n",
      "0.9086919\n",
      "[Epoch 43/50] [Batch 209/300] [D loss: 0.752255] [G loss: 0.488501] time: 1:05:10.334565\n",
      "0.9534497\n",
      "[Epoch 43/50] [Batch 210/300] [D loss: 0.752261] [G loss: 0.474119] time: 1:05:10.628805\n",
      "0.86771065\n",
      "[Epoch 43/50] [Batch 211/300] [D loss: 0.752267] [G loss: 0.472808] time: 1:05:10.910122\n",
      "0.9103047\n",
      "[Epoch 43/50] [Batch 212/300] [D loss: 0.752253] [G loss: 0.476445] time: 1:05:11.208989\n",
      "0.9497857\n",
      "[Epoch 43/50] [Batch 213/300] [D loss: 0.752264] [G loss: 0.475631] time: 1:05:11.514408\n",
      "0.93693113\n",
      "[Epoch 43/50] [Batch 214/300] [D loss: 0.752263] [G loss: 0.471817] time: 1:05:11.815209\n",
      "0.9258311\n",
      "[Epoch 43/50] [Batch 215/300] [D loss: 0.752253] [G loss: 0.478565] time: 1:05:12.097132\n",
      "0.92895824\n",
      "[Epoch 43/50] [Batch 216/300] [D loss: 0.752257] [G loss: 0.503470] time: 1:05:12.396408\n",
      "0.87891793\n",
      "[Epoch 43/50] [Batch 217/300] [D loss: 0.752275] [G loss: 0.494897] time: 1:05:12.703761\n",
      "0.9554011\n",
      "[Epoch 43/50] [Batch 218/300] [D loss: 0.752260] [G loss: 0.475897] time: 1:05:12.989649\n",
      "0.8871468\n",
      "[Epoch 43/50] [Batch 219/300] [D loss: 0.752257] [G loss: 0.484187] time: 1:05:13.278106\n",
      "0.9571908\n",
      "[Epoch 43/50] [Batch 220/300] [D loss: 0.752262] [G loss: 0.474661] time: 1:05:13.578152\n",
      "0.88301283\n",
      "[Epoch 43/50] [Batch 221/300] [D loss: 0.752264] [G loss: 0.469147] time: 1:05:13.883072\n",
      "0.87410897\n",
      "[Epoch 43/50] [Batch 222/300] [D loss: 0.752278] [G loss: 0.476016] time: 1:05:14.189554\n",
      "0.91745687\n",
      "[Epoch 43/50] [Batch 223/300] [D loss: 0.752250] [G loss: 0.476513] time: 1:05:14.473189\n",
      "0.9460617\n",
      "[Epoch 43/50] [Batch 224/300] [D loss: 0.752278] [G loss: 0.479638] time: 1:05:14.780862\n",
      "0.8997995\n",
      "[Epoch 43/50] [Batch 225/300] [D loss: 0.752269] [G loss: 0.476271] time: 1:05:15.079054\n",
      "0.95296025\n",
      "[Epoch 43/50] [Batch 226/300] [D loss: 0.752258] [G loss: 0.466096] time: 1:05:15.399559\n",
      "0.87207216\n",
      "[Epoch 43/50] [Batch 227/300] [D loss: 0.752254] [G loss: 0.479896] time: 1:05:15.703696\n",
      "0.95909494\n",
      "[Epoch 43/50] [Batch 228/300] [D loss: 0.752268] [G loss: 0.478770] time: 1:05:15.997512\n",
      "0.89167476\n",
      "[Epoch 43/50] [Batch 229/300] [D loss: 0.752257] [G loss: 0.486586] time: 1:05:16.298559\n",
      "0.9731986\n",
      "[Epoch 43/50] [Batch 230/300] [D loss: 0.752255] [G loss: 0.482699] time: 1:05:16.601811\n",
      "0.9532096\n",
      "[Epoch 43/50] [Batch 231/300] [D loss: 0.752264] [G loss: 0.489764] time: 1:05:16.900268\n",
      "0.93048406\n",
      "[Epoch 43/50] [Batch 232/300] [D loss: 0.752271] [G loss: 0.473082] time: 1:05:17.196036\n",
      "0.9371745\n",
      "[Epoch 43/50] [Batch 233/300] [D loss: 0.752250] [G loss: 0.473820] time: 1:05:17.485963\n",
      "0.9720843\n",
      "[Epoch 43/50] [Batch 234/300] [D loss: 0.752256] [G loss: 0.474281] time: 1:05:17.780186\n",
      "0.91383743\n",
      "[Epoch 43/50] [Batch 235/300] [D loss: 0.752243] [G loss: 0.477549] time: 1:05:18.086918\n",
      "0.9214204\n",
      "[Epoch 43/50] [Batch 236/300] [D loss: 0.752260] [G loss: 0.473624] time: 1:05:18.403294\n",
      "0.91959816\n",
      "[Epoch 43/50] [Batch 237/300] [D loss: 0.752270] [G loss: 0.473945] time: 1:05:18.701545\n",
      "0.91884834\n",
      "[Epoch 43/50] [Batch 238/300] [D loss: 0.752243] [G loss: 0.486586] time: 1:05:18.988442\n",
      "0.9057794\n",
      "[Epoch 43/50] [Batch 239/300] [D loss: 0.752268] [G loss: 0.469395] time: 1:05:19.274134\n",
      "0.91517353\n",
      "[Epoch 43/50] [Batch 240/300] [D loss: 0.752246] [G loss: 0.488407] time: 1:05:19.583146\n",
      "0.92323226\n",
      "[Epoch 43/50] [Batch 241/300] [D loss: 0.752264] [G loss: 0.470536] time: 1:05:19.912297\n",
      "0.9571221\n",
      "[Epoch 43/50] [Batch 242/300] [D loss: 0.752271] [G loss: 0.467637] time: 1:05:20.226539\n",
      "0.87419885\n",
      "[Epoch 43/50] [Batch 243/300] [D loss: 0.752262] [G loss: 0.475737] time: 1:05:20.520691\n",
      "0.905263\n",
      "[Epoch 43/50] [Batch 244/300] [D loss: 0.752275] [G loss: 0.473486] time: 1:05:20.818929\n",
      "0.9420147\n",
      "[Epoch 43/50] [Batch 245/300] [D loss: 0.752263] [G loss: 0.480816] time: 1:05:21.122014\n",
      "0.9404759\n",
      "[Epoch 43/50] [Batch 246/300] [D loss: 0.752255] [G loss: 0.470979] time: 1:05:21.417297\n",
      "0.89596486\n",
      "[Epoch 43/50] [Batch 247/300] [D loss: 0.752250] [G loss: 0.473291] time: 1:05:21.705995\n",
      "0.8914214\n",
      "[Epoch 43/50] [Batch 248/300] [D loss: 0.752249] [G loss: 0.470574] time: 1:05:21.992659\n",
      "0.8939672\n",
      "[Epoch 43/50] [Batch 249/300] [D loss: 0.752266] [G loss: 0.468508] time: 1:05:22.283219\n",
      "0.9150162\n",
      "[Epoch 43/50] [Batch 250/300] [D loss: 0.752256] [G loss: 0.474439] time: 1:05:22.570694\n",
      "0.9174304\n",
      "[Epoch 43/50] [Batch 251/300] [D loss: 0.752255] [G loss: 0.482257] time: 1:05:22.873281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95204395\n",
      "[Epoch 43/50] [Batch 252/300] [D loss: 0.752264] [G loss: 0.464640] time: 1:05:23.179440\n",
      "0.8676829\n",
      "[Epoch 43/50] [Batch 253/300] [D loss: 0.752263] [G loss: 0.472526] time: 1:05:23.457756\n",
      "0.9375813\n",
      "[Epoch 43/50] [Batch 254/300] [D loss: 0.752259] [G loss: 0.497365] time: 1:05:23.754958\n",
      "0.943768\n",
      "[Epoch 43/50] [Batch 255/300] [D loss: 0.752254] [G loss: 0.472416] time: 1:05:24.059697\n",
      "0.95019007\n",
      "[Epoch 43/50] [Batch 256/300] [D loss: 0.752268] [G loss: 0.465799] time: 1:05:24.367842\n",
      "0.89895415\n",
      "[Epoch 43/50] [Batch 257/300] [D loss: 0.752258] [G loss: 0.466690] time: 1:05:24.671490\n",
      "0.9105358\n",
      "[Epoch 43/50] [Batch 258/300] [D loss: 0.752267] [G loss: 0.466944] time: 1:05:24.959992\n",
      "0.9534126\n",
      "[Epoch 43/50] [Batch 259/300] [D loss: 0.752252] [G loss: 0.467445] time: 1:05:25.248930\n",
      "0.899622\n",
      "[Epoch 43/50] [Batch 260/300] [D loss: 0.752259] [G loss: 0.471929] time: 1:05:25.526411\n",
      "0.9157653\n",
      "[Epoch 43/50] [Batch 261/300] [D loss: 0.752247] [G loss: 0.477673] time: 1:05:25.826955\n",
      "0.94183475\n",
      "[Epoch 43/50] [Batch 262/300] [D loss: 0.752257] [G loss: 0.489209] time: 1:05:26.123346\n",
      "0.91058254\n",
      "[Epoch 43/50] [Batch 263/300] [D loss: 0.752257] [G loss: 0.488405] time: 1:05:26.409273\n",
      "0.9054628\n",
      "[Epoch 43/50] [Batch 264/300] [D loss: 0.752277] [G loss: 0.478585] time: 1:05:26.710101\n",
      "0.9308278\n",
      "[Epoch 43/50] [Batch 265/300] [D loss: 0.752254] [G loss: 0.472605] time: 1:05:26.993062\n",
      "0.92000705\n",
      "[Epoch 43/50] [Batch 266/300] [D loss: 0.752254] [G loss: 0.478802] time: 1:05:27.300949\n",
      "0.8987865\n",
      "[Epoch 43/50] [Batch 267/300] [D loss: 0.752255] [G loss: 0.475908] time: 1:05:27.598463\n",
      "0.9115363\n",
      "[Epoch 43/50] [Batch 268/300] [D loss: 0.752251] [G loss: 0.468740] time: 1:05:27.875701\n",
      "0.94139504\n",
      "[Epoch 43/50] [Batch 269/300] [D loss: 0.752264] [G loss: 0.474484] time: 1:05:28.162807\n",
      "0.9105429\n",
      "[Epoch 43/50] [Batch 270/300] [D loss: 0.752249] [G loss: 0.481922] time: 1:05:28.455580\n",
      "0.8864479\n",
      "[Epoch 43/50] [Batch 271/300] [D loss: 0.752254] [G loss: 0.479695] time: 1:05:28.762315\n",
      "0.9196851\n",
      "[Epoch 43/50] [Batch 272/300] [D loss: 0.752252] [G loss: 0.480419] time: 1:05:29.052487\n",
      "0.9119392\n",
      "[Epoch 43/50] [Batch 273/300] [D loss: 0.752252] [G loss: 0.491574] time: 1:05:29.345484\n",
      "0.88384104\n",
      "[Epoch 43/50] [Batch 274/300] [D loss: 0.752260] [G loss: 0.473126] time: 1:05:29.627843\n",
      "0.9001623\n",
      "[Epoch 43/50] [Batch 275/300] [D loss: 0.752253] [G loss: 0.479203] time: 1:05:29.941341\n",
      "0.97378784\n",
      "[Epoch 43/50] [Batch 276/300] [D loss: 0.752261] [G loss: 0.487760] time: 1:05:30.240670\n",
      "0.9714708\n",
      "[Epoch 43/50] [Batch 277/300] [D loss: 0.752259] [G loss: 0.492429] time: 1:05:30.547118\n",
      "0.8877661\n",
      "[Epoch 43/50] [Batch 278/300] [D loss: 0.752243] [G loss: 0.467344] time: 1:05:30.848361\n",
      "0.8853949\n",
      "[Epoch 43/50] [Batch 279/300] [D loss: 0.752260] [G loss: 0.471254] time: 1:05:31.137690\n",
      "0.93130594\n",
      "[Epoch 43/50] [Batch 280/300] [D loss: 0.752255] [G loss: 0.483635] time: 1:05:31.453165\n",
      "0.9434266\n",
      "[Epoch 43/50] [Batch 281/300] [D loss: 0.752263] [G loss: 0.475103] time: 1:05:31.753536\n",
      "0.90929943\n",
      "[Epoch 43/50] [Batch 282/300] [D loss: 0.752254] [G loss: 0.486665] time: 1:05:32.058748\n",
      "0.91975737\n",
      "[Epoch 43/50] [Batch 283/300] [D loss: 0.752260] [G loss: 0.468080] time: 1:05:32.354683\n",
      "0.9272811\n",
      "[Epoch 43/50] [Batch 284/300] [D loss: 0.752251] [G loss: 0.469455] time: 1:05:32.654032\n",
      "0.90293425\n",
      "[Epoch 43/50] [Batch 285/300] [D loss: 0.752250] [G loss: 0.478267] time: 1:05:32.953168\n",
      "0.926194\n",
      "[Epoch 43/50] [Batch 286/300] [D loss: 0.752260] [G loss: 0.477492] time: 1:05:33.242065\n",
      "0.95283884\n",
      "[Epoch 43/50] [Batch 287/300] [D loss: 0.752257] [G loss: 0.482077] time: 1:05:33.548283\n",
      "0.913263\n",
      "[Epoch 43/50] [Batch 288/300] [D loss: 0.752241] [G loss: 0.469279] time: 1:05:33.847186\n",
      "0.95213586\n",
      "[Epoch 43/50] [Batch 289/300] [D loss: 0.752253] [G loss: 0.488540] time: 1:05:34.146066\n",
      "0.94203943\n",
      "[Epoch 43/50] [Batch 290/300] [D loss: 0.752256] [G loss: 0.486304] time: 1:05:34.447358\n",
      "0.9283488\n",
      "[Epoch 43/50] [Batch 291/300] [D loss: 0.752252] [G loss: 0.472315] time: 1:05:34.727064\n",
      "0.9534108\n",
      "[Epoch 43/50] [Batch 292/300] [D loss: 0.752267] [G loss: 0.472812] time: 1:05:35.030485\n",
      "0.88620716\n",
      "[Epoch 43/50] [Batch 293/300] [D loss: 0.752255] [G loss: 0.468179] time: 1:05:35.333318\n",
      "0.924434\n",
      "[Epoch 43/50] [Batch 294/300] [D loss: 0.752261] [G loss: 0.474024] time: 1:05:35.636994\n",
      "0.90594196\n",
      "[Epoch 43/50] [Batch 295/300] [D loss: 0.752263] [G loss: 0.471853] time: 1:05:35.929944\n",
      "0.9451053\n",
      "[Epoch 43/50] [Batch 296/300] [D loss: 0.752256] [G loss: 0.474636] time: 1:05:36.214471\n",
      "0.95893353\n",
      "[Epoch 43/50] [Batch 297/300] [D loss: 0.752256] [G loss: 0.469721] time: 1:05:36.646660\n",
      "0.94210464\n",
      "[Epoch 43/50] [Batch 298/300] [D loss: 0.752261] [G loss: 0.477935] time: 1:05:36.946894\n",
      "0.8788534\n",
      "[Epoch 43/50] [Batch 299/300] [D loss: 0.752250] [G loss: 0.490494] time: 1:05:37.236625\n",
      "0.96053785\n",
      "[Epoch 44/50] [Batch 0/300] [D loss: 0.752266] [G loss: 0.473383] time: 1:05:37.545452\n",
      "0.9442346\n",
      "[Epoch 44/50] [Batch 1/300] [D loss: 0.752247] [G loss: 0.479843] time: 1:05:37.843108\n",
      "0.93301064\n",
      "[Epoch 44/50] [Batch 2/300] [D loss: 0.752259] [G loss: 0.472301] time: 1:05:38.153019\n",
      "0.95309466\n",
      "[Epoch 44/50] [Batch 3/300] [D loss: 0.752260] [G loss: 0.472146] time: 1:05:38.448709\n",
      "0.9449493\n",
      "[Epoch 44/50] [Batch 4/300] [D loss: 0.752252] [G loss: 0.482313] time: 1:05:38.756526\n",
      "0.8897422\n",
      "[Epoch 44/50] [Batch 5/300] [D loss: 0.752274] [G loss: 0.472086] time: 1:05:39.051541\n",
      "0.94780415\n",
      "[Epoch 44/50] [Batch 6/300] [D loss: 0.752273] [G loss: 0.496340] time: 1:05:39.335142\n",
      "0.9026608\n",
      "[Epoch 44/50] [Batch 7/300] [D loss: 0.752257] [G loss: 0.476480] time: 1:05:39.641065\n",
      "0.9427383\n",
      "[Epoch 44/50] [Batch 8/300] [D loss: 0.752261] [G loss: 0.468635] time: 1:05:39.941422\n",
      "0.95188195\n",
      "[Epoch 44/50] [Batch 9/300] [D loss: 0.752267] [G loss: 0.464330] time: 1:05:40.230736\n",
      "0.93301314\n",
      "[Epoch 44/50] [Batch 10/300] [D loss: 0.752250] [G loss: 0.466259] time: 1:05:40.516426\n",
      "0.9368334\n",
      "[Epoch 44/50] [Batch 11/300] [D loss: 0.752266] [G loss: 0.501231] time: 1:05:40.807672\n",
      "0.93327993\n",
      "[Epoch 44/50] [Batch 12/300] [D loss: 0.752254] [G loss: 0.487199] time: 1:05:41.103335\n",
      "0.89370817\n",
      "[Epoch 44/50] [Batch 13/300] [D loss: 0.752262] [G loss: 0.485931] time: 1:05:41.381240\n",
      "0.91429496\n",
      "[Epoch 44/50] [Batch 14/300] [D loss: 0.752261] [G loss: 0.481844] time: 1:05:41.695201\n",
      "0.9154389\n",
      "[Epoch 44/50] [Batch 15/300] [D loss: 0.752264] [G loss: 0.472808] time: 1:05:41.991404\n",
      "0.9498937\n",
      "[Epoch 44/50] [Batch 16/300] [D loss: 0.752256] [G loss: 0.473208] time: 1:05:42.290290\n",
      "0.9740589\n",
      "[Epoch 44/50] [Batch 17/300] [D loss: 0.752255] [G loss: 0.474850] time: 1:05:42.614976\n",
      "0.93151194\n",
      "[Epoch 44/50] [Batch 18/300] [D loss: 0.752258] [G loss: 0.489331] time: 1:05:42.912998\n",
      "0.92160636\n",
      "[Epoch 44/50] [Batch 19/300] [D loss: 0.752267] [G loss: 0.463255] time: 1:05:43.205635\n",
      "0.98193526\n",
      "[Epoch 44/50] [Batch 20/300] [D loss: 0.752257] [G loss: 0.469382] time: 1:05:43.504057\n",
      "0.9397132\n",
      "[Epoch 44/50] [Batch 21/300] [D loss: 0.752252] [G loss: 0.482344] time: 1:05:43.804120\n",
      "0.9645586\n",
      "[Epoch 44/50] [Batch 22/300] [D loss: 0.752254] [G loss: 0.469599] time: 1:05:44.115883\n",
      "0.95552325\n",
      "[Epoch 44/50] [Batch 23/300] [D loss: 0.752259] [G loss: 0.474998] time: 1:05:44.401761\n",
      "0.9829921\n",
      "[Epoch 44/50] [Batch 24/300] [D loss: 0.752246] [G loss: 0.471607] time: 1:05:44.696327\n",
      "0.9522257\n",
      "[Epoch 44/50] [Batch 25/300] [D loss: 0.752263] [G loss: 0.474078] time: 1:05:44.994849\n",
      "0.89377004\n",
      "[Epoch 44/50] [Batch 26/300] [D loss: 0.752244] [G loss: 0.466446] time: 1:05:45.290476\n",
      "0.94800943\n",
      "[Epoch 44/50] [Batch 27/300] [D loss: 0.752250] [G loss: 0.473590] time: 1:05:45.596909\n",
      "0.91707236\n",
      "[Epoch 44/50] [Batch 28/300] [D loss: 0.752259] [G loss: 0.464363] time: 1:05:45.910051\n",
      "0.89810133\n",
      "[Epoch 44/50] [Batch 29/300] [D loss: 0.752255] [G loss: 0.491406] time: 1:05:46.202925\n",
      "0.9166027\n",
      "[Epoch 44/50] [Batch 30/300] [D loss: 0.752265] [G loss: 0.475791] time: 1:05:46.498463\n",
      "0.976309\n",
      "[Epoch 44/50] [Batch 31/300] [D loss: 0.752252] [G loss: 0.463168] time: 1:05:46.793758\n",
      "0.9156284\n",
      "[Epoch 44/50] [Batch 32/300] [D loss: 0.752252] [G loss: 0.474242] time: 1:05:47.090849\n",
      "0.91682523\n",
      "[Epoch 44/50] [Batch 33/300] [D loss: 0.752258] [G loss: 0.495406] time: 1:05:47.393778\n",
      "0.8808641\n",
      "[Epoch 44/50] [Batch 34/300] [D loss: 0.752263] [G loss: 0.478421] time: 1:05:47.689324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8900854\n",
      "[Epoch 44/50] [Batch 35/300] [D loss: 0.752256] [G loss: 0.465836] time: 1:05:47.986863\n",
      "0.9190442\n",
      "[Epoch 44/50] [Batch 36/300] [D loss: 0.752266] [G loss: 0.488857] time: 1:05:48.306330\n",
      "0.938248\n",
      "[Epoch 44/50] [Batch 37/300] [D loss: 0.752265] [G loss: 0.467254] time: 1:05:48.608874\n",
      "0.9470269\n",
      "[Epoch 44/50] [Batch 38/300] [D loss: 0.752258] [G loss: 0.471446] time: 1:05:48.906408\n",
      "0.9399132\n",
      "[Epoch 44/50] [Batch 39/300] [D loss: 0.752261] [G loss: 0.468342] time: 1:05:49.221872\n",
      "0.90847653\n",
      "[Epoch 44/50] [Batch 40/300] [D loss: 0.752242] [G loss: 0.482760] time: 1:05:49.513595\n",
      "0.8953207\n",
      "[Epoch 44/50] [Batch 41/300] [D loss: 0.752270] [G loss: 0.494224] time: 1:05:49.809766\n",
      "0.90768975\n",
      "[Epoch 44/50] [Batch 42/300] [D loss: 0.752250] [G loss: 0.473121] time: 1:05:50.073424\n",
      "0.8828995\n",
      "[Epoch 44/50] [Batch 44/300] [D loss: 0.752268] [G loss: 0.465015] time: 1:05:50.371044\n",
      "0.93321806\n",
      "[Epoch 44/50] [Batch 45/300] [D loss: 0.752256] [G loss: 0.470395] time: 1:05:50.674145\n",
      "0.895916\n",
      "[Epoch 44/50] [Batch 46/300] [D loss: 0.752269] [G loss: 0.476968] time: 1:05:50.997238\n",
      "0.97141415\n",
      "[Epoch 44/50] [Batch 47/300] [D loss: 0.752245] [G loss: 0.476996] time: 1:05:51.286221\n",
      "0.97564125\n",
      "[Epoch 44/50] [Batch 48/300] [D loss: 0.752259] [G loss: 0.498983] time: 1:05:51.570879\n",
      "0.94300294\n",
      "[Epoch 44/50] [Batch 49/300] [D loss: 0.752261] [G loss: 0.469111] time: 1:05:51.876386\n",
      "0.9501266\n",
      "[Epoch 44/50] [Batch 50/300] [D loss: 0.752271] [G loss: 0.470178] time: 1:05:52.172868\n",
      "0.9264274\n",
      "[Epoch 44/50] [Batch 51/300] [D loss: 0.752258] [G loss: 0.471985] time: 1:05:52.462653\n",
      "0.905818\n",
      "[Epoch 44/50] [Batch 52/300] [D loss: 0.752280] [G loss: 0.463578] time: 1:05:52.764876\n",
      "0.9087909\n",
      "[Epoch 44/50] [Batch 53/300] [D loss: 0.752261] [G loss: 0.469530] time: 1:05:53.069133\n",
      "0.880574\n",
      "[Epoch 44/50] [Batch 54/300] [D loss: 0.752239] [G loss: 0.474020] time: 1:05:53.379954\n",
      "0.88987213\n",
      "[Epoch 44/50] [Batch 55/300] [D loss: 0.752258] [G loss: 0.463144] time: 1:05:53.688455\n",
      "0.93508095\n",
      "[Epoch 44/50] [Batch 56/300] [D loss: 0.752257] [G loss: 0.481023] time: 1:05:53.992827\n",
      "0.9288959\n",
      "[Epoch 44/50] [Batch 57/300] [D loss: 0.752266] [G loss: 0.475126] time: 1:05:54.319099\n",
      "0.95270944\n",
      "[Epoch 44/50] [Batch 58/300] [D loss: 0.752260] [G loss: 0.473492] time: 1:05:54.625846\n",
      "0.94640154\n",
      "[Epoch 44/50] [Batch 59/300] [D loss: 0.752277] [G loss: 0.479500] time: 1:05:54.927849\n",
      "0.8762366\n",
      "[Epoch 44/50] [Batch 60/300] [D loss: 0.752255] [G loss: 0.464893] time: 1:05:55.232715\n",
      "0.9308651\n",
      "[Epoch 44/50] [Batch 61/300] [D loss: 0.752263] [G loss: 0.463651] time: 1:05:55.524041\n",
      "0.9083912\n",
      "[Epoch 44/50] [Batch 62/300] [D loss: 0.752257] [G loss: 0.469165] time: 1:05:55.823696\n",
      "0.9507327\n",
      "[Epoch 44/50] [Batch 63/300] [D loss: 0.752255] [G loss: 0.480599] time: 1:05:56.137217\n",
      "0.8901222\n",
      "[Epoch 44/50] [Batch 64/300] [D loss: 0.752256] [G loss: 0.467116] time: 1:05:56.441750\n",
      "0.93147177\n",
      "[Epoch 44/50] [Batch 65/300] [D loss: 0.752270] [G loss: 0.471486] time: 1:05:56.746937\n",
      "0.9528907\n",
      "[Epoch 44/50] [Batch 66/300] [D loss: 0.752271] [G loss: 0.466170] time: 1:05:57.036936\n",
      "0.9835062\n",
      "[Epoch 44/50] [Batch 67/300] [D loss: 0.752258] [G loss: 0.468962] time: 1:05:57.350244\n",
      "0.9686149\n",
      "[Epoch 44/50] [Batch 68/300] [D loss: 0.752251] [G loss: 0.486222] time: 1:05:57.645510\n",
      "0.92337817\n",
      "[Epoch 44/50] [Batch 69/300] [D loss: 0.752253] [G loss: 0.486331] time: 1:05:57.924980\n",
      "0.90409404\n",
      "[Epoch 44/50] [Batch 70/300] [D loss: 0.752251] [G loss: 0.465002] time: 1:05:58.241790\n",
      "0.9571331\n",
      "[Epoch 44/50] [Batch 71/300] [D loss: 0.752260] [G loss: 0.474250] time: 1:05:58.558516\n",
      "0.86754566\n",
      "[Epoch 44/50] [Batch 72/300] [D loss: 0.752264] [G loss: 0.469979] time: 1:05:58.861220\n",
      "0.907783\n",
      "[Epoch 44/50] [Batch 73/300] [D loss: 0.752253] [G loss: 0.467999] time: 1:05:59.144479\n",
      "0.9295632\n",
      "[Epoch 44/50] [Batch 74/300] [D loss: 0.752255] [G loss: 0.474617] time: 1:05:59.452335\n",
      "0.93874073\n",
      "[Epoch 44/50] [Batch 75/300] [D loss: 0.752248] [G loss: 0.473233] time: 1:05:59.748718\n",
      "0.8918746\n",
      "[Epoch 44/50] [Batch 76/300] [D loss: 0.752243] [G loss: 0.476711] time: 1:06:00.048614\n",
      "0.9258409\n",
      "[Epoch 44/50] [Batch 77/300] [D loss: 0.752256] [G loss: 0.485288] time: 1:06:00.352038\n",
      "0.9305768\n",
      "[Epoch 44/50] [Batch 78/300] [D loss: 0.752256] [G loss: 0.478020] time: 1:06:00.674763\n",
      "0.9373565\n",
      "[Epoch 44/50] [Batch 79/300] [D loss: 0.752254] [G loss: 0.472540] time: 1:06:00.975791\n",
      "0.8825967\n",
      "[Epoch 44/50] [Batch 80/300] [D loss: 0.752253] [G loss: 0.469744] time: 1:06:01.301766\n",
      "0.9762289\n",
      "[Epoch 44/50] [Batch 81/300] [D loss: 0.752255] [G loss: 0.466471] time: 1:06:01.593532\n",
      "0.8993179\n",
      "[Epoch 44/50] [Batch 82/300] [D loss: 0.752246] [G loss: 0.473795] time: 1:06:01.894431\n",
      "0.9307764\n",
      "[Epoch 44/50] [Batch 83/300] [D loss: 0.752264] [G loss: 0.472005] time: 1:06:02.213379\n",
      "0.9436729\n",
      "[Epoch 44/50] [Batch 84/300] [D loss: 0.752261] [G loss: 0.471832] time: 1:06:02.510465\n",
      "0.8830916\n",
      "[Epoch 44/50] [Batch 85/300] [D loss: 0.752253] [G loss: 0.489338] time: 1:06:02.813201\n",
      "0.9159724\n",
      "[Epoch 44/50] [Batch 86/300] [D loss: 0.752252] [G loss: 0.472881] time: 1:06:03.115819\n",
      "0.94286734\n",
      "[Epoch 44/50] [Batch 87/300] [D loss: 0.752266] [G loss: 0.487415] time: 1:06:03.415244\n",
      "0.9171345\n",
      "[Epoch 44/50] [Batch 88/300] [D loss: 0.752259] [G loss: 0.470177] time: 1:06:03.708821\n",
      "0.9505922\n",
      "[Epoch 44/50] [Batch 89/300] [D loss: 0.752253] [G loss: 0.471671] time: 1:06:04.005444\n",
      "0.95610076\n",
      "[Epoch 44/50] [Batch 90/300] [D loss: 0.752264] [G loss: 0.471757] time: 1:06:04.301681\n",
      "0.90205246\n",
      "[Epoch 44/50] [Batch 91/300] [D loss: 0.752254] [G loss: 0.475642] time: 1:06:04.595290\n",
      "0.9447152\n",
      "[Epoch 44/50] [Batch 92/300] [D loss: 0.752254] [G loss: 0.478445] time: 1:06:04.882624\n",
      "0.9312584\n",
      "[Epoch 44/50] [Batch 93/300] [D loss: 0.752240] [G loss: 0.472222] time: 1:06:05.184292\n",
      "0.9213175\n",
      "[Epoch 44/50] [Batch 94/300] [D loss: 0.752253] [G loss: 0.477951] time: 1:06:05.483519\n",
      "0.9452195\n",
      "[Epoch 44/50] [Batch 95/300] [D loss: 0.752262] [G loss: 0.473026] time: 1:06:05.785671\n",
      "0.9288149\n",
      "[Epoch 44/50] [Batch 96/300] [D loss: 0.752253] [G loss: 0.471350] time: 1:06:06.089408\n",
      "0.93075496\n",
      "[Epoch 44/50] [Batch 97/300] [D loss: 0.752257] [G loss: 0.477587] time: 1:06:06.385380\n",
      "0.9462517\n",
      "[Epoch 44/50] [Batch 98/300] [D loss: 0.752253] [G loss: 0.468057] time: 1:06:06.687404\n",
      "0.8881752\n",
      "[Epoch 44/50] [Batch 99/300] [D loss: 0.752260] [G loss: 0.475345] time: 1:06:06.966485\n",
      "0.9016978\n",
      "[Epoch 44/50] [Batch 100/300] [D loss: 0.752251] [G loss: 0.489899] time: 1:06:07.269596\n",
      "0.93326473\n",
      "[Epoch 44/50] [Batch 101/300] [D loss: 0.752253] [G loss: 0.471074] time: 1:06:07.584950\n",
      "0.92852813\n",
      "[Epoch 44/50] [Batch 102/300] [D loss: 0.752250] [G loss: 0.472437] time: 1:06:07.876996\n",
      "0.89822054\n",
      "[Epoch 44/50] [Batch 103/300] [D loss: 0.752258] [G loss: 0.469055] time: 1:06:08.195256\n",
      "0.94428253\n",
      "[Epoch 44/50] [Batch 104/300] [D loss: 0.752248] [G loss: 0.473418] time: 1:06:08.504874\n",
      "0.89006287\n",
      "[Epoch 44/50] [Batch 105/300] [D loss: 0.752248] [G loss: 0.475697] time: 1:06:08.788117\n",
      "0.9239848\n",
      "[Epoch 44/50] [Batch 106/300] [D loss: 0.752253] [G loss: 0.472614] time: 1:06:09.097509\n",
      "0.8972996\n",
      "[Epoch 44/50] [Batch 107/300] [D loss: 0.752252] [G loss: 0.473959] time: 1:06:09.379920\n",
      "0.9590616\n",
      "[Epoch 44/50] [Batch 108/300] [D loss: 0.752265] [G loss: 0.498951] time: 1:06:09.670633\n",
      "0.9562497\n",
      "[Epoch 44/50] [Batch 109/300] [D loss: 0.752267] [G loss: 0.471231] time: 1:06:09.974740\n",
      "0.9598579\n",
      "[Epoch 44/50] [Batch 110/300] [D loss: 0.752257] [G loss: 0.467558] time: 1:06:10.263128\n",
      "0.91895634\n",
      "[Epoch 44/50] [Batch 111/300] [D loss: 0.752252] [G loss: 0.469338] time: 1:06:10.560283\n",
      "0.90539604\n",
      "[Epoch 44/50] [Batch 112/300] [D loss: 0.752254] [G loss: 0.461598] time: 1:06:10.863364\n",
      "0.8885622\n",
      "[Epoch 44/50] [Batch 113/300] [D loss: 0.752254] [G loss: 0.473188] time: 1:06:11.169590\n",
      "0.95335746\n",
      "[Epoch 44/50] [Batch 114/300] [D loss: 0.752254] [G loss: 0.473516] time: 1:06:11.453863\n",
      "0.95563823\n",
      "[Epoch 44/50] [Batch 115/300] [D loss: 0.752257] [G loss: 0.472722] time: 1:06:11.758341\n",
      "0.9456789\n",
      "[Epoch 44/50] [Batch 116/300] [D loss: 0.752250] [G loss: 0.477164] time: 1:06:12.047780\n",
      "0.9387346\n",
      "[Epoch 44/50] [Batch 117/300] [D loss: 0.752258] [G loss: 0.471354] time: 1:06:12.356379\n",
      "0.9126515\n",
      "[Epoch 44/50] [Batch 118/300] [D loss: 0.752251] [G loss: 0.476879] time: 1:06:12.649072\n",
      "0.9286809\n",
      "[Epoch 44/50] [Batch 119/300] [D loss: 0.752262] [G loss: 0.481091] time: 1:06:12.935660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9029277\n",
      "[Epoch 44/50] [Batch 120/300] [D loss: 0.752251] [G loss: 0.475814] time: 1:06:13.249434\n",
      "0.8972411\n",
      "[Epoch 44/50] [Batch 121/300] [D loss: 0.752269] [G loss: 0.500878] time: 1:06:13.562325\n",
      "0.93491673\n",
      "[Epoch 44/50] [Batch 122/300] [D loss: 0.752253] [G loss: 0.475838] time: 1:06:13.862103\n",
      "0.9099346\n",
      "[Epoch 44/50] [Batch 123/300] [D loss: 0.752257] [G loss: 0.488251] time: 1:06:14.158606\n",
      "0.9056788\n",
      "[Epoch 44/50] [Batch 124/300] [D loss: 0.752242] [G loss: 0.478906] time: 1:06:14.452559\n",
      "0.9191014\n",
      "[Epoch 44/50] [Batch 125/300] [D loss: 0.752244] [G loss: 0.505082] time: 1:06:14.757858\n",
      "0.9055688\n",
      "[Epoch 44/50] [Batch 126/300] [D loss: 0.752263] [G loss: 0.479128] time: 1:06:15.051703\n",
      "0.93314475\n",
      "[Epoch 44/50] [Batch 127/300] [D loss: 0.752257] [G loss: 0.468283] time: 1:06:15.346401\n",
      "0.9140293\n",
      "[Epoch 44/50] [Batch 128/300] [D loss: 0.752272] [G loss: 0.506764] time: 1:06:15.635770\n",
      "0.918096\n",
      "[Epoch 44/50] [Batch 129/300] [D loss: 0.752255] [G loss: 0.469124] time: 1:06:15.927406\n",
      "0.91819\n",
      "[Epoch 44/50] [Batch 130/300] [D loss: 0.752253] [G loss: 0.466407] time: 1:06:16.221911\n",
      "0.9066968\n",
      "[Epoch 44/50] [Batch 131/300] [D loss: 0.752252] [G loss: 0.472521] time: 1:06:16.498013\n",
      "0.957786\n",
      "[Epoch 44/50] [Batch 132/300] [D loss: 0.752260] [G loss: 0.473323] time: 1:06:16.797433\n",
      "0.9455323\n",
      "[Epoch 44/50] [Batch 133/300] [D loss: 0.752258] [G loss: 0.472655] time: 1:06:17.079899\n",
      "0.8988939\n",
      "[Epoch 44/50] [Batch 134/300] [D loss: 0.752261] [G loss: 0.493199] time: 1:06:17.372448\n",
      "0.90119165\n",
      "[Epoch 44/50] [Batch 135/300] [D loss: 0.752256] [G loss: 0.477948] time: 1:06:17.669064\n",
      "0.95289224\n",
      "[Epoch 44/50] [Batch 136/300] [D loss: 0.752258] [G loss: 0.464360] time: 1:06:17.975190\n",
      "0.9097865\n",
      "[Epoch 44/50] [Batch 137/300] [D loss: 0.752252] [G loss: 0.469776] time: 1:06:18.277522\n",
      "0.93321013\n",
      "[Epoch 44/50] [Batch 138/300] [D loss: 0.752258] [G loss: 0.469875] time: 1:06:18.591176\n",
      "0.918161\n",
      "[Epoch 44/50] [Batch 139/300] [D loss: 0.752255] [G loss: 0.463995] time: 1:06:18.872968\n",
      "0.93702954\n",
      "[Epoch 44/50] [Batch 140/300] [D loss: 0.752251] [G loss: 0.471603] time: 1:06:19.158031\n",
      "0.93304425\n",
      "[Epoch 44/50] [Batch 141/300] [D loss: 0.752248] [G loss: 0.470173] time: 1:06:19.449375\n",
      "0.91233224\n",
      "[Epoch 44/50] [Batch 142/300] [D loss: 0.752246] [G loss: 0.466685] time: 1:06:19.758508\n",
      "0.90748286\n",
      "[Epoch 44/50] [Batch 143/300] [D loss: 0.752254] [G loss: 0.475886] time: 1:06:20.052429\n",
      "0.93794304\n",
      "[Epoch 44/50] [Batch 144/300] [D loss: 0.752256] [G loss: 0.467974] time: 1:06:20.356117\n",
      "0.9536028\n",
      "[Epoch 44/50] [Batch 145/300] [D loss: 0.752268] [G loss: 0.470841] time: 1:06:20.667386\n",
      "0.89500976\n",
      "[Epoch 44/50] [Batch 146/300] [D loss: 0.752258] [G loss: 0.481548] time: 1:06:20.952021\n",
      "0.90415144\n",
      "[Epoch 44/50] [Batch 147/300] [D loss: 0.752253] [G loss: 0.468872] time: 1:06:21.263400\n",
      "0.91186666\n",
      "[Epoch 44/50] [Batch 148/300] [D loss: 0.752250] [G loss: 0.474744] time: 1:06:21.567344\n",
      "0.9102316\n",
      "[Epoch 44/50] [Batch 149/300] [D loss: 0.752258] [G loss: 0.476595] time: 1:06:21.869511\n",
      "0.9089225\n",
      "[Epoch 44/50] [Batch 150/300] [D loss: 0.752259] [G loss: 0.464234] time: 1:06:22.181784\n",
      "0.88483316\n",
      "[Epoch 44/50] [Batch 151/300] [D loss: 0.752240] [G loss: 0.477378] time: 1:06:22.456260\n",
      "0.9447935\n",
      "[Epoch 44/50] [Batch 152/300] [D loss: 0.752252] [G loss: 0.479244] time: 1:06:22.752436\n",
      "0.94165546\n",
      "[Epoch 44/50] [Batch 153/300] [D loss: 0.752260] [G loss: 0.469547] time: 1:06:23.074838\n",
      "0.9123585\n",
      "[Epoch 44/50] [Batch 154/300] [D loss: 0.752248] [G loss: 0.479079] time: 1:06:23.356895\n",
      "0.95539427\n",
      "[Epoch 44/50] [Batch 155/300] [D loss: 0.752261] [G loss: 0.478973] time: 1:06:23.667908\n",
      "0.9827458\n",
      "[Epoch 44/50] [Batch 156/300] [D loss: 0.752246] [G loss: 0.472984] time: 1:06:23.956037\n",
      "0.95434004\n",
      "[Epoch 44/50] [Batch 157/300] [D loss: 0.752257] [G loss: 0.503388] time: 1:06:24.257636\n",
      "0.9410476\n",
      "[Epoch 44/50] [Batch 158/300] [D loss: 0.752249] [G loss: 0.469828] time: 1:06:24.567288\n",
      "0.9225407\n",
      "[Epoch 44/50] [Batch 159/300] [D loss: 0.752260] [G loss: 0.474710] time: 1:06:24.863224\n",
      "0.92418617\n",
      "[Epoch 44/50] [Batch 160/300] [D loss: 0.752257] [G loss: 0.466209] time: 1:06:25.174532\n",
      "0.9688001\n",
      "[Epoch 44/50] [Batch 161/300] [D loss: 0.752254] [G loss: 0.466589] time: 1:06:25.472707\n",
      "0.9254078\n",
      "[Epoch 44/50] [Batch 162/300] [D loss: 0.752253] [G loss: 0.483811] time: 1:06:25.770571\n",
      "0.90203744\n",
      "[Epoch 44/50] [Batch 163/300] [D loss: 0.752249] [G loss: 0.498408] time: 1:06:26.079113\n",
      "0.9422315\n",
      "[Epoch 44/50] [Batch 164/300] [D loss: 0.752252] [G loss: 0.465918] time: 1:06:26.380047\n",
      "0.9276758\n",
      "[Epoch 44/50] [Batch 165/300] [D loss: 0.752255] [G loss: 0.500754] time: 1:06:26.681854\n",
      "0.89051527\n",
      "[Epoch 44/50] [Batch 166/300] [D loss: 0.752258] [G loss: 0.532568] time: 1:06:26.985955\n",
      "0.88888675\n",
      "[Epoch 44/50] [Batch 167/300] [D loss: 0.752266] [G loss: 0.480439] time: 1:06:27.299581\n",
      "0.8903958\n",
      "[Epoch 44/50] [Batch 168/300] [D loss: 0.752257] [G loss: 0.480233] time: 1:06:27.583980\n",
      "0.9578882\n",
      "[Epoch 44/50] [Batch 169/300] [D loss: 0.752246] [G loss: 0.466958] time: 1:06:27.875849\n",
      "0.8886513\n",
      "[Epoch 44/50] [Batch 170/300] [D loss: 0.752258] [G loss: 0.474434] time: 1:06:28.157118\n",
      "0.9107433\n",
      "[Epoch 44/50] [Batch 171/300] [D loss: 0.752250] [G loss: 0.474530] time: 1:06:28.466250\n",
      "0.9351604\n",
      "[Epoch 44/50] [Batch 172/300] [D loss: 0.752249] [G loss: 0.483221] time: 1:06:28.742621\n",
      "0.949801\n",
      "[Epoch 44/50] [Batch 173/300] [D loss: 0.752253] [G loss: 0.488766] time: 1:06:29.023927\n",
      "0.9292328\n",
      "[Epoch 44/50] [Batch 174/300] [D loss: 0.752255] [G loss: 0.475735] time: 1:06:29.322505\n",
      "0.9627957\n",
      "[Epoch 44/50] [Batch 175/300] [D loss: 0.752259] [G loss: 0.503049] time: 1:06:29.621247\n",
      "0.93159145\n",
      "[Epoch 44/50] [Batch 176/300] [D loss: 0.752251] [G loss: 0.482122] time: 1:06:29.913721\n",
      "0.9372709\n",
      "[Epoch 44/50] [Batch 177/300] [D loss: 0.752256] [G loss: 0.494267] time: 1:06:30.219668\n",
      "0.9176607\n",
      "[Epoch 44/50] [Batch 178/300] [D loss: 0.752255] [G loss: 0.468715] time: 1:06:30.510897\n",
      "0.91651803\n",
      "[Epoch 44/50] [Batch 179/300] [D loss: 0.752250] [G loss: 0.481024] time: 1:06:30.813027\n",
      "0.9248283\n",
      "[Epoch 44/50] [Batch 180/300] [D loss: 0.752250] [G loss: 0.464889] time: 1:06:31.113341\n",
      "0.9047508\n",
      "[Epoch 44/50] [Batch 181/300] [D loss: 0.752253] [G loss: 0.467805] time: 1:06:31.428375\n",
      "0.9105527\n",
      "[Epoch 44/50] [Batch 182/300] [D loss: 0.752258] [G loss: 0.480554] time: 1:06:31.729529\n",
      "0.9349802\n",
      "[Epoch 44/50] [Batch 183/300] [D loss: 0.752259] [G loss: 0.479019] time: 1:06:32.015515\n",
      "0.93269414\n",
      "[Epoch 44/50] [Batch 184/300] [D loss: 0.752246] [G loss: 0.472871] time: 1:06:32.323000\n",
      "0.9377282\n",
      "[Epoch 44/50] [Batch 185/300] [D loss: 0.752256] [G loss: 0.467114] time: 1:06:32.631493\n",
      "0.87226075\n",
      "[Epoch 44/50] [Batch 186/300] [D loss: 0.752253] [G loss: 0.481134] time: 1:06:32.933860\n",
      "0.9130725\n",
      "[Epoch 44/50] [Batch 187/300] [D loss: 0.752255] [G loss: 0.483501] time: 1:06:33.231370\n",
      "0.93770415\n",
      "[Epoch 44/50] [Batch 188/300] [D loss: 0.752240] [G loss: 0.463546] time: 1:06:33.497904\n",
      "0.91558456\n",
      "[Epoch 44/50] [Batch 189/300] [D loss: 0.752241] [G loss: 0.478194] time: 1:06:33.782920\n",
      "0.9111261\n",
      "[Epoch 44/50] [Batch 190/300] [D loss: 0.752248] [G loss: 0.488448] time: 1:06:34.079232\n",
      "0.887785\n",
      "[Epoch 44/50] [Batch 191/300] [D loss: 0.752254] [G loss: 0.471442] time: 1:06:34.370949\n",
      "0.93971735\n",
      "[Epoch 44/50] [Batch 192/300] [D loss: 0.752247] [G loss: 0.465723] time: 1:06:34.667107\n",
      "0.90047383\n",
      "[Epoch 44/50] [Batch 193/300] [D loss: 0.752251] [G loss: 0.473280] time: 1:06:34.970522\n",
      "0.91391516\n",
      "[Epoch 44/50] [Batch 194/300] [D loss: 0.752245] [G loss: 0.497109] time: 1:06:35.270019\n",
      "0.91421294\n",
      "[Epoch 44/50] [Batch 195/300] [D loss: 0.752248] [G loss: 0.493332] time: 1:06:35.569637\n",
      "0.9454414\n",
      "[Epoch 44/50] [Batch 196/300] [D loss: 0.752252] [G loss: 0.464867] time: 1:06:35.886990\n",
      "0.9361177\n",
      "[Epoch 44/50] [Batch 197/300] [D loss: 0.752252] [G loss: 0.489658] time: 1:06:36.201876\n",
      "0.91303563\n",
      "[Epoch 44/50] [Batch 198/300] [D loss: 0.752250] [G loss: 0.483654] time: 1:06:36.518751\n",
      "0.909177\n",
      "[Epoch 44/50] [Batch 199/300] [D loss: 0.752263] [G loss: 0.484236] time: 1:06:36.811117\n",
      "0.95262367\n",
      "[Epoch 44/50] [Batch 200/300] [D loss: 0.752246] [G loss: 0.479186] time: 1:06:37.116007\n",
      "0.9111622\n",
      "[Epoch 44/50] [Batch 201/300] [D loss: 0.752256] [G loss: 0.481479] time: 1:06:37.416061\n",
      "0.8906372\n",
      "[Epoch 44/50] [Batch 202/300] [D loss: 0.752248] [G loss: 0.477508] time: 1:06:37.701096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9398077\n",
      "[Epoch 44/50] [Batch 203/300] [D loss: 0.752247] [G loss: 0.481173] time: 1:06:38.011355\n",
      "0.9329408\n",
      "[Epoch 44/50] [Batch 204/300] [D loss: 0.752262] [G loss: 0.472241] time: 1:06:38.324167\n",
      "0.9349611\n",
      "[Epoch 44/50] [Batch 205/300] [D loss: 0.752246] [G loss: 0.466645] time: 1:06:38.624900\n",
      "0.93332124\n",
      "[Epoch 44/50] [Batch 206/300] [D loss: 0.752252] [G loss: 0.473933] time: 1:06:38.932677\n",
      "0.94000864\n",
      "[Epoch 44/50] [Batch 207/300] [D loss: 0.752259] [G loss: 0.478441] time: 1:06:39.242474\n",
      "0.9485114\n",
      "[Epoch 44/50] [Batch 208/300] [D loss: 0.752244] [G loss: 0.480892] time: 1:06:39.565451\n",
      "0.9609416\n",
      "[Epoch 44/50] [Batch 209/300] [D loss: 0.752254] [G loss: 0.474059] time: 1:06:39.862461\n",
      "0.94856983\n",
      "[Epoch 44/50] [Batch 210/300] [D loss: 0.752258] [G loss: 0.477147] time: 1:06:40.181125\n",
      "0.92535454\n",
      "[Epoch 44/50] [Batch 211/300] [D loss: 0.752249] [G loss: 0.476647] time: 1:06:40.475308\n",
      "0.98333424\n",
      "[Epoch 44/50] [Batch 212/300] [D loss: 0.752255] [G loss: 0.498958] time: 1:06:40.778117\n",
      "0.9233045\n",
      "[Epoch 44/50] [Batch 213/300] [D loss: 0.752258] [G loss: 0.481952] time: 1:06:41.057086\n",
      "0.8947644\n",
      "[Epoch 44/50] [Batch 214/300] [D loss: 0.752251] [G loss: 0.482626] time: 1:06:41.357244\n",
      "0.9358826\n",
      "[Epoch 44/50] [Batch 215/300] [D loss: 0.752264] [G loss: 0.482734] time: 1:06:41.655915\n",
      "0.94634175\n",
      "[Epoch 44/50] [Batch 216/300] [D loss: 0.752249] [G loss: 0.478126] time: 1:06:41.956847\n",
      "0.9047844\n",
      "[Epoch 44/50] [Batch 217/300] [D loss: 0.752270] [G loss: 0.479994] time: 1:06:42.249889\n",
      "0.97623414\n",
      "[Epoch 44/50] [Batch 218/300] [D loss: 0.752251] [G loss: 0.473201] time: 1:06:42.561151\n",
      "0.9082077\n",
      "[Epoch 44/50] [Batch 219/300] [D loss: 0.752252] [G loss: 0.476426] time: 1:06:42.845256\n",
      "0.9250901\n",
      "[Epoch 44/50] [Batch 220/300] [D loss: 0.752247] [G loss: 0.497656] time: 1:06:43.141689\n",
      "0.90534145\n",
      "[Epoch 44/50] [Batch 221/300] [D loss: 0.752259] [G loss: 0.478105] time: 1:06:43.443018\n",
      "0.91390306\n",
      "[Epoch 44/50] [Batch 222/300] [D loss: 0.752255] [G loss: 0.477359] time: 1:06:43.749621\n",
      "0.89046806\n",
      "[Epoch 44/50] [Batch 223/300] [D loss: 0.752250] [G loss: 0.481845] time: 1:06:44.060050\n",
      "0.95885545\n",
      "[Epoch 44/50] [Batch 224/300] [D loss: 0.752244] [G loss: 0.478038] time: 1:06:44.358922\n",
      "0.9480131\n",
      "[Epoch 44/50] [Batch 225/300] [D loss: 0.752254] [G loss: 0.473354] time: 1:06:44.660623\n",
      "0.96874356\n",
      "[Epoch 44/50] [Batch 226/300] [D loss: 0.752266] [G loss: 0.479642] time: 1:06:44.953495\n",
      "0.93963355\n",
      "[Epoch 44/50] [Batch 227/300] [D loss: 0.752257] [G loss: 0.491115] time: 1:06:45.257605\n",
      "0.87650055\n",
      "[Epoch 44/50] [Batch 228/300] [D loss: 0.752247] [G loss: 0.485933] time: 1:06:45.545210\n",
      "0.871939\n",
      "[Epoch 44/50] [Batch 229/300] [D loss: 0.752260] [G loss: 0.471031] time: 1:06:45.847011\n",
      "0.9458774\n",
      "[Epoch 44/50] [Batch 230/300] [D loss: 0.752265] [G loss: 0.477483] time: 1:06:46.134300\n",
      "0.92275923\n",
      "[Epoch 44/50] [Batch 231/300] [D loss: 0.752249] [G loss: 0.474764] time: 1:06:46.435713\n",
      "0.9714999\n",
      "[Epoch 44/50] [Batch 232/300] [D loss: 0.752261] [G loss: 0.475220] time: 1:06:46.736625\n",
      "0.9308362\n",
      "[Epoch 44/50] [Batch 233/300] [D loss: 0.752245] [G loss: 0.512051] time: 1:06:47.049853\n",
      "0.8964667\n",
      "[Epoch 44/50] [Batch 234/300] [D loss: 0.752258] [G loss: 0.471401] time: 1:06:47.336381\n",
      "0.9288693\n",
      "[Epoch 44/50] [Batch 235/300] [D loss: 0.752255] [G loss: 0.483755] time: 1:06:47.635360\n",
      "0.90002847\n",
      "[Epoch 44/50] [Batch 236/300] [D loss: 0.752251] [G loss: 0.469879] time: 1:06:47.938264\n",
      "0.94107825\n",
      "[Epoch 44/50] [Batch 237/300] [D loss: 0.752251] [G loss: 0.481191] time: 1:06:48.230815\n",
      "0.9601052\n",
      "[Epoch 44/50] [Batch 238/300] [D loss: 0.752255] [G loss: 0.480936] time: 1:06:48.525990\n",
      "0.892488\n",
      "[Epoch 44/50] [Batch 239/300] [D loss: 0.752259] [G loss: 0.479800] time: 1:06:48.835147\n",
      "0.9170553\n",
      "[Epoch 44/50] [Batch 240/300] [D loss: 0.752269] [G loss: 0.468204] time: 1:06:49.139638\n",
      "0.91721755\n",
      "[Epoch 44/50] [Batch 241/300] [D loss: 0.752254] [G loss: 0.484958] time: 1:06:49.433419\n",
      "0.9310005\n",
      "[Epoch 44/50] [Batch 242/300] [D loss: 0.752263] [G loss: 0.478788] time: 1:06:49.736568\n",
      "0.94803613\n",
      "[Epoch 44/50] [Batch 243/300] [D loss: 0.752254] [G loss: 0.475947] time: 1:06:50.041642\n",
      "0.8961032\n",
      "[Epoch 44/50] [Batch 244/300] [D loss: 0.752243] [G loss: 0.480603] time: 1:06:50.333656\n",
      "0.87749296\n",
      "[Epoch 44/50] [Batch 245/300] [D loss: 0.752240] [G loss: 0.481461] time: 1:06:50.641463\n",
      "0.905046\n",
      "[Epoch 44/50] [Batch 246/300] [D loss: 0.752251] [G loss: 0.488613] time: 1:06:50.950676\n",
      "0.9126632\n",
      "[Epoch 44/50] [Batch 247/300] [D loss: 0.752240] [G loss: 0.468664] time: 1:06:51.224062\n",
      "0.9141405\n",
      "[Epoch 44/50] [Batch 248/300] [D loss: 0.752264] [G loss: 0.469561] time: 1:06:51.518881\n",
      "0.95246464\n",
      "[Epoch 44/50] [Batch 249/300] [D loss: 0.752256] [G loss: 0.492782] time: 1:06:51.815673\n",
      "0.91446704\n",
      "[Epoch 44/50] [Batch 250/300] [D loss: 0.752247] [G loss: 0.483855] time: 1:06:52.108286\n",
      "0.9239214\n",
      "[Epoch 44/50] [Batch 251/300] [D loss: 0.752259] [G loss: 0.481914] time: 1:06:52.397471\n",
      "0.9532544\n",
      "[Epoch 44/50] [Batch 252/300] [D loss: 0.752258] [G loss: 0.498940] time: 1:06:52.695267\n",
      "0.91138864\n",
      "[Epoch 44/50] [Batch 253/300] [D loss: 0.752256] [G loss: 0.481768] time: 1:06:52.973662\n",
      "0.97021157\n",
      "[Epoch 44/50] [Batch 254/300] [D loss: 0.752240] [G loss: 0.471295] time: 1:06:53.256922\n",
      "0.91525394\n",
      "[Epoch 44/50] [Batch 255/300] [D loss: 0.752247] [G loss: 0.474794] time: 1:06:53.560314\n",
      "0.9149249\n",
      "[Epoch 44/50] [Batch 256/300] [D loss: 0.752266] [G loss: 0.477700] time: 1:06:53.859939\n",
      "0.94499034\n",
      "[Epoch 44/50] [Batch 257/300] [D loss: 0.752253] [G loss: 0.467383] time: 1:06:54.151333\n",
      "0.8947037\n",
      "[Epoch 44/50] [Batch 258/300] [D loss: 0.752248] [G loss: 0.474744] time: 1:06:54.437824\n",
      "0.9133397\n",
      "[Epoch 44/50] [Batch 259/300] [D loss: 0.752251] [G loss: 0.474727] time: 1:06:54.723873\n",
      "0.953317\n",
      "[Epoch 44/50] [Batch 260/300] [D loss: 0.752247] [G loss: 0.486380] time: 1:06:55.024452\n",
      "0.8987103\n",
      "[Epoch 44/50] [Batch 261/300] [D loss: 0.752254] [G loss: 0.490341] time: 1:06:55.330383\n",
      "0.950785\n",
      "[Epoch 44/50] [Batch 262/300] [D loss: 0.752246] [G loss: 0.475488] time: 1:06:55.637213\n",
      "0.94198734\n",
      "[Epoch 44/50] [Batch 263/300] [D loss: 0.752261] [G loss: 0.472597] time: 1:06:55.944480\n",
      "0.9600301\n",
      "[Epoch 44/50] [Batch 264/300] [D loss: 0.752261] [G loss: 0.467702] time: 1:06:56.244274\n",
      "0.93434113\n",
      "[Epoch 44/50] [Batch 265/300] [D loss: 0.752254] [G loss: 0.489198] time: 1:06:56.547037\n",
      "0.9430196\n",
      "[Epoch 44/50] [Batch 266/300] [D loss: 0.752241] [G loss: 0.466624] time: 1:06:56.839031\n",
      "0.96431637\n",
      "[Epoch 44/50] [Batch 267/300] [D loss: 0.752251] [G loss: 0.500848] time: 1:06:57.138200\n",
      "0.94201595\n",
      "[Epoch 44/50] [Batch 268/300] [D loss: 0.752258] [G loss: 0.477274] time: 1:06:57.446980\n",
      "0.9477544\n",
      "[Epoch 44/50] [Batch 269/300] [D loss: 0.752267] [G loss: 0.478902] time: 1:06:57.762168\n",
      "0.93294406\n",
      "[Epoch 44/50] [Batch 270/300] [D loss: 0.752244] [G loss: 0.475123] time: 1:06:58.071318\n",
      "0.91689605\n",
      "[Epoch 44/50] [Batch 271/300] [D loss: 0.752256] [G loss: 0.484815] time: 1:06:58.363621\n",
      "0.9356397\n",
      "[Epoch 44/50] [Batch 272/300] [D loss: 0.752267] [G loss: 0.494977] time: 1:06:58.662573\n",
      "0.91473675\n",
      "[Epoch 44/50] [Batch 273/300] [D loss: 0.752250] [G loss: 0.467744] time: 1:06:58.970022\n",
      "0.8809636\n",
      "[Epoch 44/50] [Batch 274/300] [D loss: 0.752241] [G loss: 0.479282] time: 1:06:59.270484\n",
      "0.92985684\n",
      "[Epoch 44/50] [Batch 275/300] [D loss: 0.752258] [G loss: 0.467146] time: 1:06:59.569579\n",
      "0.9480124\n",
      "[Epoch 44/50] [Batch 276/300] [D loss: 0.752257] [G loss: 0.494026] time: 1:06:59.864950\n",
      "0.91571826\n",
      "[Epoch 44/50] [Batch 277/300] [D loss: 0.752280] [G loss: 0.466455] time: 1:07:00.148907\n",
      "0.88757724\n",
      "[Epoch 44/50] [Batch 278/300] [D loss: 0.752264] [G loss: 0.479285] time: 1:07:00.444036\n",
      "0.8875754\n",
      "[Epoch 44/50] [Batch 279/300] [D loss: 0.752249] [G loss: 0.482527] time: 1:07:00.743466\n",
      "0.9521828\n",
      "[Epoch 44/50] [Batch 280/300] [D loss: 0.752242] [G loss: 0.478599] time: 1:07:01.038902\n",
      "0.9335613\n",
      "[Epoch 44/50] [Batch 281/300] [D loss: 0.752253] [G loss: 0.480284] time: 1:07:01.316915\n",
      "0.89523387\n",
      "[Epoch 44/50] [Batch 282/300] [D loss: 0.752257] [G loss: 0.472139] time: 1:07:01.612658\n",
      "0.9214602\n",
      "[Epoch 44/50] [Batch 283/300] [D loss: 0.752251] [G loss: 0.472890] time: 1:07:01.892908\n",
      "0.94055885\n",
      "[Epoch 44/50] [Batch 284/300] [D loss: 0.752258] [G loss: 0.473127] time: 1:07:02.182565\n",
      "0.9560608\n",
      "[Epoch 44/50] [Batch 285/300] [D loss: 0.752255] [G loss: 0.477933] time: 1:07:02.472787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90836143\n",
      "[Epoch 44/50] [Batch 286/300] [D loss: 0.752243] [G loss: 0.492304] time: 1:07:02.767460\n",
      "0.9316507\n",
      "[Epoch 44/50] [Batch 287/300] [D loss: 0.752256] [G loss: 0.473691] time: 1:07:03.055766\n",
      "0.9410618\n",
      "[Epoch 44/50] [Batch 288/300] [D loss: 0.752246] [G loss: 0.482265] time: 1:07:03.364901\n",
      "0.945787\n",
      "[Epoch 44/50] [Batch 289/300] [D loss: 0.752254] [G loss: 0.499598] time: 1:07:03.667843\n",
      "0.94280195\n",
      "[Epoch 44/50] [Batch 290/300] [D loss: 0.752241] [G loss: 0.494163] time: 1:07:03.962234\n",
      "0.887966\n",
      "[Epoch 44/50] [Batch 291/300] [D loss: 0.752254] [G loss: 0.488876] time: 1:07:04.249293\n",
      "0.9470214\n",
      "[Epoch 44/50] [Batch 292/300] [D loss: 0.752246] [G loss: 0.479061] time: 1:07:04.535958\n",
      "0.924721\n",
      "[Epoch 44/50] [Batch 293/300] [D loss: 0.752250] [G loss: 0.485649] time: 1:07:04.835739\n",
      "0.91447306\n",
      "[Epoch 44/50] [Batch 294/300] [D loss: 0.752248] [G loss: 0.489593] time: 1:07:05.104438\n",
      "0.91757244\n",
      "[Epoch 44/50] [Batch 295/300] [D loss: 0.752243] [G loss: 0.478865] time: 1:07:05.399590\n",
      "0.9158587\n",
      "[Epoch 44/50] [Batch 296/300] [D loss: 0.752251] [G loss: 0.481901] time: 1:07:05.700092\n",
      "0.9303105\n",
      "[Epoch 44/50] [Batch 297/300] [D loss: 0.752257] [G loss: 0.485686] time: 1:07:06.008608\n",
      "0.89872485\n",
      "[Epoch 44/50] [Batch 298/300] [D loss: 0.752262] [G loss: 0.495100] time: 1:07:06.299821\n",
      "0.9468837\n",
      "[Epoch 44/50] [Batch 299/300] [D loss: 0.752273] [G loss: 0.487310] time: 1:07:06.583983\n",
      "0.9128\n",
      "[Epoch 45/50] [Batch 0/300] [D loss: 0.752258] [G loss: 0.493611] time: 1:07:06.873721\n",
      "0.92235523\n",
      "[Epoch 45/50] [Batch 1/300] [D loss: 0.752254] [G loss: 0.473341] time: 1:07:07.166937\n",
      "0.941746\n",
      "[Epoch 45/50] [Batch 2/300] [D loss: 0.752263] [G loss: 0.483418] time: 1:07:07.473629\n",
      "0.93327856\n",
      "[Epoch 45/50] [Batch 3/300] [D loss: 0.752248] [G loss: 0.479037] time: 1:07:07.774837\n",
      "0.87218136\n",
      "[Epoch 45/50] [Batch 4/300] [D loss: 0.752253] [G loss: 0.474934] time: 1:07:08.068739\n",
      "0.91265106\n",
      "[Epoch 45/50] [Batch 5/300] [D loss: 0.752259] [G loss: 0.513743] time: 1:07:08.368226\n",
      "0.89278895\n",
      "[Epoch 45/50] [Batch 6/300] [D loss: 0.752247] [G loss: 0.491687] time: 1:07:08.683222\n",
      "0.9628028\n",
      "[Epoch 45/50] [Batch 7/300] [D loss: 0.752255] [G loss: 0.484584] time: 1:07:08.983621\n",
      "0.92453665\n",
      "[Epoch 45/50] [Batch 8/300] [D loss: 0.752247] [G loss: 0.481722] time: 1:07:09.275025\n",
      "0.8924987\n",
      "[Epoch 45/50] [Batch 9/300] [D loss: 0.752258] [G loss: 0.475431] time: 1:07:09.566052\n",
      "0.90576595\n",
      "[Epoch 45/50] [Batch 10/300] [D loss: 0.752255] [G loss: 0.468687] time: 1:07:09.875388\n",
      "0.900256\n",
      "[Epoch 45/50] [Batch 11/300] [D loss: 0.752244] [G loss: 0.485569] time: 1:07:10.175995\n",
      "0.9247461\n",
      "[Epoch 45/50] [Batch 12/300] [D loss: 0.752259] [G loss: 0.496226] time: 1:07:10.469606\n",
      "0.95243526\n",
      "[Epoch 45/50] [Batch 13/300] [D loss: 0.752241] [G loss: 0.485849] time: 1:07:10.768113\n",
      "0.9085594\n",
      "[Epoch 45/50] [Batch 14/300] [D loss: 0.752257] [G loss: 0.479264] time: 1:07:11.060290\n",
      "0.8872373\n",
      "[Epoch 45/50] [Batch 15/300] [D loss: 0.752248] [G loss: 0.474483] time: 1:07:11.350933\n",
      "0.90893143\n",
      "[Epoch 45/50] [Batch 16/300] [D loss: 0.752257] [G loss: 0.484788] time: 1:07:11.650397\n",
      "0.929311\n",
      "[Epoch 45/50] [Batch 17/300] [D loss: 0.752249] [G loss: 0.474542] time: 1:07:11.944811\n",
      "0.90132093\n",
      "[Epoch 45/50] [Batch 18/300] [D loss: 0.752255] [G loss: 0.490552] time: 1:07:12.228729\n",
      "0.9524403\n",
      "[Epoch 45/50] [Batch 19/300] [D loss: 0.752250] [G loss: 0.480605] time: 1:07:12.528036\n",
      "0.9406856\n",
      "[Epoch 45/50] [Batch 20/300] [D loss: 0.752252] [G loss: 0.479452] time: 1:07:12.826165\n",
      "0.91052747\n",
      "[Epoch 45/50] [Batch 21/300] [D loss: 0.752261] [G loss: 0.483267] time: 1:07:13.103759\n",
      "0.9367494\n",
      "[Epoch 45/50] [Batch 22/300] [D loss: 0.752243] [G loss: 0.521575] time: 1:07:13.389973\n",
      "0.9424608\n",
      "[Epoch 45/50] [Batch 23/300] [D loss: 0.752251] [G loss: 0.479186] time: 1:07:13.671808\n",
      "0.9272871\n",
      "[Epoch 45/50] [Batch 24/300] [D loss: 0.752253] [G loss: 0.505900] time: 1:07:13.947861\n",
      "0.8930733\n",
      "[Epoch 45/50] [Batch 25/300] [D loss: 0.752248] [G loss: 0.502383] time: 1:07:14.236661\n",
      "0.8947718\n",
      "[Epoch 45/50] [Batch 26/300] [D loss: 0.752248] [G loss: 0.490317] time: 1:07:14.522612\n",
      "0.9126646\n",
      "[Epoch 45/50] [Batch 27/300] [D loss: 0.752241] [G loss: 0.477568] time: 1:07:14.823228\n",
      "0.94271535\n",
      "[Epoch 45/50] [Batch 28/300] [D loss: 0.752263] [G loss: 0.466536] time: 1:07:15.104718\n",
      "0.8853062\n",
      "[Epoch 45/50] [Batch 29/300] [D loss: 0.752253] [G loss: 0.476509] time: 1:07:15.406194\n",
      "0.9159438\n",
      "[Epoch 45/50] [Batch 30/300] [D loss: 0.752248] [G loss: 0.473492] time: 1:07:15.707802\n",
      "0.95364577\n",
      "[Epoch 45/50] [Batch 31/300] [D loss: 0.752260] [G loss: 0.478527] time: 1:07:16.008972\n",
      "0.9378106\n",
      "[Epoch 45/50] [Batch 32/300] [D loss: 0.752258] [G loss: 0.482125] time: 1:07:16.313818\n",
      "0.934757\n",
      "[Epoch 45/50] [Batch 33/300] [D loss: 0.752252] [G loss: 0.477648] time: 1:07:16.611006\n",
      "0.9392423\n",
      "[Epoch 45/50] [Batch 34/300] [D loss: 0.752250] [G loss: 0.469095] time: 1:07:16.906049\n",
      "0.9201493\n",
      "[Epoch 45/50] [Batch 35/300] [D loss: 0.752254] [G loss: 0.469540] time: 1:07:17.211160\n",
      "0.93236184\n",
      "[Epoch 45/50] [Batch 36/300] [D loss: 0.752255] [G loss: 0.475333] time: 1:07:17.506570\n",
      "0.9090121\n",
      "[Epoch 45/50] [Batch 37/300] [D loss: 0.752245] [G loss: 0.476520] time: 1:07:17.802389\n",
      "0.9446645\n",
      "[Epoch 45/50] [Batch 38/300] [D loss: 0.752259] [G loss: 0.478161] time: 1:07:18.085524\n",
      "0.9296747\n",
      "[Epoch 45/50] [Batch 39/300] [D loss: 0.752241] [G loss: 0.468960] time: 1:07:18.367233\n",
      "0.9530787\n",
      "[Epoch 45/50] [Batch 40/300] [D loss: 0.752237] [G loss: 0.491593] time: 1:07:18.668384\n",
      "0.9055373\n",
      "[Epoch 45/50] [Batch 41/300] [D loss: 0.752253] [G loss: 0.474224] time: 1:07:18.960775\n",
      "0.9090998\n",
      "[Epoch 45/50] [Batch 42/300] [D loss: 0.752256] [G loss: 0.472406] time: 1:07:19.273589\n",
      "0.9350536\n",
      "[Epoch 45/50] [Batch 43/300] [D loss: 0.752250] [G loss: 0.486963] time: 1:07:19.580194\n",
      "0.90540624\n",
      "[Epoch 45/50] [Batch 45/300] [D loss: 0.752243] [G loss: 0.466237] time: 1:07:19.871975\n",
      "0.86827326\n",
      "[Epoch 45/50] [Batch 46/300] [D loss: 0.752250] [G loss: 0.473874] time: 1:07:20.170548\n",
      "0.92165774\n",
      "[Epoch 45/50] [Batch 47/300] [D loss: 0.752240] [G loss: 0.488542] time: 1:07:20.469037\n",
      "0.91781855\n",
      "[Epoch 45/50] [Batch 48/300] [D loss: 0.752245] [G loss: 0.465555] time: 1:07:20.750508\n",
      "0.9065037\n",
      "[Epoch 45/50] [Batch 49/300] [D loss: 0.752251] [G loss: 0.478730] time: 1:07:21.054164\n",
      "0.918873\n",
      "[Epoch 45/50] [Batch 50/300] [D loss: 0.752266] [G loss: 0.467168] time: 1:07:21.345388\n",
      "0.9061494\n",
      "[Epoch 45/50] [Batch 51/300] [D loss: 0.752262] [G loss: 0.471273] time: 1:07:21.643591\n",
      "0.9056453\n",
      "[Epoch 45/50] [Batch 52/300] [D loss: 0.752252] [G loss: 0.472408] time: 1:07:21.927837\n",
      "0.9311273\n",
      "[Epoch 45/50] [Batch 53/300] [D loss: 0.752249] [G loss: 0.483936] time: 1:07:22.238677\n",
      "0.9599382\n",
      "[Epoch 45/50] [Batch 54/300] [D loss: 0.752241] [G loss: 0.478481] time: 1:07:22.666449\n",
      "0.9464759\n",
      "[Epoch 45/50] [Batch 55/300] [D loss: 0.752246] [G loss: 0.477772] time: 1:07:22.963473\n",
      "0.97094554\n",
      "[Epoch 45/50] [Batch 56/300] [D loss: 0.752260] [G loss: 0.469669] time: 1:07:23.252389\n",
      "0.9140172\n",
      "[Epoch 45/50] [Batch 57/300] [D loss: 0.752255] [G loss: 0.483594] time: 1:07:23.548053\n",
      "0.86215276\n",
      "[Epoch 45/50] [Batch 58/300] [D loss: 0.752252] [G loss: 0.472267] time: 1:07:23.835119\n",
      "0.96199226\n",
      "[Epoch 45/50] [Batch 59/300] [D loss: 0.752257] [G loss: 0.489009] time: 1:07:24.135507\n",
      "0.90561604\n",
      "[Epoch 45/50] [Batch 60/300] [D loss: 0.752250] [G loss: 0.479124] time: 1:07:24.421917\n",
      "0.90573865\n",
      "[Epoch 45/50] [Batch 61/300] [D loss: 0.752249] [G loss: 0.473918] time: 1:07:24.726282\n",
      "0.9030531\n",
      "[Epoch 45/50] [Batch 62/300] [D loss: 0.752244] [G loss: 0.473938] time: 1:07:25.042511\n",
      "0.91743827\n",
      "[Epoch 45/50] [Batch 63/300] [D loss: 0.752250] [G loss: 0.476285] time: 1:07:25.337999\n",
      "0.9169205\n",
      "[Epoch 45/50] [Batch 64/300] [D loss: 0.752247] [G loss: 0.498584] time: 1:07:25.637994\n",
      "0.95234257\n",
      "[Epoch 45/50] [Batch 65/300] [D loss: 0.752253] [G loss: 0.494363] time: 1:07:25.926067\n",
      "0.9590402\n",
      "[Epoch 45/50] [Batch 66/300] [D loss: 0.752250] [G loss: 0.473222] time: 1:07:26.226552\n",
      "0.93660897\n",
      "[Epoch 45/50] [Batch 67/300] [D loss: 0.752254] [G loss: 0.471852] time: 1:07:26.500897\n",
      "0.9072633\n",
      "[Epoch 45/50] [Batch 68/300] [D loss: 0.752250] [G loss: 0.466875] time: 1:07:26.790382\n",
      "0.883735\n",
      "[Epoch 45/50] [Batch 69/300] [D loss: 0.752260] [G loss: 0.475375] time: 1:07:27.100069\n",
      "0.9485791\n",
      "[Epoch 45/50] [Batch 70/300] [D loss: 0.752256] [G loss: 0.471773] time: 1:07:27.403700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88385993\n",
      "[Epoch 45/50] [Batch 71/300] [D loss: 0.752248] [G loss: 0.471279] time: 1:07:27.710874\n",
      "0.9476865\n",
      "[Epoch 45/50] [Batch 72/300] [D loss: 0.752257] [G loss: 0.475790] time: 1:07:28.028682\n",
      "0.8767247\n",
      "[Epoch 45/50] [Batch 73/300] [D loss: 0.752256] [G loss: 0.467965] time: 1:07:28.326817\n",
      "0.9319498\n",
      "[Epoch 45/50] [Batch 74/300] [D loss: 0.752252] [G loss: 0.472249] time: 1:07:28.632227\n",
      "0.93488026\n",
      "[Epoch 45/50] [Batch 75/300] [D loss: 0.752245] [G loss: 0.478148] time: 1:07:28.933416\n",
      "0.89947754\n",
      "[Epoch 45/50] [Batch 76/300] [D loss: 0.752257] [G loss: 0.468315] time: 1:07:29.236192\n",
      "0.9355998\n",
      "[Epoch 45/50] [Batch 77/300] [D loss: 0.752247] [G loss: 0.469807] time: 1:07:29.538400\n",
      "0.9480114\n",
      "[Epoch 45/50] [Batch 78/300] [D loss: 0.752255] [G loss: 0.469716] time: 1:07:29.831641\n",
      "0.9392302\n",
      "[Epoch 45/50] [Batch 79/300] [D loss: 0.752257] [G loss: 0.483531] time: 1:07:30.137802\n",
      "0.9469943\n",
      "[Epoch 45/50] [Batch 80/300] [D loss: 0.752252] [G loss: 0.464482] time: 1:07:30.446349\n",
      "0.94225043\n",
      "[Epoch 45/50] [Batch 81/300] [D loss: 0.752248] [G loss: 0.467270] time: 1:07:30.751908\n",
      "0.8917256\n",
      "[Epoch 45/50] [Batch 82/300] [D loss: 0.752241] [G loss: 0.475869] time: 1:07:31.046079\n",
      "0.9830599\n",
      "[Epoch 45/50] [Batch 83/300] [D loss: 0.752251] [G loss: 0.478825] time: 1:07:31.344878\n",
      "0.93282574\n",
      "[Epoch 45/50] [Batch 84/300] [D loss: 0.752247] [G loss: 0.487161] time: 1:07:31.653403\n",
      "0.95418125\n",
      "[Epoch 45/50] [Batch 85/300] [D loss: 0.752250] [G loss: 0.474663] time: 1:07:31.948447\n",
      "0.8999892\n",
      "[Epoch 45/50] [Batch 86/300] [D loss: 0.752260] [G loss: 0.465709] time: 1:07:32.232932\n",
      "0.93149644\n",
      "[Epoch 45/50] [Batch 87/300] [D loss: 0.752246] [G loss: 0.466123] time: 1:07:32.545724\n",
      "0.9365135\n",
      "[Epoch 45/50] [Batch 88/300] [D loss: 0.752261] [G loss: 0.478357] time: 1:07:32.839989\n",
      "0.9644416\n",
      "[Epoch 45/50] [Batch 89/300] [D loss: 0.752245] [G loss: 0.465648] time: 1:07:33.123320\n",
      "0.8731987\n",
      "[Epoch 45/50] [Batch 90/300] [D loss: 0.752261] [G loss: 0.477996] time: 1:07:33.407621\n",
      "0.8938773\n",
      "[Epoch 45/50] [Batch 91/300] [D loss: 0.752245] [G loss: 0.496920] time: 1:07:33.701522\n",
      "0.9713128\n",
      "[Epoch 45/50] [Batch 92/300] [D loss: 0.752251] [G loss: 0.471501] time: 1:07:34.010205\n",
      "0.8908101\n",
      "[Epoch 45/50] [Batch 93/300] [D loss: 0.752257] [G loss: 0.485467] time: 1:07:34.307695\n",
      "0.9319096\n",
      "[Epoch 45/50] [Batch 94/300] [D loss: 0.752248] [G loss: 0.485440] time: 1:07:34.614208\n",
      "0.960212\n",
      "[Epoch 45/50] [Batch 95/300] [D loss: 0.752244] [G loss: 0.481502] time: 1:07:34.908727\n",
      "0.88050264\n",
      "[Epoch 45/50] [Batch 96/300] [D loss: 0.752237] [G loss: 0.489539] time: 1:07:35.218498\n",
      "0.8811713\n",
      "[Epoch 45/50] [Batch 97/300] [D loss: 0.752245] [G loss: 0.473072] time: 1:07:35.504521\n",
      "0.97421557\n",
      "[Epoch 45/50] [Batch 98/300] [D loss: 0.752247] [G loss: 0.477412] time: 1:07:35.827568\n",
      "0.96165204\n",
      "[Epoch 45/50] [Batch 99/300] [D loss: 0.752242] [G loss: 0.479306] time: 1:07:36.135897\n",
      "0.9111058\n",
      "[Epoch 45/50] [Batch 100/300] [D loss: 0.752269] [G loss: 0.473062] time: 1:07:36.443494\n",
      "0.9328564\n",
      "[Epoch 45/50] [Batch 101/300] [D loss: 0.752250] [G loss: 0.483604] time: 1:07:36.761587\n",
      "0.9562721\n",
      "[Epoch 45/50] [Batch 102/300] [D loss: 0.752243] [G loss: 0.472645] time: 1:07:37.053716\n",
      "0.95440453\n",
      "[Epoch 45/50] [Batch 103/300] [D loss: 0.752249] [G loss: 0.490103] time: 1:07:37.367615\n",
      "0.8811261\n",
      "[Epoch 45/50] [Batch 104/300] [D loss: 0.752252] [G loss: 0.469853] time: 1:07:37.683805\n",
      "0.95212334\n",
      "[Epoch 45/50] [Batch 105/300] [D loss: 0.752246] [G loss: 0.487738] time: 1:07:37.976042\n",
      "0.93979305\n",
      "[Epoch 45/50] [Batch 106/300] [D loss: 0.752245] [G loss: 0.467610] time: 1:07:38.276160\n",
      "0.872122\n",
      "[Epoch 45/50] [Batch 107/300] [D loss: 0.752244] [G loss: 0.483167] time: 1:07:38.588074\n",
      "0.9043639\n",
      "[Epoch 45/50] [Batch 108/300] [D loss: 0.752254] [G loss: 0.471773] time: 1:07:38.887402\n",
      "0.9534366\n",
      "[Epoch 45/50] [Batch 109/300] [D loss: 0.752250] [G loss: 0.471262] time: 1:07:39.193039\n",
      "0.9497387\n",
      "[Epoch 45/50] [Batch 110/300] [D loss: 0.752242] [G loss: 0.484247] time: 1:07:39.495134\n",
      "0.97752386\n",
      "[Epoch 45/50] [Batch 111/300] [D loss: 0.752244] [G loss: 0.474342] time: 1:07:39.789563\n",
      "0.9079775\n",
      "[Epoch 45/50] [Batch 112/300] [D loss: 0.752244] [G loss: 0.468710] time: 1:07:40.087261\n",
      "0.9460573\n",
      "[Epoch 45/50] [Batch 113/300] [D loss: 0.752245] [G loss: 0.479964] time: 1:07:40.396523\n",
      "0.90665025\n",
      "[Epoch 45/50] [Batch 114/300] [D loss: 0.752247] [G loss: 0.474920] time: 1:07:40.700310\n",
      "0.9248838\n",
      "[Epoch 45/50] [Batch 115/300] [D loss: 0.752264] [G loss: 0.474154] time: 1:07:40.999073\n",
      "0.876504\n",
      "[Epoch 45/50] [Batch 116/300] [D loss: 0.752254] [G loss: 0.466319] time: 1:07:41.309026\n",
      "0.88849527\n",
      "[Epoch 45/50] [Batch 117/300] [D loss: 0.752250] [G loss: 0.493977] time: 1:07:41.608038\n",
      "0.9292479\n",
      "[Epoch 45/50] [Batch 118/300] [D loss: 0.752252] [G loss: 0.471768] time: 1:07:41.932124\n",
      "0.9124193\n",
      "[Epoch 45/50] [Batch 119/300] [D loss: 0.752247] [G loss: 0.479377] time: 1:07:42.233852\n",
      "0.91570014\n",
      "[Epoch 45/50] [Batch 120/300] [D loss: 0.752264] [G loss: 0.480018] time: 1:07:42.524652\n",
      "0.92719644\n",
      "[Epoch 45/50] [Batch 121/300] [D loss: 0.752261] [G loss: 0.468944] time: 1:07:42.829825\n",
      "0.9346717\n",
      "[Epoch 45/50] [Batch 122/300] [D loss: 0.752248] [G loss: 0.471025] time: 1:07:43.132914\n",
      "0.93150955\n",
      "[Epoch 45/50] [Batch 123/300] [D loss: 0.752242] [G loss: 0.484168] time: 1:07:43.431437\n",
      "0.90738064\n",
      "[Epoch 45/50] [Batch 124/300] [D loss: 0.752243] [G loss: 0.479362] time: 1:07:43.739854\n",
      "0.91349244\n",
      "[Epoch 45/50] [Batch 125/300] [D loss: 0.752243] [G loss: 0.467898] time: 1:07:44.050606\n",
      "0.92803377\n",
      "[Epoch 45/50] [Batch 126/300] [D loss: 0.752247] [G loss: 0.480991] time: 1:07:44.348105\n",
      "0.93897724\n",
      "[Epoch 45/50] [Batch 127/300] [D loss: 0.752252] [G loss: 0.464941] time: 1:07:44.661182\n",
      "0.9333827\n",
      "[Epoch 45/50] [Batch 128/300] [D loss: 0.752257] [G loss: 0.469774] time: 1:07:44.951747\n",
      "0.9425249\n",
      "[Epoch 45/50] [Batch 129/300] [D loss: 0.752243] [G loss: 0.472347] time: 1:07:45.245922\n",
      "0.9275751\n",
      "[Epoch 45/50] [Batch 130/300] [D loss: 0.752255] [G loss: 0.494378] time: 1:07:45.520625\n",
      "0.9354062\n",
      "[Epoch 45/50] [Batch 131/300] [D loss: 0.752245] [G loss: 0.474389] time: 1:07:45.825665\n",
      "0.8679488\n",
      "[Epoch 45/50] [Batch 132/300] [D loss: 0.752236] [G loss: 0.495567] time: 1:07:46.124532\n",
      "0.90168405\n",
      "[Epoch 45/50] [Batch 133/300] [D loss: 0.752245] [G loss: 0.487641] time: 1:07:46.426647\n",
      "0.9521771\n",
      "[Epoch 45/50] [Batch 134/300] [D loss: 0.752265] [G loss: 0.471846] time: 1:07:46.754526\n",
      "0.91185737\n",
      "[Epoch 45/50] [Batch 135/300] [D loss: 0.752252] [G loss: 0.485730] time: 1:07:47.067493\n",
      "0.95056725\n",
      "[Epoch 45/50] [Batch 136/300] [D loss: 0.752244] [G loss: 0.478370] time: 1:07:47.371944\n",
      "0.9469282\n",
      "[Epoch 45/50] [Batch 137/300] [D loss: 0.752242] [G loss: 0.463745] time: 1:07:47.654769\n",
      "0.88619334\n",
      "[Epoch 45/50] [Batch 138/300] [D loss: 0.752245] [G loss: 0.471571] time: 1:07:47.957062\n",
      "0.9250806\n",
      "[Epoch 45/50] [Batch 139/300] [D loss: 0.752261] [G loss: 0.468172] time: 1:07:48.252556\n",
      "0.88148636\n",
      "[Epoch 45/50] [Batch 140/300] [D loss: 0.752246] [G loss: 0.494065] time: 1:07:48.560163\n",
      "0.9071846\n",
      "[Epoch 45/50] [Batch 141/300] [D loss: 0.752258] [G loss: 0.480542] time: 1:07:48.858644\n",
      "0.90637\n",
      "[Epoch 45/50] [Batch 142/300] [D loss: 0.752240] [G loss: 0.474640] time: 1:07:49.162151\n",
      "0.91836804\n",
      "[Epoch 45/50] [Batch 143/300] [D loss: 0.752242] [G loss: 0.483163] time: 1:07:49.462658\n",
      "0.9139533\n",
      "[Epoch 45/50] [Batch 144/300] [D loss: 0.752248] [G loss: 0.473129] time: 1:07:49.779123\n",
      "0.9332862\n",
      "[Epoch 45/50] [Batch 145/300] [D loss: 0.752245] [G loss: 0.468367] time: 1:07:50.092650\n",
      "0.90904826\n",
      "[Epoch 45/50] [Batch 146/300] [D loss: 0.752246] [G loss: 0.482177] time: 1:07:50.378838\n",
      "0.90944576\n",
      "[Epoch 45/50] [Batch 147/300] [D loss: 0.752247] [G loss: 0.475583] time: 1:07:50.670620\n",
      "0.8900065\n",
      "[Epoch 45/50] [Batch 148/300] [D loss: 0.752237] [G loss: 0.482367] time: 1:07:50.971943\n",
      "0.9347632\n",
      "[Epoch 45/50] [Batch 149/300] [D loss: 0.752261] [G loss: 0.483617] time: 1:07:51.267225\n",
      "0.9082398\n",
      "[Epoch 45/50] [Batch 150/300] [D loss: 0.752241] [G loss: 0.483013] time: 1:07:51.559305\n",
      "0.9100385\n",
      "[Epoch 45/50] [Batch 151/300] [D loss: 0.752237] [G loss: 0.474975] time: 1:07:51.856751\n",
      "0.8848427\n",
      "[Epoch 45/50] [Batch 152/300] [D loss: 0.752240] [G loss: 0.468648] time: 1:07:52.164909\n",
      "0.98249954\n",
      "[Epoch 45/50] [Batch 153/300] [D loss: 0.752247] [G loss: 0.471526] time: 1:07:52.455767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955014\n",
      "[Epoch 45/50] [Batch 154/300] [D loss: 0.752247] [G loss: 0.467577] time: 1:07:52.755942\n",
      "0.90982133\n",
      "[Epoch 45/50] [Batch 155/300] [D loss: 0.752243] [G loss: 0.469406] time: 1:07:53.058643\n",
      "0.90404123\n",
      "[Epoch 45/50] [Batch 156/300] [D loss: 0.752247] [G loss: 0.492468] time: 1:07:53.366442\n",
      "0.9178598\n",
      "[Epoch 45/50] [Batch 157/300] [D loss: 0.752252] [G loss: 0.477217] time: 1:07:53.676357\n",
      "0.9355518\n",
      "[Epoch 45/50] [Batch 158/300] [D loss: 0.752259] [G loss: 0.473121] time: 1:07:53.984050\n",
      "0.9453506\n",
      "[Epoch 45/50] [Batch 159/300] [D loss: 0.752252] [G loss: 0.476385] time: 1:07:54.305185\n",
      "0.92929834\n",
      "[Epoch 45/50] [Batch 160/300] [D loss: 0.752239] [G loss: 0.476737] time: 1:07:54.604208\n",
      "0.9270876\n",
      "[Epoch 45/50] [Batch 161/300] [D loss: 0.752257] [G loss: 0.480369] time: 1:07:54.916122\n",
      "0.8971376\n",
      "[Epoch 45/50] [Batch 162/300] [D loss: 0.752248] [G loss: 0.486363] time: 1:07:55.233306\n",
      "0.9114503\n",
      "[Epoch 45/50] [Batch 163/300] [D loss: 0.752262] [G loss: 0.482404] time: 1:07:55.517550\n",
      "0.92144316\n",
      "[Epoch 45/50] [Batch 164/300] [D loss: 0.752250] [G loss: 0.492761] time: 1:07:55.833953\n",
      "0.9462201\n",
      "[Epoch 45/50] [Batch 165/300] [D loss: 0.752258] [G loss: 0.476314] time: 1:07:56.138158\n",
      "0.94064754\n",
      "[Epoch 45/50] [Batch 166/300] [D loss: 0.752249] [G loss: 0.466312] time: 1:07:56.432374\n",
      "0.96669596\n",
      "[Epoch 45/50] [Batch 167/300] [D loss: 0.752249] [G loss: 0.483649] time: 1:07:56.729942\n",
      "0.9414647\n",
      "[Epoch 45/50] [Batch 168/300] [D loss: 0.752252] [G loss: 0.473996] time: 1:07:57.024506\n",
      "0.98360425\n",
      "[Epoch 45/50] [Batch 169/300] [D loss: 0.752246] [G loss: 0.470838] time: 1:07:57.339442\n",
      "0.88044864\n",
      "[Epoch 45/50] [Batch 170/300] [D loss: 0.752225] [G loss: 0.469301] time: 1:07:57.644800\n",
      "0.9289164\n",
      "[Epoch 45/50] [Batch 171/300] [D loss: 0.752249] [G loss: 0.465649] time: 1:07:57.949859\n",
      "0.899014\n",
      "[Epoch 45/50] [Batch 172/300] [D loss: 0.752251] [G loss: 0.505295] time: 1:07:58.243446\n",
      "0.91174155\n",
      "[Epoch 45/50] [Batch 173/300] [D loss: 0.752246] [G loss: 0.463348] time: 1:07:58.545488\n",
      "0.91890603\n",
      "[Epoch 45/50] [Batch 174/300] [D loss: 0.752247] [G loss: 0.471798] time: 1:07:58.849615\n",
      "0.9307144\n",
      "[Epoch 45/50] [Batch 175/300] [D loss: 0.752240] [G loss: 0.472692] time: 1:07:59.165570\n",
      "0.90857536\n",
      "[Epoch 45/50] [Batch 176/300] [D loss: 0.752244] [G loss: 0.485058] time: 1:07:59.472944\n",
      "0.88472015\n",
      "[Epoch 45/50] [Batch 177/300] [D loss: 0.752249] [G loss: 0.463445] time: 1:07:59.770019\n",
      "0.89904696\n",
      "[Epoch 45/50] [Batch 178/300] [D loss: 0.752263] [G loss: 0.471989] time: 1:08:00.072308\n",
      "0.88365245\n",
      "[Epoch 45/50] [Batch 179/300] [D loss: 0.752244] [G loss: 0.470127] time: 1:08:00.379561\n",
      "0.95883864\n",
      "[Epoch 45/50] [Batch 180/300] [D loss: 0.752250] [G loss: 0.487240] time: 1:08:00.677411\n",
      "0.9171433\n",
      "[Epoch 45/50] [Batch 181/300] [D loss: 0.752233] [G loss: 0.474628] time: 1:08:00.978722\n",
      "0.8992157\n",
      "[Epoch 45/50] [Batch 182/300] [D loss: 0.752249] [G loss: 0.470537] time: 1:08:01.259735\n",
      "0.9424744\n",
      "[Epoch 45/50] [Batch 183/300] [D loss: 0.752247] [G loss: 0.478817] time: 1:08:01.566621\n",
      "0.9072943\n",
      "[Epoch 45/50] [Batch 184/300] [D loss: 0.752247] [G loss: 0.485641] time: 1:08:01.869493\n",
      "0.9426902\n",
      "[Epoch 45/50] [Batch 185/300] [D loss: 0.752244] [G loss: 0.487482] time: 1:08:02.173020\n",
      "0.9253328\n",
      "[Epoch 45/50] [Batch 186/300] [D loss: 0.752242] [G loss: 0.488898] time: 1:08:02.484137\n",
      "0.9322078\n",
      "[Epoch 45/50] [Batch 187/300] [D loss: 0.752248] [G loss: 0.491049] time: 1:08:02.784441\n",
      "0.92583877\n",
      "[Epoch 45/50] [Batch 188/300] [D loss: 0.752246] [G loss: 0.473439] time: 1:08:03.086690\n",
      "0.94578415\n",
      "[Epoch 45/50] [Batch 189/300] [D loss: 0.752246] [G loss: 0.513038] time: 1:08:03.398379\n",
      "0.90520483\n",
      "[Epoch 45/50] [Batch 190/300] [D loss: 0.752252] [G loss: 0.471719] time: 1:08:03.703303\n",
      "0.90569586\n",
      "[Epoch 45/50] [Batch 191/300] [D loss: 0.752236] [G loss: 0.477920] time: 1:08:04.003768\n",
      "0.87379307\n",
      "[Epoch 45/50] [Batch 192/300] [D loss: 0.752237] [G loss: 0.494471] time: 1:08:04.303753\n",
      "0.92156476\n",
      "[Epoch 45/50] [Batch 193/300] [D loss: 0.752250] [G loss: 0.480496] time: 1:08:04.604184\n",
      "0.9176995\n",
      "[Epoch 45/50] [Batch 194/300] [D loss: 0.752248] [G loss: 0.485735] time: 1:08:04.921744\n",
      "0.9600809\n",
      "[Epoch 45/50] [Batch 195/300] [D loss: 0.752241] [G loss: 0.470682] time: 1:08:05.217556\n",
      "0.926846\n",
      "[Epoch 45/50] [Batch 196/300] [D loss: 0.752244] [G loss: 0.477770] time: 1:08:05.525542\n",
      "0.8739918\n",
      "[Epoch 45/50] [Batch 197/300] [D loss: 0.752245] [G loss: 0.467988] time: 1:08:05.842144\n",
      "0.9160158\n",
      "[Epoch 45/50] [Batch 198/300] [D loss: 0.752241] [G loss: 0.482096] time: 1:08:06.159965\n",
      "0.88075274\n",
      "[Epoch 45/50] [Batch 199/300] [D loss: 0.752236] [G loss: 0.471833] time: 1:08:06.440181\n",
      "0.8737421\n",
      "[Epoch 45/50] [Batch 200/300] [D loss: 0.752251] [G loss: 0.476548] time: 1:08:06.743205\n",
      "0.91185457\n",
      "[Epoch 45/50] [Batch 201/300] [D loss: 0.752246] [G loss: 0.480950] time: 1:08:07.040630\n",
      "0.88778156\n",
      "[Epoch 45/50] [Batch 202/300] [D loss: 0.752244] [G loss: 0.474720] time: 1:08:07.331193\n",
      "0.91986936\n",
      "[Epoch 45/50] [Batch 203/300] [D loss: 0.752247] [G loss: 0.485215] time: 1:08:07.643724\n",
      "0.90523744\n",
      "[Epoch 45/50] [Batch 204/300] [D loss: 0.752246] [G loss: 0.479261] time: 1:08:07.937067\n",
      "0.94164515\n",
      "[Epoch 45/50] [Batch 205/300] [D loss: 0.752244] [G loss: 0.472740] time: 1:08:08.256716\n",
      "0.90928096\n",
      "[Epoch 45/50] [Batch 206/300] [D loss: 0.752253] [G loss: 0.472704] time: 1:08:08.551559\n",
      "0.8887008\n",
      "[Epoch 45/50] [Batch 207/300] [D loss: 0.752248] [G loss: 0.502863] time: 1:08:08.841475\n",
      "0.90647507\n",
      "[Epoch 45/50] [Batch 208/300] [D loss: 0.752251] [G loss: 0.477057] time: 1:08:09.133520\n",
      "0.9307835\n",
      "[Epoch 45/50] [Batch 209/300] [D loss: 0.752247] [G loss: 0.472515] time: 1:08:09.436045\n",
      "0.912504\n",
      "[Epoch 45/50] [Batch 210/300] [D loss: 0.752257] [G loss: 0.490519] time: 1:08:09.717503\n",
      "0.9250911\n",
      "[Epoch 45/50] [Batch 211/300] [D loss: 0.752241] [G loss: 0.473126] time: 1:08:10.000677\n",
      "0.9065141\n",
      "[Epoch 45/50] [Batch 212/300] [D loss: 0.752266] [G loss: 0.482303] time: 1:08:10.292152\n",
      "0.92219466\n",
      "[Epoch 45/50] [Batch 213/300] [D loss: 0.752242] [G loss: 0.491156] time: 1:08:10.601524\n",
      "0.9457102\n",
      "[Epoch 45/50] [Batch 214/300] [D loss: 0.752259] [G loss: 0.481505] time: 1:08:10.903988\n",
      "0.9451794\n",
      "[Epoch 45/50] [Batch 215/300] [D loss: 0.752249] [G loss: 0.468841] time: 1:08:11.207845\n",
      "0.96829414\n",
      "[Epoch 45/50] [Batch 216/300] [D loss: 0.752247] [G loss: 0.474581] time: 1:08:11.516967\n",
      "0.89171076\n",
      "[Epoch 45/50] [Batch 217/300] [D loss: 0.752258] [G loss: 0.491705] time: 1:08:11.815809\n",
      "0.935026\n",
      "[Epoch 45/50] [Batch 218/300] [D loss: 0.752237] [G loss: 0.478581] time: 1:08:12.116070\n",
      "0.9360647\n",
      "[Epoch 45/50] [Batch 219/300] [D loss: 0.752252] [G loss: 0.467337] time: 1:08:12.424616\n",
      "0.92515355\n",
      "[Epoch 45/50] [Batch 220/300] [D loss: 0.752241] [G loss: 0.472262] time: 1:08:12.742132\n",
      "0.87627393\n",
      "[Epoch 45/50] [Batch 221/300] [D loss: 0.752252] [G loss: 0.480917] time: 1:08:13.033202\n",
      "0.93094325\n",
      "[Epoch 45/50] [Batch 222/300] [D loss: 0.752237] [G loss: 0.478080] time: 1:08:13.338011\n",
      "0.9159541\n",
      "[Epoch 45/50] [Batch 223/300] [D loss: 0.752257] [G loss: 0.465979] time: 1:08:13.625012\n",
      "0.9015546\n",
      "[Epoch 45/50] [Batch 224/300] [D loss: 0.752249] [G loss: 0.473264] time: 1:08:13.918556\n",
      "0.95346147\n",
      "[Epoch 45/50] [Batch 225/300] [D loss: 0.752254] [G loss: 0.494608] time: 1:08:14.211134\n",
      "0.9115686\n",
      "[Epoch 45/50] [Batch 226/300] [D loss: 0.752247] [G loss: 0.488608] time: 1:08:14.511608\n",
      "0.8917928\n",
      "[Epoch 45/50] [Batch 227/300] [D loss: 0.752242] [G loss: 0.474561] time: 1:08:14.819144\n",
      "0.89833957\n",
      "[Epoch 45/50] [Batch 228/300] [D loss: 0.752250] [G loss: 0.477985] time: 1:08:15.107662\n",
      "0.8874395\n",
      "[Epoch 45/50] [Batch 229/300] [D loss: 0.752242] [G loss: 0.483822] time: 1:08:15.406772\n",
      "0.9564937\n",
      "[Epoch 45/50] [Batch 230/300] [D loss: 0.752246] [G loss: 0.476641] time: 1:08:15.701574\n",
      "0.97591233\n",
      "[Epoch 45/50] [Batch 231/300] [D loss: 0.752253] [G loss: 0.471605] time: 1:08:16.005721\n",
      "0.87367994\n",
      "[Epoch 45/50] [Batch 232/300] [D loss: 0.752236] [G loss: 0.480452] time: 1:08:16.296940\n",
      "0.9175675\n",
      "[Epoch 45/50] [Batch 233/300] [D loss: 0.752233] [G loss: 0.474778] time: 1:08:16.592328\n",
      "0.9307194\n",
      "[Epoch 45/50] [Batch 234/300] [D loss: 0.752247] [G loss: 0.472543] time: 1:08:16.895116\n",
      "0.93320256\n",
      "[Epoch 45/50] [Batch 235/300] [D loss: 0.752249] [G loss: 0.473578] time: 1:08:17.184479\n",
      "0.8818867\n",
      "[Epoch 45/50] [Batch 236/300] [D loss: 0.752242] [G loss: 0.469019] time: 1:08:17.487616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9172812\n",
      "[Epoch 45/50] [Batch 237/300] [D loss: 0.752243] [G loss: 0.488889] time: 1:08:17.793598\n",
      "0.92551905\n",
      "[Epoch 45/50] [Batch 238/300] [D loss: 0.752238] [G loss: 0.478370] time: 1:08:18.089324\n",
      "0.8742524\n",
      "[Epoch 45/50] [Batch 239/300] [D loss: 0.752244] [G loss: 0.475021] time: 1:08:18.393034\n",
      "0.94279116\n",
      "[Epoch 45/50] [Batch 240/300] [D loss: 0.752236] [G loss: 0.470833] time: 1:08:18.687756\n",
      "0.9332557\n",
      "[Epoch 45/50] [Batch 241/300] [D loss: 0.752245] [G loss: 0.486710] time: 1:08:18.986754\n",
      "0.909595\n",
      "[Epoch 45/50] [Batch 242/300] [D loss: 0.752243] [G loss: 0.473914] time: 1:08:19.274670\n",
      "0.95317346\n",
      "[Epoch 45/50] [Batch 243/300] [D loss: 0.752254] [G loss: 0.470909] time: 1:08:19.571115\n",
      "0.91731924\n",
      "[Epoch 45/50] [Batch 244/300] [D loss: 0.752243] [G loss: 0.471057] time: 1:08:19.872216\n",
      "0.90708756\n",
      "[Epoch 45/50] [Batch 245/300] [D loss: 0.752239] [G loss: 0.486515] time: 1:08:20.167397\n",
      "0.91728276\n",
      "[Epoch 45/50] [Batch 246/300] [D loss: 0.752245] [G loss: 0.483149] time: 1:08:20.469610\n",
      "0.9405138\n",
      "[Epoch 45/50] [Batch 247/300] [D loss: 0.752248] [G loss: 0.472950] time: 1:08:20.776043\n",
      "0.9212725\n",
      "[Epoch 45/50] [Batch 248/300] [D loss: 0.752248] [G loss: 0.470792] time: 1:08:21.079102\n",
      "0.9190836\n",
      "[Epoch 45/50] [Batch 249/300] [D loss: 0.752245] [G loss: 0.482393] time: 1:08:21.389499\n",
      "0.9167052\n",
      "[Epoch 45/50] [Batch 250/300] [D loss: 0.752251] [G loss: 0.477112] time: 1:08:21.686278\n",
      "0.9400688\n",
      "[Epoch 45/50] [Batch 251/300] [D loss: 0.752252] [G loss: 0.477243] time: 1:08:21.977748\n",
      "0.9280444\n",
      "[Epoch 45/50] [Batch 252/300] [D loss: 0.752240] [G loss: 0.470833] time: 1:08:22.296378\n",
      "0.9760856\n",
      "[Epoch 45/50] [Batch 253/300] [D loss: 0.752243] [G loss: 0.466707] time: 1:08:22.591200\n",
      "0.8995648\n",
      "[Epoch 45/50] [Batch 254/300] [D loss: 0.752259] [G loss: 0.467656] time: 1:08:22.902767\n",
      "0.93360424\n",
      "[Epoch 45/50] [Batch 255/300] [D loss: 0.752242] [G loss: 0.487782] time: 1:08:23.202635\n",
      "0.90884787\n",
      "[Epoch 45/50] [Batch 256/300] [D loss: 0.752251] [G loss: 0.477147] time: 1:08:23.524629\n",
      "0.8957482\n",
      "[Epoch 45/50] [Batch 257/300] [D loss: 0.752242] [G loss: 0.474087] time: 1:08:23.822449\n",
      "0.92917746\n",
      "[Epoch 45/50] [Batch 258/300] [D loss: 0.752243] [G loss: 0.481025] time: 1:08:24.134917\n",
      "0.89495856\n",
      "[Epoch 45/50] [Batch 259/300] [D loss: 0.752236] [G loss: 0.477850] time: 1:08:24.436410\n",
      "0.88121384\n",
      "[Epoch 45/50] [Batch 260/300] [D loss: 0.752252] [G loss: 0.479437] time: 1:08:24.721866\n",
      "0.9162589\n",
      "[Epoch 45/50] [Batch 261/300] [D loss: 0.752250] [G loss: 0.473108] time: 1:08:25.020983\n",
      "0.9192937\n",
      "[Epoch 45/50] [Batch 262/300] [D loss: 0.752245] [G loss: 0.466069] time: 1:08:25.300217\n",
      "0.86854154\n",
      "[Epoch 45/50] [Batch 263/300] [D loss: 0.752247] [G loss: 0.480365] time: 1:08:25.590177\n",
      "0.87375706\n",
      "[Epoch 45/50] [Batch 264/300] [D loss: 0.752246] [G loss: 0.473719] time: 1:08:25.907125\n",
      "0.90030164\n",
      "[Epoch 45/50] [Batch 265/300] [D loss: 0.752245] [G loss: 0.480141] time: 1:08:26.181003\n",
      "0.9250609\n",
      "[Epoch 45/50] [Batch 266/300] [D loss: 0.752247] [G loss: 0.482552] time: 1:08:26.493592\n",
      "0.9259817\n",
      "[Epoch 45/50] [Batch 267/300] [D loss: 0.752246] [G loss: 0.482200] time: 1:08:26.800278\n",
      "0.91329265\n",
      "[Epoch 45/50] [Batch 268/300] [D loss: 0.752243] [G loss: 0.480797] time: 1:08:27.102748\n",
      "0.9214497\n",
      "[Epoch 45/50] [Batch 269/300] [D loss: 0.752247] [G loss: 0.476532] time: 1:08:27.410246\n",
      "0.90015703\n",
      "[Epoch 45/50] [Batch 270/300] [D loss: 0.752244] [G loss: 0.467307] time: 1:08:27.712489\n",
      "0.95613\n",
      "[Epoch 45/50] [Batch 271/300] [D loss: 0.752255] [G loss: 0.470303] time: 1:08:28.019851\n",
      "0.8874573\n",
      "[Epoch 45/50] [Batch 272/300] [D loss: 0.752256] [G loss: 0.464163] time: 1:08:28.323300\n",
      "0.91455936\n",
      "[Epoch 45/50] [Batch 273/300] [D loss: 0.752242] [G loss: 0.476613] time: 1:08:28.632226\n",
      "0.9543789\n",
      "[Epoch 45/50] [Batch 274/300] [D loss: 0.752250] [G loss: 0.473928] time: 1:08:28.936938\n",
      "0.90545875\n",
      "[Epoch 45/50] [Batch 275/300] [D loss: 0.752251] [G loss: 0.487767] time: 1:08:29.228587\n",
      "0.9110041\n",
      "[Epoch 45/50] [Batch 276/300] [D loss: 0.752235] [G loss: 0.472822] time: 1:08:29.534744\n",
      "0.9278168\n",
      "[Epoch 45/50] [Batch 277/300] [D loss: 0.752252] [G loss: 0.469243] time: 1:08:29.832857\n",
      "0.96438485\n",
      "[Epoch 45/50] [Batch 278/300] [D loss: 0.752247] [G loss: 0.479111] time: 1:08:30.120145\n",
      "0.9307386\n",
      "[Epoch 45/50] [Batch 279/300] [D loss: 0.752249] [G loss: 0.464035] time: 1:08:30.413527\n",
      "0.8836884\n",
      "[Epoch 45/50] [Batch 280/300] [D loss: 0.752249] [G loss: 0.486973] time: 1:08:30.728337\n",
      "0.9529007\n",
      "[Epoch 45/50] [Batch 281/300] [D loss: 0.752236] [G loss: 0.480080] time: 1:08:31.034063\n",
      "0.935797\n",
      "[Epoch 45/50] [Batch 282/300] [D loss: 0.752248] [G loss: 0.499538] time: 1:08:31.336604\n",
      "0.88921136\n",
      "[Epoch 45/50] [Batch 283/300] [D loss: 0.752242] [G loss: 0.470771] time: 1:08:31.631924\n",
      "0.9519438\n",
      "[Epoch 45/50] [Batch 284/300] [D loss: 0.752255] [G loss: 0.492710] time: 1:08:31.938664\n",
      "0.9055955\n",
      "[Epoch 45/50] [Batch 285/300] [D loss: 0.752250] [G loss: 0.475254] time: 1:08:32.228802\n",
      "0.93025374\n",
      "[Epoch 45/50] [Batch 286/300] [D loss: 0.752242] [G loss: 0.481949] time: 1:08:32.527937\n",
      "0.9139764\n",
      "[Epoch 45/50] [Batch 287/300] [D loss: 0.752243] [G loss: 0.469962] time: 1:08:32.838218\n",
      "0.8810084\n",
      "[Epoch 45/50] [Batch 288/300] [D loss: 0.752246] [G loss: 0.490199] time: 1:08:33.141098\n",
      "0.9322088\n",
      "[Epoch 45/50] [Batch 289/300] [D loss: 0.752248] [G loss: 0.474323] time: 1:08:33.446423\n",
      "0.93309236\n",
      "[Epoch 45/50] [Batch 290/300] [D loss: 0.752243] [G loss: 0.483539] time: 1:08:33.736391\n",
      "0.9591913\n",
      "[Epoch 45/50] [Batch 291/300] [D loss: 0.752236] [G loss: 0.476614] time: 1:08:34.029242\n",
      "0.91056156\n",
      "[Epoch 45/50] [Batch 292/300] [D loss: 0.752238] [G loss: 0.466635] time: 1:08:34.322012\n",
      "0.9249957\n",
      "[Epoch 45/50] [Batch 293/300] [D loss: 0.752253] [G loss: 0.490649] time: 1:08:34.618060\n",
      "0.9231836\n",
      "[Epoch 45/50] [Batch 294/300] [D loss: 0.752248] [G loss: 0.474525] time: 1:08:34.947733\n",
      "0.88431996\n",
      "[Epoch 45/50] [Batch 295/300] [D loss: 0.752248] [G loss: 0.490584] time: 1:08:35.244971\n",
      "0.9070425\n",
      "[Epoch 45/50] [Batch 296/300] [D loss: 0.752253] [G loss: 0.483121] time: 1:08:35.550797\n",
      "0.93428344\n",
      "[Epoch 45/50] [Batch 297/300] [D loss: 0.752240] [G loss: 0.474361] time: 1:08:35.853280\n",
      "0.958508\n",
      "[Epoch 45/50] [Batch 298/300] [D loss: 0.752251] [G loss: 0.475199] time: 1:08:36.154265\n",
      "0.94538933\n",
      "[Epoch 45/50] [Batch 299/300] [D loss: 0.752246] [G loss: 0.473968] time: 1:08:36.448700\n",
      "0.8898681\n",
      "[Epoch 46/50] [Batch 0/300] [D loss: 0.752253] [G loss: 0.490723] time: 1:08:36.747483\n",
      "0.947063\n",
      "[Epoch 46/50] [Batch 1/300] [D loss: 0.752242] [G loss: 0.474022] time: 1:08:37.051758\n",
      "0.89907223\n",
      "[Epoch 46/50] [Batch 2/300] [D loss: 0.752247] [G loss: 0.492980] time: 1:08:37.351253\n",
      "0.9502879\n",
      "[Epoch 46/50] [Batch 3/300] [D loss: 0.752236] [G loss: 0.470221] time: 1:08:37.657466\n",
      "0.9248917\n",
      "[Epoch 46/50] [Batch 4/300] [D loss: 0.752250] [G loss: 0.478950] time: 1:08:37.968052\n",
      "0.90873146\n",
      "[Epoch 46/50] [Batch 5/300] [D loss: 0.752244] [G loss: 0.488992] time: 1:08:38.274866\n",
      "0.90555024\n",
      "[Epoch 46/50] [Batch 6/300] [D loss: 0.752242] [G loss: 0.487128] time: 1:08:38.582703\n",
      "0.9057784\n",
      "[Epoch 46/50] [Batch 7/300] [D loss: 0.752242] [G loss: 0.489527] time: 1:08:38.891301\n",
      "0.89762133\n",
      "[Epoch 46/50] [Batch 8/300] [D loss: 0.752260] [G loss: 0.468782] time: 1:08:39.198708\n",
      "0.9168372\n",
      "[Epoch 46/50] [Batch 9/300] [D loss: 0.752250] [G loss: 0.496122] time: 1:08:39.483737\n",
      "0.9087441\n",
      "[Epoch 46/50] [Batch 10/300] [D loss: 0.752242] [G loss: 0.474275] time: 1:08:39.794401\n",
      "0.9207019\n",
      "[Epoch 46/50] [Batch 11/300] [D loss: 0.752254] [G loss: 0.474504] time: 1:08:40.079819\n",
      "0.90707093\n",
      "[Epoch 46/50] [Batch 12/300] [D loss: 0.752237] [G loss: 0.478405] time: 1:08:40.380922\n",
      "0.91251945\n",
      "[Epoch 46/50] [Batch 13/300] [D loss: 0.752231] [G loss: 0.470924] time: 1:08:40.668203\n",
      "0.9531961\n",
      "[Epoch 46/50] [Batch 14/300] [D loss: 0.752243] [G loss: 0.465945] time: 1:08:40.985441\n",
      "0.88500553\n",
      "[Epoch 46/50] [Batch 15/300] [D loss: 0.752251] [G loss: 0.500997] time: 1:08:41.261878\n",
      "0.9497754\n",
      "[Epoch 46/50] [Batch 16/300] [D loss: 0.752240] [G loss: 0.474280] time: 1:08:41.560012\n",
      "0.9176876\n",
      "[Epoch 46/50] [Batch 17/300] [D loss: 0.752237] [G loss: 0.481992] time: 1:08:41.860718\n",
      "0.92412186\n",
      "[Epoch 46/50] [Batch 18/300] [D loss: 0.752244] [G loss: 0.465080] time: 1:08:42.145372\n",
      "0.90300465\n",
      "[Epoch 46/50] [Batch 19/300] [D loss: 0.752247] [G loss: 0.496386] time: 1:08:42.455607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532402\n",
      "[Epoch 46/50] [Batch 20/300] [D loss: 0.752253] [G loss: 0.478170] time: 1:08:42.743847\n",
      "0.9103355\n",
      "[Epoch 46/50] [Batch 21/300] [D loss: 0.752248] [G loss: 0.476634] time: 1:08:43.045800\n",
      "0.92428285\n",
      "[Epoch 46/50] [Batch 22/300] [D loss: 0.752247] [G loss: 0.502310] time: 1:08:43.359071\n",
      "0.88113856\n",
      "[Epoch 46/50] [Batch 23/300] [D loss: 0.752245] [G loss: 0.479414] time: 1:08:43.664374\n",
      "0.9430987\n",
      "[Epoch 46/50] [Batch 24/300] [D loss: 0.752251] [G loss: 0.480778] time: 1:08:43.971605\n",
      "0.913609\n",
      "[Epoch 46/50] [Batch 25/300] [D loss: 0.752233] [G loss: 0.481413] time: 1:08:44.288366\n",
      "0.8997621\n",
      "[Epoch 46/50] [Batch 26/300] [D loss: 0.752260] [G loss: 0.484826] time: 1:08:44.592029\n",
      "0.91766995\n",
      "[Epoch 46/50] [Batch 27/300] [D loss: 0.752242] [G loss: 0.484275] time: 1:08:44.889612\n",
      "0.9421852\n",
      "[Epoch 46/50] [Batch 28/300] [D loss: 0.752246] [G loss: 0.463615] time: 1:08:45.189356\n",
      "0.9530508\n",
      "[Epoch 46/50] [Batch 29/300] [D loss: 0.752242] [G loss: 0.479214] time: 1:08:45.488505\n",
      "0.8946302\n",
      "[Epoch 46/50] [Batch 30/300] [D loss: 0.752249] [G loss: 0.490695] time: 1:08:45.802002\n",
      "0.9583338\n",
      "[Epoch 46/50] [Batch 31/300] [D loss: 0.752259] [G loss: 0.474947] time: 1:08:46.117313\n",
      "0.92886764\n",
      "[Epoch 46/50] [Batch 32/300] [D loss: 0.752254] [G loss: 0.466985] time: 1:08:46.396848\n",
      "0.8723772\n",
      "[Epoch 46/50] [Batch 33/300] [D loss: 0.752250] [G loss: 0.486236] time: 1:08:46.699510\n",
      "0.9268474\n",
      "[Epoch 46/50] [Batch 34/300] [D loss: 0.752249] [G loss: 0.482501] time: 1:08:46.995238\n",
      "0.94000274\n",
      "[Epoch 46/50] [Batch 35/300] [D loss: 0.752244] [G loss: 0.470069] time: 1:08:47.275951\n",
      "0.8648409\n",
      "[Epoch 46/50] [Batch 36/300] [D loss: 0.752241] [G loss: 0.479315] time: 1:08:47.577437\n",
      "0.98153716\n",
      "[Epoch 46/50] [Batch 37/300] [D loss: 0.752246] [G loss: 0.478445] time: 1:08:47.877998\n",
      "0.97563154\n",
      "[Epoch 46/50] [Batch 38/300] [D loss: 0.752239] [G loss: 0.474587] time: 1:08:48.191880\n",
      "0.92809075\n",
      "[Epoch 46/50] [Batch 39/300] [D loss: 0.752240] [G loss: 0.479651] time: 1:08:48.494672\n",
      "0.9142825\n",
      "[Epoch 46/50] [Batch 40/300] [D loss: 0.752249] [G loss: 0.471888] time: 1:08:48.790660\n",
      "0.9123257\n",
      "[Epoch 46/50] [Batch 41/300] [D loss: 0.752247] [G loss: 0.493024] time: 1:08:49.072441\n",
      "0.9419842\n",
      "[Epoch 46/50] [Batch 42/300] [D loss: 0.752252] [G loss: 0.485407] time: 1:08:49.369271\n",
      "0.92997044\n",
      "[Epoch 46/50] [Batch 43/300] [D loss: 0.752249] [G loss: 0.474089] time: 1:08:49.664469\n",
      "0.8862713\n",
      "[Epoch 46/50] [Batch 44/300] [D loss: 0.752246] [G loss: 0.473973] time: 1:08:49.986652\n",
      "0.90811414\n",
      "[Epoch 46/50] [Batch 46/300] [D loss: 0.752243] [G loss: 0.475105] time: 1:08:50.314695\n",
      "0.94140893\n",
      "[Epoch 46/50] [Batch 47/300] [D loss: 0.752245] [G loss: 0.486626] time: 1:08:50.617100\n",
      "0.9109866\n",
      "[Epoch 46/50] [Batch 48/300] [D loss: 0.752238] [G loss: 0.476284] time: 1:08:50.906463\n",
      "0.95599073\n",
      "[Epoch 46/50] [Batch 49/300] [D loss: 0.752255] [G loss: 0.482957] time: 1:08:51.225383\n",
      "0.95229584\n",
      "[Epoch 46/50] [Batch 50/300] [D loss: 0.752240] [G loss: 0.491324] time: 1:08:51.527066\n",
      "0.9239676\n",
      "[Epoch 46/50] [Batch 51/300] [D loss: 0.752245] [G loss: 0.489085] time: 1:08:51.838334\n",
      "0.92926955\n",
      "[Epoch 46/50] [Batch 52/300] [D loss: 0.752235] [G loss: 0.481717] time: 1:08:52.139885\n",
      "0.9403694\n",
      "[Epoch 46/50] [Batch 53/300] [D loss: 0.752241] [G loss: 0.470837] time: 1:08:52.443281\n",
      "0.959915\n",
      "[Epoch 46/50] [Batch 54/300] [D loss: 0.752238] [G loss: 0.477150] time: 1:08:52.748877\n",
      "0.9574869\n",
      "[Epoch 46/50] [Batch 55/300] [D loss: 0.752249] [G loss: 0.469569] time: 1:08:53.035006\n",
      "0.93196505\n",
      "[Epoch 46/50] [Batch 56/300] [D loss: 0.752245] [G loss: 0.464341] time: 1:08:53.342746\n",
      "0.9448819\n",
      "[Epoch 46/50] [Batch 57/300] [D loss: 0.752251] [G loss: 0.479722] time: 1:08:53.638397\n",
      "0.94124204\n",
      "[Epoch 46/50] [Batch 58/300] [D loss: 0.752238] [G loss: 0.476785] time: 1:08:53.942950\n",
      "0.8992694\n",
      "[Epoch 46/50] [Batch 59/300] [D loss: 0.752250] [G loss: 0.467810] time: 1:08:54.222985\n",
      "0.93192434\n",
      "[Epoch 46/50] [Batch 60/300] [D loss: 0.752239] [G loss: 0.472184] time: 1:08:54.510730\n",
      "0.9506524\n",
      "[Epoch 46/50] [Batch 61/300] [D loss: 0.752254] [G loss: 0.473066] time: 1:08:54.818309\n",
      "0.9115785\n",
      "[Epoch 46/50] [Batch 62/300] [D loss: 0.752243] [G loss: 0.475251] time: 1:08:55.104447\n",
      "0.9021988\n",
      "[Epoch 46/50] [Batch 63/300] [D loss: 0.752247] [G loss: 0.472648] time: 1:08:55.420359\n",
      "0.9138637\n",
      "[Epoch 46/50] [Batch 64/300] [D loss: 0.752226] [G loss: 0.467507] time: 1:08:55.726777\n",
      "0.91018724\n",
      "[Epoch 46/50] [Batch 65/300] [D loss: 0.752238] [G loss: 0.466568] time: 1:08:56.016177\n",
      "0.91801363\n",
      "[Epoch 46/50] [Batch 66/300] [D loss: 0.752246] [G loss: 0.480309] time: 1:08:56.325951\n",
      "0.8860459\n",
      "[Epoch 46/50] [Batch 67/300] [D loss: 0.752235] [G loss: 0.480828] time: 1:08:56.644370\n",
      "0.9163773\n",
      "[Epoch 46/50] [Batch 68/300] [D loss: 0.752244] [G loss: 0.469216] time: 1:08:56.953011\n",
      "0.85244066\n",
      "[Epoch 46/50] [Batch 69/300] [D loss: 0.752240] [G loss: 0.466018] time: 1:08:57.265871\n",
      "0.93311006\n",
      "[Epoch 46/50] [Batch 70/300] [D loss: 0.752245] [G loss: 0.480023] time: 1:08:57.567689\n",
      "0.94472504\n",
      "[Epoch 46/50] [Batch 71/300] [D loss: 0.752247] [G loss: 0.468571] time: 1:08:57.855805\n",
      "0.9142036\n",
      "[Epoch 46/50] [Batch 72/300] [D loss: 0.752246] [G loss: 0.467838] time: 1:08:58.167618\n",
      "0.98312896\n",
      "[Epoch 46/50] [Batch 73/300] [D loss: 0.752239] [G loss: 0.491555] time: 1:08:58.481596\n",
      "0.89073104\n",
      "[Epoch 46/50] [Batch 74/300] [D loss: 0.752235] [G loss: 0.463829] time: 1:08:58.762765\n",
      "0.9142073\n",
      "[Epoch 46/50] [Batch 75/300] [D loss: 0.752243] [G loss: 0.468701] time: 1:08:59.053377\n",
      "0.8996181\n",
      "[Epoch 46/50] [Batch 76/300] [D loss: 0.752242] [G loss: 0.464158] time: 1:08:59.365072\n",
      "0.913466\n",
      "[Epoch 46/50] [Batch 77/300] [D loss: 0.752246] [G loss: 0.478906] time: 1:08:59.657450\n",
      "0.94262964\n",
      "[Epoch 46/50] [Batch 78/300] [D loss: 0.752242] [G loss: 0.482886] time: 1:08:59.959982\n",
      "0.93303746\n",
      "[Epoch 46/50] [Batch 79/300] [D loss: 0.752253] [G loss: 0.471562] time: 1:09:00.276000\n",
      "0.9224694\n",
      "[Epoch 46/50] [Batch 80/300] [D loss: 0.752245] [G loss: 0.482163] time: 1:09:00.576057\n",
      "0.92895246\n",
      "[Epoch 46/50] [Batch 81/300] [D loss: 0.752242] [G loss: 0.474385] time: 1:09:00.897529\n",
      "0.93036\n",
      "[Epoch 46/50] [Batch 82/300] [D loss: 0.752243] [G loss: 0.478221] time: 1:09:01.202587\n",
      "0.91567594\n",
      "[Epoch 46/50] [Batch 83/300] [D loss: 0.752245] [G loss: 0.467320] time: 1:09:01.497285\n",
      "0.9083001\n",
      "[Epoch 46/50] [Batch 84/300] [D loss: 0.752243] [G loss: 0.469766] time: 1:09:01.796775\n",
      "0.94617087\n",
      "[Epoch 46/50] [Batch 85/300] [D loss: 0.752244] [G loss: 0.470245] time: 1:09:02.115493\n",
      "0.9081187\n",
      "[Epoch 46/50] [Batch 86/300] [D loss: 0.752251] [G loss: 0.475170] time: 1:09:02.545603\n",
      "0.9258437\n",
      "[Epoch 46/50] [Batch 87/300] [D loss: 0.752248] [G loss: 0.467580] time: 1:09:02.855593\n",
      "0.90368104\n",
      "[Epoch 46/50] [Batch 88/300] [D loss: 0.752244] [G loss: 0.472952] time: 1:09:03.170320\n",
      "0.9072053\n",
      "[Epoch 46/50] [Batch 89/300] [D loss: 0.752253] [G loss: 0.464782] time: 1:09:03.469341\n",
      "0.884289\n",
      "[Epoch 46/50] [Batch 90/300] [D loss: 0.752237] [G loss: 0.480302] time: 1:09:03.769327\n",
      "0.9554582\n",
      "[Epoch 46/50] [Batch 91/300] [D loss: 0.752235] [G loss: 0.480942] time: 1:09:04.053063\n",
      "0.9589963\n",
      "[Epoch 46/50] [Batch 92/300] [D loss: 0.752249] [G loss: 0.472244] time: 1:09:04.329624\n",
      "0.9331529\n",
      "[Epoch 46/50] [Batch 93/300] [D loss: 0.752238] [G loss: 0.474473] time: 1:09:04.641705\n",
      "0.96241826\n",
      "[Epoch 46/50] [Batch 94/300] [D loss: 0.752251] [G loss: 0.481295] time: 1:09:04.940565\n",
      "0.89207387\n",
      "[Epoch 46/50] [Batch 95/300] [D loss: 0.752240] [G loss: 0.482378] time: 1:09:05.235043\n",
      "0.90589005\n",
      "[Epoch 46/50] [Batch 96/300] [D loss: 0.752242] [G loss: 0.471049] time: 1:09:05.549605\n",
      "0.94612163\n",
      "[Epoch 46/50] [Batch 97/300] [D loss: 0.752247] [G loss: 0.468710] time: 1:09:05.828244\n",
      "0.9346517\n",
      "[Epoch 46/50] [Batch 98/300] [D loss: 0.752237] [G loss: 0.476929] time: 1:09:06.113917\n",
      "0.9497495\n",
      "[Epoch 46/50] [Batch 99/300] [D loss: 0.752263] [G loss: 0.470369] time: 1:09:06.421024\n",
      "0.9315079\n",
      "[Epoch 46/50] [Batch 100/300] [D loss: 0.752239] [G loss: 0.477987] time: 1:09:06.725677\n",
      "0.9531574\n",
      "[Epoch 46/50] [Batch 101/300] [D loss: 0.752247] [G loss: 0.462421] time: 1:09:07.023859\n",
      "0.9140077\n",
      "[Epoch 46/50] [Batch 102/300] [D loss: 0.752252] [G loss: 0.479295] time: 1:09:07.330125\n",
      "0.9556227\n",
      "[Epoch 46/50] [Batch 103/300] [D loss: 0.752237] [G loss: 0.471716] time: 1:09:07.626505\n",
      "0.91401386\n",
      "[Epoch 46/50] [Batch 104/300] [D loss: 0.752241] [G loss: 0.500097] time: 1:09:07.922869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9315812\n",
      "[Epoch 46/50] [Batch 105/300] [D loss: 0.752250] [G loss: 0.467109] time: 1:09:08.247149\n",
      "0.8954814\n",
      "[Epoch 46/50] [Batch 106/300] [D loss: 0.752253] [G loss: 0.469513] time: 1:09:08.547788\n",
      "0.93373877\n",
      "[Epoch 46/50] [Batch 107/300] [D loss: 0.752248] [G loss: 0.462145] time: 1:09:08.828770\n",
      "0.9100569\n",
      "[Epoch 46/50] [Batch 108/300] [D loss: 0.752229] [G loss: 0.477732] time: 1:09:09.148970\n",
      "0.9230682\n",
      "[Epoch 46/50] [Batch 109/300] [D loss: 0.752264] [G loss: 0.478202] time: 1:09:09.454838\n",
      "0.9288654\n",
      "[Epoch 46/50] [Batch 110/300] [D loss: 0.752253] [G loss: 0.468298] time: 1:09:09.751262\n",
      "0.9224766\n",
      "[Epoch 46/50] [Batch 111/300] [D loss: 0.752247] [G loss: 0.467911] time: 1:09:10.035848\n",
      "0.8997229\n",
      "[Epoch 46/50] [Batch 112/300] [D loss: 0.752240] [G loss: 0.477642] time: 1:09:10.336674\n",
      "0.9357524\n",
      "[Epoch 46/50] [Batch 113/300] [D loss: 0.752246] [G loss: 0.472445] time: 1:09:10.635654\n",
      "0.9081878\n",
      "[Epoch 46/50] [Batch 114/300] [D loss: 0.752239] [G loss: 0.481427] time: 1:09:10.940006\n",
      "0.9386773\n",
      "[Epoch 46/50] [Batch 115/300] [D loss: 0.752242] [G loss: 0.476218] time: 1:09:11.244884\n",
      "0.9342316\n",
      "[Epoch 46/50] [Batch 116/300] [D loss: 0.752239] [G loss: 0.470797] time: 1:09:11.529300\n",
      "0.9452726\n",
      "[Epoch 46/50] [Batch 117/300] [D loss: 0.752242] [G loss: 0.472001] time: 1:09:11.825090\n",
      "0.8847468\n",
      "[Epoch 46/50] [Batch 118/300] [D loss: 0.752248] [G loss: 0.472847] time: 1:09:12.128048\n",
      "0.96875316\n",
      "[Epoch 46/50] [Batch 119/300] [D loss: 0.752244] [G loss: 0.466675] time: 1:09:12.434401\n",
      "0.9522551\n",
      "[Epoch 46/50] [Batch 120/300] [D loss: 0.752244] [G loss: 0.464898] time: 1:09:12.743597\n",
      "0.93917066\n",
      "[Epoch 46/50] [Batch 121/300] [D loss: 0.752242] [G loss: 0.462677] time: 1:09:13.037004\n",
      "0.939051\n",
      "[Epoch 46/50] [Batch 122/300] [D loss: 0.752248] [G loss: 0.488359] time: 1:09:13.339730\n",
      "0.9464593\n",
      "[Epoch 46/50] [Batch 123/300] [D loss: 0.752245] [G loss: 0.476853] time: 1:09:13.632381\n",
      "0.8777737\n",
      "[Epoch 46/50] [Batch 124/300] [D loss: 0.752250] [G loss: 0.473502] time: 1:09:13.923046\n",
      "0.9552684\n",
      "[Epoch 46/50] [Batch 125/300] [D loss: 0.752255] [G loss: 0.470445] time: 1:09:14.221735\n",
      "0.93232393\n",
      "[Epoch 46/50] [Batch 126/300] [D loss: 0.752242] [G loss: 0.475189] time: 1:09:14.499688\n",
      "0.91562825\n",
      "[Epoch 46/50] [Batch 127/300] [D loss: 0.752237] [G loss: 0.470329] time: 1:09:14.780411\n",
      "0.88730097\n",
      "[Epoch 46/50] [Batch 128/300] [D loss: 0.752247] [G loss: 0.470216] time: 1:09:15.092905\n",
      "0.9546616\n",
      "[Epoch 46/50] [Batch 129/300] [D loss: 0.752235] [G loss: 0.468960] time: 1:09:15.405708\n",
      "0.9223304\n",
      "[Epoch 46/50] [Batch 130/300] [D loss: 0.752236] [G loss: 0.490857] time: 1:09:15.702262\n",
      "0.93492985\n",
      "[Epoch 46/50] [Batch 131/300] [D loss: 0.752238] [G loss: 0.474870] time: 1:09:16.003709\n",
      "0.8959465\n",
      "[Epoch 46/50] [Batch 132/300] [D loss: 0.752260] [G loss: 0.484114] time: 1:09:16.310094\n",
      "0.92893267\n",
      "[Epoch 46/50] [Batch 133/300] [D loss: 0.752240] [G loss: 0.478275] time: 1:09:16.617380\n",
      "0.89569116\n",
      "[Epoch 46/50] [Batch 134/300] [D loss: 0.752248] [G loss: 0.467913] time: 1:09:16.921183\n",
      "0.9223559\n",
      "[Epoch 46/50] [Batch 135/300] [D loss: 0.752246] [G loss: 0.480387] time: 1:09:17.227869\n",
      "0.9306081\n",
      "[Epoch 46/50] [Batch 136/300] [D loss: 0.752247] [G loss: 0.471041] time: 1:09:17.508427\n",
      "0.9100785\n",
      "[Epoch 46/50] [Batch 137/300] [D loss: 0.752237] [G loss: 0.478409] time: 1:09:17.803403\n",
      "0.9108121\n",
      "[Epoch 46/50] [Batch 138/300] [D loss: 0.752246] [G loss: 0.486611] time: 1:09:18.094380\n",
      "0.9196091\n",
      "[Epoch 46/50] [Batch 139/300] [D loss: 0.752247] [G loss: 0.468064] time: 1:09:18.381689\n",
      "0.9468212\n",
      "[Epoch 46/50] [Batch 140/300] [D loss: 0.752249] [G loss: 0.464777] time: 1:09:18.685407\n",
      "0.89916414\n",
      "[Epoch 46/50] [Batch 141/300] [D loss: 0.752245] [G loss: 0.465249] time: 1:09:18.983055\n",
      "0.8984454\n",
      "[Epoch 46/50] [Batch 142/300] [D loss: 0.752236] [G loss: 0.479860] time: 1:09:19.292825\n",
      "0.94436026\n",
      "[Epoch 46/50] [Batch 143/300] [D loss: 0.752240] [G loss: 0.465043] time: 1:09:19.596841\n",
      "0.90701765\n",
      "[Epoch 46/50] [Batch 144/300] [D loss: 0.752257] [G loss: 0.472913] time: 1:09:19.903307\n",
      "0.92972416\n",
      "[Epoch 46/50] [Batch 145/300] [D loss: 0.752237] [G loss: 0.474787] time: 1:09:20.212867\n",
      "0.88124007\n",
      "[Epoch 46/50] [Batch 146/300] [D loss: 0.752244] [G loss: 0.467640] time: 1:09:20.505823\n",
      "0.9562952\n",
      "[Epoch 46/50] [Batch 147/300] [D loss: 0.752252] [G loss: 0.472773] time: 1:09:20.803932\n",
      "0.9171128\n",
      "[Epoch 46/50] [Batch 148/300] [D loss: 0.752258] [G loss: 0.484977] time: 1:09:21.083818\n",
      "0.8955729\n",
      "[Epoch 46/50] [Batch 149/300] [D loss: 0.752242] [G loss: 0.471750] time: 1:09:21.378271\n",
      "0.9427932\n",
      "[Epoch 46/50] [Batch 150/300] [D loss: 0.752246] [G loss: 0.478654] time: 1:09:21.689648\n",
      "0.9096915\n",
      "[Epoch 46/50] [Batch 151/300] [D loss: 0.752227] [G loss: 0.474108] time: 1:09:21.991781\n",
      "0.9774694\n",
      "[Epoch 46/50] [Batch 152/300] [D loss: 0.752238] [G loss: 0.473687] time: 1:09:22.295597\n",
      "0.9313776\n",
      "[Epoch 46/50] [Batch 153/300] [D loss: 0.752244] [G loss: 0.477588] time: 1:09:22.592476\n",
      "0.9410437\n",
      "[Epoch 46/50] [Batch 154/300] [D loss: 0.752244] [G loss: 0.487411] time: 1:09:22.893511\n",
      "0.9164732\n",
      "[Epoch 46/50] [Batch 155/300] [D loss: 0.752252] [G loss: 0.466684] time: 1:09:23.205226\n",
      "0.903106\n",
      "[Epoch 46/50] [Batch 156/300] [D loss: 0.752233] [G loss: 0.474429] time: 1:09:23.510493\n",
      "0.9412852\n",
      "[Epoch 46/50] [Batch 157/300] [D loss: 0.752242] [G loss: 0.477830] time: 1:09:23.801292\n",
      "0.96905977\n",
      "[Epoch 46/50] [Batch 158/300] [D loss: 0.752245] [G loss: 0.466315] time: 1:09:24.106631\n",
      "0.8806874\n",
      "[Epoch 46/50] [Batch 159/300] [D loss: 0.752245] [G loss: 0.471317] time: 1:09:24.395015\n",
      "0.9313545\n",
      "[Epoch 46/50] [Batch 160/300] [D loss: 0.752238] [G loss: 0.472795] time: 1:09:24.704721\n",
      "0.9335704\n",
      "[Epoch 46/50] [Batch 161/300] [D loss: 0.752228] [G loss: 0.481757] time: 1:09:25.000089\n",
      "0.8984621\n",
      "[Epoch 46/50] [Batch 162/300] [D loss: 0.752247] [G loss: 0.473245] time: 1:09:25.296741\n",
      "0.89393157\n",
      "[Epoch 46/50] [Batch 163/300] [D loss: 0.752248] [G loss: 0.485006] time: 1:09:25.602709\n",
      "0.9093866\n",
      "[Epoch 46/50] [Batch 164/300] [D loss: 0.752247] [G loss: 0.469335] time: 1:09:25.910062\n",
      "0.8906347\n",
      "[Epoch 46/50] [Batch 165/300] [D loss: 0.752249] [G loss: 0.473329] time: 1:09:26.208627\n",
      "0.93874806\n",
      "[Epoch 46/50] [Batch 166/300] [D loss: 0.752245] [G loss: 0.477577] time: 1:09:26.511748\n",
      "0.9304555\n",
      "[Epoch 46/50] [Batch 167/300] [D loss: 0.752240] [G loss: 0.474714] time: 1:09:26.818499\n",
      "0.93943053\n",
      "[Epoch 46/50] [Batch 168/300] [D loss: 0.752249] [G loss: 0.468813] time: 1:09:27.125110\n",
      "0.91413754\n",
      "[Epoch 46/50] [Batch 169/300] [D loss: 0.752232] [G loss: 0.473430] time: 1:09:27.425906\n",
      "0.9354939\n",
      "[Epoch 46/50] [Batch 170/300] [D loss: 0.752251] [G loss: 0.479724] time: 1:09:27.716225\n",
      "0.9308915\n",
      "[Epoch 46/50] [Batch 171/300] [D loss: 0.752239] [G loss: 0.475726] time: 1:09:28.026801\n",
      "0.94704294\n",
      "[Epoch 46/50] [Batch 172/300] [D loss: 0.752250] [G loss: 0.478089] time: 1:09:28.316770\n",
      "0.9411535\n",
      "[Epoch 46/50] [Batch 173/300] [D loss: 0.752243] [G loss: 0.475008] time: 1:09:28.619443\n",
      "0.97591114\n",
      "[Epoch 46/50] [Batch 174/300] [D loss: 0.752241] [G loss: 0.472589] time: 1:09:28.924415\n",
      "0.9123967\n",
      "[Epoch 46/50] [Batch 175/300] [D loss: 0.752239] [G loss: 0.473420] time: 1:09:29.217478\n",
      "0.9282494\n",
      "[Epoch 46/50] [Batch 176/300] [D loss: 0.752248] [G loss: 0.480393] time: 1:09:29.498367\n",
      "0.9167091\n",
      "[Epoch 46/50] [Batch 177/300] [D loss: 0.752243] [G loss: 0.474884] time: 1:09:29.784370\n",
      "0.9398863\n",
      "[Epoch 46/50] [Batch 178/300] [D loss: 0.752245] [G loss: 0.473476] time: 1:09:30.094887\n",
      "0.90893394\n",
      "[Epoch 46/50] [Batch 179/300] [D loss: 0.752240] [G loss: 0.469718] time: 1:09:30.408604\n",
      "0.9193763\n",
      "[Epoch 46/50] [Batch 180/300] [D loss: 0.752247] [G loss: 0.469732] time: 1:09:30.716755\n",
      "0.9345601\n",
      "[Epoch 46/50] [Batch 181/300] [D loss: 0.752238] [G loss: 0.466452] time: 1:09:31.033258\n",
      "0.9164736\n",
      "[Epoch 46/50] [Batch 182/300] [D loss: 0.752236] [G loss: 0.476204] time: 1:09:31.337820\n",
      "0.9179876\n",
      "[Epoch 46/50] [Batch 183/300] [D loss: 0.752236] [G loss: 0.468427] time: 1:09:31.639225\n",
      "0.93511033\n",
      "[Epoch 46/50] [Batch 184/300] [D loss: 0.752239] [G loss: 0.494864] time: 1:09:31.949080\n",
      "0.89136964\n",
      "[Epoch 46/50] [Batch 185/300] [D loss: 0.752239] [G loss: 0.477495] time: 1:09:32.284390\n",
      "0.9050595\n",
      "[Epoch 46/50] [Batch 186/300] [D loss: 0.752241] [G loss: 0.490845] time: 1:09:32.589897\n",
      "0.9327232\n",
      "[Epoch 46/50] [Batch 187/300] [D loss: 0.752234] [G loss: 0.473516] time: 1:09:32.895074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9389456\n",
      "[Epoch 46/50] [Batch 188/300] [D loss: 0.752242] [G loss: 0.464884] time: 1:09:33.183217\n",
      "0.94431543\n",
      "[Epoch 46/50] [Batch 189/300] [D loss: 0.752243] [G loss: 0.492991] time: 1:09:33.471804\n",
      "0.89770716\n",
      "[Epoch 46/50] [Batch 190/300] [D loss: 0.752238] [G loss: 0.488158] time: 1:09:33.774543\n",
      "0.9088029\n",
      "[Epoch 46/50] [Batch 191/300] [D loss: 0.752242] [G loss: 0.467205] time: 1:09:34.082483\n",
      "0.9102995\n",
      "[Epoch 46/50] [Batch 192/300] [D loss: 0.752243] [G loss: 0.474367] time: 1:09:34.390566\n",
      "0.90636843\n",
      "[Epoch 46/50] [Batch 193/300] [D loss: 0.752238] [G loss: 0.484673] time: 1:09:34.690392\n",
      "0.9476299\n",
      "[Epoch 46/50] [Batch 194/300] [D loss: 0.752244] [G loss: 0.473974] time: 1:09:34.972828\n",
      "0.9105745\n",
      "[Epoch 46/50] [Batch 195/300] [D loss: 0.752251] [G loss: 0.466802] time: 1:09:35.272048\n",
      "0.9195433\n",
      "[Epoch 46/50] [Batch 196/300] [D loss: 0.752242] [G loss: 0.479010] time: 1:09:35.591332\n",
      "0.9210772\n",
      "[Epoch 46/50] [Batch 197/300] [D loss: 0.752251] [G loss: 0.467262] time: 1:09:35.904126\n",
      "0.91088885\n",
      "[Epoch 46/50] [Batch 198/300] [D loss: 0.752233] [G loss: 0.475969] time: 1:09:36.211701\n",
      "0.88864565\n",
      "[Epoch 46/50] [Batch 199/300] [D loss: 0.752240] [G loss: 0.496866] time: 1:09:36.521372\n",
      "0.9505432\n",
      "[Epoch 46/50] [Batch 200/300] [D loss: 0.752245] [G loss: 0.474973] time: 1:09:36.818783\n",
      "0.9691543\n",
      "[Epoch 46/50] [Batch 201/300] [D loss: 0.752236] [G loss: 0.474755] time: 1:09:37.106771\n",
      "0.91736364\n",
      "[Epoch 46/50] [Batch 202/300] [D loss: 0.752239] [G loss: 0.480275] time: 1:09:37.404900\n",
      "0.8957475\n",
      "[Epoch 46/50] [Batch 203/300] [D loss: 0.752227] [G loss: 0.479451] time: 1:09:37.710136\n",
      "0.9483917\n",
      "[Epoch 46/50] [Batch 204/300] [D loss: 0.752242] [G loss: 0.476885] time: 1:09:38.018423\n",
      "0.93550473\n",
      "[Epoch 46/50] [Batch 205/300] [D loss: 0.752237] [G loss: 0.466515] time: 1:09:38.322902\n",
      "0.92044204\n",
      "[Epoch 46/50] [Batch 206/300] [D loss: 0.752238] [G loss: 0.468626] time: 1:09:38.615956\n",
      "0.92615145\n",
      "[Epoch 46/50] [Batch 207/300] [D loss: 0.752240] [G loss: 0.473438] time: 1:09:38.909205\n",
      "0.9453705\n",
      "[Epoch 46/50] [Batch 208/300] [D loss: 0.752235] [G loss: 0.466999] time: 1:09:39.217265\n",
      "0.8746755\n",
      "[Epoch 46/50] [Batch 209/300] [D loss: 0.752246] [G loss: 0.467050] time: 1:09:39.524146\n",
      "0.8859486\n",
      "[Epoch 46/50] [Batch 210/300] [D loss: 0.752245] [G loss: 0.466751] time: 1:09:39.838629\n",
      "0.8959255\n",
      "[Epoch 46/50] [Batch 211/300] [D loss: 0.752245] [G loss: 0.477936] time: 1:09:40.140697\n",
      "0.9138852\n",
      "[Epoch 46/50] [Batch 212/300] [D loss: 0.752247] [G loss: 0.465817] time: 1:09:40.444846\n",
      "0.93511677\n",
      "[Epoch 46/50] [Batch 213/300] [D loss: 0.752247] [G loss: 0.496486] time: 1:09:40.753182\n",
      "0.91903955\n",
      "[Epoch 46/50] [Batch 214/300] [D loss: 0.752239] [G loss: 0.477762] time: 1:09:41.061234\n",
      "0.9296705\n",
      "[Epoch 46/50] [Batch 215/300] [D loss: 0.752236] [G loss: 0.472860] time: 1:09:41.384574\n",
      "0.9312937\n",
      "[Epoch 46/50] [Batch 216/300] [D loss: 0.752233] [G loss: 0.479767] time: 1:09:41.690755\n",
      "0.9241187\n",
      "[Epoch 46/50] [Batch 217/300] [D loss: 0.752253] [G loss: 0.474674] time: 1:09:41.994448\n",
      "0.86731416\n",
      "[Epoch 46/50] [Batch 218/300] [D loss: 0.752230] [G loss: 0.475355] time: 1:09:42.287081\n",
      "0.9084696\n",
      "[Epoch 46/50] [Batch 219/300] [D loss: 0.752252] [G loss: 0.467958] time: 1:09:42.588857\n",
      "0.94512147\n",
      "[Epoch 46/50] [Batch 220/300] [D loss: 0.752245] [G loss: 0.471204] time: 1:09:42.875553\n",
      "0.91657525\n",
      "[Epoch 46/50] [Batch 221/300] [D loss: 0.752232] [G loss: 0.472012] time: 1:09:43.176867\n",
      "0.87664574\n",
      "[Epoch 46/50] [Batch 222/300] [D loss: 0.752237] [G loss: 0.474560] time: 1:09:43.472530\n",
      "0.94975376\n",
      "[Epoch 46/50] [Batch 223/300] [D loss: 0.752240] [G loss: 0.473047] time: 1:09:43.775478\n",
      "0.9242304\n",
      "[Epoch 46/50] [Batch 224/300] [D loss: 0.752239] [G loss: 0.467419] time: 1:09:44.083003\n",
      "0.9493211\n",
      "[Epoch 46/50] [Batch 225/300] [D loss: 0.752252] [G loss: 0.473413] time: 1:09:44.384011\n",
      "0.88636494\n",
      "[Epoch 46/50] [Batch 226/300] [D loss: 0.752233] [G loss: 0.476529] time: 1:09:44.672686\n",
      "0.89848346\n",
      "[Epoch 46/50] [Batch 227/300] [D loss: 0.752235] [G loss: 0.494770] time: 1:09:44.960998\n",
      "0.90870285\n",
      "[Epoch 46/50] [Batch 228/300] [D loss: 0.752244] [G loss: 0.474981] time: 1:09:45.255416\n",
      "0.8859579\n",
      "[Epoch 46/50] [Batch 229/300] [D loss: 0.752229] [G loss: 0.466535] time: 1:09:45.573092\n",
      "0.93925315\n",
      "[Epoch 46/50] [Batch 230/300] [D loss: 0.752240] [G loss: 0.470109] time: 1:09:45.863133\n",
      "0.93615943\n",
      "[Epoch 46/50] [Batch 231/300] [D loss: 0.752236] [G loss: 0.474791] time: 1:09:46.160814\n",
      "0.9355505\n",
      "[Epoch 46/50] [Batch 232/300] [D loss: 0.752238] [G loss: 0.474029] time: 1:09:46.468014\n",
      "0.92933893\n",
      "[Epoch 46/50] [Batch 233/300] [D loss: 0.752242] [G loss: 0.480751] time: 1:09:46.773285\n",
      "0.94186544\n",
      "[Epoch 46/50] [Batch 234/300] [D loss: 0.752237] [G loss: 0.479784] time: 1:09:47.081539\n",
      "0.93308264\n",
      "[Epoch 46/50] [Batch 235/300] [D loss: 0.752233] [G loss: 0.484620] time: 1:09:47.378040\n",
      "0.9259103\n",
      "[Epoch 46/50] [Batch 236/300] [D loss: 0.752238] [G loss: 0.468657] time: 1:09:47.669181\n",
      "0.9155386\n",
      "[Epoch 46/50] [Batch 237/300] [D loss: 0.752246] [G loss: 0.479854] time: 1:09:47.969678\n",
      "0.9589874\n",
      "[Epoch 46/50] [Batch 238/300] [D loss: 0.752234] [G loss: 0.508990] time: 1:09:48.277596\n",
      "0.9431549\n",
      "[Epoch 46/50] [Batch 239/300] [D loss: 0.752241] [G loss: 0.480126] time: 1:09:48.565392\n",
      "0.9605741\n",
      "[Epoch 46/50] [Batch 240/300] [D loss: 0.752239] [G loss: 0.471416] time: 1:09:48.861998\n",
      "0.9050128\n",
      "[Epoch 46/50] [Batch 241/300] [D loss: 0.752239] [G loss: 0.478365] time: 1:09:49.138434\n",
      "0.9352846\n",
      "[Epoch 46/50] [Batch 242/300] [D loss: 0.752234] [G loss: 0.469202] time: 1:09:49.432259\n",
      "0.8897307\n",
      "[Epoch 46/50] [Batch 243/300] [D loss: 0.752241] [G loss: 0.474441] time: 1:09:49.737558\n",
      "0.94802517\n",
      "[Epoch 46/50] [Batch 244/300] [D loss: 0.752246] [G loss: 0.472707] time: 1:09:50.045164\n",
      "0.9358904\n",
      "[Epoch 46/50] [Batch 245/300] [D loss: 0.752251] [G loss: 0.490755] time: 1:09:50.352956\n",
      "0.8997369\n",
      "[Epoch 46/50] [Batch 246/300] [D loss: 0.752228] [G loss: 0.471730] time: 1:09:50.640378\n",
      "0.898654\n",
      "[Epoch 46/50] [Batch 247/300] [D loss: 0.752233] [G loss: 0.473426] time: 1:09:50.950560\n",
      "0.9119207\n",
      "[Epoch 46/50] [Batch 248/300] [D loss: 0.752246] [G loss: 0.469749] time: 1:09:51.254659\n",
      "0.90371186\n",
      "[Epoch 46/50] [Batch 249/300] [D loss: 0.752242] [G loss: 0.464822] time: 1:09:51.551681\n",
      "0.9335992\n",
      "[Epoch 46/50] [Batch 250/300] [D loss: 0.752233] [G loss: 0.471108] time: 1:09:51.865439\n",
      "0.94219285\n",
      "[Epoch 46/50] [Batch 251/300] [D loss: 0.752240] [G loss: 0.481109] time: 1:09:52.133546\n",
      "0.93281764\n",
      "[Epoch 46/50] [Batch 252/300] [D loss: 0.752238] [G loss: 0.476693] time: 1:09:52.434480\n",
      "0.908329\n",
      "[Epoch 46/50] [Batch 253/300] [D loss: 0.752242] [G loss: 0.463087] time: 1:09:52.723758\n",
      "0.9023846\n",
      "[Epoch 46/50] [Batch 254/300] [D loss: 0.752235] [G loss: 0.469384] time: 1:09:53.011888\n",
      "0.9524953\n",
      "[Epoch 46/50] [Batch 255/300] [D loss: 0.752246] [G loss: 0.463341] time: 1:09:53.328302\n",
      "0.93270725\n",
      "[Epoch 46/50] [Batch 256/300] [D loss: 0.752245] [G loss: 0.470442] time: 1:09:53.619980\n",
      "0.89963144\n",
      "[Epoch 46/50] [Batch 257/300] [D loss: 0.752229] [G loss: 0.469238] time: 1:09:53.926393\n",
      "0.94773597\n",
      "[Epoch 46/50] [Batch 258/300] [D loss: 0.752238] [G loss: 0.465361] time: 1:09:54.239211\n",
      "0.9090318\n",
      "[Epoch 46/50] [Batch 259/300] [D loss: 0.752236] [G loss: 0.471085] time: 1:09:54.531693\n",
      "0.8735955\n",
      "[Epoch 46/50] [Batch 260/300] [D loss: 0.752235] [G loss: 0.512208] time: 1:09:54.843283\n",
      "0.9109033\n",
      "[Epoch 46/50] [Batch 261/300] [D loss: 0.752248] [G loss: 0.467812] time: 1:09:55.153015\n",
      "0.9063103\n",
      "[Epoch 46/50] [Batch 262/300] [D loss: 0.752241] [G loss: 0.473057] time: 1:09:55.451625\n",
      "0.9275737\n",
      "[Epoch 46/50] [Batch 263/300] [D loss: 0.752252] [G loss: 0.481462] time: 1:09:55.747986\n",
      "0.89693\n",
      "[Epoch 46/50] [Batch 264/300] [D loss: 0.752240] [G loss: 0.480017] time: 1:09:56.069651\n",
      "0.9487999\n",
      "[Epoch 46/50] [Batch 265/300] [D loss: 0.752249] [G loss: 0.506328] time: 1:09:56.363309\n",
      "0.92612654\n",
      "[Epoch 46/50] [Batch 266/300] [D loss: 0.752224] [G loss: 0.490382] time: 1:09:56.657892\n",
      "0.92723894\n",
      "[Epoch 46/50] [Batch 267/300] [D loss: 0.752246] [G loss: 0.469656] time: 1:09:56.955320\n",
      "0.9528637\n",
      "[Epoch 46/50] [Batch 268/300] [D loss: 0.752241] [G loss: 0.468440] time: 1:09:57.247934\n",
      "0.9404027\n",
      "[Epoch 46/50] [Batch 269/300] [D loss: 0.752240] [G loss: 0.476115] time: 1:09:57.549634\n",
      "0.92995715\n",
      "[Epoch 46/50] [Batch 270/300] [D loss: 0.752243] [G loss: 0.484366] time: 1:09:57.854259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239637\n",
      "[Epoch 46/50] [Batch 271/300] [D loss: 0.752248] [G loss: 0.472919] time: 1:09:58.177366\n",
      "0.93092436\n",
      "[Epoch 46/50] [Batch 272/300] [D loss: 0.752241] [G loss: 0.475556] time: 1:09:58.483099\n",
      "0.9311056\n",
      "[Epoch 46/50] [Batch 273/300] [D loss: 0.752245] [G loss: 0.478513] time: 1:09:58.799062\n",
      "0.9315353\n",
      "[Epoch 46/50] [Batch 274/300] [D loss: 0.752238] [G loss: 0.493238] time: 1:09:59.097732\n",
      "0.9224308\n",
      "[Epoch 46/50] [Batch 275/300] [D loss: 0.752252] [G loss: 0.475364] time: 1:09:59.403982\n",
      "0.9528671\n",
      "[Epoch 46/50] [Batch 276/300] [D loss: 0.752247] [G loss: 0.470170] time: 1:09:59.705723\n",
      "0.9164632\n",
      "[Epoch 46/50] [Batch 277/300] [D loss: 0.752237] [G loss: 0.467256] time: 1:09:59.995335\n",
      "0.91714907\n",
      "[Epoch 46/50] [Batch 278/300] [D loss: 0.752241] [G loss: 0.466368] time: 1:10:00.292943\n",
      "0.9115836\n",
      "[Epoch 46/50] [Batch 279/300] [D loss: 0.752246] [G loss: 0.470162] time: 1:10:00.595760\n",
      "0.9460482\n",
      "[Epoch 46/50] [Batch 280/300] [D loss: 0.752222] [G loss: 0.478209] time: 1:10:00.886375\n",
      "0.8846677\n",
      "[Epoch 46/50] [Batch 281/300] [D loss: 0.752240] [G loss: 0.497468] time: 1:10:01.182040\n",
      "0.93835235\n",
      "[Epoch 46/50] [Batch 282/300] [D loss: 0.752240] [G loss: 0.485078] time: 1:10:01.469535\n",
      "0.91533214\n",
      "[Epoch 46/50] [Batch 283/300] [D loss: 0.752246] [G loss: 0.483265] time: 1:10:01.779840\n",
      "0.9386454\n",
      "[Epoch 46/50] [Batch 284/300] [D loss: 0.752235] [G loss: 0.483128] time: 1:10:02.078288\n",
      "0.8811795\n",
      "[Epoch 46/50] [Batch 285/300] [D loss: 0.752248] [G loss: 0.494173] time: 1:10:02.372017\n",
      "0.9083285\n",
      "[Epoch 46/50] [Batch 286/300] [D loss: 0.752253] [G loss: 0.482293] time: 1:10:02.672396\n",
      "0.882915\n",
      "[Epoch 46/50] [Batch 287/300] [D loss: 0.752243] [G loss: 0.469465] time: 1:10:02.990329\n",
      "0.92013985\n",
      "[Epoch 46/50] [Batch 288/300] [D loss: 0.752227] [G loss: 0.474619] time: 1:10:03.290572\n",
      "0.90853184\n",
      "[Epoch 46/50] [Batch 289/300] [D loss: 0.752249] [G loss: 0.473152] time: 1:10:03.575841\n",
      "0.9166748\n",
      "[Epoch 46/50] [Batch 290/300] [D loss: 0.752246] [G loss: 0.481567] time: 1:10:03.887374\n",
      "0.92241925\n",
      "[Epoch 46/50] [Batch 291/300] [D loss: 0.752244] [G loss: 0.480381] time: 1:10:04.183170\n",
      "0.9531708\n",
      "[Epoch 46/50] [Batch 292/300] [D loss: 0.752249] [G loss: 0.475841] time: 1:10:04.472473\n",
      "0.91632324\n",
      "[Epoch 46/50] [Batch 293/300] [D loss: 0.752229] [G loss: 0.469876] time: 1:10:04.756065\n",
      "0.9176056\n",
      "[Epoch 46/50] [Batch 294/300] [D loss: 0.752242] [G loss: 0.484524] time: 1:10:05.052710\n",
      "0.93473405\n",
      "[Epoch 46/50] [Batch 295/300] [D loss: 0.752229] [G loss: 0.479529] time: 1:10:05.378074\n",
      "0.89935756\n",
      "[Epoch 46/50] [Batch 296/300] [D loss: 0.752239] [G loss: 0.482954] time: 1:10:05.677487\n",
      "0.90676254\n",
      "[Epoch 46/50] [Batch 297/300] [D loss: 0.752240] [G loss: 0.490783] time: 1:10:05.975621\n",
      "0.91858345\n",
      "[Epoch 46/50] [Batch 298/300] [D loss: 0.752239] [G loss: 0.476239] time: 1:10:06.274376\n",
      "0.92305845\n",
      "[Epoch 46/50] [Batch 299/300] [D loss: 0.752246] [G loss: 0.480193] time: 1:10:06.569878\n",
      "0.9181817\n",
      "[Epoch 47/50] [Batch 0/300] [D loss: 0.752239] [G loss: 0.477622] time: 1:10:06.867929\n",
      "0.9044098\n",
      "[Epoch 47/50] [Batch 1/300] [D loss: 0.752234] [G loss: 0.495240] time: 1:10:07.171331\n",
      "0.9267798\n",
      "[Epoch 47/50] [Batch 2/300] [D loss: 0.752238] [G loss: 0.472292] time: 1:10:07.474673\n",
      "0.91545916\n",
      "[Epoch 47/50] [Batch 3/300] [D loss: 0.752234] [G loss: 0.487521] time: 1:10:07.771035\n",
      "0.9176585\n",
      "[Epoch 47/50] [Batch 4/300] [D loss: 0.752237] [G loss: 0.475542] time: 1:10:08.074774\n",
      "0.90536904\n",
      "[Epoch 47/50] [Batch 5/300] [D loss: 0.752231] [G loss: 0.494739] time: 1:10:08.383074\n",
      "0.8998303\n",
      "[Epoch 47/50] [Batch 6/300] [D loss: 0.752245] [G loss: 0.468705] time: 1:10:08.692331\n",
      "0.9306614\n",
      "[Epoch 47/50] [Batch 7/300] [D loss: 0.752255] [G loss: 0.471744] time: 1:10:09.003077\n",
      "0.9774988\n",
      "[Epoch 47/50] [Batch 8/300] [D loss: 0.752234] [G loss: 0.481095] time: 1:10:09.293948\n",
      "0.92480016\n",
      "[Epoch 47/50] [Batch 9/300] [D loss: 0.752229] [G loss: 0.470470] time: 1:10:09.607059\n",
      "0.893126\n",
      "[Epoch 47/50] [Batch 10/300] [D loss: 0.752260] [G loss: 0.464253] time: 1:10:09.909355\n",
      "0.90554714\n",
      "[Epoch 47/50] [Batch 11/300] [D loss: 0.752243] [G loss: 0.470653] time: 1:10:10.220436\n",
      "0.9266138\n",
      "[Epoch 47/50] [Batch 12/300] [D loss: 0.752236] [G loss: 0.497927] time: 1:10:10.535867\n",
      "0.909733\n",
      "[Epoch 47/50] [Batch 13/300] [D loss: 0.752235] [G loss: 0.474186] time: 1:10:10.823845\n",
      "0.9372852\n",
      "[Epoch 47/50] [Batch 14/300] [D loss: 0.752244] [G loss: 0.478601] time: 1:10:11.139205\n",
      "0.9042373\n",
      "[Epoch 47/50] [Batch 15/300] [D loss: 0.752261] [G loss: 0.477052] time: 1:10:11.448549\n",
      "0.93118834\n",
      "[Epoch 47/50] [Batch 16/300] [D loss: 0.752233] [G loss: 0.487270] time: 1:10:11.736928\n",
      "0.89629483\n",
      "[Epoch 47/50] [Batch 17/300] [D loss: 0.752236] [G loss: 0.482469] time: 1:10:12.042089\n",
      "0.9296219\n",
      "[Epoch 47/50] [Batch 18/300] [D loss: 0.752243] [G loss: 0.467315] time: 1:10:12.326883\n",
      "0.9745377\n",
      "[Epoch 47/50] [Batch 19/300] [D loss: 0.752237] [G loss: 0.492960] time: 1:10:12.628023\n",
      "0.8813619\n",
      "[Epoch 47/50] [Batch 20/300] [D loss: 0.752247] [G loss: 0.465568] time: 1:10:12.918405\n",
      "0.93488556\n",
      "[Epoch 47/50] [Batch 21/300] [D loss: 0.752244] [G loss: 0.484913] time: 1:10:13.219539\n",
      "0.88556224\n",
      "[Epoch 47/50] [Batch 22/300] [D loss: 0.752233] [G loss: 0.482443] time: 1:10:13.539586\n",
      "0.9418059\n",
      "[Epoch 47/50] [Batch 23/300] [D loss: 0.752241] [G loss: 0.484059] time: 1:10:13.823349\n",
      "0.93025213\n",
      "[Epoch 47/50] [Batch 24/300] [D loss: 0.752238] [G loss: 0.465923] time: 1:10:14.103698\n",
      "0.9255168\n",
      "[Epoch 47/50] [Batch 25/300] [D loss: 0.752250] [G loss: 0.484873] time: 1:10:14.433610\n",
      "0.8883941\n",
      "[Epoch 47/50] [Batch 26/300] [D loss: 0.752232] [G loss: 0.470799] time: 1:10:14.749206\n",
      "0.9581761\n",
      "[Epoch 47/50] [Batch 27/300] [D loss: 0.752241] [G loss: 0.487023] time: 1:10:15.053217\n",
      "0.87438726\n",
      "[Epoch 47/50] [Batch 28/300] [D loss: 0.752242] [G loss: 0.469345] time: 1:10:15.340737\n",
      "0.8988406\n",
      "[Epoch 47/50] [Batch 29/300] [D loss: 0.752248] [G loss: 0.473743] time: 1:10:15.646306\n",
      "0.92155474\n",
      "[Epoch 47/50] [Batch 30/300] [D loss: 0.752234] [G loss: 0.467280] time: 1:10:15.947515\n",
      "0.9835892\n",
      "[Epoch 47/50] [Batch 31/300] [D loss: 0.752241] [G loss: 0.471512] time: 1:10:16.229461\n",
      "0.91377276\n",
      "[Epoch 47/50] [Batch 32/300] [D loss: 0.752240] [G loss: 0.471705] time: 1:10:16.530051\n",
      "0.9321788\n",
      "[Epoch 47/50] [Batch 33/300] [D loss: 0.752243] [G loss: 0.476190] time: 1:10:16.829683\n",
      "0.9286552\n",
      "[Epoch 47/50] [Batch 34/300] [D loss: 0.752235] [G loss: 0.486640] time: 1:10:17.137268\n",
      "0.9353974\n",
      "[Epoch 47/50] [Batch 35/300] [D loss: 0.752223] [G loss: 0.478363] time: 1:10:17.445193\n",
      "0.884846\n",
      "[Epoch 47/50] [Batch 36/300] [D loss: 0.752240] [G loss: 0.484034] time: 1:10:17.749364\n",
      "0.9395792\n",
      "[Epoch 47/50] [Batch 37/300] [D loss: 0.752237] [G loss: 0.473807] time: 1:10:18.054847\n",
      "0.9294815\n",
      "[Epoch 47/50] [Batch 38/300] [D loss: 0.752234] [G loss: 0.465095] time: 1:10:18.363838\n",
      "0.8837064\n",
      "[Epoch 47/50] [Batch 39/300] [D loss: 0.752233] [G loss: 0.471065] time: 1:10:18.664464\n",
      "0.8873623\n",
      "[Epoch 47/50] [Batch 40/300] [D loss: 0.752241] [G loss: 0.481325] time: 1:10:18.951805\n",
      "0.95222133\n",
      "[Epoch 47/50] [Batch 41/300] [D loss: 0.752239] [G loss: 0.481168] time: 1:10:19.237064\n",
      "0.8958768\n",
      "[Epoch 47/50] [Batch 42/300] [D loss: 0.752231] [G loss: 0.480344] time: 1:10:19.535060\n",
      "0.9522123\n",
      "[Epoch 47/50] [Batch 43/300] [D loss: 0.752241] [G loss: 0.465788] time: 1:10:19.824796\n",
      "0.9458745\n",
      "[Epoch 47/50] [Batch 44/300] [D loss: 0.752240] [G loss: 0.472760] time: 1:10:20.135640\n",
      "0.9187904\n",
      "[Epoch 47/50] [Batch 45/300] [D loss: 0.752236] [G loss: 0.474391] time: 1:10:20.445761\n",
      "0.9362145\n",
      "[Epoch 47/50] [Batch 47/300] [D loss: 0.752251] [G loss: 0.486424] time: 1:10:20.753494\n",
      "0.9389673\n",
      "[Epoch 47/50] [Batch 48/300] [D loss: 0.752245] [G loss: 0.497334] time: 1:10:21.058225\n",
      "0.90572363\n",
      "[Epoch 47/50] [Batch 49/300] [D loss: 0.752240] [G loss: 0.470252] time: 1:10:21.383352\n",
      "0.8986597\n",
      "[Epoch 47/50] [Batch 50/300] [D loss: 0.752235] [G loss: 0.470734] time: 1:10:21.697087\n",
      "0.8946125\n",
      "[Epoch 47/50] [Batch 51/300] [D loss: 0.752243] [G loss: 0.463355] time: 1:10:21.986500\n",
      "0.89078087\n",
      "[Epoch 47/50] [Batch 52/300] [D loss: 0.752237] [G loss: 0.476268] time: 1:10:22.280435\n",
      "0.9373202\n",
      "[Epoch 47/50] [Batch 53/300] [D loss: 0.752239] [G loss: 0.468013] time: 1:10:22.576036\n",
      "0.94509536\n",
      "[Epoch 47/50] [Batch 54/300] [D loss: 0.752236] [G loss: 0.466450] time: 1:10:22.880304\n",
      "0.9354337\n",
      "[Epoch 47/50] [Batch 55/300] [D loss: 0.752234] [G loss: 0.476210] time: 1:10:23.177580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93154293\n",
      "[Epoch 47/50] [Batch 56/300] [D loss: 0.752234] [G loss: 0.463623] time: 1:10:23.477662\n",
      "0.95239466\n",
      "[Epoch 47/50] [Batch 57/300] [D loss: 0.752228] [G loss: 0.466548] time: 1:10:23.779686\n",
      "0.890423\n",
      "[Epoch 47/50] [Batch 58/300] [D loss: 0.752247] [G loss: 0.462258] time: 1:10:24.087242\n",
      "0.9138124\n",
      "[Epoch 47/50] [Batch 59/300] [D loss: 0.752236] [G loss: 0.473349] time: 1:10:24.395524\n",
      "0.9331916\n",
      "[Epoch 47/50] [Batch 60/300] [D loss: 0.752230] [G loss: 0.476093] time: 1:10:24.712568\n",
      "0.9379773\n",
      "[Epoch 47/50] [Batch 61/300] [D loss: 0.752249] [G loss: 0.472895] time: 1:10:25.012257\n",
      "0.97618556\n",
      "[Epoch 47/50] [Batch 62/300] [D loss: 0.752237] [G loss: 0.465929] time: 1:10:25.302388\n",
      "0.9268754\n",
      "[Epoch 47/50] [Batch 63/300] [D loss: 0.752251] [G loss: 0.485351] time: 1:10:25.601004\n",
      "0.93781596\n",
      "[Epoch 47/50] [Batch 64/300] [D loss: 0.752236] [G loss: 0.465224] time: 1:10:25.887726\n",
      "0.94788045\n",
      "[Epoch 47/50] [Batch 65/300] [D loss: 0.752236] [G loss: 0.478834] time: 1:10:26.187788\n",
      "0.8811285\n",
      "[Epoch 47/50] [Batch 66/300] [D loss: 0.752239] [G loss: 0.470744] time: 1:10:26.486872\n",
      "0.9107278\n",
      "[Epoch 47/50] [Batch 67/300] [D loss: 0.752244] [G loss: 0.473106] time: 1:10:26.781712\n",
      "0.9833093\n",
      "[Epoch 47/50] [Batch 68/300] [D loss: 0.752253] [G loss: 0.475261] time: 1:10:27.067561\n",
      "0.9306891\n",
      "[Epoch 47/50] [Batch 69/300] [D loss: 0.752245] [G loss: 0.466704] time: 1:10:27.365787\n",
      "0.9139597\n",
      "[Epoch 47/50] [Batch 70/300] [D loss: 0.752223] [G loss: 0.466562] time: 1:10:27.665834\n",
      "0.9091013\n",
      "[Epoch 47/50] [Batch 71/300] [D loss: 0.752236] [G loss: 0.465290] time: 1:10:27.968315\n",
      "0.9161164\n",
      "[Epoch 47/50] [Batch 72/300] [D loss: 0.752231] [G loss: 0.472763] time: 1:10:28.272358\n",
      "0.9188376\n",
      "[Epoch 47/50] [Batch 73/300] [D loss: 0.752235] [G loss: 0.489427] time: 1:10:28.567093\n",
      "0.9458615\n",
      "[Epoch 47/50] [Batch 74/300] [D loss: 0.752239] [G loss: 0.477553] time: 1:10:28.866650\n",
      "0.9328501\n",
      "[Epoch 47/50] [Batch 75/300] [D loss: 0.752239] [G loss: 0.467766] time: 1:10:29.167620\n",
      "0.9291356\n",
      "[Epoch 47/50] [Batch 76/300] [D loss: 0.752238] [G loss: 0.479431] time: 1:10:29.457021\n",
      "0.94726443\n",
      "[Epoch 47/50] [Batch 77/300] [D loss: 0.752232] [G loss: 0.466240] time: 1:10:29.756107\n",
      "0.94046307\n",
      "[Epoch 47/50] [Batch 78/300] [D loss: 0.752231] [G loss: 0.466435] time: 1:10:30.035901\n",
      "0.9302059\n",
      "[Epoch 47/50] [Batch 79/300] [D loss: 0.752237] [G loss: 0.472778] time: 1:10:30.323531\n",
      "0.9116621\n",
      "[Epoch 47/50] [Batch 80/300] [D loss: 0.752240] [G loss: 0.465676] time: 1:10:30.637854\n",
      "0.94630814\n",
      "[Epoch 47/50] [Batch 81/300] [D loss: 0.752231] [G loss: 0.465807] time: 1:10:30.928691\n",
      "0.89096934\n",
      "[Epoch 47/50] [Batch 82/300] [D loss: 0.752235] [G loss: 0.476433] time: 1:10:31.231636\n",
      "0.91718036\n",
      "[Epoch 47/50] [Batch 83/300] [D loss: 0.752229] [G loss: 0.491380] time: 1:10:31.533205\n",
      "0.9330592\n",
      "[Epoch 47/50] [Batch 84/300] [D loss: 0.752249] [G loss: 0.470048] time: 1:10:31.832911\n",
      "0.8996348\n",
      "[Epoch 47/50] [Batch 85/300] [D loss: 0.752240] [G loss: 0.481906] time: 1:10:32.120817\n",
      "0.9537832\n",
      "[Epoch 47/50] [Batch 86/300] [D loss: 0.752230] [G loss: 0.511021] time: 1:10:32.422182\n",
      "0.9136488\n",
      "[Epoch 47/50] [Batch 87/300] [D loss: 0.752239] [G loss: 0.475886] time: 1:10:32.733492\n",
      "0.90430546\n",
      "[Epoch 47/50] [Batch 88/300] [D loss: 0.752237] [G loss: 0.465817] time: 1:10:33.037118\n",
      "0.9346628\n",
      "[Epoch 47/50] [Batch 89/300] [D loss: 0.752226] [G loss: 0.469167] time: 1:10:33.338863\n",
      "0.9470586\n",
      "[Epoch 47/50] [Batch 90/300] [D loss: 0.752229] [G loss: 0.465706] time: 1:10:33.630002\n",
      "0.91516733\n",
      "[Epoch 47/50] [Batch 91/300] [D loss: 0.752238] [G loss: 0.467666] time: 1:10:33.936944\n",
      "0.9119689\n",
      "[Epoch 47/50] [Batch 92/300] [D loss: 0.752235] [G loss: 0.476332] time: 1:10:34.249251\n",
      "0.9420791\n",
      "[Epoch 47/50] [Batch 93/300] [D loss: 0.752242] [G loss: 0.474662] time: 1:10:34.568038\n",
      "0.9354753\n",
      "[Epoch 47/50] [Batch 94/300] [D loss: 0.752245] [G loss: 0.477151] time: 1:10:34.869471\n",
      "0.9090164\n",
      "[Epoch 47/50] [Batch 95/300] [D loss: 0.752232] [G loss: 0.468387] time: 1:10:35.193148\n",
      "0.8900309\n",
      "[Epoch 47/50] [Batch 96/300] [D loss: 0.752234] [G loss: 0.464027] time: 1:10:35.490567\n",
      "0.90025544\n",
      "[Epoch 47/50] [Batch 97/300] [D loss: 0.752242] [G loss: 0.461811] time: 1:10:35.784783\n",
      "0.9742751\n",
      "[Epoch 47/50] [Batch 98/300] [D loss: 0.752236] [G loss: 0.465199] time: 1:10:36.069995\n",
      "0.8719967\n",
      "[Epoch 47/50] [Batch 99/300] [D loss: 0.752242] [G loss: 0.469424] time: 1:10:36.344516\n",
      "0.8915984\n",
      "[Epoch 47/50] [Batch 100/300] [D loss: 0.752233] [G loss: 0.464423] time: 1:10:36.661381\n",
      "0.9250889\n",
      "[Epoch 47/50] [Batch 101/300] [D loss: 0.752233] [G loss: 0.474818] time: 1:10:36.958610\n",
      "0.8858393\n",
      "[Epoch 47/50] [Batch 102/300] [D loss: 0.752253] [G loss: 0.472710] time: 1:10:37.278724\n",
      "0.9309998\n",
      "[Epoch 47/50] [Batch 103/300] [D loss: 0.752238] [G loss: 0.469340] time: 1:10:37.607758\n",
      "0.9220453\n",
      "[Epoch 47/50] [Batch 104/300] [D loss: 0.752234] [G loss: 0.473012] time: 1:10:37.888642\n",
      "0.9083019\n",
      "[Epoch 47/50] [Batch 105/300] [D loss: 0.752231] [G loss: 0.478294] time: 1:10:38.194515\n",
      "0.931348\n",
      "[Epoch 47/50] [Batch 106/300] [D loss: 0.752234] [G loss: 0.475995] time: 1:10:38.498859\n",
      "0.93117124\n",
      "[Epoch 47/50] [Batch 107/300] [D loss: 0.752243] [G loss: 0.468464] time: 1:10:38.792150\n",
      "0.92146945\n",
      "[Epoch 47/50] [Batch 108/300] [D loss: 0.752242] [G loss: 0.480837] time: 1:10:39.075973\n",
      "0.94220227\n",
      "[Epoch 47/50] [Batch 109/300] [D loss: 0.752234] [G loss: 0.487310] time: 1:10:39.366645\n",
      "0.89567584\n",
      "[Epoch 47/50] [Batch 110/300] [D loss: 0.752233] [G loss: 0.471482] time: 1:10:39.677007\n",
      "0.90856296\n",
      "[Epoch 47/50] [Batch 111/300] [D loss: 0.752237] [G loss: 0.483077] time: 1:10:39.974584\n",
      "0.92029506\n",
      "[Epoch 47/50] [Batch 112/300] [D loss: 0.752248] [G loss: 0.470407] time: 1:10:40.284886\n",
      "0.90297174\n",
      "[Epoch 47/50] [Batch 113/300] [D loss: 0.752230] [G loss: 0.470478] time: 1:10:40.587867\n",
      "0.9336047\n",
      "[Epoch 47/50] [Batch 114/300] [D loss: 0.752238] [G loss: 0.467753] time: 1:10:40.901976\n",
      "0.93712026\n",
      "[Epoch 47/50] [Batch 115/300] [D loss: 0.752234] [G loss: 0.481556] time: 1:10:41.214827\n",
      "0.9290914\n",
      "[Epoch 47/50] [Batch 116/300] [D loss: 0.752241] [G loss: 0.484788] time: 1:10:41.517753\n",
      "0.96015245\n",
      "[Epoch 47/50] [Batch 117/300] [D loss: 0.752243] [G loss: 0.464734] time: 1:10:41.796681\n",
      "0.9455859\n",
      "[Epoch 47/50] [Batch 118/300] [D loss: 0.752241] [G loss: 0.484783] time: 1:10:42.082843\n",
      "0.9404812\n",
      "[Epoch 47/50] [Batch 119/300] [D loss: 0.752236] [G loss: 0.472239] time: 1:10:42.385262\n",
      "0.89600515\n",
      "[Epoch 47/50] [Batch 120/300] [D loss: 0.752239] [G loss: 0.466118] time: 1:10:42.694714\n",
      "0.9463515\n",
      "[Epoch 47/50] [Batch 121/300] [D loss: 0.752253] [G loss: 0.496426] time: 1:10:43.003190\n",
      "0.95059824\n",
      "[Epoch 47/50] [Batch 122/300] [D loss: 0.752235] [G loss: 0.476919] time: 1:10:43.305544\n",
      "0.91800696\n",
      "[Epoch 47/50] [Batch 123/300] [D loss: 0.752234] [G loss: 0.488865] time: 1:10:43.590920\n",
      "0.9712617\n",
      "[Epoch 47/50] [Batch 124/300] [D loss: 0.752230] [G loss: 0.470998] time: 1:10:43.893131\n",
      "0.9223229\n",
      "[Epoch 47/50] [Batch 125/300] [D loss: 0.752240] [G loss: 0.491177] time: 1:10:44.206559\n",
      "0.9100664\n",
      "[Epoch 47/50] [Batch 126/300] [D loss: 0.752248] [G loss: 0.464184] time: 1:10:44.506767\n",
      "0.893918\n",
      "[Epoch 47/50] [Batch 127/300] [D loss: 0.752237] [G loss: 0.466729] time: 1:10:44.814450\n",
      "0.95525247\n",
      "[Epoch 47/50] [Batch 128/300] [D loss: 0.752232] [G loss: 0.471485] time: 1:10:45.121398\n",
      "0.90194875\n",
      "[Epoch 47/50] [Batch 129/300] [D loss: 0.752239] [G loss: 0.468296] time: 1:10:45.419367\n",
      "0.8890433\n",
      "[Epoch 47/50] [Batch 130/300] [D loss: 0.752236] [G loss: 0.493683] time: 1:10:45.740528\n",
      "0.8821133\n",
      "[Epoch 47/50] [Batch 131/300] [D loss: 0.752237] [G loss: 0.477657] time: 1:10:46.048847\n",
      "0.9535024\n",
      "[Epoch 47/50] [Batch 132/300] [D loss: 0.752244] [G loss: 0.467002] time: 1:10:46.496475\n",
      "0.94204634\n",
      "[Epoch 47/50] [Batch 133/300] [D loss: 0.752236] [G loss: 0.466325] time: 1:10:46.811590\n",
      "0.9412589\n",
      "[Epoch 47/50] [Batch 134/300] [D loss: 0.752235] [G loss: 0.480585] time: 1:10:47.109199\n",
      "0.9190785\n",
      "[Epoch 47/50] [Batch 135/300] [D loss: 0.752240] [G loss: 0.477057] time: 1:10:47.412376\n",
      "0.9517123\n",
      "[Epoch 47/50] [Batch 136/300] [D loss: 0.752239] [G loss: 0.467043] time: 1:10:47.739678\n",
      "0.9419187\n",
      "[Epoch 47/50] [Batch 137/300] [D loss: 0.752237] [G loss: 0.466626] time: 1:10:48.026283\n",
      "0.9542044\n",
      "[Epoch 47/50] [Batch 138/300] [D loss: 0.752241] [G loss: 0.478011] time: 1:10:48.331020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184297\n",
      "[Epoch 47/50] [Batch 139/300] [D loss: 0.752234] [G loss: 0.480579] time: 1:10:48.622302\n",
      "0.9321639\n",
      "[Epoch 47/50] [Batch 140/300] [D loss: 0.752236] [G loss: 0.469314] time: 1:10:48.911527\n",
      "0.88457394\n",
      "[Epoch 47/50] [Batch 141/300] [D loss: 0.752234] [G loss: 0.469096] time: 1:10:49.210601\n",
      "0.9335799\n",
      "[Epoch 47/50] [Batch 142/300] [D loss: 0.752237] [G loss: 0.469156] time: 1:10:49.509054\n",
      "0.8943012\n",
      "[Epoch 47/50] [Batch 143/300] [D loss: 0.752239] [G loss: 0.473255] time: 1:10:49.801648\n",
      "0.93711853\n",
      "[Epoch 47/50] [Batch 144/300] [D loss: 0.752231] [G loss: 0.467220] time: 1:10:50.100315\n",
      "0.9464219\n",
      "[Epoch 47/50] [Batch 145/300] [D loss: 0.752244] [G loss: 0.498660] time: 1:10:50.383749\n",
      "0.9350274\n",
      "[Epoch 47/50] [Batch 146/300] [D loss: 0.752239] [G loss: 0.485528] time: 1:10:50.679570\n",
      "0.9001517\n",
      "[Epoch 47/50] [Batch 147/300] [D loss: 0.752249] [G loss: 0.466933] time: 1:10:50.961769\n",
      "0.96905094\n",
      "[Epoch 47/50] [Batch 148/300] [D loss: 0.752249] [G loss: 0.468490] time: 1:10:51.239122\n",
      "0.9334658\n",
      "[Epoch 47/50] [Batch 149/300] [D loss: 0.752239] [G loss: 0.468778] time: 1:10:51.548371\n",
      "0.9757481\n",
      "[Epoch 47/50] [Batch 150/300] [D loss: 0.752242] [G loss: 0.496141] time: 1:10:51.859973\n",
      "0.9052024\n",
      "[Epoch 47/50] [Batch 151/300] [D loss: 0.752227] [G loss: 0.475301] time: 1:10:52.175277\n",
      "0.91702586\n",
      "[Epoch 47/50] [Batch 152/300] [D loss: 0.752254] [G loss: 0.472494] time: 1:10:52.452724\n",
      "0.93853265\n",
      "[Epoch 47/50] [Batch 153/300] [D loss: 0.752234] [G loss: 0.496507] time: 1:10:52.745463\n",
      "0.9331684\n",
      "[Epoch 47/50] [Batch 154/300] [D loss: 0.752233] [G loss: 0.497270] time: 1:10:53.048982\n",
      "0.92769474\n",
      "[Epoch 47/50] [Batch 155/300] [D loss: 0.752243] [G loss: 0.474385] time: 1:10:53.362207\n",
      "0.90552664\n",
      "[Epoch 47/50] [Batch 156/300] [D loss: 0.752240] [G loss: 0.471962] time: 1:10:53.676775\n",
      "0.9210989\n",
      "[Epoch 47/50] [Batch 157/300] [D loss: 0.752254] [G loss: 0.474586] time: 1:10:53.973379\n",
      "0.8679423\n",
      "[Epoch 47/50] [Batch 158/300] [D loss: 0.752238] [G loss: 0.475309] time: 1:10:54.274141\n",
      "0.9713092\n",
      "[Epoch 47/50] [Batch 159/300] [D loss: 0.752233] [G loss: 0.496220] time: 1:10:54.556886\n",
      "0.93291044\n",
      "[Epoch 47/50] [Batch 160/300] [D loss: 0.752247] [G loss: 0.470978] time: 1:10:54.862494\n",
      "0.92148477\n",
      "[Epoch 47/50] [Batch 161/300] [D loss: 0.752228] [G loss: 0.470315] time: 1:10:55.154104\n",
      "0.94576555\n",
      "[Epoch 47/50] [Batch 162/300] [D loss: 0.752240] [G loss: 0.477316] time: 1:10:55.447272\n",
      "0.9376376\n",
      "[Epoch 47/50] [Batch 163/300] [D loss: 0.752239] [G loss: 0.468040] time: 1:10:55.737428\n",
      "0.9782321\n",
      "[Epoch 47/50] [Batch 164/300] [D loss: 0.752234] [G loss: 0.475793] time: 1:10:56.034695\n",
      "0.89378387\n",
      "[Epoch 47/50] [Batch 165/300] [D loss: 0.752234] [G loss: 0.470237] time: 1:10:56.316120\n",
      "0.9547753\n",
      "[Epoch 47/50] [Batch 166/300] [D loss: 0.752230] [G loss: 0.468255] time: 1:10:56.624240\n",
      "0.94577056\n",
      "[Epoch 47/50] [Batch 167/300] [D loss: 0.752233] [G loss: 0.473139] time: 1:10:56.910516\n",
      "0.9302125\n",
      "[Epoch 47/50] [Batch 168/300] [D loss: 0.752232] [G loss: 0.474367] time: 1:10:57.207465\n",
      "0.906326\n",
      "[Epoch 47/50] [Batch 169/300] [D loss: 0.752235] [G loss: 0.474739] time: 1:10:57.508311\n",
      "0.9322133\n",
      "[Epoch 47/50] [Batch 170/300] [D loss: 0.752244] [G loss: 0.463139] time: 1:10:57.804389\n",
      "0.8991173\n",
      "[Epoch 47/50] [Batch 171/300] [D loss: 0.752229] [G loss: 0.478273] time: 1:10:58.077043\n",
      "0.8957668\n",
      "[Epoch 47/50] [Batch 172/300] [D loss: 0.752235] [G loss: 0.468306] time: 1:10:58.378672\n",
      "0.95993656\n",
      "[Epoch 47/50] [Batch 173/300] [D loss: 0.752248] [G loss: 0.481172] time: 1:10:58.678792\n",
      "0.9314715\n",
      "[Epoch 47/50] [Batch 174/300] [D loss: 0.752229] [G loss: 0.470915] time: 1:10:58.975996\n",
      "0.91368407\n",
      "[Epoch 47/50] [Batch 175/300] [D loss: 0.752237] [G loss: 0.480166] time: 1:10:59.276852\n",
      "0.9303274\n",
      "[Epoch 47/50] [Batch 176/300] [D loss: 0.752232] [G loss: 0.476055] time: 1:10:59.562798\n",
      "0.9394463\n",
      "[Epoch 47/50] [Batch 177/300] [D loss: 0.752244] [G loss: 0.481118] time: 1:10:59.872411\n",
      "0.9413288\n",
      "[Epoch 47/50] [Batch 178/300] [D loss: 0.752223] [G loss: 0.488691] time: 1:11:00.180781\n",
      "0.9476907\n",
      "[Epoch 47/50] [Batch 179/300] [D loss: 0.752237] [G loss: 0.466477] time: 1:11:00.467393\n",
      "0.98143214\n",
      "[Epoch 47/50] [Batch 180/300] [D loss: 0.752231] [G loss: 0.464109] time: 1:11:00.753488\n",
      "0.93433714\n",
      "[Epoch 47/50] [Batch 181/300] [D loss: 0.752229] [G loss: 0.482854] time: 1:11:01.055718\n",
      "0.9279477\n",
      "[Epoch 47/50] [Batch 182/300] [D loss: 0.752235] [G loss: 0.475583] time: 1:11:01.348994\n",
      "0.93724054\n",
      "[Epoch 47/50] [Batch 183/300] [D loss: 0.752242] [G loss: 0.475274] time: 1:11:01.657501\n",
      "0.8810417\n",
      "[Epoch 47/50] [Batch 184/300] [D loss: 0.752241] [G loss: 0.475453] time: 1:11:01.932866\n",
      "0.89948004\n",
      "[Epoch 47/50] [Batch 185/300] [D loss: 0.752245] [G loss: 0.466660] time: 1:11:02.234315\n",
      "0.90533787\n",
      "[Epoch 47/50] [Batch 186/300] [D loss: 0.752232] [G loss: 0.471961] time: 1:11:02.500847\n",
      "0.90924853\n",
      "[Epoch 47/50] [Batch 187/300] [D loss: 0.752225] [G loss: 0.463470] time: 1:11:02.804794\n",
      "0.92234135\n",
      "[Epoch 47/50] [Batch 188/300] [D loss: 0.752239] [G loss: 0.465358] time: 1:11:03.107794\n",
      "0.9756177\n",
      "[Epoch 47/50] [Batch 189/300] [D loss: 0.752247] [G loss: 0.477637] time: 1:11:03.406684\n",
      "0.94836307\n",
      "[Epoch 47/50] [Batch 190/300] [D loss: 0.752237] [G loss: 0.497409] time: 1:11:03.704297\n",
      "0.9164389\n",
      "[Epoch 47/50] [Batch 191/300] [D loss: 0.752254] [G loss: 0.468607] time: 1:11:03.998829\n",
      "0.8673775\n",
      "[Epoch 47/50] [Batch 192/300] [D loss: 0.752239] [G loss: 0.480428] time: 1:11:04.308732\n",
      "0.9325001\n",
      "[Epoch 47/50] [Batch 193/300] [D loss: 0.752239] [G loss: 0.489081] time: 1:11:04.602391\n",
      "0.93901473\n",
      "[Epoch 47/50] [Batch 194/300] [D loss: 0.752234] [G loss: 0.473705] time: 1:11:04.915161\n",
      "0.9710021\n",
      "[Epoch 47/50] [Batch 195/300] [D loss: 0.752235] [G loss: 0.467800] time: 1:11:05.214255\n",
      "0.9117704\n",
      "[Epoch 47/50] [Batch 196/300] [D loss: 0.752232] [G loss: 0.469325] time: 1:11:05.526626\n",
      "0.93865633\n",
      "[Epoch 47/50] [Batch 197/300] [D loss: 0.752239] [G loss: 0.464973] time: 1:11:05.820217\n",
      "0.89003724\n",
      "[Epoch 47/50] [Batch 198/300] [D loss: 0.752233] [G loss: 0.502067] time: 1:11:06.107223\n",
      "0.88470364\n",
      "[Epoch 47/50] [Batch 199/300] [D loss: 0.752228] [G loss: 0.476408] time: 1:11:06.403391\n",
      "0.943367\n",
      "[Epoch 47/50] [Batch 200/300] [D loss: 0.752236] [G loss: 0.480080] time: 1:11:06.695401\n",
      "0.94226044\n",
      "[Epoch 47/50] [Batch 201/300] [D loss: 0.752235] [G loss: 0.476334] time: 1:11:07.000022\n",
      "0.9101295\n",
      "[Epoch 47/50] [Batch 202/300] [D loss: 0.752231] [G loss: 0.465979] time: 1:11:07.280235\n",
      "0.931654\n",
      "[Epoch 47/50] [Batch 203/300] [D loss: 0.752244] [G loss: 0.483210] time: 1:11:07.569805\n",
      "0.9761713\n",
      "[Epoch 47/50] [Batch 204/300] [D loss: 0.752238] [G loss: 0.482461] time: 1:11:07.849393\n",
      "0.92876333\n",
      "[Epoch 47/50] [Batch 205/300] [D loss: 0.752227] [G loss: 0.485014] time: 1:11:08.133572\n",
      "0.9149534\n",
      "[Epoch 47/50] [Batch 206/300] [D loss: 0.752227] [G loss: 0.462592] time: 1:11:08.421850\n",
      "0.93319434\n",
      "[Epoch 47/50] [Batch 207/300] [D loss: 0.752240] [G loss: 0.464497] time: 1:11:08.731273\n",
      "0.94706005\n",
      "[Epoch 47/50] [Batch 208/300] [D loss: 0.752228] [G loss: 0.467863] time: 1:11:09.022449\n",
      "0.9283304\n",
      "[Epoch 47/50] [Batch 209/300] [D loss: 0.752237] [G loss: 0.469452] time: 1:11:09.330431\n",
      "0.9384534\n",
      "[Epoch 47/50] [Batch 210/300] [D loss: 0.752238] [G loss: 0.486710] time: 1:11:09.626759\n",
      "0.94582206\n",
      "[Epoch 47/50] [Batch 211/300] [D loss: 0.752234] [G loss: 0.461681] time: 1:11:09.938895\n",
      "0.96932155\n",
      "[Epoch 47/50] [Batch 212/300] [D loss: 0.752229] [G loss: 0.476566] time: 1:11:10.242133\n",
      "0.9249905\n",
      "[Epoch 47/50] [Batch 213/300] [D loss: 0.752235] [G loss: 0.463016] time: 1:11:10.537356\n",
      "0.8936229\n",
      "[Epoch 47/50] [Batch 214/300] [D loss: 0.752245] [G loss: 0.475267] time: 1:11:10.833191\n",
      "0.9086051\n",
      "[Epoch 47/50] [Batch 215/300] [D loss: 0.752238] [G loss: 0.467508] time: 1:11:11.128629\n",
      "0.88763446\n",
      "[Epoch 47/50] [Batch 216/300] [D loss: 0.752223] [G loss: 0.487415] time: 1:11:11.426134\n",
      "0.9462742\n",
      "[Epoch 47/50] [Batch 217/300] [D loss: 0.752234] [G loss: 0.473997] time: 1:11:11.716332\n",
      "0.8886232\n",
      "[Epoch 47/50] [Batch 218/300] [D loss: 0.752237] [G loss: 0.473513] time: 1:11:12.007922\n",
      "0.90717393\n",
      "[Epoch 47/50] [Batch 219/300] [D loss: 0.752237] [G loss: 0.489042] time: 1:11:12.292240\n",
      "0.8839436\n",
      "[Epoch 47/50] [Batch 220/300] [D loss: 0.752235] [G loss: 0.470550] time: 1:11:12.591804\n",
      "0.94610983\n",
      "[Epoch 47/50] [Batch 221/300] [D loss: 0.752236] [G loss: 0.471427] time: 1:11:12.891487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95168203\n",
      "[Epoch 47/50] [Batch 222/300] [D loss: 0.752246] [G loss: 0.467194] time: 1:11:13.186697\n",
      "0.90899134\n",
      "[Epoch 47/50] [Batch 223/300] [D loss: 0.752232] [G loss: 0.473736] time: 1:11:13.487329\n",
      "0.913595\n",
      "[Epoch 47/50] [Batch 224/300] [D loss: 0.752240] [G loss: 0.462342] time: 1:11:13.799768\n",
      "0.88630056\n",
      "[Epoch 47/50] [Batch 225/300] [D loss: 0.752233] [G loss: 0.487841] time: 1:11:14.108490\n",
      "0.9017922\n",
      "[Epoch 47/50] [Batch 226/300] [D loss: 0.752242] [G loss: 0.466608] time: 1:11:14.399425\n",
      "0.94171244\n",
      "[Epoch 47/50] [Batch 227/300] [D loss: 0.752230] [G loss: 0.480096] time: 1:11:14.696333\n",
      "0.8707962\n",
      "[Epoch 47/50] [Batch 228/300] [D loss: 0.752230] [G loss: 0.485982] time: 1:11:14.995793\n",
      "0.917603\n",
      "[Epoch 47/50] [Batch 229/300] [D loss: 0.752236] [G loss: 0.469636] time: 1:11:15.292129\n",
      "0.9028519\n",
      "[Epoch 47/50] [Batch 230/300] [D loss: 0.752241] [G loss: 0.477929] time: 1:11:15.589146\n",
      "0.91208094\n",
      "[Epoch 47/50] [Batch 231/300] [D loss: 0.752241] [G loss: 0.464427] time: 1:11:15.870325\n",
      "0.9067707\n",
      "[Epoch 47/50] [Batch 232/300] [D loss: 0.752229] [G loss: 0.493499] time: 1:11:16.170165\n",
      "0.9139889\n",
      "[Epoch 47/50] [Batch 233/300] [D loss: 0.752241] [G loss: 0.473400] time: 1:11:16.471569\n",
      "0.9022705\n",
      "[Epoch 47/50] [Batch 234/300] [D loss: 0.752237] [G loss: 0.473460] time: 1:11:16.769145\n",
      "0.9721422\n",
      "[Epoch 47/50] [Batch 235/300] [D loss: 0.752240] [G loss: 0.482111] time: 1:11:17.062544\n",
      "0.98317814\n",
      "[Epoch 47/50] [Batch 236/300] [D loss: 0.752229] [G loss: 0.472073] time: 1:11:17.362339\n",
      "0.91308093\n",
      "[Epoch 47/50] [Batch 237/300] [D loss: 0.752232] [G loss: 0.477998] time: 1:11:17.659096\n",
      "0.97130376\n",
      "[Epoch 47/50] [Batch 238/300] [D loss: 0.752235] [G loss: 0.466846] time: 1:11:17.950151\n",
      "0.93475384\n",
      "[Epoch 47/50] [Batch 239/300] [D loss: 0.752244] [G loss: 0.472140] time: 1:11:18.247956\n",
      "0.92515516\n",
      "[Epoch 47/50] [Batch 240/300] [D loss: 0.752237] [G loss: 0.485568] time: 1:11:18.542741\n",
      "0.9204971\n",
      "[Epoch 47/50] [Batch 241/300] [D loss: 0.752230] [G loss: 0.477864] time: 1:11:18.836667\n",
      "0.95910645\n",
      "[Epoch 47/50] [Batch 242/300] [D loss: 0.752230] [G loss: 0.482452] time: 1:11:19.129178\n",
      "0.92907554\n",
      "[Epoch 47/50] [Batch 243/300] [D loss: 0.752235] [G loss: 0.470469] time: 1:11:19.409422\n",
      "0.884697\n",
      "[Epoch 47/50] [Batch 244/300] [D loss: 0.752228] [G loss: 0.473630] time: 1:11:19.682564\n",
      "0.88389105\n",
      "[Epoch 47/50] [Batch 245/300] [D loss: 0.752235] [G loss: 0.483787] time: 1:11:19.978130\n",
      "0.97133565\n",
      "[Epoch 47/50] [Batch 246/300] [D loss: 0.752235] [G loss: 0.492314] time: 1:11:20.298417\n",
      "0.88119155\n",
      "[Epoch 47/50] [Batch 247/300] [D loss: 0.752231] [G loss: 0.468992] time: 1:11:20.595125\n",
      "0.931644\n",
      "[Epoch 47/50] [Batch 248/300] [D loss: 0.752227] [G loss: 0.474838] time: 1:11:20.884524\n",
      "0.96022564\n",
      "[Epoch 47/50] [Batch 249/300] [D loss: 0.752242] [G loss: 0.475477] time: 1:11:21.183746\n",
      "0.9451464\n",
      "[Epoch 47/50] [Batch 250/300] [D loss: 0.752245] [G loss: 0.471738] time: 1:11:21.463824\n",
      "0.9330124\n",
      "[Epoch 47/50] [Batch 251/300] [D loss: 0.752236] [G loss: 0.469784] time: 1:11:21.746949\n",
      "0.8855912\n",
      "[Epoch 47/50] [Batch 252/300] [D loss: 0.752226] [G loss: 0.473830] time: 1:11:22.029067\n",
      "0.9417355\n",
      "[Epoch 47/50] [Batch 253/300] [D loss: 0.752238] [G loss: 0.482041] time: 1:11:22.331781\n",
      "0.9159525\n",
      "[Epoch 47/50] [Batch 254/300] [D loss: 0.752238] [G loss: 0.469247] time: 1:11:22.630933\n",
      "0.9174567\n",
      "[Epoch 47/50] [Batch 255/300] [D loss: 0.752240] [G loss: 0.495988] time: 1:11:22.916355\n",
      "0.88130474\n",
      "[Epoch 47/50] [Batch 256/300] [D loss: 0.752233] [G loss: 0.485563] time: 1:11:23.220190\n",
      "0.95897675\n",
      "[Epoch 47/50] [Batch 257/300] [D loss: 0.752242] [G loss: 0.480221] time: 1:11:23.540910\n",
      "0.93898076\n",
      "[Epoch 47/50] [Batch 258/300] [D loss: 0.752236] [G loss: 0.472410] time: 1:11:23.839908\n",
      "0.92607427\n",
      "[Epoch 47/50] [Batch 259/300] [D loss: 0.752227] [G loss: 0.475955] time: 1:11:24.127026\n",
      "0.9047983\n",
      "[Epoch 47/50] [Batch 260/300] [D loss: 0.752240] [G loss: 0.470187] time: 1:11:24.416862\n",
      "0.932518\n",
      "[Epoch 47/50] [Batch 261/300] [D loss: 0.752264] [G loss: 0.476438] time: 1:11:24.702997\n",
      "0.92049474\n",
      "[Epoch 47/50] [Batch 262/300] [D loss: 0.752220] [G loss: 0.479591] time: 1:11:24.985914\n",
      "0.9742628\n",
      "[Epoch 47/50] [Batch 263/300] [D loss: 0.752236] [G loss: 0.471659] time: 1:11:25.284484\n",
      "0.9059338\n",
      "[Epoch 47/50] [Batch 264/300] [D loss: 0.752239] [G loss: 0.471886] time: 1:11:25.574457\n",
      "0.9294874\n",
      "[Epoch 47/50] [Batch 265/300] [D loss: 0.752233] [G loss: 0.476452] time: 1:11:25.884955\n",
      "0.85266167\n",
      "[Epoch 47/50] [Batch 266/300] [D loss: 0.752227] [G loss: 0.485321] time: 1:11:26.182496\n",
      "0.9086614\n",
      "[Epoch 47/50] [Batch 267/300] [D loss: 0.752241] [G loss: 0.474082] time: 1:11:26.479929\n",
      "0.9357691\n",
      "[Epoch 47/50] [Batch 268/300] [D loss: 0.752226] [G loss: 0.467591] time: 1:11:26.771583\n",
      "0.8960517\n",
      "[Epoch 47/50] [Batch 269/300] [D loss: 0.752243] [G loss: 0.469049] time: 1:11:27.049956\n",
      "0.95319754\n",
      "[Epoch 47/50] [Batch 270/300] [D loss: 0.752242] [G loss: 0.473247] time: 1:11:27.362862\n",
      "0.9249529\n",
      "[Epoch 47/50] [Batch 271/300] [D loss: 0.752241] [G loss: 0.486263] time: 1:11:27.648606\n",
      "0.9116935\n",
      "[Epoch 47/50] [Batch 272/300] [D loss: 0.752228] [G loss: 0.466931] time: 1:11:27.945188\n",
      "0.96452683\n",
      "[Epoch 47/50] [Batch 273/300] [D loss: 0.752244] [G loss: 0.467795] time: 1:11:28.248020\n",
      "0.8975036\n",
      "[Epoch 47/50] [Batch 274/300] [D loss: 0.752230] [G loss: 0.466344] time: 1:11:28.535061\n",
      "0.942283\n",
      "[Epoch 47/50] [Batch 275/300] [D loss: 0.752228] [G loss: 0.481250] time: 1:11:28.827421\n",
      "0.9460034\n",
      "[Epoch 47/50] [Batch 276/300] [D loss: 0.752231] [G loss: 0.477243] time: 1:11:29.114777\n",
      "0.9396151\n",
      "[Epoch 47/50] [Batch 277/300] [D loss: 0.752238] [G loss: 0.476875] time: 1:11:29.404331\n",
      "0.9538705\n",
      "[Epoch 47/50] [Batch 278/300] [D loss: 0.752231] [G loss: 0.468786] time: 1:11:29.691530\n",
      "0.9457941\n",
      "[Epoch 47/50] [Batch 279/300] [D loss: 0.752244] [G loss: 0.471702] time: 1:11:29.979427\n",
      "0.9348436\n",
      "[Epoch 47/50] [Batch 280/300] [D loss: 0.752235] [G loss: 0.466001] time: 1:11:30.268750\n",
      "0.9217605\n",
      "[Epoch 47/50] [Batch 281/300] [D loss: 0.752231] [G loss: 0.469952] time: 1:11:30.573916\n",
      "0.9091541\n",
      "[Epoch 47/50] [Batch 282/300] [D loss: 0.752226] [G loss: 0.474939] time: 1:11:30.888445\n",
      "0.93386215\n",
      "[Epoch 47/50] [Batch 283/300] [D loss: 0.752231] [G loss: 0.468924] time: 1:11:31.164398\n",
      "0.87888485\n",
      "[Epoch 47/50] [Batch 284/300] [D loss: 0.752237] [G loss: 0.466365] time: 1:11:31.456824\n",
      "0.8835705\n",
      "[Epoch 47/50] [Batch 285/300] [D loss: 0.752226] [G loss: 0.476387] time: 1:11:31.768513\n",
      "0.9343257\n",
      "[Epoch 47/50] [Batch 286/300] [D loss: 0.752225] [G loss: 0.491036] time: 1:11:32.069978\n",
      "0.9304306\n",
      "[Epoch 47/50] [Batch 287/300] [D loss: 0.752232] [G loss: 0.469233] time: 1:11:32.371599\n",
      "0.8902834\n",
      "[Epoch 47/50] [Batch 288/300] [D loss: 0.752252] [G loss: 0.485766] time: 1:11:32.693637\n",
      "0.9444361\n",
      "[Epoch 47/50] [Batch 289/300] [D loss: 0.752244] [G loss: 0.467492] time: 1:11:32.987893\n",
      "0.9164857\n",
      "[Epoch 47/50] [Batch 290/300] [D loss: 0.752224] [G loss: 0.479637] time: 1:11:33.277819\n",
      "0.912844\n",
      "[Epoch 47/50] [Batch 291/300] [D loss: 0.752223] [G loss: 0.467878] time: 1:11:33.567459\n",
      "0.88731104\n",
      "[Epoch 47/50] [Batch 292/300] [D loss: 0.752222] [G loss: 0.481029] time: 1:11:33.861011\n",
      "0.955206\n",
      "[Epoch 47/50] [Batch 293/300] [D loss: 0.752230] [G loss: 0.470682] time: 1:11:34.143659\n",
      "0.9172848\n",
      "[Epoch 47/50] [Batch 294/300] [D loss: 0.752223] [G loss: 0.480733] time: 1:11:34.440780\n",
      "0.93771845\n",
      "[Epoch 47/50] [Batch 295/300] [D loss: 0.752242] [G loss: 0.462652] time: 1:11:34.733810\n",
      "0.90514714\n",
      "[Epoch 47/50] [Batch 296/300] [D loss: 0.752231] [G loss: 0.486195] time: 1:11:35.037692\n",
      "0.94954395\n",
      "[Epoch 47/50] [Batch 297/300] [D loss: 0.752246] [G loss: 0.472230] time: 1:11:35.322484\n",
      "0.91683835\n",
      "[Epoch 47/50] [Batch 298/300] [D loss: 0.752223] [G loss: 0.472838] time: 1:11:35.622159\n",
      "0.89960766\n",
      "[Epoch 47/50] [Batch 299/300] [D loss: 0.752229] [G loss: 0.464504] time: 1:11:35.931913\n",
      "0.9379005\n",
      "[Epoch 48/50] [Batch 0/300] [D loss: 0.752224] [G loss: 0.479160] time: 1:11:36.222542\n",
      "0.930368\n",
      "[Epoch 48/50] [Batch 1/300] [D loss: 0.752230] [G loss: 0.484586] time: 1:11:36.538651\n",
      "0.9313393\n",
      "[Epoch 48/50] [Batch 2/300] [D loss: 0.752236] [G loss: 0.470622] time: 1:11:36.847233\n",
      "0.94785404\n",
      "[Epoch 48/50] [Batch 3/300] [D loss: 0.752239] [G loss: 0.464718] time: 1:11:37.149750\n",
      "0.9836547\n",
      "[Epoch 48/50] [Batch 4/300] [D loss: 0.752232] [G loss: 0.465094] time: 1:11:37.448311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8899884\n",
      "[Epoch 48/50] [Batch 5/300] [D loss: 0.752238] [G loss: 0.465193] time: 1:11:37.745701\n",
      "0.9549661\n",
      "[Epoch 48/50] [Batch 6/300] [D loss: 0.752227] [G loss: 0.470156] time: 1:11:38.040049\n",
      "0.9462135\n",
      "[Epoch 48/50] [Batch 7/300] [D loss: 0.752245] [G loss: 0.472621] time: 1:11:38.334117\n",
      "0.9016757\n",
      "[Epoch 48/50] [Batch 8/300] [D loss: 0.752229] [G loss: 0.476018] time: 1:11:38.640720\n",
      "0.9176273\n",
      "[Epoch 48/50] [Batch 9/300] [D loss: 0.752233] [G loss: 0.466191] time: 1:11:38.946390\n",
      "0.93769383\n",
      "[Epoch 48/50] [Batch 10/300] [D loss: 0.752224] [G loss: 0.465478] time: 1:11:39.255131\n",
      "0.9160064\n",
      "[Epoch 48/50] [Batch 11/300] [D loss: 0.752231] [G loss: 0.477057] time: 1:11:39.570326\n",
      "0.88990253\n",
      "[Epoch 48/50] [Batch 12/300] [D loss: 0.752249] [G loss: 0.471250] time: 1:11:39.872176\n",
      "0.86721754\n",
      "[Epoch 48/50] [Batch 13/300] [D loss: 0.752228] [G loss: 0.490392] time: 1:11:40.176218\n",
      "0.9337325\n",
      "[Epoch 48/50] [Batch 14/300] [D loss: 0.752223] [G loss: 0.479048] time: 1:11:40.478474\n",
      "0.9247847\n",
      "[Epoch 48/50] [Batch 15/300] [D loss: 0.752227] [G loss: 0.485360] time: 1:11:40.788633\n",
      "0.9216296\n",
      "[Epoch 48/50] [Batch 16/300] [D loss: 0.752233] [G loss: 0.472234] time: 1:11:41.101598\n",
      "0.9199028\n",
      "[Epoch 48/50] [Batch 17/300] [D loss: 0.752237] [G loss: 0.467808] time: 1:11:41.381513\n",
      "0.9397022\n",
      "[Epoch 48/50] [Batch 18/300] [D loss: 0.752226] [G loss: 0.482197] time: 1:11:41.670579\n",
      "0.96177554\n",
      "[Epoch 48/50] [Batch 19/300] [D loss: 0.752228] [G loss: 0.470935] time: 1:11:41.963603\n",
      "0.92148\n",
      "[Epoch 48/50] [Batch 20/300] [D loss: 0.752253] [G loss: 0.477804] time: 1:11:42.270027\n",
      "0.852623\n",
      "[Epoch 48/50] [Batch 21/300] [D loss: 0.752227] [G loss: 0.481779] time: 1:11:42.554605\n",
      "0.90632457\n",
      "[Epoch 48/50] [Batch 22/300] [D loss: 0.752216] [G loss: 0.474026] time: 1:11:42.855369\n",
      "0.93326306\n",
      "[Epoch 48/50] [Batch 23/300] [D loss: 0.752234] [G loss: 0.471723] time: 1:11:43.149647\n",
      "0.9550872\n",
      "[Epoch 48/50] [Batch 24/300] [D loss: 0.752228] [G loss: 0.481115] time: 1:11:43.442127\n",
      "0.98113734\n",
      "[Epoch 48/50] [Batch 25/300] [D loss: 0.752219] [G loss: 0.477004] time: 1:11:43.754211\n",
      "0.97019786\n",
      "[Epoch 48/50] [Batch 26/300] [D loss: 0.752234] [G loss: 0.473882] time: 1:11:44.065724\n",
      "0.9167075\n",
      "[Epoch 48/50] [Batch 27/300] [D loss: 0.752221] [G loss: 0.475667] time: 1:11:44.360138\n",
      "0.895384\n",
      "[Epoch 48/50] [Batch 28/300] [D loss: 0.752246] [G loss: 0.487317] time: 1:11:44.652633\n",
      "0.8929469\n",
      "[Epoch 48/50] [Batch 29/300] [D loss: 0.752232] [G loss: 0.479223] time: 1:11:44.941008\n",
      "0.94262046\n",
      "[Epoch 48/50] [Batch 30/300] [D loss: 0.752235] [G loss: 0.480960] time: 1:11:45.238119\n",
      "0.9231847\n",
      "[Epoch 48/50] [Batch 31/300] [D loss: 0.752240] [G loss: 0.484715] time: 1:11:45.536852\n",
      "0.91600114\n",
      "[Epoch 48/50] [Batch 32/300] [D loss: 0.752246] [G loss: 0.466281] time: 1:11:45.821684\n",
      "0.91092515\n",
      "[Epoch 48/50] [Batch 33/300] [D loss: 0.752234] [G loss: 0.467182] time: 1:11:46.116539\n",
      "0.92873\n",
      "[Epoch 48/50] [Batch 34/300] [D loss: 0.752234] [G loss: 0.470586] time: 1:11:46.434796\n",
      "0.88566417\n",
      "[Epoch 48/50] [Batch 35/300] [D loss: 0.752237] [G loss: 0.487756] time: 1:11:46.723752\n",
      "0.9564395\n",
      "[Epoch 48/50] [Batch 36/300] [D loss: 0.752234] [G loss: 0.470433] time: 1:11:47.004493\n",
      "0.9292887\n",
      "[Epoch 48/50] [Batch 37/300] [D loss: 0.752236] [G loss: 0.468277] time: 1:11:47.306110\n",
      "0.9091012\n",
      "[Epoch 48/50] [Batch 38/300] [D loss: 0.752236] [G loss: 0.476906] time: 1:11:47.601334\n",
      "0.93369293\n",
      "[Epoch 48/50] [Batch 39/300] [D loss: 0.752231] [G loss: 0.486483] time: 1:11:47.898558\n",
      "0.9253237\n",
      "[Epoch 48/50] [Batch 40/300] [D loss: 0.752232] [G loss: 0.467744] time: 1:11:48.190654\n",
      "0.90695816\n",
      "[Epoch 48/50] [Batch 41/300] [D loss: 0.752236] [G loss: 0.464150] time: 1:11:48.490588\n",
      "0.8862119\n",
      "[Epoch 48/50] [Batch 42/300] [D loss: 0.752227] [G loss: 0.470443] time: 1:11:48.785824\n",
      "0.9255921\n",
      "[Epoch 48/50] [Batch 43/300] [D loss: 0.752228] [G loss: 0.481241] time: 1:11:49.071558\n",
      "0.93976253\n",
      "[Epoch 48/50] [Batch 44/300] [D loss: 0.752240] [G loss: 0.475946] time: 1:11:49.373452\n",
      "0.9188311\n",
      "[Epoch 48/50] [Batch 45/300] [D loss: 0.752227] [G loss: 0.480416] time: 1:11:49.659592\n",
      "0.9103969\n",
      "[Epoch 48/50] [Batch 46/300] [D loss: 0.752233] [G loss: 0.469204] time: 1:11:49.950830\n",
      "0.9707963\n",
      "[Epoch 48/50] [Batch 48/300] [D loss: 0.752221] [G loss: 0.466405] time: 1:11:50.254477\n",
      "0.91772366\n",
      "[Epoch 48/50] [Batch 49/300] [D loss: 0.752221] [G loss: 0.472400] time: 1:11:50.554817\n",
      "0.97108465\n",
      "[Epoch 48/50] [Batch 50/300] [D loss: 0.752228] [G loss: 0.474121] time: 1:11:50.836374\n",
      "0.9458885\n",
      "[Epoch 48/50] [Batch 51/300] [D loss: 0.752241] [G loss: 0.476236] time: 1:11:51.119848\n",
      "0.9081746\n",
      "[Epoch 48/50] [Batch 52/300] [D loss: 0.752232] [G loss: 0.463971] time: 1:11:51.422653\n",
      "0.9330786\n",
      "[Epoch 48/50] [Batch 53/300] [D loss: 0.752236] [G loss: 0.484852] time: 1:11:51.722808\n",
      "0.8822314\n",
      "[Epoch 48/50] [Batch 54/300] [D loss: 0.752225] [G loss: 0.485488] time: 1:11:52.016383\n",
      "0.93902665\n",
      "[Epoch 48/50] [Batch 55/300] [D loss: 0.752240] [G loss: 0.479997] time: 1:11:52.312400\n",
      "0.8901003\n",
      "[Epoch 48/50] [Batch 56/300] [D loss: 0.752235] [G loss: 0.468383] time: 1:11:52.596883\n",
      "0.90712494\n",
      "[Epoch 48/50] [Batch 57/300] [D loss: 0.752223] [G loss: 0.479451] time: 1:11:52.864179\n",
      "0.92493486\n",
      "[Epoch 48/50] [Batch 58/300] [D loss: 0.752238] [G loss: 0.472368] time: 1:11:53.150286\n",
      "0.9448812\n",
      "[Epoch 48/50] [Batch 59/300] [D loss: 0.752231] [G loss: 0.475703] time: 1:11:53.449955\n",
      "0.94694823\n",
      "[Epoch 48/50] [Batch 60/300] [D loss: 0.752221] [G loss: 0.467922] time: 1:11:53.753160\n",
      "0.9014974\n",
      "[Epoch 48/50] [Batch 61/300] [D loss: 0.752242] [G loss: 0.467250] time: 1:11:54.033372\n",
      "0.9818034\n",
      "[Epoch 48/50] [Batch 62/300] [D loss: 0.752234] [G loss: 0.476232] time: 1:11:54.340294\n",
      "0.90912145\n",
      "[Epoch 48/50] [Batch 63/300] [D loss: 0.752232] [G loss: 0.469823] time: 1:11:54.639380\n",
      "0.92702127\n",
      "[Epoch 48/50] [Batch 64/300] [D loss: 0.752236] [G loss: 0.473411] time: 1:11:54.924705\n",
      "0.9177139\n",
      "[Epoch 48/50] [Batch 65/300] [D loss: 0.752231] [G loss: 0.471372] time: 1:11:55.197239\n",
      "0.9215787\n",
      "[Epoch 48/50] [Batch 66/300] [D loss: 0.752230] [G loss: 0.468354] time: 1:11:55.497185\n",
      "0.94318175\n",
      "[Epoch 48/50] [Batch 67/300] [D loss: 0.752234] [G loss: 0.466971] time: 1:11:55.792089\n",
      "0.8685932\n",
      "[Epoch 48/50] [Batch 68/300] [D loss: 0.752237] [G loss: 0.469397] time: 1:11:56.071947\n",
      "0.94582796\n",
      "[Epoch 48/50] [Batch 69/300] [D loss: 0.752234] [G loss: 0.495414] time: 1:11:56.369748\n",
      "0.9379261\n",
      "[Epoch 48/50] [Batch 70/300] [D loss: 0.752237] [G loss: 0.467249] time: 1:11:56.665111\n",
      "0.89179784\n",
      "[Epoch 48/50] [Batch 71/300] [D loss: 0.752232] [G loss: 0.467478] time: 1:11:56.943577\n",
      "0.9350268\n",
      "[Epoch 48/50] [Batch 72/300] [D loss: 0.752228] [G loss: 0.487299] time: 1:11:57.242437\n",
      "0.9332507\n",
      "[Epoch 48/50] [Batch 73/300] [D loss: 0.752229] [G loss: 0.506699] time: 1:11:57.538022\n",
      "0.9416189\n",
      "[Epoch 48/50] [Batch 74/300] [D loss: 0.752243] [G loss: 0.475821] time: 1:11:57.836469\n",
      "0.91726446\n",
      "[Epoch 48/50] [Batch 75/300] [D loss: 0.752226] [G loss: 0.471088] time: 1:11:58.115743\n",
      "0.9260054\n",
      "[Epoch 48/50] [Batch 76/300] [D loss: 0.752229] [G loss: 0.466300] time: 1:11:58.406037\n",
      "0.94859433\n",
      "[Epoch 48/50] [Batch 77/300] [D loss: 0.752227] [G loss: 0.473623] time: 1:11:58.705718\n",
      "0.8902218\n",
      "[Epoch 48/50] [Batch 78/300] [D loss: 0.752238] [G loss: 0.474946] time: 1:11:58.977923\n",
      "0.9129241\n",
      "[Epoch 48/50] [Batch 79/300] [D loss: 0.752232] [G loss: 0.464372] time: 1:11:59.273924\n",
      "0.94236946\n",
      "[Epoch 48/50] [Batch 80/300] [D loss: 0.752227] [G loss: 0.470181] time: 1:11:59.570911\n",
      "0.9569271\n",
      "[Epoch 48/50] [Batch 81/300] [D loss: 0.752231] [G loss: 0.472733] time: 1:11:59.868827\n",
      "0.92133623\n",
      "[Epoch 48/50] [Batch 82/300] [D loss: 0.752231] [G loss: 0.469275] time: 1:12:00.155612\n",
      "0.9181729\n",
      "[Epoch 48/50] [Batch 83/300] [D loss: 0.752231] [G loss: 0.475351] time: 1:12:00.452802\n",
      "0.92870235\n",
      "[Epoch 48/50] [Batch 84/300] [D loss: 0.752231] [G loss: 0.484009] time: 1:12:00.745283\n",
      "0.8702329\n",
      "[Epoch 48/50] [Batch 85/300] [D loss: 0.752226] [G loss: 0.484282] time: 1:12:01.068588\n",
      "0.9157217\n",
      "[Epoch 48/50] [Batch 86/300] [D loss: 0.752234] [G loss: 0.468219] time: 1:12:01.368206\n",
      "0.95317\n",
      "[Epoch 48/50] [Batch 87/300] [D loss: 0.752237] [G loss: 0.472442] time: 1:12:01.662054\n",
      "0.9202358\n",
      "[Epoch 48/50] [Batch 88/300] [D loss: 0.752225] [G loss: 0.480205] time: 1:12:01.967251\n",
      "0.9454301\n",
      "[Epoch 48/50] [Batch 89/300] [D loss: 0.752225] [G loss: 0.463419] time: 1:12:02.261162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90880233\n",
      "[Epoch 48/50] [Batch 90/300] [D loss: 0.752232] [G loss: 0.480236] time: 1:12:02.554332\n",
      "0.94259953\n",
      "[Epoch 48/50] [Batch 91/300] [D loss: 0.752233] [G loss: 0.476286] time: 1:12:02.849617\n",
      "0.9453917\n",
      "[Epoch 48/50] [Batch 92/300] [D loss: 0.752230] [G loss: 0.474111] time: 1:12:03.156121\n",
      "0.90754557\n",
      "[Epoch 48/50] [Batch 93/300] [D loss: 0.752224] [G loss: 0.468724] time: 1:12:03.419274\n",
      "0.928771\n",
      "[Epoch 48/50] [Batch 94/300] [D loss: 0.752237] [G loss: 0.466813] time: 1:12:03.714499\n",
      "0.93478745\n",
      "[Epoch 48/50] [Batch 95/300] [D loss: 0.752228] [G loss: 0.468598] time: 1:12:04.008355\n",
      "0.9463735\n",
      "[Epoch 48/50] [Batch 96/300] [D loss: 0.752222] [G loss: 0.471860] time: 1:12:04.307291\n",
      "0.9457442\n",
      "[Epoch 48/50] [Batch 97/300] [D loss: 0.752238] [G loss: 0.467716] time: 1:12:04.612425\n",
      "0.89541984\n",
      "[Epoch 48/50] [Batch 98/300] [D loss: 0.752239] [G loss: 0.473673] time: 1:12:04.909728\n",
      "0.8811638\n",
      "[Epoch 48/50] [Batch 99/300] [D loss: 0.752221] [G loss: 0.467798] time: 1:12:05.210792\n",
      "0.8526719\n",
      "[Epoch 48/50] [Batch 100/300] [D loss: 0.752230] [G loss: 0.497795] time: 1:12:05.512475\n",
      "0.9038334\n",
      "[Epoch 48/50] [Batch 101/300] [D loss: 0.752225] [G loss: 0.473118] time: 1:12:05.817222\n",
      "0.8864375\n",
      "[Epoch 48/50] [Batch 102/300] [D loss: 0.752235] [G loss: 0.473760] time: 1:12:06.109594\n",
      "0.92824596\n",
      "[Epoch 48/50] [Batch 103/300] [D loss: 0.752224] [G loss: 0.486404] time: 1:12:06.400006\n",
      "0.92768687\n",
      "[Epoch 48/50] [Batch 104/300] [D loss: 0.752236] [G loss: 0.475810] time: 1:12:06.689291\n",
      "0.95658207\n",
      "[Epoch 48/50] [Batch 105/300] [D loss: 0.752230] [G loss: 0.489959] time: 1:12:06.998282\n",
      "0.97751504\n",
      "[Epoch 48/50] [Batch 106/300] [D loss: 0.752245] [G loss: 0.468989] time: 1:12:07.288621\n",
      "0.8812937\n",
      "[Epoch 48/50] [Batch 107/300] [D loss: 0.752228] [G loss: 0.496430] time: 1:12:07.590316\n",
      "0.90058345\n",
      "[Epoch 48/50] [Batch 108/300] [D loss: 0.752234] [G loss: 0.469318] time: 1:12:07.879188\n",
      "0.85241634\n",
      "[Epoch 48/50] [Batch 109/300] [D loss: 0.752220] [G loss: 0.468597] time: 1:12:08.184032\n",
      "0.93140197\n",
      "[Epoch 48/50] [Batch 110/300] [D loss: 0.752229] [G loss: 0.471364] time: 1:12:08.493530\n",
      "0.931999\n",
      "[Epoch 48/50] [Batch 111/300] [D loss: 0.752227] [G loss: 0.477403] time: 1:12:08.782590\n",
      "0.94717646\n",
      "[Epoch 48/50] [Batch 112/300] [D loss: 0.752241] [G loss: 0.471421] time: 1:12:09.070885\n",
      "0.9440899\n",
      "[Epoch 48/50] [Batch 113/300] [D loss: 0.752231] [G loss: 0.475161] time: 1:12:09.375066\n",
      "0.885977\n",
      "[Epoch 48/50] [Batch 114/300] [D loss: 0.752220] [G loss: 0.467931] time: 1:12:09.670270\n",
      "0.90905803\n",
      "[Epoch 48/50] [Batch 115/300] [D loss: 0.752224] [G loss: 0.469475] time: 1:12:09.974909\n",
      "0.91248846\n",
      "[Epoch 48/50] [Batch 116/300] [D loss: 0.752238] [G loss: 0.472375] time: 1:12:10.240638\n",
      "0.9054505\n",
      "[Epoch 48/50] [Batch 117/300] [D loss: 0.752236] [G loss: 0.466617] time: 1:12:10.541399\n",
      "0.91075987\n",
      "[Epoch 48/50] [Batch 118/300] [D loss: 0.752241] [G loss: 0.478563] time: 1:12:10.837267\n",
      "0.9129972\n",
      "[Epoch 48/50] [Batch 119/300] [D loss: 0.752236] [G loss: 0.483282] time: 1:12:11.142654\n",
      "0.92263585\n",
      "[Epoch 48/50] [Batch 120/300] [D loss: 0.752239] [G loss: 0.465379] time: 1:12:11.445898\n",
      "0.9774022\n",
      "[Epoch 48/50] [Batch 121/300] [D loss: 0.752233] [G loss: 0.474170] time: 1:12:11.748604\n",
      "0.89799684\n",
      "[Epoch 48/50] [Batch 122/300] [D loss: 0.752234] [G loss: 0.476650] time: 1:12:12.061334\n",
      "0.8860545\n",
      "[Epoch 48/50] [Batch 123/300] [D loss: 0.752223] [G loss: 0.473083] time: 1:12:12.374302\n",
      "0.944983\n",
      "[Epoch 48/50] [Batch 124/300] [D loss: 0.752242] [G loss: 0.466349] time: 1:12:12.657320\n",
      "0.9420311\n",
      "[Epoch 48/50] [Batch 125/300] [D loss: 0.752240] [G loss: 0.493661] time: 1:12:12.957524\n",
      "0.9276771\n",
      "[Epoch 48/50] [Batch 126/300] [D loss: 0.752229] [G loss: 0.471691] time: 1:12:13.258492\n",
      "0.9366215\n",
      "[Epoch 48/50] [Batch 127/300] [D loss: 0.752231] [G loss: 0.469858] time: 1:12:13.567570\n",
      "0.9142256\n",
      "[Epoch 48/50] [Batch 128/300] [D loss: 0.752241] [G loss: 0.480566] time: 1:12:13.870641\n",
      "0.91516227\n",
      "[Epoch 48/50] [Batch 129/300] [D loss: 0.752236] [G loss: 0.462094] time: 1:12:14.172965\n",
      "0.91668826\n",
      "[Epoch 48/50] [Batch 130/300] [D loss: 0.752233] [G loss: 0.485106] time: 1:12:14.445229\n",
      "0.9061945\n",
      "[Epoch 48/50] [Batch 131/300] [D loss: 0.752235] [G loss: 0.463828] time: 1:12:14.746896\n",
      "0.9142563\n",
      "[Epoch 48/50] [Batch 132/300] [D loss: 0.752226] [G loss: 0.476887] time: 1:12:15.041991\n",
      "0.87528497\n",
      "[Epoch 48/50] [Batch 133/300] [D loss: 0.752231] [G loss: 0.462150] time: 1:12:15.318715\n",
      "0.9382778\n",
      "[Epoch 48/50] [Batch 134/300] [D loss: 0.752223] [G loss: 0.469728] time: 1:12:15.607748\n",
      "0.9689478\n",
      "[Epoch 48/50] [Batch 135/300] [D loss: 0.752250] [G loss: 0.464430] time: 1:12:15.894906\n",
      "0.9329273\n",
      "[Epoch 48/50] [Batch 136/300] [D loss: 0.752224] [G loss: 0.471923] time: 1:12:16.166749\n",
      "0.9448015\n",
      "[Epoch 48/50] [Batch 137/300] [D loss: 0.752228] [G loss: 0.467203] time: 1:12:16.471494\n",
      "0.9213836\n",
      "[Epoch 48/50] [Batch 138/300] [D loss: 0.752244] [G loss: 0.465845] time: 1:12:16.778132\n",
      "0.8945174\n",
      "[Epoch 48/50] [Batch 139/300] [D loss: 0.752231] [G loss: 0.465491] time: 1:12:17.056904\n",
      "0.9425151\n",
      "[Epoch 48/50] [Batch 140/300] [D loss: 0.752237] [G loss: 0.470788] time: 1:12:17.350638\n",
      "0.94222385\n",
      "[Epoch 48/50] [Batch 141/300] [D loss: 0.752227] [G loss: 0.469792] time: 1:12:17.643630\n",
      "0.9269431\n",
      "[Epoch 48/50] [Batch 142/300] [D loss: 0.752229] [G loss: 0.470945] time: 1:12:17.936528\n",
      "0.8806209\n",
      "[Epoch 48/50] [Batch 143/300] [D loss: 0.752225] [G loss: 0.484067] time: 1:12:18.236451\n",
      "0.90810657\n",
      "[Epoch 48/50] [Batch 144/300] [D loss: 0.752240] [G loss: 0.462027] time: 1:12:18.529809\n",
      "0.92599076\n",
      "[Epoch 48/50] [Batch 145/300] [D loss: 0.752221] [G loss: 0.471394] time: 1:12:18.830075\n",
      "0.9046054\n",
      "[Epoch 48/50] [Batch 146/300] [D loss: 0.752238] [G loss: 0.464487] time: 1:12:19.121932\n",
      "0.9230549\n",
      "[Epoch 48/50] [Batch 147/300] [D loss: 0.752226] [G loss: 0.473838] time: 1:12:19.409987\n",
      "0.93748504\n",
      "[Epoch 48/50] [Batch 148/300] [D loss: 0.752218] [G loss: 0.467093] time: 1:12:19.704595\n",
      "0.9054871\n",
      "[Epoch 48/50] [Batch 149/300] [D loss: 0.752237] [G loss: 0.470368] time: 1:12:19.996238\n",
      "0.94561213\n",
      "[Epoch 48/50] [Batch 150/300] [D loss: 0.752236] [G loss: 0.473059] time: 1:12:20.304361\n",
      "0.906153\n",
      "[Epoch 48/50] [Batch 151/300] [D loss: 0.752238] [G loss: 0.468579] time: 1:12:20.581505\n",
      "0.9479235\n",
      "[Epoch 48/50] [Batch 152/300] [D loss: 0.752237] [G loss: 0.475773] time: 1:12:20.878759\n",
      "0.9166651\n",
      "[Epoch 48/50] [Batch 153/300] [D loss: 0.752231] [G loss: 0.474008] time: 1:12:21.171558\n",
      "0.94792897\n",
      "[Epoch 48/50] [Batch 154/300] [D loss: 0.752224] [G loss: 0.470471] time: 1:12:21.463332\n",
      "0.9338936\n",
      "[Epoch 48/50] [Batch 155/300] [D loss: 0.752237] [G loss: 0.475546] time: 1:12:21.757968\n",
      "0.945693\n",
      "[Epoch 48/50] [Batch 156/300] [D loss: 0.752230] [G loss: 0.471173] time: 1:12:22.068039\n",
      "0.9323544\n",
      "[Epoch 48/50] [Batch 157/300] [D loss: 0.752227] [G loss: 0.464532] time: 1:12:22.344459\n",
      "0.8986991\n",
      "[Epoch 48/50] [Batch 158/300] [D loss: 0.752226] [G loss: 0.468598] time: 1:12:22.643620\n",
      "0.9390671\n",
      "[Epoch 48/50] [Batch 159/300] [D loss: 0.752232] [G loss: 0.469477] time: 1:12:22.933665\n",
      "0.8959155\n",
      "[Epoch 48/50] [Batch 160/300] [D loss: 0.752234] [G loss: 0.468571] time: 1:12:23.226313\n",
      "0.94221544\n",
      "[Epoch 48/50] [Batch 161/300] [D loss: 0.752230] [G loss: 0.469198] time: 1:12:23.521636\n",
      "0.9057066\n",
      "[Epoch 48/50] [Batch 162/300] [D loss: 0.752224] [G loss: 0.474913] time: 1:12:23.820653\n",
      "0.8879387\n",
      "[Epoch 48/50] [Batch 163/300] [D loss: 0.752220] [G loss: 0.470502] time: 1:12:24.109919\n",
      "0.9466321\n",
      "[Epoch 48/50] [Batch 164/300] [D loss: 0.752223] [G loss: 0.494979] time: 1:12:24.414512\n",
      "0.8977356\n",
      "[Epoch 48/50] [Batch 165/300] [D loss: 0.752231] [G loss: 0.485579] time: 1:12:24.724662\n",
      "0.9457764\n",
      "[Epoch 48/50] [Batch 166/300] [D loss: 0.752239] [G loss: 0.469139] time: 1:12:25.017368\n",
      "0.94415873\n",
      "[Epoch 48/50] [Batch 167/300] [D loss: 0.752228] [G loss: 0.469840] time: 1:12:25.309564\n",
      "0.9075716\n",
      "[Epoch 48/50] [Batch 168/300] [D loss: 0.752231] [G loss: 0.463931] time: 1:12:25.608191\n",
      "0.92895395\n",
      "[Epoch 48/50] [Batch 169/300] [D loss: 0.752223] [G loss: 0.465951] time: 1:12:25.893012\n",
      "0.9165668\n",
      "[Epoch 48/50] [Batch 170/300] [D loss: 0.752236] [G loss: 0.472647] time: 1:12:26.195872\n",
      "0.9645811\n",
      "[Epoch 48/50] [Batch 171/300] [D loss: 0.752240] [G loss: 0.466741] time: 1:12:26.484455\n",
      "0.9290154\n",
      "[Epoch 48/50] [Batch 172/300] [D loss: 0.752228] [G loss: 0.465097] time: 1:12:26.780844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689347\n",
      "[Epoch 48/50] [Batch 173/300] [D loss: 0.752228] [G loss: 0.470160] time: 1:12:27.076199\n",
      "0.9313879\n",
      "[Epoch 48/50] [Batch 174/300] [D loss: 0.752238] [G loss: 0.467013] time: 1:12:27.364148\n",
      "0.9297571\n",
      "[Epoch 48/50] [Batch 175/300] [D loss: 0.752256] [G loss: 0.465815] time: 1:12:27.639521\n",
      "0.9289444\n",
      "[Epoch 48/50] [Batch 176/300] [D loss: 0.752235] [G loss: 0.463407] time: 1:12:27.940917\n",
      "0.8971097\n",
      "[Epoch 48/50] [Batch 177/300] [D loss: 0.752233] [G loss: 0.470352] time: 1:12:28.239069\n",
      "0.8997647\n",
      "[Epoch 48/50] [Batch 178/300] [D loss: 0.752225] [G loss: 0.479659] time: 1:12:28.523937\n",
      "0.9247405\n",
      "[Epoch 48/50] [Batch 179/300] [D loss: 0.752246] [G loss: 0.472667] time: 1:12:28.826293\n",
      "0.8528889\n",
      "[Epoch 48/50] [Batch 180/300] [D loss: 0.752228] [G loss: 0.473541] time: 1:12:29.127987\n",
      "0.9031629\n",
      "[Epoch 48/50] [Batch 181/300] [D loss: 0.752232] [G loss: 0.469697] time: 1:12:29.422787\n",
      "0.93144065\n",
      "[Epoch 48/50] [Batch 182/300] [D loss: 0.752251] [G loss: 0.476185] time: 1:12:29.730173\n",
      "0.8915343\n",
      "[Epoch 48/50] [Batch 183/300] [D loss: 0.752243] [G loss: 0.482936] time: 1:12:30.029997\n",
      "0.92013985\n",
      "[Epoch 48/50] [Batch 184/300] [D loss: 0.752233] [G loss: 0.495488] time: 1:12:30.335595\n",
      "0.9554305\n",
      "[Epoch 48/50] [Batch 185/300] [D loss: 0.752240] [G loss: 0.466271] time: 1:12:30.634887\n",
      "0.9455411\n",
      "[Epoch 48/50] [Batch 186/300] [D loss: 0.752246] [G loss: 0.474661] time: 1:12:30.932025\n",
      "0.91973597\n",
      "[Epoch 48/50] [Batch 187/300] [D loss: 0.752228] [G loss: 0.489641] time: 1:12:31.249248\n",
      "0.8863203\n",
      "[Epoch 48/50] [Batch 188/300] [D loss: 0.752224] [G loss: 0.472254] time: 1:12:31.548851\n",
      "0.87180835\n",
      "[Epoch 48/50] [Batch 189/300] [D loss: 0.752239] [G loss: 0.484994] time: 1:12:31.840291\n",
      "0.96188205\n",
      "[Epoch 48/50] [Batch 190/300] [D loss: 0.752225] [G loss: 0.463802] time: 1:12:32.116816\n",
      "0.94289297\n",
      "[Epoch 48/50] [Batch 191/300] [D loss: 0.752233] [G loss: 0.477128] time: 1:12:32.413404\n",
      "0.9315184\n",
      "[Epoch 48/50] [Batch 192/300] [D loss: 0.752238] [G loss: 0.481877] time: 1:12:32.717581\n",
      "0.9430242\n",
      "[Epoch 48/50] [Batch 193/300] [D loss: 0.752226] [G loss: 0.501775] time: 1:12:33.005421\n",
      "0.89499205\n",
      "[Epoch 48/50] [Batch 194/300] [D loss: 0.752224] [G loss: 0.487742] time: 1:12:33.326027\n",
      "0.9164669\n",
      "[Epoch 48/50] [Batch 195/300] [D loss: 0.752229] [G loss: 0.465766] time: 1:12:33.624334\n",
      "0.9533438\n",
      "[Epoch 48/50] [Batch 196/300] [D loss: 0.752234] [G loss: 0.481215] time: 1:12:33.924802\n",
      "0.88388413\n",
      "[Epoch 48/50] [Batch 197/300] [D loss: 0.752229] [G loss: 0.473189] time: 1:12:34.240926\n",
      "0.916784\n",
      "[Epoch 48/50] [Batch 198/300] [D loss: 0.752223] [G loss: 0.483292] time: 1:12:34.544559\n",
      "0.9668503\n",
      "[Epoch 48/50] [Batch 199/300] [D loss: 0.752233] [G loss: 0.462640] time: 1:12:34.848572\n",
      "0.9343062\n",
      "[Epoch 48/50] [Batch 200/300] [D loss: 0.752228] [G loss: 0.470460] time: 1:12:35.128855\n",
      "0.9386882\n",
      "[Epoch 48/50] [Batch 201/300] [D loss: 0.752224] [G loss: 0.463493] time: 1:12:35.426788\n",
      "0.92120504\n",
      "[Epoch 48/50] [Batch 202/300] [D loss: 0.752228] [G loss: 0.468809] time: 1:12:35.730814\n",
      "0.9293907\n",
      "[Epoch 48/50] [Batch 203/300] [D loss: 0.752223] [G loss: 0.467388] time: 1:12:36.032366\n",
      "0.9452898\n",
      "[Epoch 48/50] [Batch 204/300] [D loss: 0.752226] [G loss: 0.462956] time: 1:12:36.316048\n",
      "0.9105976\n",
      "[Epoch 48/50] [Batch 205/300] [D loss: 0.752238] [G loss: 0.479537] time: 1:12:36.631604\n",
      "0.9472351\n",
      "[Epoch 48/50] [Batch 206/300] [D loss: 0.752229] [G loss: 0.463768] time: 1:12:36.927762\n",
      "0.9349685\n",
      "[Epoch 48/50] [Batch 207/300] [D loss: 0.752236] [G loss: 0.463767] time: 1:12:37.227806\n",
      "0.9300166\n",
      "[Epoch 48/50] [Batch 208/300] [D loss: 0.752241] [G loss: 0.469463] time: 1:12:37.528806\n",
      "0.9556691\n",
      "[Epoch 48/50] [Batch 209/300] [D loss: 0.752226] [G loss: 0.476633] time: 1:12:37.844261\n",
      "0.92136604\n",
      "[Epoch 48/50] [Batch 210/300] [D loss: 0.752232] [G loss: 0.476091] time: 1:12:38.146868\n",
      "0.899909\n",
      "[Epoch 48/50] [Batch 211/300] [D loss: 0.752222] [G loss: 0.463543] time: 1:12:38.448182\n",
      "0.9332133\n",
      "[Epoch 48/50] [Batch 212/300] [D loss: 0.752232] [G loss: 0.469138] time: 1:12:38.754673\n",
      "0.93074924\n",
      "[Epoch 48/50] [Batch 213/300] [D loss: 0.752231] [G loss: 0.470346] time: 1:12:39.049488\n",
      "0.88323975\n",
      "[Epoch 48/50] [Batch 214/300] [D loss: 0.752234] [G loss: 0.463500] time: 1:12:39.354035\n",
      "0.8887804\n",
      "[Epoch 48/50] [Batch 215/300] [D loss: 0.752227] [G loss: 0.471100] time: 1:12:39.647256\n",
      "0.9621687\n",
      "[Epoch 48/50] [Batch 216/300] [D loss: 0.752230] [G loss: 0.482358] time: 1:12:39.943659\n",
      "0.8828395\n",
      "[Epoch 48/50] [Batch 217/300] [D loss: 0.752229] [G loss: 0.471570] time: 1:12:40.251808\n",
      "0.89094764\n",
      "[Epoch 48/50] [Batch 218/300] [D loss: 0.752229] [G loss: 0.479511] time: 1:12:40.556806\n",
      "0.8981168\n",
      "[Epoch 48/50] [Batch 219/300] [D loss: 0.752235] [G loss: 0.470482] time: 1:12:40.860015\n",
      "0.9219299\n",
      "[Epoch 48/50] [Batch 220/300] [D loss: 0.752228] [G loss: 0.501964] time: 1:12:41.137090\n",
      "0.9434188\n",
      "[Epoch 48/50] [Batch 221/300] [D loss: 0.752234] [G loss: 0.461090] time: 1:12:41.429365\n",
      "0.93788815\n",
      "[Epoch 48/50] [Batch 222/300] [D loss: 0.752220] [G loss: 0.481064] time: 1:12:41.732757\n",
      "0.98400736\n",
      "[Epoch 48/50] [Batch 223/300] [D loss: 0.752238] [G loss: 0.474056] time: 1:12:42.031299\n",
      "0.97157246\n",
      "[Epoch 48/50] [Batch 224/300] [D loss: 0.752231] [G loss: 0.460516] time: 1:12:42.326637\n",
      "0.852429\n",
      "[Epoch 48/50] [Batch 225/300] [D loss: 0.752229] [G loss: 0.478693] time: 1:12:42.608252\n",
      "0.9069767\n",
      "[Epoch 48/50] [Batch 226/300] [D loss: 0.752232] [G loss: 0.473808] time: 1:12:42.905483\n",
      "0.92149216\n",
      "[Epoch 48/50] [Batch 227/300] [D loss: 0.752232] [G loss: 0.478199] time: 1:12:43.206535\n",
      "0.93314743\n",
      "[Epoch 48/50] [Batch 228/300] [D loss: 0.752228] [G loss: 0.463257] time: 1:12:43.499526\n",
      "0.92230254\n",
      "[Epoch 48/50] [Batch 229/300] [D loss: 0.752235] [G loss: 0.466974] time: 1:12:43.800039\n",
      "0.91318995\n",
      "[Epoch 48/50] [Batch 230/300] [D loss: 0.752232] [G loss: 0.463772] time: 1:12:44.110580\n",
      "0.93621284\n",
      "[Epoch 48/50] [Batch 231/300] [D loss: 0.752244] [G loss: 0.468719] time: 1:12:44.403103\n",
      "0.8811044\n",
      "[Epoch 48/50] [Batch 232/300] [D loss: 0.752232] [G loss: 0.475233] time: 1:12:44.686278\n",
      "0.94599277\n",
      "[Epoch 48/50] [Batch 233/300] [D loss: 0.752237] [G loss: 0.465603] time: 1:12:44.983481\n",
      "0.96012586\n",
      "[Epoch 48/50] [Batch 234/300] [D loss: 0.752237] [G loss: 0.463377] time: 1:12:45.265736\n",
      "0.92486197\n",
      "[Epoch 48/50] [Batch 235/300] [D loss: 0.752234] [G loss: 0.476551] time: 1:12:45.549551\n",
      "0.9355145\n",
      "[Epoch 48/50] [Batch 236/300] [D loss: 0.752229] [G loss: 0.476776] time: 1:12:45.866494\n",
      "0.9476256\n",
      "[Epoch 48/50] [Batch 237/300] [D loss: 0.752236] [G loss: 0.490662] time: 1:12:46.175025\n",
      "0.8914276\n",
      "[Epoch 48/50] [Batch 238/300] [D loss: 0.752235] [G loss: 0.473313] time: 1:12:46.463022\n",
      "0.88347715\n",
      "[Epoch 48/50] [Batch 239/300] [D loss: 0.752226] [G loss: 0.470427] time: 1:12:46.766715\n",
      "0.93026286\n",
      "[Epoch 48/50] [Batch 240/300] [D loss: 0.752226] [G loss: 0.473556] time: 1:12:47.067444\n",
      "0.9359916\n",
      "[Epoch 48/50] [Batch 241/300] [D loss: 0.752224] [G loss: 0.495095] time: 1:12:47.356441\n",
      "0.9202482\n",
      "[Epoch 48/50] [Batch 242/300] [D loss: 0.752224] [G loss: 0.473544] time: 1:12:47.668003\n",
      "0.95559716\n",
      "[Epoch 48/50] [Batch 243/300] [D loss: 0.752237] [G loss: 0.470177] time: 1:12:47.966797\n",
      "0.9024069\n",
      "[Epoch 48/50] [Batch 244/300] [D loss: 0.752236] [G loss: 0.468150] time: 1:12:48.217765\n",
      "0.9345679\n",
      "[Epoch 48/50] [Batch 245/300] [D loss: 0.752226] [G loss: 0.483333] time: 1:12:48.503168\n",
      "0.95312184\n",
      "[Epoch 48/50] [Batch 246/300] [D loss: 0.752231] [G loss: 0.469991] time: 1:12:48.804044\n",
      "0.95207196\n",
      "[Epoch 48/50] [Batch 247/300] [D loss: 0.752229] [G loss: 0.473722] time: 1:12:49.077230\n",
      "0.9154382\n",
      "[Epoch 48/50] [Batch 248/300] [D loss: 0.752233] [G loss: 0.476788] time: 1:12:49.351730\n",
      "0.90674114\n",
      "[Epoch 48/50] [Batch 249/300] [D loss: 0.752233] [G loss: 0.470707] time: 1:12:49.642652\n",
      "0.9053671\n",
      "[Epoch 48/50] [Batch 250/300] [D loss: 0.752229] [G loss: 0.469683] time: 1:12:49.926477\n",
      "0.9215568\n",
      "[Epoch 48/50] [Batch 251/300] [D loss: 0.752237] [G loss: 0.480742] time: 1:12:50.203345\n",
      "0.92325336\n",
      "[Epoch 48/50] [Batch 252/300] [D loss: 0.752224] [G loss: 0.475281] time: 1:12:50.517280\n",
      "0.9283533\n",
      "[Epoch 48/50] [Batch 253/300] [D loss: 0.752229] [G loss: 0.469598] time: 1:12:50.809248\n",
      "0.95585346\n",
      "[Epoch 48/50] [Batch 254/300] [D loss: 0.752238] [G loss: 0.469329] time: 1:12:51.114867\n",
      "0.96027154\n",
      "[Epoch 48/50] [Batch 255/300] [D loss: 0.752247] [G loss: 0.470373] time: 1:12:51.413819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9430018\n",
      "[Epoch 48/50] [Batch 256/300] [D loss: 0.752236] [G loss: 0.477833] time: 1:12:51.709154\n",
      "0.8831539\n",
      "[Epoch 48/50] [Batch 257/300] [D loss: 0.752236] [G loss: 0.462404] time: 1:12:52.017126\n",
      "0.9361458\n",
      "[Epoch 48/50] [Batch 258/300] [D loss: 0.752232] [G loss: 0.483565] time: 1:12:52.312651\n",
      "0.8846443\n",
      "[Epoch 48/50] [Batch 259/300] [D loss: 0.752229] [G loss: 0.470589] time: 1:12:52.608146\n",
      "0.9239621\n",
      "[Epoch 48/50] [Batch 260/300] [D loss: 0.752236] [G loss: 0.477377] time: 1:12:52.900101\n",
      "0.87619233\n",
      "[Epoch 48/50] [Batch 261/300] [D loss: 0.752238] [G loss: 0.469825] time: 1:12:53.189133\n",
      "0.8856282\n",
      "[Epoch 48/50] [Batch 262/300] [D loss: 0.752222] [G loss: 0.480479] time: 1:12:53.485324\n",
      "0.9109394\n",
      "[Epoch 48/50] [Batch 263/300] [D loss: 0.752223] [G loss: 0.486104] time: 1:12:53.790949\n",
      "0.95169514\n",
      "[Epoch 48/50] [Batch 264/300] [D loss: 0.752237] [G loss: 0.471524] time: 1:12:54.097624\n",
      "0.95332384\n",
      "[Epoch 48/50] [Batch 265/300] [D loss: 0.752230] [G loss: 0.474488] time: 1:12:54.399522\n",
      "0.944897\n",
      "[Epoch 48/50] [Batch 266/300] [D loss: 0.752233] [G loss: 0.467660] time: 1:12:54.700404\n",
      "0.91852546\n",
      "[Epoch 48/50] [Batch 267/300] [D loss: 0.752225] [G loss: 0.472323] time: 1:12:55.008300\n",
      "0.90545607\n",
      "[Epoch 48/50] [Batch 268/300] [D loss: 0.752240] [G loss: 0.484733] time: 1:12:55.318531\n",
      "0.95561856\n",
      "[Epoch 48/50] [Batch 269/300] [D loss: 0.752223] [G loss: 0.481142] time: 1:12:55.622650\n",
      "0.9221781\n",
      "[Epoch 48/50] [Batch 270/300] [D loss: 0.752225] [G loss: 0.466897] time: 1:12:55.924999\n",
      "0.9532942\n",
      "[Epoch 48/50] [Batch 271/300] [D loss: 0.752227] [G loss: 0.467510] time: 1:12:56.224024\n",
      "0.9132611\n",
      "[Epoch 48/50] [Batch 272/300] [D loss: 0.752237] [G loss: 0.470178] time: 1:12:56.534429\n",
      "0.88605994\n",
      "[Epoch 48/50] [Batch 273/300] [D loss: 0.752231] [G loss: 0.468190] time: 1:12:56.825385\n",
      "0.9099536\n",
      "[Epoch 48/50] [Batch 274/300] [D loss: 0.752232] [G loss: 0.470673] time: 1:12:57.134769\n",
      "0.9318456\n",
      "[Epoch 48/50] [Batch 275/300] [D loss: 0.752237] [G loss: 0.469951] time: 1:12:57.427177\n",
      "0.9464257\n",
      "[Epoch 48/50] [Batch 276/300] [D loss: 0.752234] [G loss: 0.478277] time: 1:12:57.726490\n",
      "0.9359224\n",
      "[Epoch 48/50] [Batch 277/300] [D loss: 0.752220] [G loss: 0.474718] time: 1:12:58.013589\n",
      "0.9535269\n",
      "[Epoch 48/50] [Batch 278/300] [D loss: 0.752227] [G loss: 0.475648] time: 1:12:58.310885\n",
      "0.9398119\n",
      "[Epoch 48/50] [Batch 279/300] [D loss: 0.752232] [G loss: 0.464453] time: 1:12:58.593357\n",
      "0.97110647\n",
      "[Epoch 48/50] [Batch 280/300] [D loss: 0.752228] [G loss: 0.465363] time: 1:12:58.896792\n",
      "0.94203496\n",
      "[Epoch 48/50] [Batch 281/300] [D loss: 0.752224] [G loss: 0.470296] time: 1:12:59.185041\n",
      "0.9213868\n",
      "[Epoch 48/50] [Batch 282/300] [D loss: 0.752231] [G loss: 0.461173] time: 1:12:59.472927\n",
      "0.9368219\n",
      "[Epoch 48/50] [Batch 283/300] [D loss: 0.752235] [G loss: 0.467405] time: 1:12:59.768510\n",
      "0.90942794\n",
      "[Epoch 48/50] [Batch 284/300] [D loss: 0.752232] [G loss: 0.465272] time: 1:13:00.068198\n",
      "0.8854765\n",
      "[Epoch 48/50] [Batch 285/300] [D loss: 0.752233] [G loss: 0.493014] time: 1:13:00.379129\n",
      "0.9114492\n",
      "[Epoch 48/50] [Batch 286/300] [D loss: 0.752236] [G loss: 0.466399] time: 1:13:00.685788\n",
      "0.9532287\n",
      "[Epoch 48/50] [Batch 287/300] [D loss: 0.752223] [G loss: 0.466804] time: 1:13:00.982629\n",
      "0.898859\n",
      "[Epoch 48/50] [Batch 288/300] [D loss: 0.752232] [G loss: 0.469013] time: 1:13:01.261995\n",
      "0.944861\n",
      "[Epoch 48/50] [Batch 289/300] [D loss: 0.752233] [G loss: 0.467148] time: 1:13:01.573754\n",
      "0.9140262\n",
      "[Epoch 48/50] [Batch 290/300] [D loss: 0.752237] [G loss: 0.477271] time: 1:13:01.889614\n",
      "0.9318175\n",
      "[Epoch 48/50] [Batch 291/300] [D loss: 0.752219] [G loss: 0.476106] time: 1:13:02.197353\n",
      "0.90717775\n",
      "[Epoch 48/50] [Batch 292/300] [D loss: 0.752228] [G loss: 0.476790] time: 1:13:02.475360\n",
      "0.90845966\n",
      "[Epoch 48/50] [Batch 293/300] [D loss: 0.752230] [G loss: 0.478824] time: 1:13:02.760006\n",
      "0.9111803\n",
      "[Epoch 48/50] [Batch 294/300] [D loss: 0.752220] [G loss: 0.467544] time: 1:13:03.071900\n",
      "0.9307862\n",
      "[Epoch 48/50] [Batch 295/300] [D loss: 0.752221] [G loss: 0.477603] time: 1:13:03.379377\n",
      "0.95345336\n",
      "[Epoch 48/50] [Batch 296/300] [D loss: 0.752244] [G loss: 0.475622] time: 1:13:03.672028\n",
      "0.9057376\n",
      "[Epoch 48/50] [Batch 297/300] [D loss: 0.752226] [G loss: 0.476949] time: 1:13:03.997510\n",
      "0.89278585\n",
      "[Epoch 48/50] [Batch 298/300] [D loss: 0.752238] [G loss: 0.472747] time: 1:13:04.289678\n",
      "0.88571364\n",
      "[Epoch 48/50] [Batch 299/300] [D loss: 0.752232] [G loss: 0.478801] time: 1:13:04.584346\n",
      "0.9001174\n",
      "[Epoch 49/50] [Batch 0/300] [D loss: 0.752229] [G loss: 0.467774] time: 1:13:04.892045\n",
      "0.8851683\n",
      "[Epoch 49/50] [Batch 1/300] [D loss: 0.752233] [G loss: 0.472449] time: 1:13:05.202801\n",
      "0.895873\n",
      "[Epoch 49/50] [Batch 2/300] [D loss: 0.752230] [G loss: 0.468697] time: 1:13:05.508379\n",
      "0.98367834\n",
      "[Epoch 49/50] [Batch 3/300] [D loss: 0.752220] [G loss: 0.467629] time: 1:13:05.817780\n",
      "0.95213383\n",
      "[Epoch 49/50] [Batch 4/300] [D loss: 0.752222] [G loss: 0.474708] time: 1:13:06.117909\n",
      "0.91242236\n",
      "[Epoch 49/50] [Batch 5/300] [D loss: 0.752227] [G loss: 0.485265] time: 1:13:06.420619\n",
      "0.8678584\n",
      "[Epoch 49/50] [Batch 6/300] [D loss: 0.752225] [G loss: 0.490168] time: 1:13:06.695896\n",
      "0.9054437\n",
      "[Epoch 49/50] [Batch 7/300] [D loss: 0.752222] [G loss: 0.468404] time: 1:13:07.005861\n",
      "0.9497898\n",
      "[Epoch 49/50] [Batch 8/300] [D loss: 0.752230] [G loss: 0.467169] time: 1:13:07.313085\n",
      "0.946048\n",
      "[Epoch 49/50] [Batch 9/300] [D loss: 0.752229] [G loss: 0.464656] time: 1:13:07.588066\n",
      "0.89400834\n",
      "[Epoch 49/50] [Batch 10/300] [D loss: 0.752230] [G loss: 0.477379] time: 1:13:07.884831\n",
      "0.9246618\n",
      "[Epoch 49/50] [Batch 11/300] [D loss: 0.752237] [G loss: 0.465207] time: 1:13:08.190920\n",
      "0.911699\n",
      "[Epoch 49/50] [Batch 12/300] [D loss: 0.752223] [G loss: 0.479480] time: 1:13:08.490731\n",
      "0.9111338\n",
      "[Epoch 49/50] [Batch 13/300] [D loss: 0.752231] [G loss: 0.465641] time: 1:13:08.788158\n",
      "0.9254113\n",
      "[Epoch 49/50] [Batch 14/300] [D loss: 0.752220] [G loss: 0.465229] time: 1:13:09.084929\n",
      "0.9436149\n",
      "[Epoch 49/50] [Batch 15/300] [D loss: 0.752231] [G loss: 0.468029] time: 1:13:09.389677\n",
      "0.90015787\n",
      "[Epoch 49/50] [Batch 16/300] [D loss: 0.752230] [G loss: 0.476348] time: 1:13:09.677624\n",
      "0.909509\n",
      "[Epoch 49/50] [Batch 17/300] [D loss: 0.752237] [G loss: 0.487312] time: 1:13:09.969558\n",
      "0.89105386\n",
      "[Epoch 49/50] [Batch 18/300] [D loss: 0.752237] [G loss: 0.473023] time: 1:13:10.263982\n",
      "0.98313016\n",
      "[Epoch 49/50] [Batch 19/300] [D loss: 0.752229] [G loss: 0.481919] time: 1:13:10.572252\n",
      "0.91178465\n",
      "[Epoch 49/50] [Batch 20/300] [D loss: 0.752225] [G loss: 0.468163] time: 1:13:10.883969\n",
      "0.908241\n",
      "[Epoch 49/50] [Batch 21/300] [D loss: 0.752237] [G loss: 0.477692] time: 1:13:11.189733\n",
      "0.9372163\n",
      "[Epoch 49/50] [Batch 22/300] [D loss: 0.752235] [G loss: 0.484445] time: 1:13:11.509570\n",
      "0.9391127\n",
      "[Epoch 49/50] [Batch 23/300] [D loss: 0.752238] [G loss: 0.472065] time: 1:13:11.802972\n",
      "0.9372063\n",
      "[Epoch 49/50] [Batch 24/300] [D loss: 0.752230] [G loss: 0.461943] time: 1:13:12.123231\n",
      "0.946043\n",
      "[Epoch 49/50] [Batch 25/300] [D loss: 0.752221] [G loss: 0.465798] time: 1:13:12.414962\n",
      "0.88229626\n",
      "[Epoch 49/50] [Batch 26/300] [D loss: 0.752232] [G loss: 0.497580] time: 1:13:12.704954\n",
      "0.9065728\n",
      "[Epoch 49/50] [Batch 27/300] [D loss: 0.752233] [G loss: 0.480223] time: 1:13:13.007354\n",
      "0.97086763\n",
      "[Epoch 49/50] [Batch 28/300] [D loss: 0.752224] [G loss: 0.479248] time: 1:13:13.289551\n",
      "0.9608066\n",
      "[Epoch 49/50] [Batch 29/300] [D loss: 0.752241] [G loss: 0.494120] time: 1:13:13.575763\n",
      "0.9425897\n",
      "[Epoch 49/50] [Batch 30/300] [D loss: 0.752230] [G loss: 0.478588] time: 1:13:13.873113\n",
      "0.9532365\n",
      "[Epoch 49/50] [Batch 31/300] [D loss: 0.752224] [G loss: 0.476100] time: 1:13:14.169190\n",
      "0.9064474\n",
      "[Epoch 49/50] [Batch 32/300] [D loss: 0.752234] [G loss: 0.468242] time: 1:13:14.468801\n",
      "0.8926182\n",
      "[Epoch 49/50] [Batch 33/300] [D loss: 0.752218] [G loss: 0.479732] time: 1:13:14.769966\n",
      "0.93069553\n",
      "[Epoch 49/50] [Batch 34/300] [D loss: 0.752229] [G loss: 0.474656] time: 1:13:15.071471\n",
      "0.98301595\n",
      "[Epoch 49/50] [Batch 35/300] [D loss: 0.752230] [G loss: 0.470329] time: 1:13:15.381166\n",
      "0.9052727\n",
      "[Epoch 49/50] [Batch 36/300] [D loss: 0.752229] [G loss: 0.477058] time: 1:13:15.675202\n",
      "0.8818135\n",
      "[Epoch 49/50] [Batch 37/300] [D loss: 0.752234] [G loss: 0.488074] time: 1:13:15.973167\n",
      "0.91240907\n",
      "[Epoch 49/50] [Batch 38/300] [D loss: 0.752231] [G loss: 0.469078] time: 1:13:16.265670\n",
      "0.95476246\n",
      "[Epoch 49/50] [Batch 39/300] [D loss: 0.752229] [G loss: 0.464400] time: 1:13:16.568071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9530956\n",
      "[Epoch 49/50] [Batch 40/300] [D loss: 0.752233] [G loss: 0.472465] time: 1:13:16.861188\n",
      "0.86335707\n",
      "[Epoch 49/50] [Batch 41/300] [D loss: 0.752234] [G loss: 0.465799] time: 1:13:17.170401\n",
      "0.88065654\n",
      "[Epoch 49/50] [Batch 42/300] [D loss: 0.752219] [G loss: 0.485988] time: 1:13:17.466299\n",
      "0.92922235\n",
      "[Epoch 49/50] [Batch 43/300] [D loss: 0.752234] [G loss: 0.465068] time: 1:13:17.768421\n",
      "0.950716\n",
      "[Epoch 49/50] [Batch 44/300] [D loss: 0.752232] [G loss: 0.477727] time: 1:13:18.072733\n",
      "0.9687364\n",
      "[Epoch 49/50] [Batch 45/300] [D loss: 0.752228] [G loss: 0.489163] time: 1:13:18.375968\n",
      "0.91180104\n",
      "[Epoch 49/50] [Batch 46/300] [D loss: 0.752235] [G loss: 0.464187] time: 1:13:18.678900\n",
      "0.8888231\n",
      "[Epoch 49/50] [Batch 47/300] [D loss: 0.752231] [G loss: 0.483874] time: 1:13:18.972652\n",
      "0.89656514\n",
      "[Epoch 49/50] [Batch 49/300] [D loss: 0.752217] [G loss: 0.469032] time: 1:13:19.267157\n",
      "0.9202854\n",
      "[Epoch 49/50] [Batch 50/300] [D loss: 0.752223] [G loss: 0.474474] time: 1:13:19.552445\n",
      "0.9221584\n",
      "[Epoch 49/50] [Batch 51/300] [D loss: 0.752237] [G loss: 0.462268] time: 1:13:19.853751\n",
      "0.91382605\n",
      "[Epoch 49/50] [Batch 52/300] [D loss: 0.752232] [G loss: 0.469566] time: 1:13:20.159849\n",
      "0.875344\n",
      "[Epoch 49/50] [Batch 53/300] [D loss: 0.752229] [G loss: 0.466046] time: 1:13:20.457110\n",
      "0.98158425\n",
      "[Epoch 49/50] [Batch 54/300] [D loss: 0.752232] [G loss: 0.463670] time: 1:13:20.755178\n",
      "0.9465525\n",
      "[Epoch 49/50] [Batch 55/300] [D loss: 0.752238] [G loss: 0.474939] time: 1:13:21.043836\n",
      "0.9082369\n",
      "[Epoch 49/50] [Batch 56/300] [D loss: 0.752216] [G loss: 0.472284] time: 1:13:21.352236\n",
      "0.92157793\n",
      "[Epoch 49/50] [Batch 57/300] [D loss: 0.752234] [G loss: 0.469347] time: 1:13:21.654345\n",
      "0.89703614\n",
      "[Epoch 49/50] [Batch 58/300] [D loss: 0.752221] [G loss: 0.465371] time: 1:13:21.957646\n",
      "0.96007985\n",
      "[Epoch 49/50] [Batch 59/300] [D loss: 0.752228] [G loss: 0.463747] time: 1:13:22.243395\n",
      "0.939007\n",
      "[Epoch 49/50] [Batch 60/300] [D loss: 0.752231] [G loss: 0.478779] time: 1:13:22.540022\n",
      "0.9312715\n",
      "[Epoch 49/50] [Batch 61/300] [D loss: 0.752221] [G loss: 0.467343] time: 1:13:22.838207\n",
      "0.91062313\n",
      "[Epoch 49/50] [Batch 62/300] [D loss: 0.752220] [G loss: 0.476607] time: 1:13:23.112816\n",
      "0.94305974\n",
      "[Epoch 49/50] [Batch 63/300] [D loss: 0.752229] [G loss: 0.477255] time: 1:13:23.418096\n",
      "0.9381915\n",
      "[Epoch 49/50] [Batch 64/300] [D loss: 0.752226] [G loss: 0.472973] time: 1:13:23.724038\n",
      "0.9355199\n",
      "[Epoch 49/50] [Batch 65/300] [D loss: 0.752224] [G loss: 0.472602] time: 1:13:24.025464\n",
      "0.9215149\n",
      "[Epoch 49/50] [Batch 66/300] [D loss: 0.752232] [G loss: 0.483909] time: 1:13:24.326125\n",
      "0.9618216\n",
      "[Epoch 49/50] [Batch 67/300] [D loss: 0.752224] [G loss: 0.485002] time: 1:13:24.614032\n",
      "0.96465844\n",
      "[Epoch 49/50] [Batch 68/300] [D loss: 0.752236] [G loss: 0.475654] time: 1:13:24.923629\n",
      "0.9337278\n",
      "[Epoch 49/50] [Batch 69/300] [D loss: 0.752228] [G loss: 0.476244] time: 1:13:25.219088\n",
      "0.900275\n",
      "[Epoch 49/50] [Batch 70/300] [D loss: 0.752223] [G loss: 0.475536] time: 1:13:25.495213\n",
      "0.96006924\n",
      "[Epoch 49/50] [Batch 71/300] [D loss: 0.752227] [G loss: 0.476008] time: 1:13:25.799842\n",
      "0.94813824\n",
      "[Epoch 49/50] [Batch 72/300] [D loss: 0.752228] [G loss: 0.474744] time: 1:13:26.088561\n",
      "0.9313405\n",
      "[Epoch 49/50] [Batch 73/300] [D loss: 0.752225] [G loss: 0.478226] time: 1:13:26.387621\n",
      "0.94625944\n",
      "[Epoch 49/50] [Batch 74/300] [D loss: 0.752233] [G loss: 0.478501] time: 1:13:26.679569\n",
      "0.8854203\n",
      "[Epoch 49/50] [Batch 75/300] [D loss: 0.752220] [G loss: 0.471573] time: 1:13:26.996555\n",
      "0.9494392\n",
      "[Epoch 49/50] [Batch 76/300] [D loss: 0.752237] [G loss: 0.477693] time: 1:13:27.309055\n",
      "0.9174723\n",
      "[Epoch 49/50] [Batch 77/300] [D loss: 0.752220] [G loss: 0.468611] time: 1:13:27.615994\n",
      "0.8913794\n",
      "[Epoch 49/50] [Batch 78/300] [D loss: 0.752230] [G loss: 0.459604] time: 1:13:27.899157\n",
      "0.9056611\n",
      "[Epoch 49/50] [Batch 79/300] [D loss: 0.752234] [G loss: 0.460861] time: 1:13:28.203147\n",
      "0.9314632\n",
      "[Epoch 49/50] [Batch 80/300] [D loss: 0.752229] [G loss: 0.475126] time: 1:13:28.500299\n",
      "0.91967136\n",
      "[Epoch 49/50] [Batch 81/300] [D loss: 0.752234] [G loss: 0.474900] time: 1:13:28.801479\n",
      "0.91405076\n",
      "[Epoch 49/50] [Batch 82/300] [D loss: 0.752240] [G loss: 0.464790] time: 1:13:29.104495\n",
      "0.9170472\n",
      "[Epoch 49/50] [Batch 83/300] [D loss: 0.752227] [G loss: 0.475731] time: 1:13:29.400224\n",
      "0.9477261\n",
      "[Epoch 49/50] [Batch 84/300] [D loss: 0.752218] [G loss: 0.466619] time: 1:13:29.695167\n",
      "0.88463616\n",
      "[Epoch 49/50] [Batch 85/300] [D loss: 0.752215] [G loss: 0.468458] time: 1:13:29.992488\n",
      "0.9046758\n",
      "[Epoch 49/50] [Batch 86/300] [D loss: 0.752242] [G loss: 0.462966] time: 1:13:30.293284\n",
      "0.8927667\n",
      "[Epoch 49/50] [Batch 87/300] [D loss: 0.752220] [G loss: 0.470722] time: 1:13:30.595664\n",
      "0.93858266\n",
      "[Epoch 49/50] [Batch 88/300] [D loss: 0.752226] [G loss: 0.499178] time: 1:13:30.906636\n",
      "0.9122303\n",
      "[Epoch 49/50] [Batch 89/300] [D loss: 0.752234] [G loss: 0.468756] time: 1:13:31.194629\n",
      "0.9182162\n",
      "[Epoch 49/50] [Batch 90/300] [D loss: 0.752225] [G loss: 0.481112] time: 1:13:31.490837\n",
      "0.926024\n",
      "[Epoch 49/50] [Batch 91/300] [D loss: 0.752218] [G loss: 0.493418] time: 1:13:31.792688\n",
      "0.9000313\n",
      "[Epoch 49/50] [Batch 92/300] [D loss: 0.752236] [G loss: 0.468289] time: 1:13:32.086661\n",
      "0.9293542\n",
      "[Epoch 49/50] [Batch 93/300] [D loss: 0.752222] [G loss: 0.502941] time: 1:13:32.396693\n",
      "0.97566336\n",
      "[Epoch 49/50] [Batch 94/300] [D loss: 0.752230] [G loss: 0.470428] time: 1:13:32.699468\n",
      "0.9161044\n",
      "[Epoch 49/50] [Batch 95/300] [D loss: 0.752222] [G loss: 0.466643] time: 1:13:33.005827\n",
      "0.90230465\n",
      "[Epoch 49/50] [Batch 96/300] [D loss: 0.752225] [G loss: 0.480029] time: 1:13:33.309378\n",
      "0.90219146\n",
      "[Epoch 49/50] [Batch 97/300] [D loss: 0.752234] [G loss: 0.468532] time: 1:13:33.611706\n",
      "0.9315939\n",
      "[Epoch 49/50] [Batch 98/300] [D loss: 0.752234] [G loss: 0.465421] time: 1:13:33.930521\n",
      "0.94333386\n",
      "[Epoch 49/50] [Batch 99/300] [D loss: 0.752229] [G loss: 0.476747] time: 1:13:34.231960\n",
      "0.9478671\n",
      "[Epoch 49/50] [Batch 100/300] [D loss: 0.752234] [G loss: 0.467176] time: 1:13:34.535923\n",
      "0.8886633\n",
      "[Epoch 49/50] [Batch 101/300] [D loss: 0.752221] [G loss: 0.468971] time: 1:13:34.838801\n",
      "0.9036177\n",
      "[Epoch 49/50] [Batch 102/300] [D loss: 0.752228] [G loss: 0.467605] time: 1:13:35.144680\n",
      "0.96458834\n",
      "[Epoch 49/50] [Batch 103/300] [D loss: 0.752229] [G loss: 0.473127] time: 1:13:35.436068\n",
      "0.90822244\n",
      "[Epoch 49/50] [Batch 104/300] [D loss: 0.752220] [G loss: 0.471698] time: 1:13:35.734067\n",
      "0.91767883\n",
      "[Epoch 49/50] [Batch 105/300] [D loss: 0.752230] [G loss: 0.467092] time: 1:13:36.023250\n",
      "0.90293366\n",
      "[Epoch 49/50] [Batch 106/300] [D loss: 0.752221] [G loss: 0.471085] time: 1:13:36.298939\n",
      "0.9069132\n",
      "[Epoch 49/50] [Batch 107/300] [D loss: 0.752215] [G loss: 0.486427] time: 1:13:36.595681\n",
      "0.9036693\n",
      "[Epoch 49/50] [Batch 108/300] [D loss: 0.752229] [G loss: 0.489943] time: 1:13:36.881149\n",
      "0.9555084\n",
      "[Epoch 49/50] [Batch 109/300] [D loss: 0.752228] [G loss: 0.475123] time: 1:13:37.191544\n",
      "0.9164729\n",
      "[Epoch 49/50] [Batch 110/300] [D loss: 0.752239] [G loss: 0.467410] time: 1:13:37.485825\n",
      "0.92201537\n",
      "[Epoch 49/50] [Batch 111/300] [D loss: 0.752226] [G loss: 0.465881] time: 1:13:37.779824\n",
      "0.8900241\n",
      "[Epoch 49/50] [Batch 112/300] [D loss: 0.752225] [G loss: 0.466841] time: 1:13:38.077930\n",
      "0.9330511\n",
      "[Epoch 49/50] [Batch 113/300] [D loss: 0.752225] [G loss: 0.461611] time: 1:13:38.358554\n",
      "0.9148558\n",
      "[Epoch 49/50] [Batch 114/300] [D loss: 0.752229] [G loss: 0.471714] time: 1:13:38.637273\n",
      "0.9550628\n",
      "[Epoch 49/50] [Batch 115/300] [D loss: 0.752236] [G loss: 0.467798] time: 1:13:38.939487\n",
      "0.9325885\n",
      "[Epoch 49/50] [Batch 116/300] [D loss: 0.752224] [G loss: 0.480418] time: 1:13:39.222882\n",
      "0.9561875\n",
      "[Epoch 49/50] [Batch 117/300] [D loss: 0.752226] [G loss: 0.479493] time: 1:13:39.506594\n",
      "0.9356006\n",
      "[Epoch 49/50] [Batch 118/300] [D loss: 0.752234] [G loss: 0.472853] time: 1:13:39.775998\n",
      "0.91209126\n",
      "[Epoch 49/50] [Batch 119/300] [D loss: 0.752221] [G loss: 0.472758] time: 1:13:40.073153\n",
      "0.94304204\n",
      "[Epoch 49/50] [Batch 120/300] [D loss: 0.752232] [G loss: 0.469617] time: 1:13:40.379458\n",
      "0.9061251\n",
      "[Epoch 49/50] [Batch 121/300] [D loss: 0.752227] [G loss: 0.476430] time: 1:13:40.659499\n",
      "0.9711173\n",
      "[Epoch 49/50] [Batch 122/300] [D loss: 0.752226] [G loss: 0.467202] time: 1:13:40.960397\n",
      "0.9687781\n",
      "[Epoch 49/50] [Batch 123/300] [D loss: 0.752231] [G loss: 0.463260] time: 1:13:41.237233\n",
      "0.92952245\n",
      "[Epoch 49/50] [Batch 124/300] [D loss: 0.752215] [G loss: 0.486346] time: 1:13:41.534303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913811\n",
      "[Epoch 49/50] [Batch 125/300] [D loss: 0.752226] [G loss: 0.467220] time: 1:13:41.834842\n",
      "0.98356515\n",
      "[Epoch 49/50] [Batch 126/300] [D loss: 0.752230] [G loss: 0.493865] time: 1:13:42.128583\n",
      "0.92475885\n",
      "[Epoch 49/50] [Batch 127/300] [D loss: 0.752234] [G loss: 0.474640] time: 1:13:42.411419\n",
      "0.9316365\n",
      "[Epoch 49/50] [Batch 128/300] [D loss: 0.752228] [G loss: 0.483341] time: 1:13:42.696712\n",
      "0.9352329\n",
      "[Epoch 49/50] [Batch 129/300] [D loss: 0.752238] [G loss: 0.467877] time: 1:13:43.006787\n",
      "0.9306626\n",
      "[Epoch 49/50] [Batch 130/300] [D loss: 0.752228] [G loss: 0.473336] time: 1:13:43.302544\n",
      "0.9045479\n",
      "[Epoch 49/50] [Batch 131/300] [D loss: 0.752226] [G loss: 0.471902] time: 1:13:43.593014\n",
      "0.925021\n",
      "[Epoch 49/50] [Batch 132/300] [D loss: 0.752233] [G loss: 0.465277] time: 1:13:43.883389\n",
      "0.88955396\n",
      "[Epoch 49/50] [Batch 133/300] [D loss: 0.752226] [G loss: 0.472186] time: 1:13:44.180671\n",
      "0.9821194\n",
      "[Epoch 49/50] [Batch 134/300] [D loss: 0.752232] [G loss: 0.466712] time: 1:13:44.472736\n",
      "0.9710362\n",
      "[Epoch 49/50] [Batch 135/300] [D loss: 0.752242] [G loss: 0.461357] time: 1:13:44.775200\n",
      "0.91515917\n",
      "[Epoch 49/50] [Batch 136/300] [D loss: 0.752221] [G loss: 0.471711] time: 1:13:45.075597\n",
      "0.8895773\n",
      "[Epoch 49/50] [Batch 137/300] [D loss: 0.752248] [G loss: 0.502957] time: 1:13:45.367373\n",
      "0.8841209\n",
      "[Epoch 49/50] [Batch 138/300] [D loss: 0.752227] [G loss: 0.465923] time: 1:13:45.685397\n",
      "0.9524236\n",
      "[Epoch 49/50] [Batch 139/300] [D loss: 0.752220] [G loss: 0.477667] time: 1:13:45.988709\n",
      "0.95324105\n",
      "[Epoch 49/50] [Batch 140/300] [D loss: 0.752227] [G loss: 0.475484] time: 1:13:46.278725\n",
      "0.91705626\n",
      "[Epoch 49/50] [Batch 141/300] [D loss: 0.752223] [G loss: 0.473291] time: 1:13:46.582236\n",
      "0.9572377\n",
      "[Epoch 49/50] [Batch 142/300] [D loss: 0.752221] [G loss: 0.479494] time: 1:13:46.890281\n",
      "0.88746613\n",
      "[Epoch 49/50] [Batch 143/300] [D loss: 0.752229] [G loss: 0.479161] time: 1:13:47.165956\n",
      "0.96883947\n",
      "[Epoch 49/50] [Batch 144/300] [D loss: 0.752233] [G loss: 0.468521] time: 1:13:47.437049\n",
      "0.9248194\n",
      "[Epoch 49/50] [Batch 145/300] [D loss: 0.752235] [G loss: 0.465552] time: 1:13:47.723969\n",
      "0.97578573\n",
      "[Epoch 49/50] [Batch 146/300] [D loss: 0.752216] [G loss: 0.461507] time: 1:13:48.018462\n",
      "0.9070554\n",
      "[Epoch 49/50] [Batch 147/300] [D loss: 0.752227] [G loss: 0.465536] time: 1:13:48.325476\n",
      "0.90570575\n",
      "[Epoch 49/50] [Batch 148/300] [D loss: 0.752230] [G loss: 0.471349] time: 1:13:48.634908\n",
      "0.9386216\n",
      "[Epoch 49/50] [Batch 149/300] [D loss: 0.752228] [G loss: 0.475811] time: 1:13:48.936086\n",
      "0.912792\n",
      "[Epoch 49/50] [Batch 150/300] [D loss: 0.752232] [G loss: 0.470787] time: 1:13:49.238286\n",
      "0.90077347\n",
      "[Epoch 49/50] [Batch 151/300] [D loss: 0.752232] [G loss: 0.483092] time: 1:13:49.523730\n",
      "0.97740334\n",
      "[Epoch 49/50] [Batch 152/300] [D loss: 0.752221] [G loss: 0.471947] time: 1:13:49.818426\n",
      "0.904583\n",
      "[Epoch 49/50] [Batch 153/300] [D loss: 0.752227] [G loss: 0.474838] time: 1:13:50.116453\n",
      "0.873712\n",
      "[Epoch 49/50] [Batch 154/300] [D loss: 0.752223] [G loss: 0.469573] time: 1:13:50.418632\n",
      "0.90877885\n",
      "[Epoch 49/50] [Batch 155/300] [D loss: 0.752232] [G loss: 0.480190] time: 1:13:50.712091\n",
      "0.8863332\n",
      "[Epoch 49/50] [Batch 156/300] [D loss: 0.752221] [G loss: 0.471258] time: 1:13:51.026746\n",
      "0.9154809\n",
      "[Epoch 49/50] [Batch 157/300] [D loss: 0.752224] [G loss: 0.469173] time: 1:13:51.327994\n",
      "0.9298534\n",
      "[Epoch 49/50] [Batch 158/300] [D loss: 0.752213] [G loss: 0.463185] time: 1:13:51.610046\n",
      "0.9094496\n",
      "[Epoch 49/50] [Batch 159/300] [D loss: 0.752234] [G loss: 0.466144] time: 1:13:51.919029\n",
      "0.91942316\n",
      "[Epoch 49/50] [Batch 160/300] [D loss: 0.752223] [G loss: 0.462142] time: 1:13:52.202341\n",
      "0.93199676\n",
      "[Epoch 49/50] [Batch 161/300] [D loss: 0.752226] [G loss: 0.462854] time: 1:13:52.505395\n",
      "0.95317554\n",
      "[Epoch 49/50] [Batch 162/300] [D loss: 0.752219] [G loss: 0.470470] time: 1:13:52.835088\n",
      "0.90791124\n",
      "[Epoch 49/50] [Batch 163/300] [D loss: 0.752241] [G loss: 0.462962] time: 1:13:53.138585\n",
      "0.94200516\n",
      "[Epoch 49/50] [Batch 164/300] [D loss: 0.752223] [G loss: 0.465416] time: 1:13:53.431732\n",
      "0.9617967\n",
      "[Epoch 49/50] [Batch 165/300] [D loss: 0.752237] [G loss: 0.463560] time: 1:13:53.737038\n",
      "0.910013\n",
      "[Epoch 49/50] [Batch 166/300] [D loss: 0.752219] [G loss: 0.465888] time: 1:13:54.040429\n",
      "0.95578426\n",
      "[Epoch 49/50] [Batch 167/300] [D loss: 0.752226] [G loss: 0.464731] time: 1:13:54.347187\n",
      "0.93152136\n",
      "[Epoch 49/50] [Batch 168/300] [D loss: 0.752226] [G loss: 0.470089] time: 1:13:54.648339\n",
      "0.9579777\n",
      "[Epoch 49/50] [Batch 169/300] [D loss: 0.752228] [G loss: 0.477082] time: 1:13:54.937024\n",
      "0.9024059\n",
      "[Epoch 49/50] [Batch 170/300] [D loss: 0.752222] [G loss: 0.463185] time: 1:13:55.239830\n",
      "0.91586494\n",
      "[Epoch 49/50] [Batch 171/300] [D loss: 0.752224] [G loss: 0.465142] time: 1:13:55.517133\n",
      "0.9105468\n",
      "[Epoch 49/50] [Batch 172/300] [D loss: 0.752226] [G loss: 0.463669] time: 1:13:55.821153\n",
      "0.8955202\n",
      "[Epoch 49/50] [Batch 173/300] [D loss: 0.752225] [G loss: 0.459273] time: 1:13:56.131937\n",
      "0.93103194\n",
      "[Epoch 49/50] [Batch 174/300] [D loss: 0.752230] [G loss: 0.463507] time: 1:13:56.445989\n",
      "0.9171408\n",
      "[Epoch 49/50] [Batch 175/300] [D loss: 0.752221] [G loss: 0.512826] time: 1:13:56.738355\n",
      "0.9419741\n",
      "[Epoch 49/50] [Batch 176/300] [D loss: 0.752234] [G loss: 0.469696] time: 1:13:57.047432\n",
      "0.9361504\n",
      "[Epoch 49/50] [Batch 177/300] [D loss: 0.752227] [G loss: 0.469172] time: 1:13:57.338645\n",
      "0.87410814\n",
      "[Epoch 49/50] [Batch 178/300] [D loss: 0.752234] [G loss: 0.467605] time: 1:13:57.631187\n",
      "0.9091671\n",
      "[Epoch 49/50] [Batch 179/300] [D loss: 0.752229] [G loss: 0.464366] time: 1:13:57.947863\n",
      "0.94613695\n",
      "[Epoch 49/50] [Batch 180/300] [D loss: 0.752231] [G loss: 0.466184] time: 1:13:58.255267\n",
      "0.9309874\n",
      "[Epoch 49/50] [Batch 181/300] [D loss: 0.752220] [G loss: 0.460669] time: 1:13:58.528509\n",
      "0.9292984\n",
      "[Epoch 49/50] [Batch 182/300] [D loss: 0.752227] [G loss: 0.463820] time: 1:13:58.824344\n",
      "0.95641494\n",
      "[Epoch 49/50] [Batch 183/300] [D loss: 0.752222] [G loss: 0.467183] time: 1:13:59.124088\n",
      "0.90591353\n",
      "[Epoch 49/50] [Batch 184/300] [D loss: 0.752215] [G loss: 0.463006] time: 1:13:59.412599\n",
      "0.9135623\n",
      "[Epoch 49/50] [Batch 185/300] [D loss: 0.752231] [G loss: 0.469204] time: 1:13:59.708013\n",
      "0.95334655\n",
      "[Epoch 49/50] [Batch 186/300] [D loss: 0.752223] [G loss: 0.488408] time: 1:13:59.997717\n",
      "0.946301\n",
      "[Epoch 49/50] [Batch 187/300] [D loss: 0.752223] [G loss: 0.469849] time: 1:14:00.276872\n",
      "0.9326727\n",
      "[Epoch 49/50] [Batch 188/300] [D loss: 0.752231] [G loss: 0.493048] time: 1:14:00.563194\n",
      "0.9065614\n",
      "[Epoch 49/50] [Batch 189/300] [D loss: 0.752224] [G loss: 0.460474] time: 1:14:00.880497\n",
      "0.9574151\n",
      "[Epoch 49/50] [Batch 190/300] [D loss: 0.752233] [G loss: 0.486675] time: 1:14:01.181436\n",
      "0.9104295\n",
      "[Epoch 49/50] [Batch 191/300] [D loss: 0.752226] [G loss: 0.464932] time: 1:14:01.463211\n",
      "0.94501704\n",
      "[Epoch 49/50] [Batch 192/300] [D loss: 0.752242] [G loss: 0.468394] time: 1:14:01.759482\n",
      "0.8893698\n",
      "[Epoch 49/50] [Batch 193/300] [D loss: 0.752224] [G loss: 0.466266] time: 1:14:02.057925\n",
      "0.9319184\n",
      "[Epoch 49/50] [Batch 194/300] [D loss: 0.752212] [G loss: 0.476037] time: 1:14:02.357671\n",
      "0.97444487\n",
      "[Epoch 49/50] [Batch 195/300] [D loss: 0.752221] [G loss: 0.477488] time: 1:14:02.674062\n",
      "0.94218737\n",
      "[Epoch 49/50] [Batch 196/300] [D loss: 0.752230] [G loss: 0.470202] time: 1:14:02.967910\n",
      "0.9092303\n",
      "[Epoch 49/50] [Batch 197/300] [D loss: 0.752215] [G loss: 0.473902] time: 1:14:03.279346\n",
      "0.92353374\n",
      "[Epoch 49/50] [Batch 198/300] [D loss: 0.752227] [G loss: 0.486440] time: 1:14:03.582949\n",
      "0.9837621\n",
      "[Epoch 49/50] [Batch 199/300] [D loss: 0.752229] [G loss: 0.472364] time: 1:14:03.885683\n",
      "0.9579168\n",
      "[Epoch 49/50] [Batch 200/300] [D loss: 0.752243] [G loss: 0.469930] time: 1:14:04.184815\n",
      "0.94782263\n",
      "[Epoch 49/50] [Batch 201/300] [D loss: 0.752231] [G loss: 0.471956] time: 1:14:04.482758\n",
      "0.9387424\n",
      "[Epoch 49/50] [Batch 202/300] [D loss: 0.752226] [G loss: 0.473636] time: 1:14:04.795008\n",
      "0.90511745\n",
      "[Epoch 49/50] [Batch 203/300] [D loss: 0.752230] [G loss: 0.468238] time: 1:14:05.089546\n",
      "0.92540246\n",
      "[Epoch 49/50] [Batch 204/300] [D loss: 0.752225] [G loss: 0.491894] time: 1:14:05.403568\n",
      "0.93226546\n",
      "[Epoch 49/50] [Batch 205/300] [D loss: 0.752231] [G loss: 0.482525] time: 1:14:05.699454\n",
      "0.888593\n",
      "[Epoch 49/50] [Batch 206/300] [D loss: 0.752229] [G loss: 0.492661] time: 1:14:05.990580\n",
      "0.9331296\n",
      "[Epoch 49/50] [Batch 207/300] [D loss: 0.752229] [G loss: 0.463724] time: 1:14:06.278851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93881756\n",
      "[Epoch 49/50] [Batch 208/300] [D loss: 0.752237] [G loss: 0.475775] time: 1:14:06.584857\n",
      "0.87646604\n",
      "[Epoch 49/50] [Batch 209/300] [D loss: 0.752215] [G loss: 0.478820] time: 1:14:06.898368\n",
      "0.8730964\n",
      "[Epoch 49/50] [Batch 210/300] [D loss: 0.752227] [G loss: 0.466051] time: 1:14:07.216927\n",
      "0.91688204\n",
      "[Epoch 49/50] [Batch 211/300] [D loss: 0.752229] [G loss: 0.470583] time: 1:14:07.503507\n",
      "0.97553045\n",
      "[Epoch 49/50] [Batch 212/300] [D loss: 0.752233] [G loss: 0.464378] time: 1:14:07.779710\n",
      "0.90441656\n",
      "[Epoch 49/50] [Batch 213/300] [D loss: 0.752230] [G loss: 0.467312] time: 1:14:08.083662\n",
      "0.93158334\n",
      "[Epoch 49/50] [Batch 214/300] [D loss: 0.752223] [G loss: 0.464424] time: 1:14:08.367838\n",
      "0.9327238\n",
      "[Epoch 49/50] [Batch 215/300] [D loss: 0.752231] [G loss: 0.464688] time: 1:14:08.670578\n",
      "0.9498635\n",
      "[Epoch 49/50] [Batch 216/300] [D loss: 0.752229] [G loss: 0.475119] time: 1:14:08.958532\n",
      "0.9254907\n",
      "[Epoch 49/50] [Batch 217/300] [D loss: 0.752219] [G loss: 0.491252] time: 1:14:09.251093\n",
      "0.8528843\n",
      "[Epoch 49/50] [Batch 218/300] [D loss: 0.752226] [G loss: 0.470479] time: 1:14:09.555928\n",
      "0.96421033\n",
      "[Epoch 49/50] [Batch 219/300] [D loss: 0.752215] [G loss: 0.465795] time: 1:14:09.857667\n",
      "0.9163656\n",
      "[Epoch 49/50] [Batch 220/300] [D loss: 0.752228] [G loss: 0.482802] time: 1:14:10.163142\n",
      "0.9481485\n",
      "[Epoch 49/50] [Batch 221/300] [D loss: 0.752233] [G loss: 0.462125] time: 1:14:10.467146\n",
      "0.9292944\n",
      "[Epoch 49/50] [Batch 222/300] [D loss: 0.752216] [G loss: 0.472128] time: 1:14:10.762412\n",
      "0.91319865\n",
      "[Epoch 49/50] [Batch 223/300] [D loss: 0.752237] [G loss: 0.485720] time: 1:14:11.064138\n",
      "0.9431847\n",
      "[Epoch 49/50] [Batch 224/300] [D loss: 0.752215] [G loss: 0.471905] time: 1:14:11.352736\n",
      "0.93812746\n",
      "[Epoch 49/50] [Batch 225/300] [D loss: 0.752230] [G loss: 0.484957] time: 1:14:11.665546\n",
      "0.9165835\n",
      "[Epoch 49/50] [Batch 226/300] [D loss: 0.752222] [G loss: 0.472567] time: 1:14:11.953364\n",
      "0.9449236\n",
      "[Epoch 49/50] [Batch 227/300] [D loss: 0.752216] [G loss: 0.467890] time: 1:14:12.256897\n",
      "0.9373169\n",
      "[Epoch 49/50] [Batch 228/300] [D loss: 0.752233] [G loss: 0.478207] time: 1:14:12.535389\n",
      "0.9355777\n",
      "[Epoch 49/50] [Batch 229/300] [D loss: 0.752231] [G loss: 0.466187] time: 1:14:12.828126\n",
      "0.91705924\n",
      "[Epoch 49/50] [Batch 230/300] [D loss: 0.752224] [G loss: 0.470677] time: 1:14:13.133166\n",
      "0.90359706\n",
      "[Epoch 49/50] [Batch 231/300] [D loss: 0.752225] [G loss: 0.467294] time: 1:14:13.433876\n",
      "0.9118268\n",
      "[Epoch 49/50] [Batch 232/300] [D loss: 0.752224] [G loss: 0.471322] time: 1:14:13.758488\n",
      "0.934855\n",
      "[Epoch 49/50] [Batch 233/300] [D loss: 0.752222] [G loss: 0.490151] time: 1:14:14.056953\n",
      "0.93910646\n",
      "[Epoch 49/50] [Batch 234/300] [D loss: 0.752214] [G loss: 0.467438] time: 1:14:14.336130\n",
      "0.9201637\n",
      "[Epoch 49/50] [Batch 235/300] [D loss: 0.752224] [G loss: 0.465405] time: 1:14:14.640242\n",
      "0.9755667\n",
      "[Epoch 49/50] [Batch 236/300] [D loss: 0.752221] [G loss: 0.473947] time: 1:14:14.948081\n",
      "0.9822925\n",
      "[Epoch 49/50] [Batch 237/300] [D loss: 0.752228] [G loss: 0.467764] time: 1:14:15.219554\n",
      "0.8745006\n",
      "[Epoch 49/50] [Batch 238/300] [D loss: 0.752237] [G loss: 0.464531] time: 1:14:15.522067\n",
      "0.94311786\n",
      "[Epoch 49/50] [Batch 239/300] [D loss: 0.752233] [G loss: 0.482899] time: 1:14:15.815736\n",
      "0.92838293\n",
      "[Epoch 49/50] [Batch 240/300] [D loss: 0.752229] [G loss: 0.466839] time: 1:14:16.123606\n",
      "0.9536647\n",
      "[Epoch 49/50] [Batch 241/300] [D loss: 0.752228] [G loss: 0.471632] time: 1:14:16.421852\n",
      "0.97104836\n",
      "[Epoch 49/50] [Batch 242/300] [D loss: 0.752234] [G loss: 0.475786] time: 1:14:16.720282\n",
      "0.93450767\n",
      "[Epoch 49/50] [Batch 243/300] [D loss: 0.752215] [G loss: 0.484148] time: 1:14:17.045643\n",
      "0.9562767\n",
      "[Epoch 49/50] [Batch 244/300] [D loss: 0.752213] [G loss: 0.491441] time: 1:14:17.316767\n",
      "0.93900055\n",
      "[Epoch 49/50] [Batch 245/300] [D loss: 0.752222] [G loss: 0.469383] time: 1:14:17.597941\n",
      "0.8933117\n",
      "[Epoch 49/50] [Batch 246/300] [D loss: 0.752229] [G loss: 0.470164] time: 1:14:17.891903\n",
      "0.91741437\n",
      "[Epoch 49/50] [Batch 247/300] [D loss: 0.752228] [G loss: 0.467780] time: 1:14:18.214102\n",
      "0.9168351\n",
      "[Epoch 49/50] [Batch 248/300] [D loss: 0.752226] [G loss: 0.468139] time: 1:14:18.514121\n",
      "0.9497595\n",
      "[Epoch 49/50] [Batch 249/300] [D loss: 0.752225] [G loss: 0.482994] time: 1:14:18.809506\n",
      "0.93581796\n",
      "[Epoch 49/50] [Batch 250/300] [D loss: 0.752226] [G loss: 0.485102] time: 1:14:19.106166\n",
      "0.9193506\n",
      "[Epoch 49/50] [Batch 251/300] [D loss: 0.752228] [G loss: 0.481844] time: 1:14:19.401506\n",
      "0.9296555\n",
      "[Epoch 49/50] [Batch 252/300] [D loss: 0.752220] [G loss: 0.482893] time: 1:14:19.714376\n",
      "0.9352222\n",
      "[Epoch 49/50] [Batch 253/300] [D loss: 0.752227] [G loss: 0.469380] time: 1:14:20.027786\n",
      "0.9385467\n",
      "[Epoch 49/50] [Batch 254/300] [D loss: 0.752218] [G loss: 0.466349] time: 1:14:20.310638\n",
      "0.9384191\n",
      "[Epoch 49/50] [Batch 255/300] [D loss: 0.752237] [G loss: 0.479952] time: 1:14:20.610650\n",
      "0.8873753\n",
      "[Epoch 49/50] [Batch 256/300] [D loss: 0.752218] [G loss: 0.473809] time: 1:14:20.903204\n",
      "0.9395275\n",
      "[Epoch 49/50] [Batch 257/300] [D loss: 0.752237] [G loss: 0.473688] time: 1:14:21.200945\n",
      "0.93787235\n",
      "[Epoch 49/50] [Batch 258/300] [D loss: 0.752214] [G loss: 0.471969] time: 1:14:21.509582\n",
      "0.9334566\n",
      "[Epoch 49/50] [Batch 259/300] [D loss: 0.752229] [G loss: 0.471188] time: 1:14:21.811331\n",
      "0.9553819\n",
      "[Epoch 49/50] [Batch 260/300] [D loss: 0.752229] [G loss: 0.489594] time: 1:14:22.096642\n",
      "0.9421704\n",
      "[Epoch 49/50] [Batch 261/300] [D loss: 0.752216] [G loss: 0.473582] time: 1:14:22.397566\n",
      "0.9026125\n",
      "[Epoch 49/50] [Batch 262/300] [D loss: 0.752222] [G loss: 0.466783] time: 1:14:22.684741\n",
      "0.9140107\n",
      "[Epoch 49/50] [Batch 263/300] [D loss: 0.752226] [G loss: 0.464857] time: 1:14:22.967109\n",
      "0.92044497\n",
      "[Epoch 49/50] [Batch 264/300] [D loss: 0.752217] [G loss: 0.475451] time: 1:14:23.265019\n",
      "0.8882933\n",
      "[Epoch 49/50] [Batch 265/300] [D loss: 0.752221] [G loss: 0.486737] time: 1:14:23.546883\n",
      "0.9457099\n",
      "[Epoch 49/50] [Batch 266/300] [D loss: 0.752230] [G loss: 0.497645] time: 1:14:23.852075\n",
      "0.9064513\n",
      "[Epoch 49/50] [Batch 267/300] [D loss: 0.752223] [G loss: 0.469501] time: 1:14:24.137180\n",
      "0.92399615\n",
      "[Epoch 49/50] [Batch 268/300] [D loss: 0.752219] [G loss: 0.469131] time: 1:14:24.415219\n",
      "0.91027135\n",
      "[Epoch 49/50] [Batch 269/300] [D loss: 0.752228] [G loss: 0.469768] time: 1:14:24.695630\n",
      "0.9456524\n",
      "[Epoch 49/50] [Batch 270/300] [D loss: 0.752221] [G loss: 0.472682] time: 1:14:24.987617\n",
      "0.9092555\n",
      "[Epoch 49/50] [Batch 271/300] [D loss: 0.752215] [G loss: 0.469311] time: 1:14:25.282644\n",
      "0.8938656\n",
      "[Epoch 49/50] [Batch 272/300] [D loss: 0.752222] [G loss: 0.469773] time: 1:14:25.572101\n",
      "0.95965844\n",
      "[Epoch 49/50] [Batch 273/300] [D loss: 0.752225] [G loss: 0.459349] time: 1:14:25.848359\n",
      "0.9218536\n",
      "[Epoch 49/50] [Batch 274/300] [D loss: 0.752228] [G loss: 0.466457] time: 1:14:26.141118\n",
      "0.9251322\n",
      "[Epoch 49/50] [Batch 275/300] [D loss: 0.752225] [G loss: 0.477274] time: 1:14:26.438736\n",
      "0.87248915\n",
      "[Epoch 49/50] [Batch 276/300] [D loss: 0.752221] [G loss: 0.475399] time: 1:14:26.740448\n",
      "0.9457934\n",
      "[Epoch 49/50] [Batch 277/300] [D loss: 0.752230] [G loss: 0.467144] time: 1:14:27.041088\n",
      "0.91189116\n",
      "[Epoch 49/50] [Batch 278/300] [D loss: 0.752231] [G loss: 0.465712] time: 1:14:27.352296\n",
      "0.8703425\n",
      "[Epoch 49/50] [Batch 279/300] [D loss: 0.752227] [G loss: 0.467191] time: 1:14:27.649733\n",
      "0.88755244\n",
      "[Epoch 49/50] [Batch 280/300] [D loss: 0.752236] [G loss: 0.479045] time: 1:14:27.944285\n",
      "0.9212007\n",
      "[Epoch 49/50] [Batch 281/300] [D loss: 0.752213] [G loss: 0.474801] time: 1:14:28.250242\n",
      "0.9719452\n",
      "[Epoch 49/50] [Batch 282/300] [D loss: 0.752225] [G loss: 0.487911] time: 1:14:28.545969\n",
      "0.89707464\n",
      "[Epoch 49/50] [Batch 283/300] [D loss: 0.752221] [G loss: 0.475508] time: 1:14:28.846695\n",
      "0.9458492\n",
      "[Epoch 49/50] [Batch 284/300] [D loss: 0.752230] [G loss: 0.488620] time: 1:14:29.139288\n",
      "0.9166592\n",
      "[Epoch 49/50] [Batch 285/300] [D loss: 0.752223] [G loss: 0.471909] time: 1:14:29.436218\n",
      "0.93295723\n",
      "[Epoch 49/50] [Batch 286/300] [D loss: 0.752220] [G loss: 0.469232] time: 1:14:29.725166\n",
      "0.9274549\n",
      "[Epoch 49/50] [Batch 287/300] [D loss: 0.752217] [G loss: 0.474838] time: 1:14:30.050889\n",
      "0.96007484\n",
      "[Epoch 49/50] [Batch 288/300] [D loss: 0.752226] [G loss: 0.467411] time: 1:14:30.358628\n",
      "0.95230633\n",
      "[Epoch 49/50] [Batch 289/300] [D loss: 0.752229] [G loss: 0.459006] time: 1:14:30.655484\n",
      "0.91912174\n",
      "[Epoch 49/50] [Batch 290/300] [D loss: 0.752220] [G loss: 0.465071] time: 1:14:30.933652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9274518\n",
      "[Epoch 49/50] [Batch 291/300] [D loss: 0.752217] [G loss: 0.475135] time: 1:14:31.207473\n",
      "0.91326314\n",
      "[Epoch 49/50] [Batch 292/300] [D loss: 0.752216] [G loss: 0.473667] time: 1:14:31.513986\n",
      "0.90811545\n",
      "[Epoch 49/50] [Batch 293/300] [D loss: 0.752225] [G loss: 0.469189] time: 1:14:31.788729\n",
      "0.9384785\n",
      "[Epoch 49/50] [Batch 294/300] [D loss: 0.752216] [G loss: 0.480050] time: 1:14:32.083475\n",
      "0.9080636\n",
      "[Epoch 49/50] [Batch 295/300] [D loss: 0.752226] [G loss: 0.466794] time: 1:14:32.390952\n",
      "0.9330349\n",
      "[Epoch 49/50] [Batch 296/300] [D loss: 0.752225] [G loss: 0.486086] time: 1:14:32.701600\n",
      "0.9158961\n",
      "[Epoch 49/50] [Batch 297/300] [D loss: 0.752222] [G loss: 0.465930] time: 1:14:33.005087\n",
      "0.89887685\n",
      "[Epoch 49/50] [Batch 298/300] [D loss: 0.752227] [G loss: 0.469089] time: 1:14:33.307348\n",
      "0.9324015\n",
      "[Epoch 49/50] [Batch 299/300] [D loss: 0.752225] [G loss: 0.463222] time: 1:14:33.585350\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte\n",
    "import numpy as np \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "test_first_imgs, test_last_imgs = next(test_batch_generator)\n",
    "steps_per_epoch = (nbr_train_data // cfg.BATCH_SIZE)\n",
    "g_loss_vector = np.zeros((steps_per_epoch, cfg.NUM_EPOCHS))\n",
    "d_loss_vector = np.zeros((steps_per_epoch, cfg.NUM_EPOCHS))\n",
    "\n",
    "\"\"\"g_loss_vector = np.zeros(steps_per_epoch*cfg.BATCH_SIZE)\n",
    "d_loss_vector = np.zeros(steps_per_epoch*cfg.BATCH_SIZE)\"\"\"\n",
    "\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    for batch_i in range(steps_per_epoch):\n",
    "        first_frames, last_frames= next(train_batch_generator)\n",
    "        if first_frames.shape[0] == cfg.BATCH_SIZE: \n",
    "             \n",
    "            # Condition on the first frame and generate the last frame\n",
    "            fake_last_frames = modelObj.generator.predict(first_frames)\n",
    "            #plt.imshow(fake_last_frames[1])\n",
    "            #print(fake_last_frames.shape)\n",
    "            #print(tf.keras.backend.mean(fake_last_frames[0]))\n",
    "            print(np.mean(fake_last_frames[0]))\n",
    "\n",
    "            # Train the discriminator with combined loss  \n",
    "            d_loss_real = modelObj.discriminator.train_on_batch([last_frames, first_frames], valid)\n",
    "            d_loss_fake = modelObj.discriminator.train_on_batch([fake_last_frames, first_frames], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            d_loss_vector[batch_i,epoch] = d_loss[0]\n",
    "            #d_loss_vector[batch_i*epoch] = d_loss[0]\n",
    " \n",
    "            # Train the generator\n",
    "            g_loss = modelObj.combined.train_on_batch([last_frames, first_frames], [valid, last_frames])\n",
    "            g_loss_vector[batch_i,epoch] = g_loss[0]\n",
    "            #g_loss_vector[batch_i*epoch] = g_loss[0]\n",
    "            #print(\"batch_i: \", batch_i)\n",
    "            elapsed_time = datetime.now() - start_time \n",
    "            print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] time: %s\" % (epoch, cfg.NUM_EPOCHS,\n",
    "                                                                                               batch_i,\n",
    "                                                                                                steps_per_epoch,\n",
    "                                                                                               d_loss[0], \n",
    "                                                                                               g_loss[0],\n",
    "                                                                                               elapsed_time))\n",
    "            # run some tests to check how the generated images evolve during training\n",
    "            test_fake_last_imgs = modelObj.generator.predict(test_first_imgs)\n",
    "            test_img_name = output_log_dir + \"/gen_img_epoc_\" + str(epoch) + \".png\"\n",
    "            merged_img = np.vstack((first_frames[0],last_frames[0],fake_last_frames[0]))\n",
    "            imageio.imwrite(test_img_name, img_as_ubyte(merged_img)) #scipy.misc.imsave(test_img_name, merged_img)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model and print the test images to logg \n",
    "for batch_i in range(100):\n",
    "    test_first_imgs, test_last_imgs = next(test_batch_generator)\n",
    "    test_fake_last_imgs = modelObj.generator.predict(test_first_imgs) \n",
    "\n",
    "    test_img_name = output_log_dir + \"/gen_img_test_\" + str(batch_i) + \".png\"\n",
    "    merged_img = np.vstack((test_first_imgs[0],test_last_imgs[0],test_fake_last_imgs[0]))\n",
    "    imageio.imwrite(test_img_name, img_as_ubyte(merged_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Loss plot \n",
    "#print(g_loss_vector)\n",
    "#print(d_loss_vector)\n",
    "g_lossLine= np.zeros(steps_per_epoch*cfg.NUM_EPOCHS)\n",
    "d_lossLine= np.zeros(steps_per_epoch*cfg.NUM_EPOCHS)\n",
    "for i in range(cfg.NUM_EPOCHS):\n",
    "    for j in range(steps_per_epoch):\n",
    "        g_lossLine[j+i*300]= g_loss_vector[j,i]\n",
    "        d_lossLine[j+i*300]= d_loss_vector[j,i]\n",
    "       \n",
    "plt.plot(d_lossLine[200:-1], label = \"Discriminator Loss\" )\n",
    "plt.plot(g_lossLine[200:-1], label = \"Generator Loss\" )\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Batch  ')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean discriminator the last 300 samples:  0.7504358902091888\n",
      "Mean generator the last 300 samples:  0.5615976029394781\n",
      "Variance  discriminator the last 300 samples:  0.001871578015766786\n",
      "Variance generator the last 300 samples:  0.016251593094894223\n"
     ]
    }
   ],
   "source": [
    "#print(np.mean(d_lossLine))\n",
    "#print(np.mean(g_lossLine))\n",
    "print(\"Mean discriminator the last 300 samples: \",np.mean(d_lossLine[800:-1]))\n",
    "print(\"Mean generator the last 300 samples: \", np.mean(g_lossLine[800:-1]))\n",
    "print(\"Variance  discriminator the last 300 samples: \",np.var(d_lossLine[800:-1]))\n",
    "print(\"Variance generator the last 300 samples: \", np.var(g_lossLine[800:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsfElEQVR4nO3deZwcdZn48c8zd+6QixASyGEChIQMOglHMKAucqjggSvIhkOFzc/FXWEXibKLIAoIqMiCRl4uIK4oiKwiBCKEQLjNBBJCyEESApkkkMl9zSRzPL8/unrS0z2V7pqpmq7jeb9e85rub1dXPd+q6nrq+Na3RFUxxhiTXCXFDsAYY0xxWSIwxpiEs0RgjDEJZ4nAGGMSzhKBMcYkXFmxA/Bq0KBBOnLkyGKHYYwxkbJw4cLNqjq4o88ilwhGjhxJbW1tscMwxphIEZH33D6zU0PGGJNwlgiMMSbhLBEYY0zCRe4agTEmv6amJurq6mhsbCx2KKabVVVVMXz4cMrLywv+jiUCY2Korq6OPn36MHLkSESk2OGYbqKqbNmyhbq6OkaNGlXw9+zUkDEx1NjYyMCBAy0JJIyIMHDgQM9HgpYIjIkpSwLJ1JnlnphEsOKDXfzkbyvYsntfsUMxxphQSUwiWF2/m/9+dhWbd+8vdijGJEJpaSnV1dUce+yxTJo0iZ/+9Ke0trYCUFtby7/+6792eRqzZs3igQce8PSdk08+udPTu//++9mwYUOnvw9w/fXXc/vtt3dpHH5LzMXi0pLU4VJTS2uRIzEmGXr06MGiRYsA2LRpE1/96lfZsWMHN9xwAzU1NdTU1HRp/M3NzcyYMcPz915++eVOT/P+++9nwoQJDBs2rODvtLS0UFpa2ulpdofEHBGUl6YSQUurPZHNmO42ZMgQ7rnnHu666y5Uleeee47PfvazADz//PNUV1dTXV3N8ccfz65duwC49dZbmThxIpMmTWLmzJkAnHbaaXzve9/j1FNP5ec//3m7vevTTjuNK6+8kmnTpnHMMcewYMECvvjFLzJ27Fj+8z//sy2W3r17A/Dcc89x2mmncd5553H00Udz4YUXkn5i4w9+8AMmT57MhAkTuPzyy1FVHnnkEWpra7nwwguprq6moaGBuXPncvzxxzNx4kS+9rWvsW9f6tTzyJEj+cEPfsApp5zCH//4x7zzR1W5+uqrmTBhAhMnTuShhx4CYOPGjUybNo3q6momTJjACy+8QEtLC5dccknbsD/72c+6vHwSc0RQVpLKec2tdkRgkuWGvy7l7Q07fR3n+GF9+f7njvX0ndGjR9Pa2sqmTZvald9+++3cfffdTJ06ld27d1NVVcWTTz7Jn//8Z1577TV69uzJ1q1b24bfvn07zz//PJA6zZKpoqKC+fPn8/Of/5xzzz2XhQsXMmDAAMaMGcOVV17JwIED2w3/xhtvsHTpUoYNG8bUqVN56aWXOOWUU7jiiiu47rrrAJg+fTqPP/445513HnfddRe33347NTU1NDY2cskllzB37lzGjRvHRRddxC9/+Uu+/e1vA6n2/C+++GJB8+bRRx9l0aJFLF68mM2bNzN58mSmTZvGgw8+yBlnnMG1115LS0sLe/fuZdGiRaxfv5633nqrbX50VWKOCMraTg3ZEYExxdLRM9KnTp3KVVddxZ133sn27dspKyvjmWee4dJLL6Vnz54ADBgwoG34r3zlK67jP+eccwCYOHEixx57LIcddhiVlZWMHj2adevW5Qw/ZcoUhg8fTklJCdXV1axduxaAefPmccIJJzBx4kSeffZZli5dmvPdFStWMGrUKMaNGwfAxRdfzPz58wuKM9uLL77IBRdcQGlpKYceeiinnnoqCxYsYPLkydx3331cf/31LFmyhD59+jB69GjWrFnDt771LZ566in69u1b8HTcJOeIoNQ5IrBEYBLG6557UNasWUNpaSlDhgxh2bJlbeUzZ87kM5/5DLNnz+bEE0/kmWeeQVVdm0H26tXLdRqVlZUAlJSUtL1Ov29ubnYdHlIXt5ubm2lsbOSb3/wmtbW1jBgxguuvv77DdvkdJbVC4yx0XNOmTWP+/Pk88cQTTJ8+nauvvpqLLrqIxYsXM2fOHO6++24efvhh7r333oKn1ZHEHBGkLxZv22uthozpbvX19cyYMYMrrrgiZwO/evVqJk6cyDXXXENNTQ3Lly/n05/+NPfeey979+4FaHdqKGjpjf6gQYPYvXs3jzzySNtnffr0abuGcfTRR7N27VpWrVoFwG9/+1tOPfXUTk1z2rRpPPTQQ7S0tFBfX8/8+fOZMmUK7733HkOGDOGyyy7j61//Oq+//jqbN2+mtbWVL33pS9x44428/vrrXaxxgo4I1m7eA8DPnl7J5yYVfsXfGNM5DQ0NVFdX09TURFlZGdOnT+eqq67KGe6OO+5g3rx5lJaWMn78eM466ywqKytZtGgRNTU1VFRUcPbZZ3PTTTd1S9z9+/fnsssuY+LEiYwcOZLJkye3fXbJJZcwY8YMevTowSuvvMJ9993Hl7/8ZZqbm5k8eXLBrZh++MMfcscdd7S9X7duHa+88gqTJk1CRLj11lsZOnQov/nNb7jtttsoLy+nd+/ePPDAA6xfv55LL720rSnuzTff3OU6S77Dm7CpqanRzjyYZkdDE5Nu+BvnTBrGnRccH0BkxoTHsmXLOOaYY4odhimSjpa/iCxU1Q7b7Cbm1FDfqtTBz2OLu3YziDHGxE1iEoH1u2KMMR1LTCIwJmmidtrX+KMzyz3QRCAiZ4rIChFZJSIzO/i8n4j8VUQWi8hSEbk0yHimfiR1M8m7zoVjY+KqqqqKLVu2WDJImPTzCKqqqjx9L7BWQyJSCtwNnA7UAQtE5DFVfTtjsH8B3lbVz4nIYGCFiPxOVQNp4/nSqi0A/OiJZfz64q71c2JMmA0fPpy6ujrq6+uLHYrpZuknlHkRZPPRKcAqVV0DICJ/AM4FMhOBAn0kdQK/N7AVyL3rwycvz/wkJ9/yLK+u2RLUJIwJhfLyck9PqDLJFuSpocOBzHu665yyTHcBxwAbgCXAv6lqTmdAInK5iNSKSG1X9nCG9e8BwO59geUaY4yJnCATQUfNdLJPWJ4BLAKGAdXAXSKS03GGqt6jqjWqWjN48GBfgvvp0yt9GY8xxkRdkImgDhiR8X44qT3/TJcCj2rKKuBd4OgAY+LGz08A4M657wQ5GWOMiYwgE8ECYKyIjBKRCuB84LGsYd4HPgUgIocCRwFrAoyJ6Sce2fb6kYV1QU7KGGMiIbBEoKrNwBXAHGAZ8LCqLhWRGSKS7pDjRuBkEVkCzAWuUdXNQcWU9u+np7qN/Y8/LqaxqSXoyRljTKglpq+hbCNnPtH2+p0fnUV5qd1bZ4yJL+trqANv3XBG2+ux1z7ZLjEYY0ySJDYR9K4sY8UPz2xXNnLmE4yc+QR/W/pBkaIyxpjul5jnEXSksqyU7519NDfNXt6u/PLfLswZ9p7pH+P08Yda53XGmNhJdCLIdNnHR/HPp46h5ofPdPh5R8kBYGjfKj4ypDdHDe3DC+/Uc9zw/hzWr4rD+/dgwuH92Lu/hf49y6kqK6VnZSlV5aWUlwoVpSWWVIwxoWCJIMOg3pWsveUzAPz93a38469eyfudD3Y28sHORl5clWrstPLD3Z6n27uyjPJSoay0hFIRPtiZelTekQN7UlVWighUlpWw8sPdNDS1UHPkIZSIUFqS+vtwZyPvbNrNKR8ZREVZ6mxfiUBTi/L8yno+cdRgqspL24YX4M+LNvDxsYMY3KeSEkmVicDDtXWcdtRghvXvgfN0T0pE+L/X13PciH6MHdIHnGEF4eXVmxnQq4Jjh/Vtl9iWbdxJw/4WpowakFlV1m7Zw/tb93LauCEZ44GNOxpZsn4HZxw7lMz8uHd/C/OWb+KcrKfKNbcqTyzZyLmThlFS0j6hPvXWB3zi6CFUlZcgGfc1zlu+iY8eeQj9epS3TRfgtXe3MmZwLwb3ST2/Nv2dhe9t49C+lYwY0LPd+Fdt2k1Lq3LU0PS8SA2/cXsDm3fv47jh/dsNv2XPPtbU72HKqAFt01Rgd2Mzb6zbzrSxg9qGFRGaW1PL7VNHDyF7X2H+ynpOGjOI8lJxYk15Zc0Wqkf0p0dF+5/0q2u2cMzQPvTrWXFgGsDbG3cysFcFh/atajeNd+v3IAJHDmz/vN1NOxvZ3tDUVue0rbv3s357A5NGtK/z3v0tLF2/g8lZy39fUwsL3tvGxz9yoM7p5iovr97CyWMGkrk4VVPL5/gj+lNZ1v5M9qJ1OxgzuBd9qtrX+c26HQzr34NBvSvaLf/V9bupLC9luNPDQNrGHY3sbWpmzKDeBwoFtu3ZT/2ufYzLqnPD/hZWfriL6qw6N7Uoi9Zto2bkgHZ307aq8uqarZw0ZmDOXba1a7dRfUR/yrLW4cV12xl3aB96Ossz3ajn6KF9mTi8H35LbKuhtHvmr+am2cu57OOjuPYz49vKF6zdypdnvULNkYfwyP87ua18z75mjv3+HKrKS1h+41moKnv2t7CrsYmTbn4WgB9/aSK7GpsZ1r8Hm3fv47q/LAXghnOOpbGphcamVlpU225qu2DKCFI/T6W1FR6qTfXMceaxQ4HURm9fcwsvvJNKNuMO7c2AXhW0tCotrcrr729vi2/C4X0RUhuTZRt3tpWPHdKbFk0N/96WvW3lh/fvgaqiwIc7G2l1VodBvSvaXreqsn1vE5B6wI8CqLMxc7rr6FFeimbcON7YlOopJL3BUk1t9JtaUsOUlkjbdCO2ChpTNDNOHcPMszp3z+3BWg3ZEUEXiQi9K8voXXlgVn5l8hHthkkngotPHtmuPJ0Ibv7ice3K04lg1vSPtSv/6I1Ps3XPfn73jRPb9l4Bzr/nFV5ds5UHLzuBk8cc2NO6c+47/PTplXzrkx/h3z99VFv5s8s/5Gv31/KJowZz36VT2srXb29g6i3PMqxfFS9/91Ptpp1uVfXm9Wd0WL7sxtwL7wDv/OjsDstX39Rx+bs3ty//8qxXqH1vGw9edgJTRh7Yu7z5yeX8z4vv8h+fHsfl08YAqYQ1e8lGrnp4MZ86egh3X/jRtuE3bG/gkz95nkG9K3jhO59sl7TGXzcHaN+STFWZeP3fAFj8/U+322s+Lqs8ncgm3ZAqX3Td6W17oopS/YOnAXjjv05vm6oAU3/8LHv3t/D4t05p6wcL4HuPLuGppR/w76eP44ITjnB2EeChBeu4bc4Kzjx2KD/6woS2JLq6fjfn3/Mqh/Qs529Xnto23aYWZeotqZ2Tv1/7KQRpq/eUH81NlX+v/XKectPctuEPzIyMcpfhX81aX864Yz47Gpr444yTGH5Ij7b58c//u5DF67ZzyxcncupRg9t2EH71/Bruf3ktn5s0jO9mbOhef38bVzz4BkP7VvHoNw/skO1qbOaMO+YDqc4kM53s1PmljHJV5ZQfz2srV9W2I7n0PHrxmk8g4uygKHz81nlt5QfGA9Num4cq/PWKU+jfs7ztsysefJ3FdTu48fMTOG3cga5wbpuzgscWb+CSk0fy9VMOdAT48urNXPOnJYwe3IvfZPwON+/exxd+8TIAL3znwLSBnKMfv1giMKGSfd0k/baspISyjHs9Sp1D6fLSkrbTYZBqAABQWV5CVXlpW3n6dXlpCT0qDpRnykzmmfr1KPdU3j/jNEymQ3q1Lz+kZwV79zfQv2c5AzI+Sw83oHcFg3ofSPjp6Q3oXcHAjPJte1O9tg/qXdluB2F/c+qorERgSJ+O+6cf0tel3OPwQ/u1L+9TVcaOhiaG9q3isH4Hkly6DkP7tS9Pf39Yv6p2SXHjjtRp0sP6ty/f1Zg6Qq0oK2lXnulwj+XDD+lZUHnfqnJ2NDQxrH9Vu+WQXu7DD+nR7nRiehlmlw+pT9V5xCE925Wn18+BvSpyTksGJbHNR40xxqRYIjDGmISzRGCMMQlnicAYYxIu8YnAmi4aY5Iu8YkgLbu1ShgThNd7PsJYB6/c6uA2LzTnIXjp8iiJ/nL2L6bwVc593fM6oi6H4htLBHmEsRcIrzGFsAq+cZsXEoNae61DGNdVv0Spal5jDcNys0RgIsGvH0sIfnMmJuLUV5glggQK46kEk1+cF5utkwcUY15YIkiwOO3RJEmsl5qd9mzTnT9PSwTGGJNwlgiMMSbhLBEYY0zCWSKIEK/XkNza1EeJWw28XlCL0nM3PNctBsvZTYQWW6TWsWyWCDqpmO3Us6ecd/2L8UXh7OUQ4d9iDu/3i4RvOfvW7DdE63D+n1thsYYpgVsiiJEwbgj84rlmbjeahWiDYgyEo+VT4hOB+6mH8GRrY0z4hGED7pfEJ4I0t4Ua571sY4wBSwTGREeMj1LDdL682IoxLywRGBMxcb7MYR3tZeq+ylkiSKAY71gaYzrBEkGEeG87f/DPo7Az5Vff71FKfn4v52Lwq7FFCKsWS5YIHFFa4bw2gYzCBr+z4nxqIIr92mfzq7luCKvmKkqxpiU+EURxoSVRoduTKCV0E1E+rWRhOpJLfCIw8WQJ3gQtTndNWyKIEb+anYVoR6XT4lCHOLPlc0AYbl61RGDaFH+/pOviUAdjupslAhfFz9GFC8GRpTEFsVX1gDD9bhOfCPJu8EO0sIwxJgiBJgIROVNEVojIKhGZ6TLMaSKySESWisjzQcZzMK7b+xAdGng9lxii0DvNr+cRxEGcq5zE5emqCPOiLKgRi0gpcDdwOlAHLBCRx1T17Yxh+gO/AM5U1fdFZEhQ8XgV5gOBOLQvN+7yXfSPwjMYOhtS9rqa/6bI8Kzcfi+HuDy8fgqwSlXXqOp+4A/AuVnDfBV4VFXfB1DVTQHG44swblTzrYCFrqAh3J54Foc65BPlDtryRR6Fp7P59aRAv363fggyERwOrMt4X+eUZRoHHCIiz4nIQhG5qKMRicjlIlIrIrX19fUBhRt++dobZ+8ddTZnhTDXeRblOoRpLzco2TV0W7Xdy+Mzj3LqUoSqBZkIOqpOdo4rAz4GfAY4A/gvERmX8yXVe1S1RlVrBg8e7H+kJrRcnxMRn+1AwbzOi2LOozgvHmn7n7Xj5bYcIjA3ArtGQOoIYETG++HAhg6G2ayqe4A9IjIfmASsDDAuY4wxGYI8IlgAjBWRUSJSAZwPPJY1zF+Aj4tImYj0BE4AlgUYkzHGmCyBHRGoarOIXAHMAUqBe1V1qYjMcD6fparLROQp4E2gFfi1qr4VVEzGGGNyBXlqCFWdDczOKpuV9f424LYg44iLJN5HYIwJXuLvLHYT5o2o14uAUb6wmsQbyrw2iQzjvPArpDDWzU2UYs2W+ESQd+FFeCMaLz494CRCyzNKsbrxqwpRmhdRijUt8YmgTQQXnskVhi59gxLfmkVrbzrwo50izAtLBCaW4nTDUbYotEvvLM+nPYs5L/x6MI1beUy6mDAhFaGdL2NMN7BEkGAx3mk2xnhgicAYYxLOEoExxiScJYII8XxuP0pNMVy4VSEObe3dRKEr5nz8mt9RagUWxuVQKEsEHoVhvfTaUiIOrUz86o44StdFPC/nEFbOr5CitA5HKdY0SwSdFKbfXAhykzGJ4ddRSph+t5YIXIRhz9+rMCWnYrNZYaIiDL9bSwR5hGAZGQNEc+ckzoLagBdjMVsiMCZiwrAHGRSvVbN54Q9LBMYYk3CWCIwxJuEsEURJnpOH2eeQ3fvyP/iIwnQqurPPI8j+OEptvL1GGsZrB/nmd6Ehh7Bqrjq7HMKw/CwRRJEc9G3u4K4DyEHehYtrD42exxPmWmbx3BNn+Pg2v8NYORdRvG5hicAY020iuI0MTJjmhSUCY4zxwLcH0/g0Hj9YIjCxFKa9LRNPcXoMpyUCY4xJOEsELqLUysQYY7rCEkEeYThsMwai1SWzV3Gum1fFmBUFJQIR6SUiJc7rcSJyjoiUBxuayRaH9uWe+dXTY4TmRb5Yo7Bv0tn5nb3jFaV54fc6FsaH188HqkTkcGAucClwf1BBdacongLyuoKE6cfitzgfscWh3x3/nkcQHVGKNa3QRCCquhf4IvDfqvoFYHxwYXU/txtforQnGWd+PXQljBtLY4qt4EQgIicBFwJPOGVlwYQUDlG6AzVfrorD7fxu55BzutXw2A1HmLl2r+FWHsK6Fdrtidvw+b5XjCr71b1J3q5eurFyhSaCbwPfBf5PVZeKyGhgXmBRmQ557Uqis3u/0UmB7vyaF8UQpVg7K7uKbkd8ro8o9TecIsvq6qUIlStor15VnweeB3AuGm9W1X8NMjBjgGRsFQvk+fnMAcVR0LRjvNjSdcteHu5JK/wzo9BWQw+KSF8R6QW8DawQkauDDc0YY0x3KPTU0HhV3Ql8HpgNHAFMDyooY4wx3afQRFDu3DfweeAvqtpEuK8txpLdR1D00XSLKMXqxq86RGleRCnWbIUmgl8Ba4FewHwRORLYGVRQYRDm+wu898EfX7E+F+11+BDOC7uPIBoKvVh8J3BnRtF7IvKJYEIKlzD+uJLI7iOIdzcMXusW3zkR7i4m+onIT0Wk1vn7CamjA2NMN4twLsvL7po/IIxdTNwL7AL+0fnbCdwXVFDGdFaYT+mZePDt+oc/o/FFoYlgjKp+X1XXOH83AKPzfUlEzhSRFSKySkRmHmS4ySLSIiLnFRq4X2J8tJ1ocd5TNOGQxAfTNIjIKek3IjIVaDjYF0SkFLgbOItUv0QXiEhO/0TOcD8G5hQadBDCsDCMMaYYCu0vaAbwgIj0c95vAy7O850pwCpVXQMgIn8AziV1Q1qmbwF/AiYXGIvpIjsIMsZkKuiIQFUXq+ok4DjgOFU9Hvhknq8dDqzLeF/nlLVxurX+AjDrYCMSkcvTF6rr6+sLCTmWvLesOPjwdhRkjAGPTyhT1Z3OHcYAV+UZvKPNTPaW6Q7gGlVtyTPde1S1RlVrBg8eXFiwMea5z5kIb/Dde9qMb3NDrxe8w3idy6+QonTxP0qxZutKV9L5Ni91wIiM98OBDVnD1AB/cDZsg4CzRaRZVf/chbhMDLmtbHG+uS4OCT9OF1QLFqVYHV1JBPnS3wJgrIiMAtYD5wNfbTcC1VHp1yJyP/B4sZJAGPeqjDGmOxw0EYjILjre4AvQ42DfVdVmEbmCVGugUuBe51kGM5zPD3pdoLu47ml4fEBGUYUyKGNMVBw0Eahqn66MXFVnk+qtNLOswwSgqpd0ZVpBcetLPIJHfwWzvBJOcVouOU/x8li5Yna3EfS1gGJca/B0sdiEVAI79koyv/pdKoa8T9nzuBYWc14EPenufKCNJQJjjEm4xCcCu0hsjEm6xCeCtCgcbSfxwTRudfA+LyI0M7yeLw/h1QPfZnf4quYqSqtYNksEEeT9gSXtvxHFFdb1weCe29pHIOM7vN8jEcK6+Xb9KoR1cxGlWNMsESRY9FZXY0wQLBEYY0zCWSIwsRLF014mWnx7ME2I1lVLBC5CtIxMJ0TpWoBJtjCsqZYI8rDtiQmLMO1B+s1zK7BAovAmqIvCoX14vTHGdAd7eP0BYXx4vQkBz/2xBBNGt3JrIx/neRGP+0X8CSqUVXMRpVizWSKIoCSernLt/C/Ge5Ce6xbCyvl1+iSMdXMTpVjTLBEYY0zCWSIwxpiEs0TgcH0+TZRP/BljTAEsEbgI82m+nOTk1w0u/owmEIVeNM6XuMNcx2zeH9YSTBxdkb3c8oXo2slghJ4YWPhyOPiA3bk8LRFESL6LUNkfdzaZhSkJdvYisV/zohjcYnXveM+tvJi1Pvi0C10+Xsu7U/bs7fTvLXs8RaicJQJjjEk4SwQuon3I6QwfTBjdyu4jKGD4UFbO7iOIEksEeYSxTXAYYwqa3UeQf4MfxvWi0PsI8m1Ec+ZF58LpFl1dDtbFhDEm0eKc2L2yLiaMMcZ0G0sExhiTcJYITKyE+dyxiQe/1rEwXeS3RGDiKc4nj02shOFh95YIjDEm4SwRRIhbm/oDn2e9dx3c23iKyb1rAW99SYTpMDwf9RhsGKvmV1cfUVpunV0QedflbmCJIIJyDiXzdbdQYNcExT9Adedahzzv834hxOLQlDKobhjCrNBQw1QnSwTGGJNwlghcROqQ1BhjusASQR5hOnwzyRbnfZM4dLntl2JUzRKBMRET550Tz1WzeeELSwQeeW3R0S1CGFKx2KwwgfPrQVAhWlktEXRScR/60bHwRVRENjNMwPzaBNgNZcYT733wh2iXo5O8PrrwIGPqaijdxvvzCMJXN9+6YYjUcotOrNkCTQQicqaIrBCRVSIys4PPLxSRN52/l0VkUpDxxIX39uXF3+MITAiPzPziebmFcF74FVGU1uEwni3IJ7BEICKlwN3AWcB44AIRGZ812LvAqap6HHAjcE9Q8RgDdsbImI4EeUQwBVilqmtUdT/wB+DczAFU9WVV3ea8fRUYHmA8HQrjYbUxxnSnIBPB4cC6jPd1TpmbrwNPdvSBiFwuIrUiUltfX+9jiJnTCGS0oWS5zxiTKchE0NGmtcNNkIh8glQiuKajz1X1HlWtUdWawYMH+xhiskXpvKsxJjhlAY67DhiR8X44sCF7IBE5Dvg1cJaqbgkwHk+i3ALAGGO8CPKIYAEwVkRGiUgFcD7wWOYAInIE8CgwXVVXBhhLp9lec7TE+ZpPrOvmdceriLPCr51Et7EUYzkHdkSgqs0icgUwBygF7lXVpSIyw/l8FnAdMBD4hdPkqllVa4KKKepi3HTed3FO4HGum9eLdcWcE34tB/du4ruvdkGeGkJVZwOzs8pmZbz+BvCNIGMw0ea61+R1PBFKit5vHAwfv/Zq47zcwsTuLE6AOLSIKvTBNPnHE52ZEY8H0wS71xxGUYo1zRKBMcYknCUCY4xJOEsExhiTcIlPBFG+wGOMMX5IfCJIc2sKFoUby/LFWGiyC3NNXbujzvM+dzxhrmV77nXu+IMw1ix7fueN0aXShS7/MCj495ZnuO5cVy0RuAhjW+18EeW00OhkFcJUc7dY8s+Lg78PM6/tysNYtXythbI/dfu9uY4mBJX2ax3LHU/3V84SgYswHgkk8YYyu48gszy6RwJ5h3c7yvFrBegGfq1jxThqtUSQRxiPDLyK0t6wG7uPIKPcbe85wFg6y/P8djvq8Wn5dwffHmHZjeuqJQJjjEk4SwSOMJ4KMsaY7pD4RBChMwV5+da/iy9jKa4oXRNIojgsHv+uCfgznq5IfCKIA996QfRlLMUVhzrEmS2fA8K0E2qJwBhjEs4SgYmVEBxlm5iL0ymhNEsEURKDfuq9cm07n6dy2YfdUZoXcbhHwq+QQli1Nn6tY2E4RZT4RBDGH1E+cein3ivPd566jie+wrBByRbCkAIXxTonPhGkxeHGsUJFMPcZYwJkicBFFI8UvArjHqRJJu+P54zvD7QY2x5LBHnYxtKETZzXyTh3GRJmlgiMMSbhLBEYY0zCWSLwKIxnJuN8vtQzmxUmYP41jQ3PymqJoJOKcWYy34qTfb40Sk/j8i7PvMgeOkKzwvtyC1/lotw3f6Fy17HOxRqGFouWCCLI64oTh+tpXvvm9zqeMPJ6ITSMVYti3/xdFaFQ21giMMaYhLNEYIwxCWeJwBhjEi7xiSC8l6KCE+Lrb8aYIkh8IkiLcm+VnRXFi1pJFucEHoceV6PMEoExERPn/O25N9kYz4zurJslggjx3DFXDPaa3OrgWu6ybxmmm3fyicPecZyfn+36jAzP4+l6LH6xRBBB3vvgj/5uk+t9BF7LIzQv4tABW5yfp+0+v6P3kAxLBMYYk3CWCIwxJuEsERhjTMJZIjDGmIQLNBGIyJkiskJEVonIzA4+FxG50/n8TRH5aJDxGGOMyRVYIhCRUuBu4CxgPHCBiIzPGuwsYKzzdznwy6DiMcYY07EgjwimAKtUdY2q7gf+AJybNcy5wAOa8irQX0QOCzCmHOWlqVlQVtJ+VpQ6TcMqy9qXp1t6VZaXBh5bth4VqWlmtz+uLEuVl2Q1Q6twYi/N+iD9vqK0fd1KnDpXFaFubi3xqpw6ZzdDdKtbejmWu9Stsjw8Z0OrnFiymyFWutWtVJz/WXUr6XhdTetRhOXZs6Ksw/K2umXVucKpW/ZyK0uvq9m/Q+frVWXFq1v2/QRVLr/D8jJnueWsq85yK3WpW3cuN1UN5A84D/h1xvvpwF1ZwzwOnJLxfi5Q08G4LgdqgdojjjhC/dSwv1lveuJt3buvuV15S0ur3vrUMq3f1ZjznV/MW6WrN+3KKf/tK2t10fvbcsr/smi9zl+5Kad83vIP9fHFG3LKa9du1d+/9l5O+Tsf7tRfPb8qp/zDHQ16+5zl2tLS2q58d2OT3vTE29rY1L5uzS2tesuTy3Tr7n3tyltbW/W/567U9zbvyZnG/S+9q0vqtueUP/r6On1pVX1O+TNvf6BPLtmYU/7ami360IL3c8qXbdyhv35hTU75+m179WdPr9DW1vZ129GwX2+a/bbub25pV76/uUVvmv227mjYn1O3nz29Quu27c2Zxq9fWKNvb9iRU/7wgvf1tTVbcsqfemujPr30g5zyl1bV658WrsspX1K3Xe9/6d2c8ve37NE7n1mZU7dte/bpzbOXaVNW3RqbUuvq7samnLr9ZM5y/WBHQ8407nl+ta78YGdO+e9fe09r127NKX/izQ367PIPc8pfWFmvf36jLqd80fvb9LevrM0pX1O/W++e905O+eZdjXrrU8ty1tW9+1J1a9hf+O/w7nnv6Jr63TnlXn+Hzy7/UJ94s+u/ww92NOhP5izPWZ5uv8Om5ha9efYy3bYn93d45zMr9f0tub/DrgBq1WV7LRrQ7W0i8mXgDFX9hvN+OjBFVb+VMcwTwM2q+qLzfi7wHVVd6Dbempoara2tDSRmY4yJKxFZqKo1HX0W5HFyHTAi4/1wYEMnhjHGGBOgIBPBAmCsiIwSkQrgfOCxrGEeAy5yWg+dCOxQ1Y0BxmSMMSZLx1d0fKCqzSJyBTAHKAXuVdWlIjLD+XwWMBs4G1gF7AUuDSoeY4wxHQssEQCo6mxSG/vMslkZrxX4lyBjMMYYc3DhaUtnjDGmKCwRGGNMwlkiMMaYhLNEYIwxCRfYDWVBEZF64L1Ofn0QsNnHcIJgMXZd2OOD8McY9vjAYvTqSFUd3NEHkUsEXSEitW531oWFxdh1YY8Pwh9j2OMDi9FPdmrIGGMSzhKBMcYkXNISwT3FDqAAFmPXhT0+CH+MYY8PLEbfJOoagTHGmFxJOyIwxhiTxRKBMcYkXGISgYicKSIrRGSViMzsxumOEJF5IrJMRJaKyL855QNE5GkRecf5f0jGd77rxLlCRM7IKP+YiCxxPrtTsp9x2LU4S0XkDRF5PKTx9ReRR0RkuTMvTwphjFc6y/gtEfm9iFQVO0YRuVdENonIWxllvsUkIpUi8pBT/pqIjPQhvtuc5fymiPyfiPQvVnxuMWZ89h8ioiIyqJgxdpnbo8vi9EeqG+zVwGigAlgMjO+maR8GfNR53QdYCYwHbgVmOuUzgR87r8c78VUCo5y4S53P/g6cROrRyU8CZ/kY51XAg8Djzvuwxfcb4BvO6wqgf5hiBA4H3gV6OO8fBi4pdozANOCjwFsZZb7FBHwTmOW8Ph94yIf4Pg2UOa9/XMz43GJ0ykeQ6mb/PWBQMWPs8vrb3RMsxp8z8+dkvP8u8N0ixfIX4HRgBXCYU3YYsKKj2JwV7SRnmOUZ5RcAv/IppuGknhf9SQ4kgjDF15fURlayysMU4+HAOmAAqe7dH3c2aEWPERhJ+w2tbzGlh3Fel5G6i1a6El/WZ18AflfM+NxiBB4BJgFrOZAIihZjV/6Scmoo/SNNq3PKupVzyHc88BpwqDpPY3P+D3EGc4v1cOd1drkf7gC+A7RmlIUpvtFAPXCfc/rq1yLSK0wxqup64HbgfWAjqaft/S1MMWbwM6a276hqM7ADGOhjrF8jtfccqvhE5BxgvaouzvooNDF6kZRE0NE51m5tNysivYE/Ad9W1Z0HG7SDMj1IeVfj+iywSVUXFvoVlziCnMdlpA7Nf6mqxwN7SJ3ScNPtMTrn2c8ldTpgGNBLRP7pYF9xiaWY62pnYgpynl4LNAO/yzOtbo1PRHoC1wLXdfSxy/SKMg8LlZREUEfqfF7acGBDd01cRMpJJYHfqeqjTvGHInKY8/lhwKY8sdY5r7PLu2oqcI6IrAX+AHxSRP43RPGlp1mnqq857x8hlRjCFOM/AO+qar2qNgGPAieHLMY0P2Nq+46IlAH9gK1dDVBELgY+C1yozjmTEMU3hlTCX+z8boYDr4vI0BDF6ElSEsECYKyIjBKRClIXZB7rjgk7LQP+B1imqj/N+Ogx4GLn9cWkrh2ky893WhKMAsYCf3cO4XeJyInOOC/K+E6nqep3VXW4qo4kNV+eVdV/Ckt8TowfAOtE5Cin6FPA22GKkdQpoRNFpKcz7k8By0IWY5qfMWWO6zxS609X97jPBK4BzlHVvVlxFz0+VV2iqkNUdaTzu6kj1SDkg7DE6Fl3XpAo5h9wNqkWO6uBa7txuqeQOsx7E1jk/J1N6hzgXOAd5/+AjO9c68S5gowWI0AN8Jbz2V34fEEJOI0DF4tDFR9QDdQ68/HPwCEhjPEGYLkz/t+SajlS1BiB35O6ZtFEaoP1dT9jAqqAPwKrSLWKGe1DfKtInTNP/15mFSs+txizPl+Lc7G4WDF29c+6mDDGmIRLyqkhY4wxLiwRGGNMwlkiMMaYhLNEYIwxCWeJwBhjEs4SgTEOEWkRkUUislhEXheRk/MM319EvlnAeJ8TkdA/wNwklyUCYw5oUNVqVZ1EqvOwm/MM359Uz5HGRJolAmM61hfYBql+okRkrnOUsEREznWGuQUY4xxF3OYM+x1nmMUickvG+L4sIn8XkZUi8vHurYoxB1dW7ACMCZEeIrKI1J2eh5HqlhugEfiCqu50HkDyqog8RqrjuwmqWg0gImcBnwdOUNW9IjIgY9xlqjpFRM4Gvk+qbyJjQsESgTEHNGRs1E8CHhCRCaR6h7xJRKaR6qr7cODQDr7/D8B96vSPo6qZHYelOxtcSKpve2NCwxKBMR1Q1Vecvf/BpPqGGgx8TFWbnB4nqzr4muDeffA+538L9rszIWPXCIzpgIgcTeoRp1tIdQu8yUkCnwCOdAbbRerxo2l/A77m9FdP1qkhY0LL9kyMOSB9jQBSe/cXq2qLiPwO+KuI1JLqDXM5gKpuEZGXJPVQ8ydV9WoRqQZqRWQ/MBv4XndXwhivrPdRY4xJODs1ZIwxCWeJwBhjEs4SgTHGJJwlAmOMSThLBMYYk3CWCIwxJuEsERhjTML9fwfDulDE7amiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(g_lossLine, label = \"Generator Loss\" )\n",
    "plt.plot(d_lossLine, label = \"Discriminator Loss\" )\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Batch  ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
